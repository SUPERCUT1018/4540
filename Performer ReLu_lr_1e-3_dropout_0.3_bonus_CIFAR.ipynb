{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54efcba5-7e63-4c81-bb62-175975f3e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5  # Scaling factor for stability\n",
    "\n",
    "        # Linear projections for Q, K, V\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        # Learnable kernel function fθ\n",
    "        self.learnable_kernel = nn.Sequential(\n",
    "            nn.Linear(dim_head, dim_head),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim_head, dim_head)\n",
    "        )\n",
    "\n",
    "        # Output projection\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute Q, K, V\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
    "\n",
    "        # Apply learnable kernel function fθ\n",
    "        q = self.learnable_kernel(q)\n",
    "        k = self.learnable_kernel(k)\n",
    "\n",
    "        # Compute attention using kernelized linear attention\n",
    "        # Step 1: Compute Key-Value projection\n",
    "        kv = torch.einsum('bhnd,bhmd->bhnm', k, v)\n",
    "\n",
    "        # Step 2: Compute Query and projected KV\n",
    "        out = torch.einsum('bhnd,bhnm->bhmd', q, kv)\n",
    "\n",
    "        # Reshape and project back\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),  # 调用改造后的 Attention\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x  # Add residual connection\n",
    "            x = ff(x) + x    # Add residual connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViTPR(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=3, dim_head=64, dropout=0., emb_dropout=0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        # Patch embedding\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        # Positional embedding\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        # Transformer with Performer-ReLU Attention\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        # Classification head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)  # Convert image to patches\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        # Add CLS token\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through Transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Pooling\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf59f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing CIFAR10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building Vision Transformer model...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "# 超参数\n",
    "lr = 1e-3 # original 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "patch_size = 4\n",
    "image_size = 32\n",
    "num_classes = 10\n",
    "dim = 128\n",
    "depth = 6\n",
    "heads = 8\n",
    "mlp_dim = 512\n",
    "dropout = 0.3 #original 0.1\n",
    "emb_dropout = 0.3 # original 0.1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 数据集\n",
    "print(\"==> Preparing CIFAR10 dataset...\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化 ViTPR 模型\n",
    "print(\"==> Building Vision Transformer model...\")\n",
    "net = ViTPR(\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_classes=num_classes,\n",
    "    dim=dim,\n",
    "    depth=depth,\n",
    "    heads=heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    dropout=dropout,\n",
    "    emb_dropout=emb_dropout\n",
    ").to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "# 定义训练函数\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(f\"Train Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] \"\n",
    "              f\"Loss: {loss.item():.4f} | Acc: {100.*correct/total:.2f}%\")\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f}s.\")\n",
    "    return epoch_time, 100. * correct / total\n",
    "\n",
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Test Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Loss: {test_loss/len(test_loader):.4f} | Acc: {acc:.2f}% | Inference Time: {inference_time:.2f}s\")\n",
    "    return acc, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac2ee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ./Performer ReLu_lr_1e-3_dropout_0.3_checkpoint.pth...\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZBLibra\\AppData\\Local\\Temp\\ipykernel_26460\\2737574286.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [57/100] Batch [1/782] Loss: 0.4358 | Acc: 85.94%\n",
      "Train Epoch [57/100] Batch [2/782] Loss: 0.5404 | Acc: 84.38%\n",
      "Train Epoch [57/100] Batch [3/782] Loss: 0.9410 | Acc: 79.17%\n",
      "Train Epoch [57/100] Batch [4/782] Loss: 0.5803 | Acc: 80.08%\n",
      "Train Epoch [57/100] Batch [5/782] Loss: 0.6770 | Acc: 79.06%\n",
      "Train Epoch [57/100] Batch [6/782] Loss: 0.4439 | Acc: 79.69%\n",
      "Train Epoch [57/100] Batch [7/782] Loss: 0.5528 | Acc: 79.69%\n",
      "Train Epoch [57/100] Batch [8/782] Loss: 0.6030 | Acc: 79.69%\n",
      "Train Epoch [57/100] Batch [9/782] Loss: 0.5958 | Acc: 79.17%\n",
      "Train Epoch [57/100] Batch [10/782] Loss: 0.5467 | Acc: 79.53%\n",
      "Train Epoch [57/100] Batch [11/782] Loss: 0.4173 | Acc: 80.54%\n",
      "Train Epoch [57/100] Batch [12/782] Loss: 0.5798 | Acc: 80.73%\n",
      "Train Epoch [57/100] Batch [13/782] Loss: 0.6478 | Acc: 80.89%\n",
      "Train Epoch [57/100] Batch [14/782] Loss: 0.7786 | Acc: 80.25%\n",
      "Train Epoch [57/100] Batch [15/782] Loss: 0.6517 | Acc: 80.10%\n",
      "Train Epoch [57/100] Batch [16/782] Loss: 0.4993 | Acc: 80.47%\n",
      "Train Epoch [57/100] Batch [17/782] Loss: 0.5581 | Acc: 80.33%\n",
      "Train Epoch [57/100] Batch [18/782] Loss: 0.7439 | Acc: 80.03%\n",
      "Train Epoch [57/100] Batch [19/782] Loss: 0.5026 | Acc: 80.02%\n",
      "Train Epoch [57/100] Batch [20/782] Loss: 0.5772 | Acc: 80.16%\n",
      "Train Epoch [57/100] Batch [21/782] Loss: 0.5180 | Acc: 80.43%\n",
      "Train Epoch [57/100] Batch [22/782] Loss: 0.8862 | Acc: 79.83%\n",
      "Train Epoch [57/100] Batch [23/782] Loss: 0.7836 | Acc: 79.28%\n",
      "Train Epoch [57/100] Batch [24/782] Loss: 0.6063 | Acc: 79.04%\n",
      "Train Epoch [57/100] Batch [25/782] Loss: 0.5553 | Acc: 79.00%\n",
      "Train Epoch [57/100] Batch [26/782] Loss: 0.6915 | Acc: 78.97%\n",
      "Train Epoch [57/100] Batch [27/782] Loss: 0.5293 | Acc: 79.11%\n",
      "Train Epoch [57/100] Batch [28/782] Loss: 0.6285 | Acc: 79.13%\n",
      "Train Epoch [57/100] Batch [29/782] Loss: 0.6490 | Acc: 79.04%\n",
      "Train Epoch [57/100] Batch [30/782] Loss: 0.7344 | Acc: 78.75%\n",
      "Train Epoch [57/100] Batch [31/782] Loss: 0.5654 | Acc: 78.83%\n",
      "Train Epoch [57/100] Batch [32/782] Loss: 0.4266 | Acc: 79.00%\n",
      "Train Epoch [57/100] Batch [33/782] Loss: 0.6659 | Acc: 78.93%\n",
      "Train Epoch [57/100] Batch [34/782] Loss: 0.5256 | Acc: 78.95%\n",
      "Train Epoch [57/100] Batch [35/782] Loss: 1.0090 | Acc: 78.30%\n",
      "Train Epoch [57/100] Batch [36/782] Loss: 0.7093 | Acc: 77.99%\n",
      "Train Epoch [57/100] Batch [37/782] Loss: 0.5995 | Acc: 77.91%\n",
      "Train Epoch [57/100] Batch [38/782] Loss: 0.6439 | Acc: 77.88%\n",
      "Train Epoch [57/100] Batch [39/782] Loss: 0.6093 | Acc: 77.88%\n",
      "Train Epoch [57/100] Batch [40/782] Loss: 0.8195 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [41/782] Loss: 0.6547 | Acc: 77.48%\n",
      "Train Epoch [57/100] Batch [42/782] Loss: 0.6094 | Acc: 77.46%\n",
      "Train Epoch [57/100] Batch [43/782] Loss: 0.6640 | Acc: 77.43%\n",
      "Train Epoch [57/100] Batch [44/782] Loss: 0.6125 | Acc: 77.45%\n",
      "Train Epoch [57/100] Batch [45/782] Loss: 0.5046 | Acc: 77.40%\n",
      "Train Epoch [57/100] Batch [46/782] Loss: 0.5237 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [47/782] Loss: 0.4359 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [48/782] Loss: 0.4420 | Acc: 77.90%\n",
      "Train Epoch [57/100] Batch [49/782] Loss: 0.7414 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [50/782] Loss: 0.3651 | Acc: 78.06%\n",
      "Train Epoch [57/100] Batch [51/782] Loss: 0.6275 | Acc: 78.03%\n",
      "Train Epoch [57/100] Batch [52/782] Loss: 0.7494 | Acc: 77.88%\n",
      "Train Epoch [57/100] Batch [53/782] Loss: 0.7520 | Acc: 77.89%\n",
      "Train Epoch [57/100] Batch [54/782] Loss: 0.7279 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [55/782] Loss: 0.4989 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [56/782] Loss: 0.4914 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [57/782] Loss: 0.5325 | Acc: 77.91%\n",
      "Train Epoch [57/100] Batch [58/782] Loss: 0.6687 | Acc: 77.88%\n",
      "Train Epoch [57/100] Batch [59/782] Loss: 0.5809 | Acc: 77.91%\n",
      "Train Epoch [57/100] Batch [60/782] Loss: 0.8310 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [61/782] Loss: 0.5483 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [62/782] Loss: 0.5236 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [63/782] Loss: 0.8161 | Acc: 77.63%\n",
      "Train Epoch [57/100] Batch [64/782] Loss: 0.4310 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [65/782] Loss: 0.5434 | Acc: 77.86%\n",
      "Train Epoch [57/100] Batch [66/782] Loss: 0.6890 | Acc: 77.89%\n",
      "Train Epoch [57/100] Batch [67/782] Loss: 0.7785 | Acc: 77.80%\n",
      "Train Epoch [57/100] Batch [68/782] Loss: 0.5960 | Acc: 77.83%\n",
      "Train Epoch [57/100] Batch [69/782] Loss: 0.5921 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [70/782] Loss: 0.6966 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [71/782] Loss: 0.5911 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [72/782] Loss: 0.7223 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [73/782] Loss: 0.7799 | Acc: 77.57%\n",
      "Train Epoch [57/100] Batch [74/782] Loss: 0.5399 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [75/782] Loss: 0.6653 | Acc: 77.54%\n",
      "Train Epoch [57/100] Batch [76/782] Loss: 0.7948 | Acc: 77.47%\n",
      "Train Epoch [57/100] Batch [77/782] Loss: 0.6170 | Acc: 77.44%\n",
      "Train Epoch [57/100] Batch [78/782] Loss: 0.6081 | Acc: 77.48%\n",
      "Train Epoch [57/100] Batch [79/782] Loss: 0.5801 | Acc: 77.45%\n",
      "Train Epoch [57/100] Batch [80/782] Loss: 0.6400 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [81/782] Loss: 0.4262 | Acc: 77.70%\n",
      "Train Epoch [57/100] Batch [82/782] Loss: 0.5776 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [83/782] Loss: 0.8249 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [84/782] Loss: 0.5788 | Acc: 77.59%\n",
      "Train Epoch [57/100] Batch [85/782] Loss: 0.7688 | Acc: 77.52%\n",
      "Train Epoch [57/100] Batch [86/782] Loss: 0.4988 | Acc: 77.54%\n",
      "Train Epoch [57/100] Batch [87/782] Loss: 0.6199 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [88/782] Loss: 0.6783 | Acc: 77.47%\n",
      "Train Epoch [57/100] Batch [89/782] Loss: 0.5265 | Acc: 77.48%\n",
      "Train Epoch [57/100] Batch [90/782] Loss: 0.5940 | Acc: 77.50%\n",
      "Train Epoch [57/100] Batch [91/782] Loss: 0.6406 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [92/782] Loss: 0.6821 | Acc: 77.45%\n",
      "Train Epoch [57/100] Batch [93/782] Loss: 0.6608 | Acc: 77.44%\n",
      "Train Epoch [57/100] Batch [94/782] Loss: 0.4134 | Acc: 77.48%\n",
      "Train Epoch [57/100] Batch [95/782] Loss: 0.6752 | Acc: 77.50%\n",
      "Train Epoch [57/100] Batch [96/782] Loss: 0.6709 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [97/782] Loss: 0.6230 | Acc: 77.56%\n",
      "Train Epoch [57/100] Batch [98/782] Loss: 0.6442 | Acc: 77.54%\n",
      "Train Epoch [57/100] Batch [99/782] Loss: 0.6336 | Acc: 77.53%\n",
      "Train Epoch [57/100] Batch [100/782] Loss: 0.9648 | Acc: 77.45%\n",
      "Train Epoch [57/100] Batch [101/782] Loss: 0.4382 | Acc: 77.57%\n",
      "Train Epoch [57/100] Batch [102/782] Loss: 0.6301 | Acc: 77.59%\n",
      "Train Epoch [57/100] Batch [103/782] Loss: 0.6307 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [104/782] Loss: 0.6131 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [105/782] Loss: 0.6604 | Acc: 77.56%\n",
      "Train Epoch [57/100] Batch [106/782] Loss: 0.4358 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [107/782] Loss: 0.4452 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [108/782] Loss: 0.7685 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [109/782] Loss: 0.5423 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [110/782] Loss: 0.7740 | Acc: 77.60%\n",
      "Train Epoch [57/100] Batch [111/782] Loss: 0.4949 | Acc: 77.62%\n",
      "Train Epoch [57/100] Batch [112/782] Loss: 0.6981 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [113/782] Loss: 0.5495 | Acc: 77.64%\n",
      "Train Epoch [57/100] Batch [114/782] Loss: 0.6341 | Acc: 77.63%\n",
      "Train Epoch [57/100] Batch [115/782] Loss: 0.4262 | Acc: 77.70%\n",
      "Train Epoch [57/100] Batch [116/782] Loss: 0.5791 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [117/782] Loss: 0.6552 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [118/782] Loss: 0.4469 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [119/782] Loss: 0.6526 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [120/782] Loss: 0.4898 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [121/782] Loss: 0.6108 | Acc: 77.70%\n",
      "Train Epoch [57/100] Batch [122/782] Loss: 0.5283 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [123/782] Loss: 0.6002 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [124/782] Loss: 0.5953 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [125/782] Loss: 0.6026 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [126/782] Loss: 0.6816 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [127/782] Loss: 0.4856 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [128/782] Loss: 0.6905 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [129/782] Loss: 0.7150 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [130/782] Loss: 0.6117 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [131/782] Loss: 0.5065 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [132/782] Loss: 0.5793 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [133/782] Loss: 0.6511 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [134/782] Loss: 0.5896 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [135/782] Loss: 0.5873 | Acc: 77.85%\n",
      "Train Epoch [57/100] Batch [136/782] Loss: 0.7604 | Acc: 77.83%\n",
      "Train Epoch [57/100] Batch [137/782] Loss: 0.4639 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [138/782] Loss: 0.5754 | Acc: 77.85%\n",
      "Train Epoch [57/100] Batch [139/782] Loss: 0.6730 | Acc: 77.86%\n",
      "Train Epoch [57/100] Batch [140/782] Loss: 0.8574 | Acc: 77.80%\n",
      "Train Epoch [57/100] Batch [141/782] Loss: 0.6971 | Acc: 77.75%\n",
      "Train Epoch [57/100] Batch [142/782] Loss: 0.6933 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [143/782] Loss: 0.4825 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [144/782] Loss: 0.7721 | Acc: 77.80%\n",
      "Train Epoch [57/100] Batch [145/782] Loss: 0.5638 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [146/782] Loss: 0.6782 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [147/782] Loss: 0.5510 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [148/782] Loss: 0.5798 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [149/782] Loss: 0.7990 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [150/782] Loss: 0.8364 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [151/782] Loss: 0.6067 | Acc: 77.71%\n",
      "Train Epoch [57/100] Batch [152/782] Loss: 0.6104 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [153/782] Loss: 0.6296 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [154/782] Loss: 0.6016 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [155/782] Loss: 0.7307 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [156/782] Loss: 0.4595 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [157/782] Loss: 0.6081 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [158/782] Loss: 0.8204 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [159/782] Loss: 0.6550 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [160/782] Loss: 0.5275 | Acc: 77.86%\n",
      "Train Epoch [57/100] Batch [161/782] Loss: 0.8056 | Acc: 77.87%\n",
      "Train Epoch [57/100] Batch [162/782] Loss: 0.4760 | Acc: 77.89%\n",
      "Train Epoch [57/100] Batch [163/782] Loss: 0.5780 | Acc: 77.90%\n",
      "Train Epoch [57/100] Batch [164/782] Loss: 0.5350 | Acc: 77.91%\n",
      "Train Epoch [57/100] Batch [165/782] Loss: 0.6377 | Acc: 77.92%\n",
      "Train Epoch [57/100] Batch [166/782] Loss: 0.5653 | Acc: 77.95%\n",
      "Train Epoch [57/100] Batch [167/782] Loss: 0.6060 | Acc: 77.95%\n",
      "Train Epoch [57/100] Batch [168/782] Loss: 0.5470 | Acc: 77.95%\n",
      "Train Epoch [57/100] Batch [169/782] Loss: 0.6203 | Acc: 77.95%\n",
      "Train Epoch [57/100] Batch [170/782] Loss: 0.6563 | Acc: 77.94%\n",
      "Train Epoch [57/100] Batch [171/782] Loss: 0.6193 | Acc: 77.95%\n",
      "Train Epoch [57/100] Batch [172/782] Loss: 0.5901 | Acc: 77.98%\n",
      "Train Epoch [57/100] Batch [173/782] Loss: 0.8481 | Acc: 77.94%\n",
      "Train Epoch [57/100] Batch [174/782] Loss: 0.6291 | Acc: 77.93%\n",
      "Train Epoch [57/100] Batch [175/782] Loss: 0.4778 | Acc: 77.96%\n",
      "Train Epoch [57/100] Batch [176/782] Loss: 0.6336 | Acc: 77.92%\n",
      "Train Epoch [57/100] Batch [177/782] Loss: 0.7249 | Acc: 77.90%\n",
      "Train Epoch [57/100] Batch [178/782] Loss: 0.6038 | Acc: 77.91%\n",
      "Train Epoch [57/100] Batch [179/782] Loss: 0.6740 | Acc: 77.87%\n",
      "Train Epoch [57/100] Batch [180/782] Loss: 0.7651 | Acc: 77.87%\n",
      "Train Epoch [57/100] Batch [181/782] Loss: 0.6219 | Acc: 77.89%\n",
      "Train Epoch [57/100] Batch [182/782] Loss: 0.6748 | Acc: 77.88%\n",
      "Train Epoch [57/100] Batch [183/782] Loss: 0.7739 | Acc: 77.84%\n",
      "Train Epoch [57/100] Batch [184/782] Loss: 0.6654 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [185/782] Loss: 0.6098 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [186/782] Loss: 0.6788 | Acc: 77.75%\n",
      "Train Epoch [57/100] Batch [187/782] Loss: 0.5850 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [188/782] Loss: 0.7010 | Acc: 77.79%\n",
      "Train Epoch [57/100] Batch [189/782] Loss: 0.4304 | Acc: 77.84%\n",
      "Train Epoch [57/100] Batch [190/782] Loss: 0.7098 | Acc: 77.80%\n",
      "Train Epoch [57/100] Batch [191/782] Loss: 0.7411 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [192/782] Loss: 0.5222 | Acc: 77.78%\n",
      "Train Epoch [57/100] Batch [193/782] Loss: 0.4884 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [194/782] Loss: 0.6105 | Acc: 77.82%\n",
      "Train Epoch [57/100] Batch [195/782] Loss: 0.5249 | Acc: 77.84%\n",
      "Train Epoch [57/100] Batch [196/782] Loss: 0.6130 | Acc: 77.84%\n",
      "Train Epoch [57/100] Batch [197/782] Loss: 0.7581 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [198/782] Loss: 0.7023 | Acc: 77.80%\n",
      "Train Epoch [57/100] Batch [199/782] Loss: 0.6142 | Acc: 77.81%\n",
      "Train Epoch [57/100] Batch [200/782] Loss: 0.7520 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [201/782] Loss: 0.6768 | Acc: 77.75%\n",
      "Train Epoch [57/100] Batch [202/782] Loss: 0.7383 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [203/782] Loss: 0.5791 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [204/782] Loss: 0.5945 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [205/782] Loss: 0.6820 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [206/782] Loss: 0.4381 | Acc: 77.77%\n",
      "Train Epoch [57/100] Batch [207/782] Loss: 0.5376 | Acc: 77.76%\n",
      "Train Epoch [57/100] Batch [208/782] Loss: 0.6600 | Acc: 77.74%\n",
      "Train Epoch [57/100] Batch [209/782] Loss: 0.7022 | Acc: 77.73%\n",
      "Train Epoch [57/100] Batch [210/782] Loss: 0.7600 | Acc: 77.72%\n",
      "Train Epoch [57/100] Batch [211/782] Loss: 0.6284 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [212/782] Loss: 0.6166 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [213/782] Loss: 0.5465 | Acc: 77.70%\n",
      "Train Epoch [57/100] Batch [214/782] Loss: 0.6485 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [215/782] Loss: 0.6187 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [216/782] Loss: 0.7722 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [217/782] Loss: 0.5362 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [218/782] Loss: 0.8153 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [219/782] Loss: 0.7477 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [220/782] Loss: 0.7869 | Acc: 77.64%\n",
      "Train Epoch [57/100] Batch [221/782] Loss: 0.5875 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [222/782] Loss: 0.6369 | Acc: 77.63%\n",
      "Train Epoch [57/100] Batch [223/782] Loss: 0.4577 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [224/782] Loss: 0.6770 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [225/782] Loss: 0.6546 | Acc: 77.64%\n",
      "Train Epoch [57/100] Batch [226/782] Loss: 0.7816 | Acc: 77.61%\n",
      "Train Epoch [57/100] Batch [227/782] Loss: 0.4434 | Acc: 77.66%\n",
      "Train Epoch [57/100] Batch [228/782] Loss: 0.8071 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [229/782] Loss: 0.4357 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [230/782] Loss: 0.6201 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [231/782] Loss: 0.7626 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [232/782] Loss: 0.5507 | Acc: 77.69%\n",
      "Train Epoch [57/100] Batch [233/782] Loss: 0.7675 | Acc: 77.68%\n",
      "Train Epoch [57/100] Batch [234/782] Loss: 0.7531 | Acc: 77.66%\n",
      "Train Epoch [57/100] Batch [235/782] Loss: 0.6555 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [236/782] Loss: 0.8097 | Acc: 77.63%\n",
      "Train Epoch [57/100] Batch [237/782] Loss: 0.5913 | Acc: 77.64%\n",
      "Train Epoch [57/100] Batch [238/782] Loss: 0.5771 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [239/782] Loss: 0.5708 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [240/782] Loss: 0.6863 | Acc: 77.64%\n",
      "Train Epoch [57/100] Batch [241/782] Loss: 0.5624 | Acc: 77.66%\n",
      "Train Epoch [57/100] Batch [242/782] Loss: 0.4669 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [243/782] Loss: 0.6157 | Acc: 77.67%\n",
      "Train Epoch [57/100] Batch [244/782] Loss: 0.8485 | Acc: 77.65%\n",
      "Train Epoch [57/100] Batch [245/782] Loss: 0.6179 | Acc: 77.66%\n",
      "Train Epoch [57/100] Batch [246/782] Loss: 0.5053 | Acc: 77.66%\n",
      "Train Epoch [57/100] Batch [247/782] Loss: 0.8714 | Acc: 77.61%\n",
      "Train Epoch [57/100] Batch [248/782] Loss: 0.6943 | Acc: 77.59%\n",
      "Train Epoch [57/100] Batch [249/782] Loss: 0.7478 | Acc: 77.57%\n",
      "Train Epoch [57/100] Batch [250/782] Loss: 0.6689 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [251/782] Loss: 0.5534 | Acc: 77.59%\n",
      "Train Epoch [57/100] Batch [252/782] Loss: 0.7011 | Acc: 77.57%\n",
      "Train Epoch [57/100] Batch [253/782] Loss: 0.6068 | Acc: 77.56%\n",
      "Train Epoch [57/100] Batch [254/782] Loss: 0.6406 | Acc: 77.55%\n",
      "Train Epoch [57/100] Batch [255/782] Loss: 0.7057 | Acc: 77.56%\n",
      "Train Epoch [57/100] Batch [256/782] Loss: 0.6132 | Acc: 77.58%\n",
      "Train Epoch [57/100] Batch [257/782] Loss: 0.5838 | Acc: 77.55%\n",
      "Train Epoch [57/100] Batch [258/782] Loss: 0.5526 | Acc: 77.54%\n",
      "Train Epoch [57/100] Batch [259/782] Loss: 0.6380 | Acc: 77.55%\n",
      "Train Epoch [57/100] Batch [260/782] Loss: 0.7530 | Acc: 77.53%\n",
      "Train Epoch [57/100] Batch [261/782] Loss: 0.7366 | Acc: 77.53%\n",
      "Train Epoch [57/100] Batch [262/782] Loss: 0.6489 | Acc: 77.50%\n",
      "Train Epoch [57/100] Batch [263/782] Loss: 0.7099 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [264/782] Loss: 0.5886 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [265/782] Loss: 0.6715 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [266/782] Loss: 0.4774 | Acc: 77.53%\n",
      "Train Epoch [57/100] Batch [267/782] Loss: 0.7294 | Acc: 77.52%\n",
      "Train Epoch [57/100] Batch [268/782] Loss: 0.7193 | Acc: 77.50%\n",
      "Train Epoch [57/100] Batch [269/782] Loss: 0.5900 | Acc: 77.51%\n",
      "Train Epoch [57/100] Batch [270/782] Loss: 0.5656 | Acc: 77.50%\n",
      "Train Epoch [57/100] Batch [271/782] Loss: 0.5970 | Acc: 77.47%\n",
      "Train Epoch [57/100] Batch [272/782] Loss: 0.6312 | Acc: 77.46%\n",
      "Train Epoch [57/100] Batch [273/782] Loss: 0.6468 | Acc: 77.46%\n",
      "Train Epoch [57/100] Batch [274/782] Loss: 0.7399 | Acc: 77.43%\n",
      "Train Epoch [57/100] Batch [275/782] Loss: 0.6450 | Acc: 77.44%\n",
      "Train Epoch [57/100] Batch [276/782] Loss: 0.6008 | Acc: 77.44%\n",
      "Train Epoch [57/100] Batch [277/782] Loss: 0.6762 | Acc: 77.44%\n",
      "Train Epoch [57/100] Batch [278/782] Loss: 0.8542 | Acc: 77.41%\n",
      "Train Epoch [57/100] Batch [279/782] Loss: 0.6249 | Acc: 77.41%\n",
      "Train Epoch [57/100] Batch [280/782] Loss: 0.5876 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [281/782] Loss: 0.6306 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [282/782] Loss: 0.4629 | Acc: 77.43%\n",
      "Train Epoch [57/100] Batch [283/782] Loss: 0.8143 | Acc: 77.41%\n",
      "Train Epoch [57/100] Batch [284/782] Loss: 0.7715 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [285/782] Loss: 0.7188 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [286/782] Loss: 0.6476 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [287/782] Loss: 0.6453 | Acc: 77.37%\n",
      "Train Epoch [57/100] Batch [288/782] Loss: 0.7109 | Acc: 77.38%\n",
      "Train Epoch [57/100] Batch [289/782] Loss: 0.5537 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [290/782] Loss: 0.5923 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [291/782] Loss: 0.4446 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [292/782] Loss: 0.6425 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [293/782] Loss: 0.6353 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [294/782] Loss: 0.5800 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [295/782] Loss: 0.6803 | Acc: 77.42%\n",
      "Train Epoch [57/100] Batch [296/782] Loss: 0.6845 | Acc: 77.39%\n",
      "Train Epoch [57/100] Batch [297/782] Loss: 0.8828 | Acc: 77.37%\n",
      "Train Epoch [57/100] Batch [298/782] Loss: 0.5324 | Acc: 77.38%\n",
      "Train Epoch [57/100] Batch [299/782] Loss: 0.5291 | Acc: 77.37%\n",
      "Train Epoch [57/100] Batch [300/782] Loss: 0.7805 | Acc: 77.33%\n",
      "Train Epoch [57/100] Batch [301/782] Loss: 0.8123 | Acc: 77.33%\n",
      "Train Epoch [57/100] Batch [302/782] Loss: 0.5869 | Acc: 77.33%\n",
      "Train Epoch [57/100] Batch [303/782] Loss: 0.5137 | Acc: 77.35%\n",
      "Train Epoch [57/100] Batch [304/782] Loss: 0.6364 | Acc: 77.35%\n",
      "Train Epoch [57/100] Batch [305/782] Loss: 0.5581 | Acc: 77.35%\n",
      "Train Epoch [57/100] Batch [306/782] Loss: 0.5482 | Acc: 77.34%\n",
      "Train Epoch [57/100] Batch [307/782] Loss: 0.6809 | Acc: 77.32%\n",
      "Train Epoch [57/100] Batch [308/782] Loss: 0.8233 | Acc: 77.30%\n",
      "Train Epoch [57/100] Batch [309/782] Loss: 0.7333 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [310/782] Loss: 0.7291 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [311/782] Loss: 0.7691 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [312/782] Loss: 0.4766 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [313/782] Loss: 0.5974 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [314/782] Loss: 0.6884 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [315/782] Loss: 0.9764 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [316/782] Loss: 0.7004 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [317/782] Loss: 0.7372 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [318/782] Loss: 0.5022 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [319/782] Loss: 0.6670 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [320/782] Loss: 0.6107 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [321/782] Loss: 0.6887 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [322/782] Loss: 0.6751 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [323/782] Loss: 0.4747 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [324/782] Loss: 0.4659 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [325/782] Loss: 0.5280 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [326/782] Loss: 0.7881 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [327/782] Loss: 0.7952 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [328/782] Loss: 0.6862 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [329/782] Loss: 0.8369 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [330/782] Loss: 0.6706 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [331/782] Loss: 0.6054 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [332/782] Loss: 0.5449 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [333/782] Loss: 0.8153 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [334/782] Loss: 0.5043 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [335/782] Loss: 0.7954 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [336/782] Loss: 0.8594 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [337/782] Loss: 0.7540 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [338/782] Loss: 0.8180 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [339/782] Loss: 0.5713 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [340/782] Loss: 0.5944 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [341/782] Loss: 0.7745 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [342/782] Loss: 0.5249 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [343/782] Loss: 0.5853 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [344/782] Loss: 0.4343 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [345/782] Loss: 0.6489 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [346/782] Loss: 0.7108 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [347/782] Loss: 0.5850 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [348/782] Loss: 0.6540 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [349/782] Loss: 0.6138 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [350/782] Loss: 0.7434 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [351/782] Loss: 0.6210 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [352/782] Loss: 0.6528 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [353/782] Loss: 0.6453 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [354/782] Loss: 0.6884 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [355/782] Loss: 0.7320 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [356/782] Loss: 0.6800 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [357/782] Loss: 0.7618 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [358/782] Loss: 0.7219 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [359/782] Loss: 0.3893 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [360/782] Loss: 0.4399 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [361/782] Loss: 0.5086 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [362/782] Loss: 0.8189 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [363/782] Loss: 0.5438 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [364/782] Loss: 0.6779 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [365/782] Loss: 0.5991 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [366/782] Loss: 0.6291 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [367/782] Loss: 0.5651 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [368/782] Loss: 0.5145 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [369/782] Loss: 0.8836 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [370/782] Loss: 0.5663 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [371/782] Loss: 0.8477 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [372/782] Loss: 0.6473 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [373/782] Loss: 0.6318 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [374/782] Loss: 0.5742 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [375/782] Loss: 0.5499 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [376/782] Loss: 0.6499 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [377/782] Loss: 0.8886 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [378/782] Loss: 1.0194 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [379/782] Loss: 0.6065 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [380/782] Loss: 0.5745 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [381/782] Loss: 0.4834 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [382/782] Loss: 0.7736 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [383/782] Loss: 0.4510 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [384/782] Loss: 0.5659 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [385/782] Loss: 0.5963 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [386/782] Loss: 0.7368 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [387/782] Loss: 0.7293 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [388/782] Loss: 0.6755 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [389/782] Loss: 0.5277 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [390/782] Loss: 0.6247 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [391/782] Loss: 0.5795 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [392/782] Loss: 0.7541 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [393/782] Loss: 0.4856 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [394/782] Loss: 0.6085 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [395/782] Loss: 0.4547 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [396/782] Loss: 0.5672 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [397/782] Loss: 0.6869 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [398/782] Loss: 0.6418 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [399/782] Loss: 0.7098 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [400/782] Loss: 0.6248 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [401/782] Loss: 0.6908 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [402/782] Loss: 0.6957 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [403/782] Loss: 0.8465 | Acc: 77.08%\n",
      "Train Epoch [57/100] Batch [404/782] Loss: 0.5325 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [405/782] Loss: 0.5584 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [406/782] Loss: 0.7945 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [407/782] Loss: 0.5653 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [408/782] Loss: 0.7071 | Acc: 77.09%\n",
      "Train Epoch [57/100] Batch [409/782] Loss: 0.4671 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [410/782] Loss: 0.8144 | Acc: 77.07%\n",
      "Train Epoch [57/100] Batch [411/782] Loss: 0.6249 | Acc: 77.07%\n",
      "Train Epoch [57/100] Batch [412/782] Loss: 0.6733 | Acc: 77.07%\n",
      "Train Epoch [57/100] Batch [413/782] Loss: 0.3927 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [414/782] Loss: 0.6018 | Acc: 77.10%\n",
      "Train Epoch [57/100] Batch [415/782] Loss: 0.5674 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [416/782] Loss: 0.6631 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [417/782] Loss: 0.5984 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [418/782] Loss: 0.4746 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [419/782] Loss: 0.5883 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [420/782] Loss: 0.7263 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [421/782] Loss: 0.6488 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [422/782] Loss: 0.6404 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [423/782] Loss: 0.6672 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [424/782] Loss: 0.5425 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [425/782] Loss: 0.5178 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [426/782] Loss: 0.5170 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [427/782] Loss: 0.5930 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [428/782] Loss: 0.6586 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [429/782] Loss: 0.4805 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [430/782] Loss: 0.5791 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [431/782] Loss: 0.4988 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [432/782] Loss: 0.5456 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [433/782] Loss: 0.6591 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [434/782] Loss: 0.7942 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [435/782] Loss: 1.0393 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [436/782] Loss: 0.4105 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [437/782] Loss: 0.5150 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [438/782] Loss: 0.6381 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [439/782] Loss: 0.5458 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [440/782] Loss: 0.4517 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [441/782] Loss: 0.4618 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [442/782] Loss: 0.5573 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [443/782] Loss: 0.5737 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [444/782] Loss: 0.4810 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [445/782] Loss: 0.6612 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [446/782] Loss: 0.5660 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [447/782] Loss: 0.6173 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [448/782] Loss: 0.3813 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [449/782] Loss: 0.4399 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [450/782] Loss: 0.6305 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [451/782] Loss: 0.6942 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [452/782] Loss: 0.7998 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [453/782] Loss: 0.4584 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [454/782] Loss: 0.6453 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [455/782] Loss: 0.5638 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [456/782] Loss: 0.5511 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [457/782] Loss: 0.7620 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [458/782] Loss: 0.6124 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [459/782] Loss: 0.6532 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [460/782] Loss: 0.4393 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [461/782] Loss: 0.7909 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [462/782] Loss: 0.9990 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [463/782] Loss: 0.5933 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [464/782] Loss: 0.4664 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [465/782] Loss: 0.7729 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [466/782] Loss: 0.6175 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [467/782] Loss: 0.6402 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [468/782] Loss: 0.5689 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [469/782] Loss: 0.6412 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [470/782] Loss: 0.5215 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [471/782] Loss: 0.5361 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [472/782] Loss: 0.5720 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [473/782] Loss: 0.5234 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [474/782] Loss: 0.5566 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [475/782] Loss: 0.7323 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [476/782] Loss: 1.0442 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [477/782] Loss: 0.3509 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [478/782] Loss: 0.6282 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [479/782] Loss: 0.4708 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [480/782] Loss: 0.5677 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [481/782] Loss: 0.6397 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [482/782] Loss: 0.5675 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [483/782] Loss: 0.7080 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [484/782] Loss: 0.5854 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [485/782] Loss: 0.5371 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [486/782] Loss: 0.6993 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [487/782] Loss: 0.8479 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [488/782] Loss: 0.6946 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [489/782] Loss: 0.7635 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [490/782] Loss: 0.5811 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [491/782] Loss: 0.6788 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [492/782] Loss: 0.6676 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [493/782] Loss: 0.5435 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [494/782] Loss: 0.6621 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [495/782] Loss: 0.6935 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [496/782] Loss: 0.5787 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [497/782] Loss: 0.5955 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [498/782] Loss: 0.7438 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [499/782] Loss: 0.7680 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [500/782] Loss: 0.4653 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [501/782] Loss: 0.7959 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [502/782] Loss: 0.8404 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [503/782] Loss: 0.6526 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [504/782] Loss: 0.5281 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [505/782] Loss: 0.6136 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [506/782] Loss: 0.6470 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [507/782] Loss: 0.8159 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [508/782] Loss: 0.5183 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [509/782] Loss: 0.5781 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [510/782] Loss: 0.5941 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [511/782] Loss: 0.7764 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [512/782] Loss: 0.4748 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [513/782] Loss: 0.6442 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [514/782] Loss: 0.5602 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [515/782] Loss: 0.5770 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [516/782] Loss: 0.7660 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [517/782] Loss: 0.6569 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [518/782] Loss: 0.7230 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [519/782] Loss: 0.6865 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [520/782] Loss: 0.6778 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [521/782] Loss: 0.6016 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [522/782] Loss: 0.7226 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [523/782] Loss: 0.5995 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [524/782] Loss: 0.6296 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [525/782] Loss: 0.6731 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [526/782] Loss: 0.4243 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [527/782] Loss: 0.6463 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [528/782] Loss: 0.7433 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [529/782] Loss: 0.6905 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [530/782] Loss: 0.7261 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [531/782] Loss: 0.5905 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [532/782] Loss: 0.5159 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [533/782] Loss: 0.6121 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [534/782] Loss: 0.8250 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [535/782] Loss: 0.7139 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [536/782] Loss: 0.6998 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [537/782] Loss: 0.5349 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [538/782] Loss: 0.5845 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [539/782] Loss: 0.8378 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [540/782] Loss: 0.5202 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [541/782] Loss: 0.7430 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [542/782] Loss: 0.7783 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [543/782] Loss: 0.6406 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [544/782] Loss: 0.6241 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [545/782] Loss: 0.6171 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [546/782] Loss: 0.7376 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [547/782] Loss: 0.6782 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [548/782] Loss: 0.6253 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [549/782] Loss: 0.5547 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [550/782] Loss: 0.7867 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [551/782] Loss: 0.7362 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [552/782] Loss: 0.6299 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [553/782] Loss: 0.7058 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [554/782] Loss: 0.6334 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [555/782] Loss: 0.7359 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [556/782] Loss: 0.6745 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [557/782] Loss: 0.6047 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [558/782] Loss: 0.5957 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [559/782] Loss: 0.5630 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [560/782] Loss: 0.4775 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [561/782] Loss: 0.9467 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [562/782] Loss: 0.6289 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [563/782] Loss: 0.6417 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [564/782] Loss: 0.6548 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [565/782] Loss: 0.7197 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [566/782] Loss: 0.6022 | Acc: 77.11%\n",
      "Train Epoch [57/100] Batch [567/782] Loss: 0.4815 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [568/782] Loss: 0.6837 | Acc: 77.12%\n",
      "Train Epoch [57/100] Batch [569/782] Loss: 0.5524 | Acc: 77.13%\n",
      "Train Epoch [57/100] Batch [570/782] Loss: 0.5611 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [571/782] Loss: 0.5333 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [572/782] Loss: 0.6624 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [573/782] Loss: 0.6387 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [574/782] Loss: 0.8151 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [575/782] Loss: 0.5936 | Acc: 77.14%\n",
      "Train Epoch [57/100] Batch [576/782] Loss: 0.5255 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [577/782] Loss: 0.6180 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [578/782] Loss: 0.6788 | Acc: 77.15%\n",
      "Train Epoch [57/100] Batch [579/782] Loss: 0.4393 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [580/782] Loss: 0.3318 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [581/782] Loss: 0.6887 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [582/782] Loss: 0.5064 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [583/782] Loss: 0.6633 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [584/782] Loss: 0.4062 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [585/782] Loss: 0.5680 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [586/782] Loss: 0.6381 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [587/782] Loss: 0.4509 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [588/782] Loss: 0.7152 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [589/782] Loss: 0.5559 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [590/782] Loss: 0.6116 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [591/782] Loss: 0.5464 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [592/782] Loss: 0.5512 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [593/782] Loss: 0.7383 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [594/782] Loss: 0.5601 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [595/782] Loss: 0.5631 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [596/782] Loss: 0.4103 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [597/782] Loss: 0.7715 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [598/782] Loss: 0.8462 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [599/782] Loss: 0.6905 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [600/782] Loss: 0.7841 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [601/782] Loss: 0.6412 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [602/782] Loss: 0.7159 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [603/782] Loss: 0.6575 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [604/782] Loss: 0.6522 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [605/782] Loss: 0.6966 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [606/782] Loss: 0.8087 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [607/782] Loss: 0.6762 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [608/782] Loss: 0.5808 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [609/782] Loss: 0.5033 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [610/782] Loss: 0.8003 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [611/782] Loss: 0.7049 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [612/782] Loss: 0.9288 | Acc: 77.16%\n",
      "Train Epoch [57/100] Batch [613/782] Loss: 0.5581 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [614/782] Loss: 0.7439 | Acc: 77.17%\n",
      "Train Epoch [57/100] Batch [615/782] Loss: 0.5488 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [616/782] Loss: 0.6291 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [617/782] Loss: 0.4482 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [618/782] Loss: 0.7584 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [619/782] Loss: 0.4214 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [620/782] Loss: 0.4355 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [621/782] Loss: 0.5442 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [622/782] Loss: 0.4527 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [623/782] Loss: 0.5885 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [624/782] Loss: 0.5649 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [625/782] Loss: 0.6428 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [626/782] Loss: 0.3934 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [627/782] Loss: 0.5885 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [628/782] Loss: 0.7226 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [629/782] Loss: 0.8357 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [630/782] Loss: 0.5608 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [631/782] Loss: 0.7987 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [632/782] Loss: 0.4292 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [633/782] Loss: 0.6076 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [634/782] Loss: 0.5681 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [635/782] Loss: 0.6570 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [636/782] Loss: 0.4571 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [637/782] Loss: 0.6366 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [638/782] Loss: 0.5437 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [639/782] Loss: 0.4623 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [640/782] Loss: 0.5289 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [641/782] Loss: 0.4442 | Acc: 77.30%\n",
      "Train Epoch [57/100] Batch [642/782] Loss: 0.6634 | Acc: 77.30%\n",
      "Train Epoch [57/100] Batch [643/782] Loss: 0.6975 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [644/782] Loss: 0.6842 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [645/782] Loss: 0.5651 | Acc: 77.30%\n",
      "Train Epoch [57/100] Batch [646/782] Loss: 0.6825 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [647/782] Loss: 0.6543 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [648/782] Loss: 0.4708 | Acc: 77.29%\n",
      "Train Epoch [57/100] Batch [649/782] Loss: 0.7578 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [650/782] Loss: 0.7892 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [651/782] Loss: 0.6353 | Acc: 77.28%\n",
      "Train Epoch [57/100] Batch [652/782] Loss: 0.6782 | Acc: 77.27%\n",
      "Train Epoch [57/100] Batch [653/782] Loss: 0.6156 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [654/782] Loss: 0.7168 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [655/782] Loss: 0.7918 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [656/782] Loss: 0.8524 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [657/782] Loss: 0.5857 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [658/782] Loss: 0.6754 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [659/782] Loss: 0.5764 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [660/782] Loss: 0.6037 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [661/782] Loss: 0.6505 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [662/782] Loss: 0.5198 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [663/782] Loss: 0.5133 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [664/782] Loss: 0.7869 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [665/782] Loss: 0.4305 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [666/782] Loss: 0.8430 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [667/782] Loss: 0.7207 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [668/782] Loss: 0.5862 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [669/782] Loss: 0.5711 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [670/782] Loss: 0.5829 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [671/782] Loss: 0.8112 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [672/782] Loss: 0.8507 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [673/782] Loss: 0.5630 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [674/782] Loss: 0.6949 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [675/782] Loss: 0.6302 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [676/782] Loss: 0.5537 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [677/782] Loss: 0.7967 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [678/782] Loss: 0.5902 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [679/782] Loss: 0.6032 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [680/782] Loss: 0.7800 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [681/782] Loss: 0.6807 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [682/782] Loss: 0.7815 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [683/782] Loss: 0.7939 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [684/782] Loss: 0.6360 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [685/782] Loss: 0.6161 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [686/782] Loss: 0.7155 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [687/782] Loss: 0.7310 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [688/782] Loss: 0.5985 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [689/782] Loss: 0.4728 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [690/782] Loss: 0.5933 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [691/782] Loss: 0.5074 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [692/782] Loss: 0.4964 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [693/782] Loss: 0.5147 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [694/782] Loss: 0.6102 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [695/782] Loss: 0.5749 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [696/782] Loss: 0.6345 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [697/782] Loss: 0.8478 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [698/782] Loss: 0.7217 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [699/782] Loss: 0.7402 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [700/782] Loss: 0.4758 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [701/782] Loss: 0.5587 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [702/782] Loss: 0.6674 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [703/782] Loss: 0.7128 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [704/782] Loss: 0.6154 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [705/782] Loss: 0.7758 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [706/782] Loss: 0.7307 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [707/782] Loss: 0.8157 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [708/782] Loss: 0.6745 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [709/782] Loss: 0.7962 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [710/782] Loss: 0.6739 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [711/782] Loss: 0.5042 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [712/782] Loss: 0.6714 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [713/782] Loss: 0.5512 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [714/782] Loss: 0.3729 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [715/782] Loss: 0.7709 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [716/782] Loss: 0.8150 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [717/782] Loss: 0.7731 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [718/782] Loss: 0.6516 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [719/782] Loss: 0.6486 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [720/782] Loss: 0.5413 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [721/782] Loss: 0.5995 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [722/782] Loss: 0.5913 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [723/782] Loss: 0.5357 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [724/782] Loss: 0.5860 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [725/782] Loss: 0.7474 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [726/782] Loss: 0.6149 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [727/782] Loss: 0.5806 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [728/782] Loss: 0.5206 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [729/782] Loss: 0.6152 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [730/782] Loss: 0.7817 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [731/782] Loss: 0.8959 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [732/782] Loss: 0.7238 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [733/782] Loss: 0.5638 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [734/782] Loss: 0.7090 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [735/782] Loss: 0.6234 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [736/782] Loss: 0.4794 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [737/782] Loss: 0.6929 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [738/782] Loss: 0.6590 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [739/782] Loss: 0.7736 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [740/782] Loss: 0.7092 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [741/782] Loss: 0.4378 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [742/782] Loss: 0.7966 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [743/782] Loss: 0.7574 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [744/782] Loss: 0.7131 | Acc: 77.18%\n",
      "Train Epoch [57/100] Batch [745/782] Loss: 0.6109 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [746/782] Loss: 0.5280 | Acc: 77.19%\n",
      "Train Epoch [57/100] Batch [747/782] Loss: 0.5438 | Acc: 77.20%\n",
      "Train Epoch [57/100] Batch [748/782] Loss: 0.5276 | Acc: 77.21%\n",
      "Train Epoch [57/100] Batch [749/782] Loss: 0.3558 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [750/782] Loss: 0.5432 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [751/782] Loss: 0.6355 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [752/782] Loss: 0.5933 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [753/782] Loss: 0.6357 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [754/782] Loss: 0.6725 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [755/782] Loss: 0.5853 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [756/782] Loss: 0.5070 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [757/782] Loss: 0.6235 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [758/782] Loss: 0.7030 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [759/782] Loss: 0.5948 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [760/782] Loss: 0.7582 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [761/782] Loss: 0.8031 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [762/782] Loss: 0.6471 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [763/782] Loss: 0.3907 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [764/782] Loss: 0.4764 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [765/782] Loss: 0.7711 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [766/782] Loss: 0.7079 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [767/782] Loss: 0.7308 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [768/782] Loss: 0.6146 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [769/782] Loss: 0.5934 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [770/782] Loss: 0.6614 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [771/782] Loss: 0.5078 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [772/782] Loss: 0.7728 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [773/782] Loss: 0.6282 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [774/782] Loss: 0.9794 | Acc: 77.22%\n",
      "Train Epoch [57/100] Batch [775/782] Loss: 0.5506 | Acc: 77.23%\n",
      "Train Epoch [57/100] Batch [776/782] Loss: 0.5417 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [777/782] Loss: 0.6564 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [778/782] Loss: 0.6632 | Acc: 77.24%\n",
      "Train Epoch [57/100] Batch [779/782] Loss: 0.4242 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [780/782] Loss: 0.5342 | Acc: 77.26%\n",
      "Train Epoch [57/100] Batch [781/782] Loss: 0.7178 | Acc: 77.25%\n",
      "Train Epoch [57/100] Batch [782/782] Loss: 0.6188 | Acc: 77.26%\n",
      "Epoch 57 completed in 29.02s.\n",
      "Test Epoch [57/100] Loss: 0.8588 | Acc: 72.64% | Inference Time: 8.19s\n",
      "Epoch 57 results saved to CSV.\n",
      "Epoch 58/100\n",
      "Train Epoch [58/100] Batch [1/782] Loss: 0.5761 | Acc: 81.25%\n",
      "Train Epoch [58/100] Batch [2/782] Loss: 0.5050 | Acc: 82.03%\n",
      "Train Epoch [58/100] Batch [3/782] Loss: 0.6121 | Acc: 80.21%\n",
      "Train Epoch [58/100] Batch [4/782] Loss: 0.6072 | Acc: 80.08%\n",
      "Train Epoch [58/100] Batch [5/782] Loss: 0.5774 | Acc: 79.38%\n",
      "Train Epoch [58/100] Batch [6/782] Loss: 0.7689 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [7/782] Loss: 0.7225 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [8/782] Loss: 0.4798 | Acc: 78.52%\n",
      "Train Epoch [58/100] Batch [9/782] Loss: 0.6112 | Acc: 78.30%\n",
      "Train Epoch [58/100] Batch [10/782] Loss: 0.5112 | Acc: 78.44%\n",
      "Train Epoch [58/100] Batch [11/782] Loss: 0.7758 | Acc: 77.70%\n",
      "Train Epoch [58/100] Batch [12/782] Loss: 0.4029 | Acc: 78.39%\n",
      "Train Epoch [58/100] Batch [13/782] Loss: 0.5453 | Acc: 78.85%\n",
      "Train Epoch [58/100] Batch [14/782] Loss: 0.6690 | Acc: 78.46%\n",
      "Train Epoch [58/100] Batch [15/782] Loss: 0.4863 | Acc: 78.75%\n",
      "Train Epoch [58/100] Batch [16/782] Loss: 0.6525 | Acc: 78.32%\n",
      "Train Epoch [58/100] Batch [17/782] Loss: 0.5776 | Acc: 78.49%\n",
      "Train Epoch [58/100] Batch [18/782] Loss: 0.5259 | Acc: 78.56%\n",
      "Train Epoch [58/100] Batch [19/782] Loss: 0.7355 | Acc: 78.37%\n",
      "Train Epoch [58/100] Batch [20/782] Loss: 0.7053 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [21/782] Loss: 0.7993 | Acc: 77.60%\n",
      "Train Epoch [58/100] Batch [22/782] Loss: 0.6194 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [23/782] Loss: 0.7173 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [24/782] Loss: 0.5170 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [25/782] Loss: 0.4980 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [26/782] Loss: 0.5670 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [27/782] Loss: 0.7231 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [28/782] Loss: 0.5062 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [29/782] Loss: 0.6867 | Acc: 77.37%\n",
      "Train Epoch [58/100] Batch [30/782] Loss: 0.5577 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [31/782] Loss: 0.7402 | Acc: 77.37%\n",
      "Train Epoch [58/100] Batch [32/782] Loss: 0.7897 | Acc: 77.25%\n",
      "Train Epoch [58/100] Batch [33/782] Loss: 0.5620 | Acc: 77.27%\n",
      "Train Epoch [58/100] Batch [34/782] Loss: 0.5817 | Acc: 77.30%\n",
      "Train Epoch [58/100] Batch [35/782] Loss: 0.5801 | Acc: 77.37%\n",
      "Train Epoch [58/100] Batch [36/782] Loss: 0.5620 | Acc: 77.34%\n",
      "Train Epoch [58/100] Batch [37/782] Loss: 0.6822 | Acc: 77.24%\n",
      "Train Epoch [58/100] Batch [38/782] Loss: 0.5578 | Acc: 77.18%\n",
      "Train Epoch [58/100] Batch [39/782] Loss: 0.5010 | Acc: 77.32%\n",
      "Train Epoch [58/100] Batch [40/782] Loss: 0.6796 | Acc: 77.34%\n",
      "Train Epoch [58/100] Batch [41/782] Loss: 0.6847 | Acc: 77.44%\n",
      "Train Epoch [58/100] Batch [42/782] Loss: 0.5551 | Acc: 77.53%\n",
      "Train Epoch [58/100] Batch [43/782] Loss: 0.7259 | Acc: 77.51%\n",
      "Train Epoch [58/100] Batch [44/782] Loss: 0.6747 | Acc: 77.56%\n",
      "Train Epoch [58/100] Batch [45/782] Loss: 0.4887 | Acc: 77.64%\n",
      "Train Epoch [58/100] Batch [46/782] Loss: 0.4668 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [47/782] Loss: 0.5907 | Acc: 77.73%\n",
      "Train Epoch [58/100] Batch [48/782] Loss: 0.5508 | Acc: 77.70%\n",
      "Train Epoch [58/100] Batch [49/782] Loss: 0.5485 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [50/782] Loss: 0.7714 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [51/782] Loss: 0.5368 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [52/782] Loss: 0.6302 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [53/782] Loss: 0.6414 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [54/782] Loss: 0.7254 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [55/782] Loss: 0.6841 | Acc: 77.73%\n",
      "Train Epoch [58/100] Batch [56/782] Loss: 0.5704 | Acc: 77.71%\n",
      "Train Epoch [58/100] Batch [57/782] Loss: 0.5602 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [58/782] Loss: 0.5935 | Acc: 77.67%\n",
      "Train Epoch [58/100] Batch [59/782] Loss: 0.8585 | Acc: 77.52%\n",
      "Train Epoch [58/100] Batch [60/782] Loss: 0.6005 | Acc: 77.47%\n",
      "Train Epoch [58/100] Batch [61/782] Loss: 0.6819 | Acc: 77.38%\n",
      "Train Epoch [58/100] Batch [62/782] Loss: 0.4990 | Acc: 77.42%\n",
      "Train Epoch [58/100] Batch [63/782] Loss: 0.6907 | Acc: 77.41%\n",
      "Train Epoch [58/100] Batch [64/782] Loss: 0.5765 | Acc: 77.37%\n",
      "Train Epoch [58/100] Batch [65/782] Loss: 0.5803 | Acc: 77.40%\n",
      "Train Epoch [58/100] Batch [66/782] Loss: 0.6718 | Acc: 77.34%\n",
      "Train Epoch [58/100] Batch [67/782] Loss: 0.5352 | Acc: 77.45%\n",
      "Train Epoch [58/100] Batch [68/782] Loss: 0.6005 | Acc: 77.48%\n",
      "Train Epoch [58/100] Batch [69/782] Loss: 0.9073 | Acc: 77.31%\n",
      "Train Epoch [58/100] Batch [70/782] Loss: 0.6583 | Acc: 77.30%\n",
      "Train Epoch [58/100] Batch [71/782] Loss: 0.6588 | Acc: 77.31%\n",
      "Train Epoch [58/100] Batch [72/782] Loss: 0.7114 | Acc: 77.28%\n",
      "Train Epoch [58/100] Batch [73/782] Loss: 0.5179 | Acc: 77.33%\n",
      "Train Epoch [58/100] Batch [74/782] Loss: 0.4782 | Acc: 77.36%\n",
      "Train Epoch [58/100] Batch [75/782] Loss: 0.4812 | Acc: 77.48%\n",
      "Train Epoch [58/100] Batch [76/782] Loss: 0.5675 | Acc: 77.53%\n",
      "Train Epoch [58/100] Batch [77/782] Loss: 0.4812 | Acc: 77.62%\n",
      "Train Epoch [58/100] Batch [78/782] Loss: 0.7614 | Acc: 77.62%\n",
      "Train Epoch [58/100] Batch [79/782] Loss: 0.6325 | Acc: 77.61%\n",
      "Train Epoch [58/100] Batch [80/782] Loss: 0.5709 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [81/782] Loss: 0.7850 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [82/782] Loss: 0.7276 | Acc: 77.69%\n",
      "Train Epoch [58/100] Batch [83/782] Loss: 0.5407 | Acc: 77.69%\n",
      "Train Epoch [58/100] Batch [84/782] Loss: 0.6522 | Acc: 77.64%\n",
      "Train Epoch [58/100] Batch [85/782] Loss: 0.5163 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [86/782] Loss: 0.6635 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [87/782] Loss: 0.4087 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [88/782] Loss: 0.5199 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [89/782] Loss: 0.7011 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [90/782] Loss: 0.6189 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [91/782] Loss: 0.6223 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [92/782] Loss: 0.5904 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [93/782] Loss: 0.9263 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [94/782] Loss: 0.6367 | Acc: 77.73%\n",
      "Train Epoch [58/100] Batch [95/782] Loss: 0.6712 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [96/782] Loss: 0.4500 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [97/782] Loss: 0.5210 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [98/782] Loss: 0.5653 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [99/782] Loss: 0.3443 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [100/782] Loss: 0.6212 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [101/782] Loss: 0.5846 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [102/782] Loss: 0.6065 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [103/782] Loss: 0.7612 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [104/782] Loss: 0.5935 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [105/782] Loss: 0.8040 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [106/782] Loss: 0.5347 | Acc: 77.71%\n",
      "Train Epoch [58/100] Batch [107/782] Loss: 0.5910 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [108/782] Loss: 0.6355 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [109/782] Loss: 0.6394 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [110/782] Loss: 0.8749 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [111/782] Loss: 0.6907 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [112/782] Loss: 0.6340 | Acc: 77.61%\n",
      "Train Epoch [58/100] Batch [113/782] Loss: 0.5478 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [114/782] Loss: 0.5260 | Acc: 77.70%\n",
      "Train Epoch [58/100] Batch [115/782] Loss: 0.5600 | Acc: 77.70%\n",
      "Train Epoch [58/100] Batch [116/782] Loss: 0.7137 | Acc: 77.67%\n",
      "Train Epoch [58/100] Batch [117/782] Loss: 0.5416 | Acc: 77.70%\n",
      "Train Epoch [58/100] Batch [118/782] Loss: 0.6161 | Acc: 77.71%\n",
      "Train Epoch [58/100] Batch [119/782] Loss: 0.6267 | Acc: 77.67%\n",
      "Train Epoch [58/100] Batch [120/782] Loss: 0.5938 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [121/782] Loss: 0.4328 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [122/782] Loss: 0.7185 | Acc: 77.69%\n",
      "Train Epoch [58/100] Batch [123/782] Loss: 0.7849 | Acc: 77.71%\n",
      "Train Epoch [58/100] Batch [124/782] Loss: 0.7172 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [125/782] Loss: 0.6177 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [126/782] Loss: 0.5605 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [127/782] Loss: 0.7639 | Acc: 77.63%\n",
      "Train Epoch [58/100] Batch [128/782] Loss: 0.5026 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [129/782] Loss: 0.4377 | Acc: 77.73%\n",
      "Train Epoch [58/100] Batch [130/782] Loss: 0.7784 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [131/782] Loss: 0.7533 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [132/782] Loss: 0.7180 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [133/782] Loss: 0.6544 | Acc: 77.64%\n",
      "Train Epoch [58/100] Batch [134/782] Loss: 0.8039 | Acc: 77.58%\n",
      "Train Epoch [58/100] Batch [135/782] Loss: 0.5700 | Acc: 77.58%\n",
      "Train Epoch [58/100] Batch [136/782] Loss: 0.7345 | Acc: 77.52%\n",
      "Train Epoch [58/100] Batch [137/782] Loss: 0.4750 | Acc: 77.57%\n",
      "Train Epoch [58/100] Batch [138/782] Loss: 0.8865 | Acc: 77.50%\n",
      "Train Epoch [58/100] Batch [139/782] Loss: 0.6186 | Acc: 77.53%\n",
      "Train Epoch [58/100] Batch [140/782] Loss: 0.7933 | Acc: 77.50%\n",
      "Train Epoch [58/100] Batch [141/782] Loss: 0.4970 | Acc: 77.55%\n",
      "Train Epoch [58/100] Batch [142/782] Loss: 0.5706 | Acc: 77.55%\n",
      "Train Epoch [58/100] Batch [143/782] Loss: 0.5713 | Acc: 77.61%\n",
      "Train Epoch [58/100] Batch [144/782] Loss: 0.6007 | Acc: 77.60%\n",
      "Train Epoch [58/100] Batch [145/782] Loss: 0.5638 | Acc: 77.62%\n",
      "Train Epoch [58/100] Batch [146/782] Loss: 0.7057 | Acc: 77.61%\n",
      "Train Epoch [58/100] Batch [147/782] Loss: 0.7059 | Acc: 77.59%\n",
      "Train Epoch [58/100] Batch [148/782] Loss: 0.5694 | Acc: 77.60%\n",
      "Train Epoch [58/100] Batch [149/782] Loss: 0.4197 | Acc: 77.63%\n",
      "Train Epoch [58/100] Batch [150/782] Loss: 0.6129 | Acc: 77.64%\n",
      "Train Epoch [58/100] Batch [151/782] Loss: 0.5620 | Acc: 77.67%\n",
      "Train Epoch [58/100] Batch [152/782] Loss: 0.6051 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [153/782] Loss: 0.6074 | Acc: 77.69%\n",
      "Train Epoch [58/100] Batch [154/782] Loss: 0.5844 | Acc: 77.65%\n",
      "Train Epoch [58/100] Batch [155/782] Loss: 0.4926 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [156/782] Loss: 0.4867 | Acc: 77.66%\n",
      "Train Epoch [58/100] Batch [157/782] Loss: 0.5019 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [158/782] Loss: 0.7037 | Acc: 77.71%\n",
      "Train Epoch [58/100] Batch [159/782] Loss: 0.4710 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [160/782] Loss: 0.5128 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [161/782] Loss: 0.7359 | Acc: 77.69%\n",
      "Train Epoch [58/100] Batch [162/782] Loss: 0.8506 | Acc: 77.67%\n",
      "Train Epoch [58/100] Batch [163/782] Loss: 0.7305 | Acc: 77.68%\n",
      "Train Epoch [58/100] Batch [164/782] Loss: 0.5928 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [165/782] Loss: 0.5241 | Acc: 77.72%\n",
      "Train Epoch [58/100] Batch [166/782] Loss: 0.6462 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [167/782] Loss: 0.5082 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [168/782] Loss: 0.6200 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [169/782] Loss: 0.6499 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [170/782] Loss: 0.5595 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [171/782] Loss: 0.5832 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [172/782] Loss: 0.7038 | Acc: 77.73%\n",
      "Train Epoch [58/100] Batch [173/782] Loss: 0.4871 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [174/782] Loss: 0.5476 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [175/782] Loss: 0.7266 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [176/782] Loss: 0.4979 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [177/782] Loss: 0.4862 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [178/782] Loss: 0.5100 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [179/782] Loss: 0.6267 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [180/782] Loss: 0.5578 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [181/782] Loss: 0.6850 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [182/782] Loss: 0.5149 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [183/782] Loss: 0.4443 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [184/782] Loss: 0.3866 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [185/782] Loss: 0.6394 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [186/782] Loss: 0.8065 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [187/782] Loss: 0.7255 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [188/782] Loss: 0.4477 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [189/782] Loss: 0.6280 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [190/782] Loss: 0.3843 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [191/782] Loss: 0.8410 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [192/782] Loss: 0.4571 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [193/782] Loss: 0.8389 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [194/782] Loss: 0.5826 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [195/782] Loss: 0.6963 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [196/782] Loss: 0.6726 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [197/782] Loss: 0.5874 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [198/782] Loss: 0.5443 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [199/782] Loss: 0.7300 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [200/782] Loss: 0.7024 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [201/782] Loss: 0.6263 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [202/782] Loss: 0.6331 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [203/782] Loss: 0.5860 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [204/782] Loss: 0.7773 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [205/782] Loss: 0.7001 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [206/782] Loss: 0.6107 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [207/782] Loss: 0.3925 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [208/782] Loss: 0.7014 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [209/782] Loss: 0.5559 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [210/782] Loss: 0.6880 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [211/782] Loss: 0.4774 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [212/782] Loss: 0.5985 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [213/782] Loss: 0.3468 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [214/782] Loss: 0.4111 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [215/782] Loss: 0.4734 | Acc: 77.97%\n",
      "Train Epoch [58/100] Batch [216/782] Loss: 0.5065 | Acc: 77.99%\n",
      "Train Epoch [58/100] Batch [217/782] Loss: 0.4569 | Acc: 78.00%\n",
      "Train Epoch [58/100] Batch [218/782] Loss: 0.5506 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [219/782] Loss: 0.4870 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [220/782] Loss: 0.6629 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [221/782] Loss: 0.5771 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [222/782] Loss: 0.5147 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [223/782] Loss: 0.6391 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [224/782] Loss: 0.8926 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [225/782] Loss: 0.8280 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [226/782] Loss: 0.4840 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [227/782] Loss: 0.6704 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [228/782] Loss: 0.5652 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [229/782] Loss: 0.5928 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [230/782] Loss: 0.6177 | Acc: 78.03%\n",
      "Train Epoch [58/100] Batch [231/782] Loss: 0.6182 | Acc: 78.02%\n",
      "Train Epoch [58/100] Batch [232/782] Loss: 0.5470 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [233/782] Loss: 0.6551 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [234/782] Loss: 0.6084 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [235/782] Loss: 0.4283 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [236/782] Loss: 0.6544 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [237/782] Loss: 0.5109 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [238/782] Loss: 0.9428 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [239/782] Loss: 0.5524 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [240/782] Loss: 0.5836 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [241/782] Loss: 0.5615 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [242/782] Loss: 0.5767 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [243/782] Loss: 0.6366 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [244/782] Loss: 0.5982 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [245/782] Loss: 0.7758 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [246/782] Loss: 0.4274 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [247/782] Loss: 0.5696 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [248/782] Loss: 0.6574 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [249/782] Loss: 0.6865 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [250/782] Loss: 0.6118 | Acc: 78.13%\n",
      "Train Epoch [58/100] Batch [251/782] Loss: 0.5537 | Acc: 78.13%\n",
      "Train Epoch [58/100] Batch [252/782] Loss: 0.5919 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [253/782] Loss: 0.5634 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [254/782] Loss: 0.5260 | Acc: 78.16%\n",
      "Train Epoch [58/100] Batch [255/782] Loss: 0.6504 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [256/782] Loss: 0.6245 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [257/782] Loss: 0.6012 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [258/782] Loss: 0.7967 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [259/782] Loss: 0.6182 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [260/782] Loss: 0.4121 | Acc: 78.18%\n",
      "Train Epoch [58/100] Batch [261/782] Loss: 0.6230 | Acc: 78.18%\n",
      "Train Epoch [58/100] Batch [262/782] Loss: 0.7419 | Acc: 78.18%\n",
      "Train Epoch [58/100] Batch [263/782] Loss: 0.6506 | Acc: 78.19%\n",
      "Train Epoch [58/100] Batch [264/782] Loss: 0.5218 | Acc: 78.18%\n",
      "Train Epoch [58/100] Batch [265/782] Loss: 0.4071 | Acc: 78.23%\n",
      "Train Epoch [58/100] Batch [266/782] Loss: 0.7691 | Acc: 78.21%\n",
      "Train Epoch [58/100] Batch [267/782] Loss: 0.7174 | Acc: 78.18%\n",
      "Train Epoch [58/100] Batch [268/782] Loss: 0.6389 | Acc: 78.17%\n",
      "Train Epoch [58/100] Batch [269/782] Loss: 0.6061 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [270/782] Loss: 0.4507 | Acc: 78.17%\n",
      "Train Epoch [58/100] Batch [271/782] Loss: 0.7014 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [272/782] Loss: 0.6251 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [273/782] Loss: 0.5449 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [274/782] Loss: 0.6029 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [275/782] Loss: 0.6166 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [276/782] Loss: 0.5117 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [277/782] Loss: 0.5386 | Acc: 78.12%\n",
      "Train Epoch [58/100] Batch [278/782] Loss: 0.6192 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [279/782] Loss: 0.6960 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [280/782] Loss: 0.5826 | Acc: 78.13%\n",
      "Train Epoch [58/100] Batch [281/782] Loss: 0.4510 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [282/782] Loss: 0.6009 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [283/782] Loss: 0.6767 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [284/782] Loss: 0.5934 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [285/782] Loss: 0.6007 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [286/782] Loss: 0.5226 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [287/782] Loss: 0.5362 | Acc: 78.14%\n",
      "Train Epoch [58/100] Batch [288/782] Loss: 0.9873 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [289/782] Loss: 0.7961 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [290/782] Loss: 0.5905 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [291/782] Loss: 0.6295 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [292/782] Loss: 0.6547 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [293/782] Loss: 0.5631 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [294/782] Loss: 0.6034 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [295/782] Loss: 0.5859 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [296/782] Loss: 0.4430 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [297/782] Loss: 0.6725 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [298/782] Loss: 0.4858 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [299/782] Loss: 0.5594 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [300/782] Loss: 0.7578 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [301/782] Loss: 0.3578 | Acc: 78.13%\n",
      "Train Epoch [58/100] Batch [302/782] Loss: 0.4208 | Acc: 78.16%\n",
      "Train Epoch [58/100] Batch [303/782] Loss: 0.4653 | Acc: 78.17%\n",
      "Train Epoch [58/100] Batch [304/782] Loss: 0.5726 | Acc: 78.17%\n",
      "Train Epoch [58/100] Batch [305/782] Loss: 0.8523 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [306/782] Loss: 0.5654 | Acc: 78.15%\n",
      "Train Epoch [58/100] Batch [307/782] Loss: 0.8149 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [308/782] Loss: 0.6849 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [309/782] Loss: 0.4988 | Acc: 78.10%\n",
      "Train Epoch [58/100] Batch [310/782] Loss: 0.7795 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [311/782] Loss: 0.5680 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [312/782] Loss: 0.5523 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [313/782] Loss: 0.9205 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [314/782] Loss: 0.7351 | Acc: 78.03%\n",
      "Train Epoch [58/100] Batch [315/782] Loss: 0.4757 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [316/782] Loss: 0.5231 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [317/782] Loss: 0.6598 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [318/782] Loss: 0.5993 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [319/782] Loss: 0.4155 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [320/782] Loss: 0.4708 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [321/782] Loss: 0.6246 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [322/782] Loss: 0.5836 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [323/782] Loss: 0.5649 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [324/782] Loss: 0.6468 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [325/782] Loss: 0.4776 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [326/782] Loss: 0.4548 | Acc: 78.09%\n",
      "Train Epoch [58/100] Batch [327/782] Loss: 0.4377 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [328/782] Loss: 0.6112 | Acc: 78.11%\n",
      "Train Epoch [58/100] Batch [329/782] Loss: 0.8077 | Acc: 78.08%\n",
      "Train Epoch [58/100] Batch [330/782] Loss: 0.8372 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [331/782] Loss: 0.8133 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [332/782] Loss: 0.7543 | Acc: 78.02%\n",
      "Train Epoch [58/100] Batch [333/782] Loss: 0.7779 | Acc: 78.00%\n",
      "Train Epoch [58/100] Batch [334/782] Loss: 0.4346 | Acc: 78.02%\n",
      "Train Epoch [58/100] Batch [335/782] Loss: 0.5229 | Acc: 78.01%\n",
      "Train Epoch [58/100] Batch [336/782] Loss: 0.7633 | Acc: 78.01%\n",
      "Train Epoch [58/100] Batch [337/782] Loss: 0.6987 | Acc: 78.00%\n",
      "Train Epoch [58/100] Batch [338/782] Loss: 0.4351 | Acc: 78.03%\n",
      "Train Epoch [58/100] Batch [339/782] Loss: 0.4282 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [340/782] Loss: 0.7522 | Acc: 78.03%\n",
      "Train Epoch [58/100] Batch [341/782] Loss: 0.6587 | Acc: 78.02%\n",
      "Train Epoch [58/100] Batch [342/782] Loss: 0.4238 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [343/782] Loss: 0.5883 | Acc: 78.05%\n",
      "Train Epoch [58/100] Batch [344/782] Loss: 0.6163 | Acc: 78.07%\n",
      "Train Epoch [58/100] Batch [345/782] Loss: 0.7026 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [346/782] Loss: 0.5341 | Acc: 78.06%\n",
      "Train Epoch [58/100] Batch [347/782] Loss: 0.6990 | Acc: 78.04%\n",
      "Train Epoch [58/100] Batch [348/782] Loss: 0.5777 | Acc: 78.02%\n",
      "Train Epoch [58/100] Batch [349/782] Loss: 0.7865 | Acc: 78.00%\n",
      "Train Epoch [58/100] Batch [350/782] Loss: 0.8644 | Acc: 77.98%\n",
      "Train Epoch [58/100] Batch [351/782] Loss: 0.5201 | Acc: 77.99%\n",
      "Train Epoch [58/100] Batch [352/782] Loss: 0.6852 | Acc: 77.98%\n",
      "Train Epoch [58/100] Batch [353/782] Loss: 0.6615 | Acc: 77.97%\n",
      "Train Epoch [58/100] Batch [354/782] Loss: 0.5761 | Acc: 77.98%\n",
      "Train Epoch [58/100] Batch [355/782] Loss: 0.6214 | Acc: 77.98%\n",
      "Train Epoch [58/100] Batch [356/782] Loss: 0.6279 | Acc: 77.99%\n",
      "Train Epoch [58/100] Batch [357/782] Loss: 0.7345 | Acc: 77.98%\n",
      "Train Epoch [58/100] Batch [358/782] Loss: 0.7836 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [359/782] Loss: 0.7668 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [360/782] Loss: 0.5115 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [361/782] Loss: 0.5845 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [362/782] Loss: 0.5420 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [363/782] Loss: 0.5240 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [364/782] Loss: 0.6488 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [365/782] Loss: 0.4575 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [366/782] Loss: 0.6295 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [367/782] Loss: 0.6275 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [368/782] Loss: 0.7533 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [369/782] Loss: 0.7241 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [370/782] Loss: 0.5802 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [371/782] Loss: 0.4739 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [372/782] Loss: 0.7169 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [373/782] Loss: 0.7234 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [374/782] Loss: 0.5216 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [375/782] Loss: 0.5817 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [376/782] Loss: 0.8033 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [377/782] Loss: 0.6053 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [378/782] Loss: 0.4582 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [379/782] Loss: 0.6776 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [380/782] Loss: 0.5700 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [381/782] Loss: 0.5088 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [382/782] Loss: 0.5046 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [383/782] Loss: 0.7446 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [384/782] Loss: 0.5686 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [385/782] Loss: 0.7033 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [386/782] Loss: 0.7620 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [387/782] Loss: 0.7582 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [388/782] Loss: 0.7730 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [389/782] Loss: 0.9465 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [390/782] Loss: 0.6811 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [391/782] Loss: 0.5479 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [392/782] Loss: 0.5037 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [393/782] Loss: 0.5741 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [394/782] Loss: 0.6907 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [395/782] Loss: 0.7597 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [396/782] Loss: 0.5224 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [397/782] Loss: 0.6229 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [398/782] Loss: 0.7499 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [399/782] Loss: 0.6385 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [400/782] Loss: 0.7355 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [401/782] Loss: 0.6972 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [402/782] Loss: 0.7326 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [403/782] Loss: 0.4579 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [404/782] Loss: 0.6412 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [405/782] Loss: 0.6560 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [406/782] Loss: 0.5319 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [407/782] Loss: 0.9052 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [408/782] Loss: 0.5387 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [409/782] Loss: 0.6351 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [410/782] Loss: 0.3703 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [411/782] Loss: 0.5427 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [412/782] Loss: 0.6847 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [413/782] Loss: 0.7013 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [414/782] Loss: 0.6112 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [415/782] Loss: 0.5832 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [416/782] Loss: 0.7969 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [417/782] Loss: 0.6499 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [418/782] Loss: 0.6546 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [419/782] Loss: 0.5372 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [420/782] Loss: 0.5283 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [421/782] Loss: 0.6269 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [422/782] Loss: 0.4867 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [423/782] Loss: 0.7991 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [424/782] Loss: 0.5063 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [425/782] Loss: 0.6663 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [426/782] Loss: 0.4833 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [427/782] Loss: 0.7373 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [428/782] Loss: 0.5066 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [429/782] Loss: 0.8283 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [430/782] Loss: 0.5610 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [431/782] Loss: 0.6880 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [432/782] Loss: 0.7410 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [433/782] Loss: 0.5504 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [434/782] Loss: 0.7036 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [435/782] Loss: 0.7020 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [436/782] Loss: 0.5468 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [437/782] Loss: 0.6828 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [438/782] Loss: 0.5388 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [439/782] Loss: 0.5380 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [440/782] Loss: 0.6680 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [441/782] Loss: 0.5787 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [442/782] Loss: 0.5665 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [443/782] Loss: 0.8961 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [444/782] Loss: 0.7131 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [445/782] Loss: 0.6911 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [446/782] Loss: 0.6497 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [447/782] Loss: 0.6949 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [448/782] Loss: 0.6227 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [449/782] Loss: 0.6344 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [450/782] Loss: 0.5987 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [451/782] Loss: 0.6404 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [452/782] Loss: 0.4532 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [453/782] Loss: 0.5547 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [454/782] Loss: 0.5242 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [455/782] Loss: 0.8256 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [456/782] Loss: 0.6183 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [457/782] Loss: 0.6122 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [458/782] Loss: 0.4431 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [459/782] Loss: 0.7695 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [460/782] Loss: 0.7227 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [461/782] Loss: 0.5605 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [462/782] Loss: 0.5215 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [463/782] Loss: 0.4998 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [464/782] Loss: 0.5670 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [465/782] Loss: 0.4882 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [466/782] Loss: 0.5271 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [467/782] Loss: 0.8075 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [468/782] Loss: 0.7699 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [469/782] Loss: 0.7591 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [470/782] Loss: 0.4041 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [471/782] Loss: 0.5327 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [472/782] Loss: 0.6361 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [473/782] Loss: 0.5562 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [474/782] Loss: 0.6805 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [475/782] Loss: 0.6243 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [476/782] Loss: 0.5262 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [477/782] Loss: 0.6531 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [478/782] Loss: 0.6687 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [479/782] Loss: 0.5498 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [480/782] Loss: 0.8022 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [481/782] Loss: 0.6399 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [482/782] Loss: 0.7398 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [483/782] Loss: 0.3865 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [484/782] Loss: 0.8255 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [485/782] Loss: 0.5083 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [486/782] Loss: 0.7387 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [487/782] Loss: 0.5791 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [488/782] Loss: 0.7041 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [489/782] Loss: 0.4874 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [490/782] Loss: 0.5898 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [491/782] Loss: 0.4300 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [492/782] Loss: 0.6679 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [493/782] Loss: 0.8142 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [494/782] Loss: 0.6413 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [495/782] Loss: 0.7570 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [496/782] Loss: 0.5797 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [497/782] Loss: 0.7108 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [498/782] Loss: 0.4516 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [499/782] Loss: 0.4632 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [500/782] Loss: 0.6231 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [501/782] Loss: 0.7740 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [502/782] Loss: 0.5756 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [503/782] Loss: 0.6455 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [504/782] Loss: 0.5289 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [505/782] Loss: 0.4893 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [506/782] Loss: 0.3929 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [507/782] Loss: 0.5311 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [508/782] Loss: 0.8398 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [509/782] Loss: 0.6722 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [510/782] Loss: 0.5499 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [511/782] Loss: 0.5478 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [512/782] Loss: 0.5935 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [513/782] Loss: 0.4905 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [514/782] Loss: 0.5460 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [515/782] Loss: 0.6992 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [516/782] Loss: 0.5631 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [517/782] Loss: 0.5461 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [518/782] Loss: 0.5620 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [519/782] Loss: 0.4402 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [520/782] Loss: 0.6487 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [521/782] Loss: 0.6415 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [522/782] Loss: 0.5461 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [523/782] Loss: 0.4937 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [524/782] Loss: 0.7734 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [525/782] Loss: 0.5938 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [526/782] Loss: 0.9027 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [527/782] Loss: 0.5803 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [528/782] Loss: 0.5175 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [529/782] Loss: 0.4901 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [530/782] Loss: 0.4721 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [531/782] Loss: 0.8020 | Acc: 77.96%\n",
      "Train Epoch [58/100] Batch [532/782] Loss: 0.6352 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [533/782] Loss: 0.5824 | Acc: 77.95%\n",
      "Train Epoch [58/100] Batch [534/782] Loss: 0.6846 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [535/782] Loss: 0.6276 | Acc: 77.94%\n",
      "Train Epoch [58/100] Batch [536/782] Loss: 0.9019 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [537/782] Loss: 0.6160 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [538/782] Loss: 0.4450 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [539/782] Loss: 0.6480 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [540/782] Loss: 0.6217 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [541/782] Loss: 0.5688 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [542/782] Loss: 0.6349 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [543/782] Loss: 0.7043 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [544/782] Loss: 0.6822 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [545/782] Loss: 0.5820 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [546/782] Loss: 0.4588 | Acc: 77.93%\n",
      "Train Epoch [58/100] Batch [547/782] Loss: 0.7856 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [548/782] Loss: 0.7148 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [549/782] Loss: 0.7846 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [550/782] Loss: 0.4415 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [551/782] Loss: 0.7961 | Acc: 77.92%\n",
      "Train Epoch [58/100] Batch [552/782] Loss: 0.6836 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [553/782] Loss: 0.7017 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [554/782] Loss: 0.7558 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [555/782] Loss: 0.7695 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [556/782] Loss: 0.5327 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [557/782] Loss: 0.7423 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [558/782] Loss: 0.9086 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [559/782] Loss: 0.7412 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [560/782] Loss: 0.7670 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [561/782] Loss: 0.5517 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [562/782] Loss: 0.6840 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [563/782] Loss: 0.6506 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [564/782] Loss: 0.6901 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [565/782] Loss: 0.6624 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [566/782] Loss: 0.5605 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [567/782] Loss: 0.6291 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [568/782] Loss: 0.5812 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [569/782] Loss: 0.6252 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [570/782] Loss: 0.6245 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [571/782] Loss: 0.6627 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [572/782] Loss: 0.6839 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [573/782] Loss: 0.7545 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [574/782] Loss: 0.5185 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [575/782] Loss: 0.6142 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [576/782] Loss: 0.4324 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [577/782] Loss: 0.7048 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [578/782] Loss: 0.5965 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [579/782] Loss: 0.4469 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [580/782] Loss: 0.6102 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [581/782] Loss: 0.6661 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [582/782] Loss: 0.5402 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [583/782] Loss: 0.7149 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [584/782] Loss: 0.8081 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [585/782] Loss: 0.5889 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [586/782] Loss: 0.7454 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [587/782] Loss: 0.5398 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [588/782] Loss: 0.6720 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [589/782] Loss: 0.6971 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [590/782] Loss: 0.6567 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [591/782] Loss: 0.6075 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [592/782] Loss: 0.8020 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [593/782] Loss: 0.8617 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [594/782] Loss: 0.6656 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [595/782] Loss: 0.9207 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [596/782] Loss: 0.6492 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [597/782] Loss: 0.5527 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [598/782] Loss: 0.6298 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [599/782] Loss: 0.6523 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [600/782] Loss: 0.4991 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [601/782] Loss: 0.5487 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [602/782] Loss: 0.5189 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [603/782] Loss: 0.5926 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [604/782] Loss: 0.6341 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [605/782] Loss: 0.5736 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [606/782] Loss: 0.5719 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [607/782] Loss: 0.5615 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [608/782] Loss: 0.5151 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [609/782] Loss: 0.5822 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [610/782] Loss: 0.7780 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [611/782] Loss: 0.4801 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [612/782] Loss: 0.6696 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [613/782] Loss: 0.3877 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [614/782] Loss: 0.5650 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [615/782] Loss: 0.7015 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [616/782] Loss: 0.7275 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [617/782] Loss: 0.5810 | Acc: 77.91%\n",
      "Train Epoch [58/100] Batch [618/782] Loss: 0.7566 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [619/782] Loss: 0.6837 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [620/782] Loss: 0.6656 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [621/782] Loss: 0.6855 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [622/782] Loss: 0.5898 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [623/782] Loss: 0.6079 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [624/782] Loss: 0.4200 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [625/782] Loss: 0.8093 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [626/782] Loss: 0.6877 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [627/782] Loss: 0.6092 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [628/782] Loss: 0.5964 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [629/782] Loss: 0.5455 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [630/782] Loss: 0.5494 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [631/782] Loss: 0.5028 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [632/782] Loss: 0.7159 | Acc: 77.90%\n",
      "Train Epoch [58/100] Batch [633/782] Loss: 0.7226 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [634/782] Loss: 0.7464 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [635/782] Loss: 0.7212 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [636/782] Loss: 0.5373 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [637/782] Loss: 0.7165 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [638/782] Loss: 0.6863 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [639/782] Loss: 0.6653 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [640/782] Loss: 0.7270 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [641/782] Loss: 0.5128 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [642/782] Loss: 0.4546 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [643/782] Loss: 0.7017 | Acc: 77.89%\n",
      "Train Epoch [58/100] Batch [644/782] Loss: 0.8026 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [645/782] Loss: 0.6724 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [646/782] Loss: 0.4925 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [647/782] Loss: 0.7124 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [648/782] Loss: 0.6486 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [649/782] Loss: 0.5017 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [650/782] Loss: 0.4905 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [651/782] Loss: 0.8209 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [652/782] Loss: 0.6390 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [653/782] Loss: 0.7524 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [654/782] Loss: 0.3570 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [655/782] Loss: 0.5140 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [656/782] Loss: 0.6775 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [657/782] Loss: 0.5716 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [658/782] Loss: 0.5577 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [659/782] Loss: 0.5695 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [660/782] Loss: 0.6561 | Acc: 77.86%\n",
      "Train Epoch [58/100] Batch [661/782] Loss: 0.5347 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [662/782] Loss: 0.5915 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [663/782] Loss: 0.5706 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [664/782] Loss: 0.5449 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [665/782] Loss: 0.6233 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [666/782] Loss: 0.5350 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [667/782] Loss: 0.5883 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [668/782] Loss: 0.5892 | Acc: 77.88%\n",
      "Train Epoch [58/100] Batch [669/782] Loss: 0.6736 | Acc: 77.87%\n",
      "Train Epoch [58/100] Batch [670/782] Loss: 0.8360 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [671/782] Loss: 0.5536 | Acc: 77.85%\n",
      "Train Epoch [58/100] Batch [672/782] Loss: 0.7404 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [673/782] Loss: 0.5756 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [674/782] Loss: 0.6644 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [675/782] Loss: 0.5698 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [676/782] Loss: 0.6431 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [677/782] Loss: 0.6408 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [678/782] Loss: 0.7091 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [679/782] Loss: 0.6398 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [680/782] Loss: 0.7611 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [681/782] Loss: 0.5865 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [682/782] Loss: 0.6390 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [683/782] Loss: 0.8196 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [684/782] Loss: 0.7281 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [685/782] Loss: 0.7333 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [686/782] Loss: 0.7282 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [687/782] Loss: 0.6094 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [688/782] Loss: 0.8421 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [689/782] Loss: 0.5020 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [690/782] Loss: 0.5873 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [691/782] Loss: 0.5641 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [692/782] Loss: 0.8815 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [693/782] Loss: 0.4827 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [694/782] Loss: 0.7488 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [695/782] Loss: 0.4849 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [696/782] Loss: 0.5889 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [697/782] Loss: 0.5516 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [698/782] Loss: 0.6502 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [699/782] Loss: 0.5610 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [700/782] Loss: 0.6811 | Acc: 77.74%\n",
      "Train Epoch [58/100] Batch [701/782] Loss: 0.5766 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [702/782] Loss: 0.4295 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [703/782] Loss: 0.5555 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [704/782] Loss: 0.5964 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [705/782] Loss: 0.5831 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [706/782] Loss: 0.6594 | Acc: 77.75%\n",
      "Train Epoch [58/100] Batch [707/782] Loss: 0.3983 | Acc: 77.77%\n",
      "Train Epoch [58/100] Batch [708/782] Loss: 0.5496 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [709/782] Loss: 0.4455 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [710/782] Loss: 0.6133 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [711/782] Loss: 0.5654 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [712/782] Loss: 0.6912 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [713/782] Loss: 0.6813 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [714/782] Loss: 0.5183 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [715/782] Loss: 0.7363 | Acc: 77.76%\n",
      "Train Epoch [58/100] Batch [716/782] Loss: 0.4483 | Acc: 77.78%\n",
      "Train Epoch [58/100] Batch [717/782] Loss: 0.5584 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [718/782] Loss: 0.5970 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [719/782] Loss: 0.5887 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [720/782] Loss: 0.5133 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [721/782] Loss: 0.6471 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [722/782] Loss: 0.4408 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [723/782] Loss: 0.4668 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [724/782] Loss: 0.6431 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [725/782] Loss: 0.6369 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [726/782] Loss: 0.5584 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [727/782] Loss: 0.6666 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [728/782] Loss: 0.6217 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [729/782] Loss: 0.5850 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [730/782] Loss: 0.6687 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [731/782] Loss: 0.6090 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [732/782] Loss: 0.6814 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [733/782] Loss: 0.4700 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [734/782] Loss: 0.5924 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [735/782] Loss: 0.8801 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [736/782] Loss: 0.5923 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [737/782] Loss: 0.5492 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [738/782] Loss: 0.7898 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [739/782] Loss: 0.5608 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [740/782] Loss: 0.5085 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [741/782] Loss: 0.5452 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [742/782] Loss: 0.6620 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [743/782] Loss: 0.5491 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [744/782] Loss: 0.6271 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [745/782] Loss: 0.7039 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [746/782] Loss: 0.4659 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [747/782] Loss: 0.5767 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [748/782] Loss: 0.5885 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [749/782] Loss: 0.6291 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [750/782] Loss: 0.8587 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [751/782] Loss: 0.6943 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [752/782] Loss: 0.4218 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [753/782] Loss: 0.5016 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [754/782] Loss: 0.5150 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [755/782] Loss: 0.4189 | Acc: 77.84%\n",
      "Train Epoch [58/100] Batch [756/782] Loss: 0.6691 | Acc: 77.83%\n",
      "Train Epoch [58/100] Batch [757/782] Loss: 0.7776 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [758/782] Loss: 0.7230 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [759/782] Loss: 0.7103 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [760/782] Loss: 0.5608 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [761/782] Loss: 0.6714 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [762/782] Loss: 0.7120 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [763/782] Loss: 0.6564 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [764/782] Loss: 0.6685 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [765/782] Loss: 0.4917 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [766/782] Loss: 0.7513 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [767/782] Loss: 0.6187 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [768/782] Loss: 0.6315 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [769/782] Loss: 0.6262 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [770/782] Loss: 0.5529 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [771/782] Loss: 0.6736 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [772/782] Loss: 0.4675 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [773/782] Loss: 0.5787 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [774/782] Loss: 0.4955 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [775/782] Loss: 0.6573 | Acc: 77.82%\n",
      "Train Epoch [58/100] Batch [776/782] Loss: 0.6693 | Acc: 77.81%\n",
      "Train Epoch [58/100] Batch [777/782] Loss: 0.8112 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [778/782] Loss: 0.7353 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [779/782] Loss: 0.6011 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [780/782] Loss: 0.7012 | Acc: 77.79%\n",
      "Train Epoch [58/100] Batch [781/782] Loss: 0.6381 | Acc: 77.80%\n",
      "Train Epoch [58/100] Batch [782/782] Loss: 0.6728 | Acc: 77.80%\n",
      "Epoch 58 completed in 29.74s.\n",
      "Test Epoch [58/100] Loss: 0.8682 | Acc: 72.60% | Inference Time: 8.21s\n",
      "Epoch 58 results saved to CSV.\n",
      "Epoch 59/100\n",
      "Train Epoch [59/100] Batch [1/782] Loss: 0.5281 | Acc: 81.25%\n",
      "Train Epoch [59/100] Batch [2/782] Loss: 0.5159 | Acc: 82.81%\n",
      "Train Epoch [59/100] Batch [3/782] Loss: 0.7004 | Acc: 81.25%\n",
      "Train Epoch [59/100] Batch [4/782] Loss: 0.6380 | Acc: 79.69%\n",
      "Train Epoch [59/100] Batch [5/782] Loss: 0.5791 | Acc: 79.06%\n",
      "Train Epoch [59/100] Batch [6/782] Loss: 0.5790 | Acc: 78.65%\n",
      "Train Epoch [59/100] Batch [7/782] Loss: 0.8114 | Acc: 77.23%\n",
      "Train Epoch [59/100] Batch [8/782] Loss: 0.3740 | Acc: 78.32%\n",
      "Train Epoch [59/100] Batch [9/782] Loss: 0.5203 | Acc: 78.82%\n",
      "Train Epoch [59/100] Batch [10/782] Loss: 0.5202 | Acc: 79.22%\n",
      "Train Epoch [59/100] Batch [11/782] Loss: 0.6602 | Acc: 78.98%\n",
      "Train Epoch [59/100] Batch [12/782] Loss: 0.5634 | Acc: 79.17%\n",
      "Train Epoch [59/100] Batch [13/782] Loss: 0.6930 | Acc: 78.73%\n",
      "Train Epoch [59/100] Batch [14/782] Loss: 0.5257 | Acc: 79.02%\n",
      "Train Epoch [59/100] Batch [15/782] Loss: 0.7109 | Acc: 78.33%\n",
      "Train Epoch [59/100] Batch [16/782] Loss: 0.3984 | Acc: 78.91%\n",
      "Train Epoch [59/100] Batch [17/782] Loss: 0.5495 | Acc: 78.77%\n",
      "Train Epoch [59/100] Batch [18/782] Loss: 0.5669 | Acc: 78.73%\n",
      "Train Epoch [59/100] Batch [19/782] Loss: 0.6897 | Acc: 78.62%\n",
      "Train Epoch [59/100] Batch [20/782] Loss: 0.8615 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [21/782] Loss: 0.5806 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [22/782] Loss: 0.7262 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [23/782] Loss: 0.6145 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [24/782] Loss: 0.5658 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [25/782] Loss: 0.5437 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [26/782] Loss: 0.5298 | Acc: 78.00%\n",
      "Train Epoch [59/100] Batch [27/782] Loss: 0.4942 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [28/782] Loss: 0.5122 | Acc: 78.24%\n",
      "Train Epoch [59/100] Batch [29/782] Loss: 0.7161 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [30/782] Loss: 0.6127 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [31/782] Loss: 0.4854 | Acc: 78.28%\n",
      "Train Epoch [59/100] Batch [32/782] Loss: 0.4191 | Acc: 78.56%\n",
      "Train Epoch [59/100] Batch [33/782] Loss: 0.6690 | Acc: 78.55%\n",
      "Train Epoch [59/100] Batch [34/782] Loss: 0.6488 | Acc: 78.45%\n",
      "Train Epoch [59/100] Batch [35/782] Loss: 0.6894 | Acc: 78.35%\n",
      "Train Epoch [59/100] Batch [36/782] Loss: 0.8241 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [37/782] Loss: 0.5085 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [38/782] Loss: 0.4790 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [39/782] Loss: 0.5006 | Acc: 78.21%\n",
      "Train Epoch [59/100] Batch [40/782] Loss: 0.5268 | Acc: 78.24%\n",
      "Train Epoch [59/100] Batch [41/782] Loss: 0.7690 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [42/782] Loss: 0.6261 | Acc: 78.16%\n",
      "Train Epoch [59/100] Batch [43/782] Loss: 0.6675 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [44/782] Loss: 0.6862 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [45/782] Loss: 0.7826 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [46/782] Loss: 0.6754 | Acc: 77.55%\n",
      "Train Epoch [59/100] Batch [47/782] Loss: 0.6757 | Acc: 77.53%\n",
      "Train Epoch [59/100] Batch [48/782] Loss: 0.4725 | Acc: 77.54%\n",
      "Train Epoch [59/100] Batch [49/782] Loss: 0.7472 | Acc: 77.49%\n",
      "Train Epoch [59/100] Batch [50/782] Loss: 0.6115 | Acc: 77.53%\n",
      "Train Epoch [59/100] Batch [51/782] Loss: 0.7023 | Acc: 77.36%\n",
      "Train Epoch [59/100] Batch [52/782] Loss: 0.6414 | Acc: 77.37%\n",
      "Train Epoch [59/100] Batch [53/782] Loss: 0.6873 | Acc: 77.21%\n",
      "Train Epoch [59/100] Batch [54/782] Loss: 0.5284 | Acc: 77.37%\n",
      "Train Epoch [59/100] Batch [55/782] Loss: 0.6889 | Acc: 77.39%\n",
      "Train Epoch [59/100] Batch [56/782] Loss: 0.4515 | Acc: 77.54%\n",
      "Train Epoch [59/100] Batch [57/782] Loss: 0.5979 | Acc: 77.60%\n",
      "Train Epoch [59/100] Batch [58/782] Loss: 0.6106 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [59/782] Loss: 0.4283 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [60/782] Loss: 0.7766 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [61/782] Loss: 0.5212 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [62/782] Loss: 0.7888 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [63/782] Loss: 0.6204 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [64/782] Loss: 0.6374 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [65/782] Loss: 0.5086 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [66/782] Loss: 0.8137 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [67/782] Loss: 0.6811 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [68/782] Loss: 0.5273 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [69/782] Loss: 0.5921 | Acc: 77.63%\n",
      "Train Epoch [59/100] Batch [70/782] Loss: 0.6138 | Acc: 77.59%\n",
      "Train Epoch [59/100] Batch [71/782] Loss: 0.5317 | Acc: 77.68%\n",
      "Train Epoch [59/100] Batch [72/782] Loss: 0.4764 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [73/782] Loss: 0.5783 | Acc: 77.83%\n",
      "Train Epoch [59/100] Batch [74/782] Loss: 0.7186 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [75/782] Loss: 0.7199 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [76/782] Loss: 0.5252 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [77/782] Loss: 0.5731 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [78/782] Loss: 0.5703 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [79/782] Loss: 0.6245 | Acc: 77.99%\n",
      "Train Epoch [59/100] Batch [80/782] Loss: 0.4755 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [81/782] Loss: 0.6675 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [82/782] Loss: 0.4086 | Acc: 78.14%\n",
      "Train Epoch [59/100] Batch [83/782] Loss: 0.6882 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [84/782] Loss: 0.8912 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [85/782] Loss: 0.7881 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [86/782] Loss: 0.6008 | Acc: 77.83%\n",
      "Train Epoch [59/100] Batch [87/782] Loss: 0.7520 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [88/782] Loss: 0.5757 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [89/782] Loss: 0.4857 | Acc: 77.83%\n",
      "Train Epoch [59/100] Batch [90/782] Loss: 0.5761 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [91/782] Loss: 0.6459 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [92/782] Loss: 0.5812 | Acc: 77.82%\n",
      "Train Epoch [59/100] Batch [93/782] Loss: 0.4249 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [94/782] Loss: 0.6281 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [95/782] Loss: 0.6641 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [96/782] Loss: 0.4752 | Acc: 77.99%\n",
      "Train Epoch [59/100] Batch [97/782] Loss: 0.7042 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [98/782] Loss: 0.6606 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [99/782] Loss: 0.7010 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [100/782] Loss: 0.4268 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [101/782] Loss: 0.6206 | Acc: 78.00%\n",
      "Train Epoch [59/100] Batch [102/782] Loss: 0.8015 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [103/782] Loss: 0.5701 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [104/782] Loss: 0.4895 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [105/782] Loss: 0.5576 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [106/782] Loss: 0.4184 | Acc: 78.11%\n",
      "Train Epoch [59/100] Batch [107/782] Loss: 0.8834 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [108/782] Loss: 0.6349 | Acc: 77.99%\n",
      "Train Epoch [59/100] Batch [109/782] Loss: 0.5015 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [110/782] Loss: 0.6357 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [111/782] Loss: 0.5287 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [112/782] Loss: 0.6040 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [113/782] Loss: 0.6193 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [114/782] Loss: 0.6537 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [115/782] Loss: 0.6152 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [116/782] Loss: 0.7044 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [117/782] Loss: 0.6998 | Acc: 78.00%\n",
      "Train Epoch [59/100] Batch [118/782] Loss: 0.6306 | Acc: 77.99%\n",
      "Train Epoch [59/100] Batch [119/782] Loss: 0.5376 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [120/782] Loss: 0.6196 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [121/782] Loss: 0.6773 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [122/782] Loss: 0.5229 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [123/782] Loss: 0.6480 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [124/782] Loss: 0.8367 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [125/782] Loss: 0.6690 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [126/782] Loss: 0.5810 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [127/782] Loss: 0.5428 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [128/782] Loss: 0.5376 | Acc: 78.00%\n",
      "Train Epoch [59/100] Batch [129/782] Loss: 0.7090 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [130/782] Loss: 0.7140 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [131/782] Loss: 0.6068 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [132/782] Loss: 0.7594 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [133/782] Loss: 0.6217 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [134/782] Loss: 0.5569 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [135/782] Loss: 0.6093 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [136/782] Loss: 0.6062 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [137/782] Loss: 0.6732 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [138/782] Loss: 0.4720 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [139/782] Loss: 0.5840 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [140/782] Loss: 0.5388 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [141/782] Loss: 0.4565 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [142/782] Loss: 0.6981 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [143/782] Loss: 0.5619 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [144/782] Loss: 0.5830 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [145/782] Loss: 0.6355 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [146/782] Loss: 0.6187 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [147/782] Loss: 0.7122 | Acc: 77.83%\n",
      "Train Epoch [59/100] Batch [148/782] Loss: 0.8255 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [149/782] Loss: 0.7752 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [150/782] Loss: 0.5314 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [151/782] Loss: 0.3803 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [152/782] Loss: 0.5989 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [153/782] Loss: 0.6950 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [154/782] Loss: 0.7221 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [155/782] Loss: 0.6998 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [156/782] Loss: 0.5928 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [157/782] Loss: 0.3967 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [158/782] Loss: 0.5226 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [159/782] Loss: 0.7737 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [160/782] Loss: 0.5117 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [161/782] Loss: 0.4539 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [162/782] Loss: 0.5380 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [163/782] Loss: 0.9044 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [164/782] Loss: 0.5516 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [165/782] Loss: 0.6207 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [166/782] Loss: 0.7484 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [167/782] Loss: 0.5989 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [168/782] Loss: 0.6354 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [169/782] Loss: 0.6356 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [170/782] Loss: 0.5854 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [171/782] Loss: 0.6885 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [172/782] Loss: 0.5081 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [173/782] Loss: 0.5486 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [174/782] Loss: 0.5109 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [175/782] Loss: 0.6118 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [176/782] Loss: 0.5394 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [177/782] Loss: 0.6634 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [178/782] Loss: 0.6515 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [179/782] Loss: 0.6169 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [180/782] Loss: 0.4625 | Acc: 77.80%\n",
      "Train Epoch [59/100] Batch [181/782] Loss: 0.7160 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [182/782] Loss: 0.6979 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [183/782] Loss: 0.6980 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [184/782] Loss: 0.6386 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [185/782] Loss: 0.6151 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [186/782] Loss: 0.6402 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [187/782] Loss: 0.7861 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [188/782] Loss: 0.7073 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [189/782] Loss: 0.5983 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [190/782] Loss: 0.7367 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [191/782] Loss: 0.8568 | Acc: 77.68%\n",
      "Train Epoch [59/100] Batch [192/782] Loss: 0.5682 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [193/782] Loss: 0.7138 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [194/782] Loss: 0.5794 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [195/782] Loss: 0.5681 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [196/782] Loss: 0.9240 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [197/782] Loss: 0.5024 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [198/782] Loss: 0.8930 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [199/782] Loss: 0.5836 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [200/782] Loss: 0.7805 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [201/782] Loss: 0.4157 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [202/782] Loss: 0.5001 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [203/782] Loss: 0.5353 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [204/782] Loss: 0.5164 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [205/782] Loss: 0.6887 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [206/782] Loss: 0.8329 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [207/782] Loss: 0.8847 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [208/782] Loss: 0.7878 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [209/782] Loss: 0.6704 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [210/782] Loss: 0.3518 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [211/782] Loss: 0.6180 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [212/782] Loss: 0.5668 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [213/782] Loss: 0.6437 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [214/782] Loss: 0.7076 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [215/782] Loss: 0.7899 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [216/782] Loss: 0.7254 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [217/782] Loss: 0.3758 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [218/782] Loss: 0.6720 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [219/782] Loss: 0.7556 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [220/782] Loss: 0.5248 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [221/782] Loss: 0.5053 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [222/782] Loss: 0.6840 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [223/782] Loss: 0.5785 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [224/782] Loss: 0.3571 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [225/782] Loss: 0.7698 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [226/782] Loss: 0.6545 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [227/782] Loss: 0.5769 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [228/782] Loss: 0.6572 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [229/782] Loss: 0.7204 | Acc: 77.65%\n",
      "Train Epoch [59/100] Batch [230/782] Loss: 0.5890 | Acc: 77.63%\n",
      "Train Epoch [59/100] Batch [231/782] Loss: 0.4774 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [232/782] Loss: 0.8197 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [233/782] Loss: 0.6055 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [234/782] Loss: 0.5825 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [235/782] Loss: 0.5470 | Acc: 77.65%\n",
      "Train Epoch [59/100] Batch [236/782] Loss: 0.5395 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [237/782] Loss: 0.4579 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [238/782] Loss: 0.7829 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [239/782] Loss: 0.9587 | Acc: 77.61%\n",
      "Train Epoch [59/100] Batch [240/782] Loss: 0.5553 | Acc: 77.61%\n",
      "Train Epoch [59/100] Batch [241/782] Loss: 0.5348 | Acc: 77.63%\n",
      "Train Epoch [59/100] Batch [242/782] Loss: 0.5681 | Acc: 77.63%\n",
      "Train Epoch [59/100] Batch [243/782] Loss: 0.3744 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [244/782] Loss: 0.6018 | Acc: 77.68%\n",
      "Train Epoch [59/100] Batch [245/782] Loss: 0.4906 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [246/782] Loss: 0.6191 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [247/782] Loss: 0.6335 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [248/782] Loss: 0.7038 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [249/782] Loss: 0.4904 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [250/782] Loss: 0.6644 | Acc: 77.65%\n",
      "Train Epoch [59/100] Batch [251/782] Loss: 0.7647 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [252/782] Loss: 0.6441 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [253/782] Loss: 0.6246 | Acc: 77.62%\n",
      "Train Epoch [59/100] Batch [254/782] Loss: 0.6051 | Acc: 77.62%\n",
      "Train Epoch [59/100] Batch [255/782] Loss: 0.7898 | Acc: 77.61%\n",
      "Train Epoch [59/100] Batch [256/782] Loss: 0.5452 | Acc: 77.62%\n",
      "Train Epoch [59/100] Batch [257/782] Loss: 0.5631 | Acc: 77.63%\n",
      "Train Epoch [59/100] Batch [258/782] Loss: 0.8225 | Acc: 77.60%\n",
      "Train Epoch [59/100] Batch [259/782] Loss: 0.7622 | Acc: 77.59%\n",
      "Train Epoch [59/100] Batch [260/782] Loss: 0.5104 | Acc: 77.60%\n",
      "Train Epoch [59/100] Batch [261/782] Loss: 0.6989 | Acc: 77.60%\n",
      "Train Epoch [59/100] Batch [262/782] Loss: 0.4467 | Acc: 77.64%\n",
      "Train Epoch [59/100] Batch [263/782] Loss: 0.4790 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [264/782] Loss: 0.8212 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [265/782] Loss: 0.5631 | Acc: 77.66%\n",
      "Train Epoch [59/100] Batch [266/782] Loss: 0.6527 | Acc: 77.67%\n",
      "Train Epoch [59/100] Batch [267/782] Loss: 0.5286 | Acc: 77.68%\n",
      "Train Epoch [59/100] Batch [268/782] Loss: 0.6525 | Acc: 77.69%\n",
      "Train Epoch [59/100] Batch [269/782] Loss: 0.4187 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [270/782] Loss: 0.6908 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [271/782] Loss: 0.6364 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [272/782] Loss: 0.6290 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [273/782] Loss: 0.4847 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [274/782] Loss: 0.5768 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [275/782] Loss: 0.6692 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [276/782] Loss: 0.5907 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [277/782] Loss: 0.6686 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [278/782] Loss: 0.5993 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [279/782] Loss: 0.5479 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [280/782] Loss: 0.6153 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [281/782] Loss: 0.7104 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [282/782] Loss: 0.6395 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [283/782] Loss: 0.7024 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [284/782] Loss: 0.8463 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [285/782] Loss: 0.5964 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [286/782] Loss: 0.8155 | Acc: 77.71%\n",
      "Train Epoch [59/100] Batch [287/782] Loss: 0.6571 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [288/782] Loss: 0.5263 | Acc: 77.75%\n",
      "Train Epoch [59/100] Batch [289/782] Loss: 0.8933 | Acc: 77.70%\n",
      "Train Epoch [59/100] Batch [290/782] Loss: 0.4411 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [291/782] Loss: 0.5589 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [292/782] Loss: 0.7123 | Acc: 77.72%\n",
      "Train Epoch [59/100] Batch [293/782] Loss: 0.6353 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [294/782] Loss: 0.5528 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [295/782] Loss: 0.5560 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [296/782] Loss: 0.7658 | Acc: 77.73%\n",
      "Train Epoch [59/100] Batch [297/782] Loss: 0.6749 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [298/782] Loss: 0.6222 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [299/782] Loss: 0.3766 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [300/782] Loss: 0.6847 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [301/782] Loss: 0.6954 | Acc: 77.77%\n",
      "Train Epoch [59/100] Batch [302/782] Loss: 0.8296 | Acc: 77.74%\n",
      "Train Epoch [59/100] Batch [303/782] Loss: 0.5288 | Acc: 77.76%\n",
      "Train Epoch [59/100] Batch [304/782] Loss: 0.6522 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [305/782] Loss: 0.7108 | Acc: 77.78%\n",
      "Train Epoch [59/100] Batch [306/782] Loss: 0.6778 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [307/782] Loss: 0.5604 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [308/782] Loss: 0.5593 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [309/782] Loss: 0.3419 | Acc: 77.82%\n",
      "Train Epoch [59/100] Batch [310/782] Loss: 0.9444 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [311/782] Loss: 0.4707 | Acc: 77.82%\n",
      "Train Epoch [59/100] Batch [312/782] Loss: 0.6256 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [313/782] Loss: 0.5952 | Acc: 77.82%\n",
      "Train Epoch [59/100] Batch [314/782] Loss: 0.6413 | Acc: 77.79%\n",
      "Train Epoch [59/100] Batch [315/782] Loss: 0.6167 | Acc: 77.81%\n",
      "Train Epoch [59/100] Batch [316/782] Loss: 0.5289 | Acc: 77.82%\n",
      "Train Epoch [59/100] Batch [317/782] Loss: 0.4389 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [318/782] Loss: 0.5229 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [319/782] Loss: 0.6276 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [320/782] Loss: 0.5719 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [321/782] Loss: 0.6060 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [322/782] Loss: 0.4776 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [323/782] Loss: 0.5758 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [324/782] Loss: 0.6455 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [325/782] Loss: 0.6317 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [326/782] Loss: 0.5541 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [327/782] Loss: 0.4798 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [328/782] Loss: 0.4438 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [329/782] Loss: 0.5424 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [330/782] Loss: 0.5238 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [331/782] Loss: 0.6463 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [332/782] Loss: 0.5018 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [333/782] Loss: 0.6668 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [334/782] Loss: 0.6982 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [335/782] Loss: 0.4992 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [336/782] Loss: 0.6249 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [337/782] Loss: 0.8994 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [338/782] Loss: 0.5615 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [339/782] Loss: 0.5357 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [340/782] Loss: 0.6989 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [341/782] Loss: 0.6469 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [342/782] Loss: 0.5776 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [343/782] Loss: 0.5372 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [344/782] Loss: 0.7036 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [345/782] Loss: 0.6424 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [346/782] Loss: 0.6553 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [347/782] Loss: 0.6828 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [348/782] Loss: 0.4530 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [349/782] Loss: 0.8465 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [350/782] Loss: 0.5491 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [351/782] Loss: 0.5767 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [352/782] Loss: 0.5872 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [353/782] Loss: 0.5253 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [354/782] Loss: 0.6936 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [355/782] Loss: 0.6481 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [356/782] Loss: 0.4924 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [357/782] Loss: 0.4405 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [358/782] Loss: 0.5935 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [359/782] Loss: 0.8275 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [360/782] Loss: 0.6726 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [361/782] Loss: 0.5659 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [362/782] Loss: 0.5158 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [363/782] Loss: 0.6469 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [364/782] Loss: 0.8231 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [365/782] Loss: 0.5426 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [366/782] Loss: 0.7338 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [367/782] Loss: 0.5620 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [368/782] Loss: 0.5663 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [369/782] Loss: 0.6020 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [370/782] Loss: 0.7039 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [371/782] Loss: 0.6034 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [372/782] Loss: 0.4285 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [373/782] Loss: 0.7515 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [374/782] Loss: 0.7269 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [375/782] Loss: 0.7331 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [376/782] Loss: 0.5848 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [377/782] Loss: 0.7593 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [378/782] Loss: 0.7278 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [379/782] Loss: 0.6294 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [380/782] Loss: 0.5228 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [381/782] Loss: 0.6841 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [382/782] Loss: 0.6704 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [383/782] Loss: 0.7114 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [384/782] Loss: 0.6039 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [385/782] Loss: 0.5688 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [386/782] Loss: 0.5309 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [387/782] Loss: 0.4584 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [388/782] Loss: 0.7334 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [389/782] Loss: 0.4313 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [390/782] Loss: 0.8329 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [391/782] Loss: 0.5329 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [392/782] Loss: 0.4912 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [393/782] Loss: 0.5817 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [394/782] Loss: 0.5960 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [395/782] Loss: 0.7557 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [396/782] Loss: 0.6516 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [397/782] Loss: 0.7737 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [398/782] Loss: 0.7085 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [399/782] Loss: 0.7054 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [400/782] Loss: 0.5363 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [401/782] Loss: 0.4961 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [402/782] Loss: 0.4948 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [403/782] Loss: 0.4603 | Acc: 78.00%\n",
      "Train Epoch [59/100] Batch [404/782] Loss: 0.3756 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [405/782] Loss: 0.7517 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [406/782] Loss: 0.6106 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [407/782] Loss: 0.6123 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [408/782] Loss: 0.4970 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [409/782] Loss: 0.5423 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [410/782] Loss: 0.4774 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [411/782] Loss: 0.5071 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [412/782] Loss: 0.4406 | Acc: 78.08%\n",
      "Train Epoch [59/100] Batch [413/782] Loss: 0.5654 | Acc: 78.08%\n",
      "Train Epoch [59/100] Batch [414/782] Loss: 0.6403 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [415/782] Loss: 0.5590 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [416/782] Loss: 0.7482 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [417/782] Loss: 0.5089 | Acc: 78.07%\n",
      "Train Epoch [59/100] Batch [418/782] Loss: 0.5734 | Acc: 78.07%\n",
      "Train Epoch [59/100] Batch [419/782] Loss: 0.4118 | Acc: 78.08%\n",
      "Train Epoch [59/100] Batch [420/782] Loss: 0.4736 | Acc: 78.10%\n",
      "Train Epoch [59/100] Batch [421/782] Loss: 0.5221 | Acc: 78.10%\n",
      "Train Epoch [59/100] Batch [422/782] Loss: 0.5623 | Acc: 78.11%\n",
      "Train Epoch [59/100] Batch [423/782] Loss: 0.7885 | Acc: 78.08%\n",
      "Train Epoch [59/100] Batch [424/782] Loss: 0.4446 | Acc: 78.10%\n",
      "Train Epoch [59/100] Batch [425/782] Loss: 0.5206 | Acc: 78.12%\n",
      "Train Epoch [59/100] Batch [426/782] Loss: 0.7639 | Acc: 78.11%\n",
      "Train Epoch [59/100] Batch [427/782] Loss: 0.9241 | Acc: 78.08%\n",
      "Train Epoch [59/100] Batch [428/782] Loss: 0.6356 | Acc: 78.07%\n",
      "Train Epoch [59/100] Batch [429/782] Loss: 0.8268 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [430/782] Loss: 0.8588 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [431/782] Loss: 0.4434 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [432/782] Loss: 0.6932 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [433/782] Loss: 0.4480 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [434/782] Loss: 0.4442 | Acc: 78.07%\n",
      "Train Epoch [59/100] Batch [435/782] Loss: 0.6929 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [436/782] Loss: 0.5539 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [437/782] Loss: 0.6860 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [438/782] Loss: 0.4698 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [439/782] Loss: 0.6018 | Acc: 78.07%\n",
      "Train Epoch [59/100] Batch [440/782] Loss: 0.8616 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [441/782] Loss: 0.6512 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [442/782] Loss: 0.6144 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [443/782] Loss: 0.5646 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [444/782] Loss: 0.5860 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [445/782] Loss: 0.6583 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [446/782] Loss: 0.5792 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [447/782] Loss: 1.0497 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [448/782] Loss: 0.5959 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [449/782] Loss: 0.5710 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [450/782] Loss: 0.6265 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [451/782] Loss: 0.6588 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [452/782] Loss: 0.6075 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [453/782] Loss: 0.4063 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [454/782] Loss: 0.6542 | Acc: 78.02%\n",
      "Train Epoch [59/100] Batch [455/782] Loss: 0.4429 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [456/782] Loss: 0.5701 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [457/782] Loss: 0.7493 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [458/782] Loss: 0.4929 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [459/782] Loss: 0.6518 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [460/782] Loss: 0.6394 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [461/782] Loss: 0.6125 | Acc: 78.03%\n",
      "Train Epoch [59/100] Batch [462/782] Loss: 0.5392 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [463/782] Loss: 0.7148 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [464/782] Loss: 0.4916 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [465/782] Loss: 0.4913 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [466/782] Loss: 0.6308 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [467/782] Loss: 0.6967 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [468/782] Loss: 0.7995 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [469/782] Loss: 0.5893 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [470/782] Loss: 0.4314 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [471/782] Loss: 0.6041 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [472/782] Loss: 0.6339 | Acc: 78.05%\n",
      "Train Epoch [59/100] Batch [473/782] Loss: 0.5620 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [474/782] Loss: 0.5525 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [475/782] Loss: 0.6763 | Acc: 78.06%\n",
      "Train Epoch [59/100] Batch [476/782] Loss: 0.6414 | Acc: 78.04%\n",
      "Train Epoch [59/100] Batch [477/782] Loss: 0.9382 | Acc: 78.01%\n",
      "Train Epoch [59/100] Batch [478/782] Loss: 0.7454 | Acc: 77.99%\n",
      "Train Epoch [59/100] Batch [479/782] Loss: 0.5661 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [480/782] Loss: 0.6351 | Acc: 77.98%\n",
      "Train Epoch [59/100] Batch [481/782] Loss: 0.7703 | Acc: 77.97%\n",
      "Train Epoch [59/100] Batch [482/782] Loss: 0.5907 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [483/782] Loss: 0.7789 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [484/782] Loss: 0.6186 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [485/782] Loss: 0.6558 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [486/782] Loss: 0.7812 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [487/782] Loss: 0.6435 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [488/782] Loss: 0.6253 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [489/782] Loss: 0.6731 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [490/782] Loss: 0.6635 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [491/782] Loss: 0.5422 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [492/782] Loss: 0.6592 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [493/782] Loss: 0.6885 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [494/782] Loss: 0.7418 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [495/782] Loss: 0.6198 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [496/782] Loss: 0.6059 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [497/782] Loss: 0.4393 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [498/782] Loss: 0.5045 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [499/782] Loss: 0.7660 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [500/782] Loss: 0.4940 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [501/782] Loss: 0.7075 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [502/782] Loss: 0.4604 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [503/782] Loss: 0.5384 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [504/782] Loss: 0.5623 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [505/782] Loss: 0.5858 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [506/782] Loss: 0.4303 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [507/782] Loss: 0.7538 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [508/782] Loss: 0.4844 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [509/782] Loss: 0.7656 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [510/782] Loss: 0.7647 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [511/782] Loss: 0.6367 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [512/782] Loss: 0.6053 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [513/782] Loss: 0.5455 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [514/782] Loss: 0.6365 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [515/782] Loss: 0.6010 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [516/782] Loss: 0.4687 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [517/782] Loss: 0.5648 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [518/782] Loss: 0.5002 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [519/782] Loss: 0.7754 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [520/782] Loss: 0.6338 | Acc: 77.96%\n",
      "Train Epoch [59/100] Batch [521/782] Loss: 0.6728 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [522/782] Loss: 0.6023 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [523/782] Loss: 0.6631 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [524/782] Loss: 0.6017 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [525/782] Loss: 0.5044 | Acc: 77.95%\n",
      "Train Epoch [59/100] Batch [526/782] Loss: 0.7103 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [527/782] Loss: 0.5727 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [528/782] Loss: 0.6692 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [529/782] Loss: 0.6593 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [530/782] Loss: 0.6531 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [531/782] Loss: 0.7512 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [532/782] Loss: 0.4270 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [533/782] Loss: 0.6695 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [534/782] Loss: 0.5904 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [535/782] Loss: 0.5738 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [536/782] Loss: 0.6179 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [537/782] Loss: 0.6239 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [538/782] Loss: 0.6949 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [539/782] Loss: 0.7312 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [540/782] Loss: 0.4541 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [541/782] Loss: 0.7128 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [542/782] Loss: 0.6096 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [543/782] Loss: 0.6453 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [544/782] Loss: 0.4570 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [545/782] Loss: 0.6198 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [546/782] Loss: 0.6998 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [547/782] Loss: 0.6143 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [548/782] Loss: 0.6444 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [549/782] Loss: 0.4331 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [550/782] Loss: 0.3887 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [551/782] Loss: 0.6305 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [552/782] Loss: 0.6610 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [553/782] Loss: 0.7781 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [554/782] Loss: 0.6999 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [555/782] Loss: 0.5794 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [556/782] Loss: 0.5093 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [557/782] Loss: 0.8010 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [558/782] Loss: 0.7868 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [559/782] Loss: 0.5282 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [560/782] Loss: 0.5885 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [561/782] Loss: 0.5734 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [562/782] Loss: 0.6486 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [563/782] Loss: 0.6631 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [564/782] Loss: 0.5736 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [565/782] Loss: 0.6171 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [566/782] Loss: 0.9961 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [567/782] Loss: 0.4312 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [568/782] Loss: 0.5746 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [569/782] Loss: 0.5612 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [570/782] Loss: 0.5745 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [571/782] Loss: 0.8778 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [572/782] Loss: 0.7048 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [573/782] Loss: 0.3756 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [574/782] Loss: 0.6631 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [575/782] Loss: 0.6410 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [576/782] Loss: 0.6247 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [577/782] Loss: 0.4245 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [578/782] Loss: 0.6452 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [579/782] Loss: 0.5999 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [580/782] Loss: 0.6116 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [581/782] Loss: 0.8238 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [582/782] Loss: 0.8489 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [583/782] Loss: 0.7521 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [584/782] Loss: 0.7430 | Acc: 77.84%\n",
      "Train Epoch [59/100] Batch [585/782] Loss: 0.4541 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [586/782] Loss: 0.5279 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [587/782] Loss: 0.6992 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [588/782] Loss: 0.6216 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [589/782] Loss: 0.5190 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [590/782] Loss: 0.3797 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [591/782] Loss: 0.5432 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [592/782] Loss: 0.4293 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [593/782] Loss: 0.6669 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [594/782] Loss: 0.7367 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [595/782] Loss: 0.5812 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [596/782] Loss: 0.7474 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [597/782] Loss: 0.5665 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [598/782] Loss: 0.7060 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [599/782] Loss: 0.4420 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [600/782] Loss: 0.5751 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [601/782] Loss: 0.4930 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [602/782] Loss: 0.6649 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [603/782] Loss: 0.6541 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [604/782] Loss: 0.5528 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [605/782] Loss: 0.5138 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [606/782] Loss: 0.7485 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [607/782] Loss: 0.7904 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [608/782] Loss: 0.5407 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [609/782] Loss: 0.5346 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [610/782] Loss: 0.6499 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [611/782] Loss: 0.4477 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [612/782] Loss: 0.5913 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [613/782] Loss: 0.9409 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [614/782] Loss: 0.6293 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [615/782] Loss: 0.4809 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [616/782] Loss: 0.9264 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [617/782] Loss: 0.5706 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [618/782] Loss: 0.4843 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [619/782] Loss: 0.7063 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [620/782] Loss: 0.6942 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [621/782] Loss: 0.4545 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [622/782] Loss: 0.7014 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [623/782] Loss: 0.7126 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [624/782] Loss: 0.5968 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [625/782] Loss: 0.5843 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [626/782] Loss: 0.5566 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [627/782] Loss: 0.4840 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [628/782] Loss: 0.6433 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [629/782] Loss: 0.5932 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [630/782] Loss: 0.6886 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [631/782] Loss: 0.5111 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [632/782] Loss: 0.6884 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [633/782] Loss: 0.4596 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [634/782] Loss: 0.7185 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [635/782] Loss: 0.5599 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [636/782] Loss: 0.6631 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [637/782] Loss: 0.5344 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [638/782] Loss: 0.5265 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [639/782] Loss: 0.8554 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [640/782] Loss: 0.5692 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [641/782] Loss: 0.5821 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [642/782] Loss: 0.6510 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [643/782] Loss: 0.6137 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [644/782] Loss: 0.7534 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [645/782] Loss: 0.7055 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [646/782] Loss: 0.5490 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [647/782] Loss: 0.6623 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [648/782] Loss: 0.5264 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [649/782] Loss: 0.4365 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [650/782] Loss: 0.6462 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [651/782] Loss: 0.4722 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [652/782] Loss: 0.8691 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [653/782] Loss: 0.5599 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [654/782] Loss: 0.7727 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [655/782] Loss: 0.6917 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [656/782] Loss: 0.7702 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [657/782] Loss: 0.9128 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [658/782] Loss: 0.5629 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [659/782] Loss: 0.5869 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [660/782] Loss: 0.8023 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [661/782] Loss: 0.4720 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [662/782] Loss: 0.5361 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [663/782] Loss: 0.4951 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [664/782] Loss: 0.4084 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [665/782] Loss: 0.7547 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [666/782] Loss: 0.7788 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [667/782] Loss: 0.6471 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [668/782] Loss: 0.6368 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [669/782] Loss: 0.6191 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [670/782] Loss: 0.5610 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [671/782] Loss: 0.6858 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [672/782] Loss: 0.5991 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [673/782] Loss: 0.6824 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [674/782] Loss: 0.6290 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [675/782] Loss: 0.6062 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [676/782] Loss: 0.6896 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [677/782] Loss: 0.4188 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [678/782] Loss: 0.6158 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [679/782] Loss: 0.5810 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [680/782] Loss: 0.6174 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [681/782] Loss: 0.4207 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [682/782] Loss: 0.4807 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [683/782] Loss: 0.6615 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [684/782] Loss: 0.4157 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [685/782] Loss: 0.6563 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [686/782] Loss: 0.5557 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [687/782] Loss: 0.5503 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [688/782] Loss: 0.5319 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [689/782] Loss: 0.6579 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [690/782] Loss: 0.6845 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [691/782] Loss: 0.5521 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [692/782] Loss: 0.5828 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [693/782] Loss: 0.4650 | Acc: 77.94%\n",
      "Train Epoch [59/100] Batch [694/782] Loss: 0.5701 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [695/782] Loss: 0.7548 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [696/782] Loss: 0.7133 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [697/782] Loss: 0.6797 | Acc: 77.92%\n",
      "Train Epoch [59/100] Batch [698/782] Loss: 0.6562 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [699/782] Loss: 0.6090 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [700/782] Loss: 0.5777 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [701/782] Loss: 0.5606 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [702/782] Loss: 0.6418 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [703/782] Loss: 0.7471 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [704/782] Loss: 0.8539 | Acc: 77.93%\n",
      "Train Epoch [59/100] Batch [705/782] Loss: 0.6849 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [706/782] Loss: 0.6542 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [707/782] Loss: 0.6863 | Acc: 77.91%\n",
      "Train Epoch [59/100] Batch [708/782] Loss: 0.6694 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [709/782] Loss: 0.5975 | Acc: 77.90%\n",
      "Train Epoch [59/100] Batch [710/782] Loss: 0.6650 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [711/782] Loss: 0.4837 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [712/782] Loss: 0.8534 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [713/782] Loss: 0.8262 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [714/782] Loss: 0.6284 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [715/782] Loss: 0.4888 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [716/782] Loss: 0.5803 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [717/782] Loss: 0.5597 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [718/782] Loss: 0.5112 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [719/782] Loss: 0.5171 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [720/782] Loss: 0.6658 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [721/782] Loss: 0.7315 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [722/782] Loss: 0.7965 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [723/782] Loss: 0.6086 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [724/782] Loss: 0.5036 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [725/782] Loss: 0.7291 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [726/782] Loss: 0.7064 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [727/782] Loss: 0.6153 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [728/782] Loss: 0.4475 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [729/782] Loss: 0.6564 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [730/782] Loss: 0.5350 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [731/782] Loss: 0.7182 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [732/782] Loss: 0.8235 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [733/782] Loss: 0.8261 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [734/782] Loss: 0.4658 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [735/782] Loss: 0.8375 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [736/782] Loss: 0.4567 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [737/782] Loss: 0.7246 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [738/782] Loss: 0.6013 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [739/782] Loss: 0.5810 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [740/782] Loss: 0.7718 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [741/782] Loss: 0.6010 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [742/782] Loss: 0.6198 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [743/782] Loss: 0.7006 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [744/782] Loss: 0.5124 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [745/782] Loss: 0.5468 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [746/782] Loss: 0.6179 | Acc: 77.85%\n",
      "Train Epoch [59/100] Batch [747/782] Loss: 0.6018 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [748/782] Loss: 0.5394 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [749/782] Loss: 0.4397 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [750/782] Loss: 0.6136 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [751/782] Loss: 0.6324 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [752/782] Loss: 0.5441 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [753/782] Loss: 0.5931 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [754/782] Loss: 0.6024 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [755/782] Loss: 0.5558 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [756/782] Loss: 0.6422 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [757/782] Loss: 0.5784 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [758/782] Loss: 0.6676 | Acc: 77.89%\n",
      "Train Epoch [59/100] Batch [759/782] Loss: 0.6519 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [760/782] Loss: 0.6939 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [761/782] Loss: 0.6624 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [762/782] Loss: 0.5488 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [763/782] Loss: 0.7313 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [764/782] Loss: 0.4736 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [765/782] Loss: 0.6303 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [766/782] Loss: 0.7561 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [767/782] Loss: 0.8557 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [768/782] Loss: 0.5089 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [769/782] Loss: 0.5271 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [770/782] Loss: 0.6735 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [771/782] Loss: 0.6825 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [772/782] Loss: 0.5610 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [773/782] Loss: 0.4995 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [774/782] Loss: 0.6750 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [775/782] Loss: 0.6308 | Acc: 77.86%\n",
      "Train Epoch [59/100] Batch [776/782] Loss: 0.5604 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [777/782] Loss: 0.6340 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [778/782] Loss: 0.5637 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [779/782] Loss: 0.5309 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [780/782] Loss: 0.6295 | Acc: 77.87%\n",
      "Train Epoch [59/100] Batch [781/782] Loss: 0.4216 | Acc: 77.88%\n",
      "Train Epoch [59/100] Batch [782/782] Loss: 0.6492 | Acc: 77.88%\n",
      "Epoch 59 completed in 29.83s.\n",
      "Test Epoch [59/100] Loss: 0.8619 | Acc: 72.86% | Inference Time: 8.16s\n",
      "Epoch 59 results saved to CSV.\n",
      "Epoch 60/100\n",
      "Train Epoch [60/100] Batch [1/782] Loss: 0.5900 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [2/782] Loss: 0.6535 | Acc: 82.03%\n",
      "Train Epoch [60/100] Batch [3/782] Loss: 0.4544 | Acc: 83.33%\n",
      "Train Epoch [60/100] Batch [4/782] Loss: 0.4036 | Acc: 83.59%\n",
      "Train Epoch [60/100] Batch [5/782] Loss: 0.4230 | Acc: 83.75%\n",
      "Train Epoch [60/100] Batch [6/782] Loss: 0.7636 | Acc: 81.77%\n",
      "Train Epoch [60/100] Batch [7/782] Loss: 0.5590 | Acc: 81.03%\n",
      "Train Epoch [60/100] Batch [8/782] Loss: 0.6136 | Acc: 80.86%\n",
      "Train Epoch [60/100] Batch [9/782] Loss: 0.4912 | Acc: 81.60%\n",
      "Train Epoch [60/100] Batch [10/782] Loss: 0.6820 | Acc: 80.47%\n",
      "Train Epoch [60/100] Batch [11/782] Loss: 0.4768 | Acc: 80.26%\n",
      "Train Epoch [60/100] Batch [12/782] Loss: 0.5769 | Acc: 80.60%\n",
      "Train Epoch [60/100] Batch [13/782] Loss: 0.7988 | Acc: 79.81%\n",
      "Train Epoch [60/100] Batch [14/782] Loss: 0.6442 | Acc: 79.91%\n",
      "Train Epoch [60/100] Batch [15/782] Loss: 0.6399 | Acc: 79.38%\n",
      "Train Epoch [60/100] Batch [16/782] Loss: 0.2491 | Acc: 80.18%\n",
      "Train Epoch [60/100] Batch [17/782] Loss: 0.5711 | Acc: 79.96%\n",
      "Train Epoch [60/100] Batch [18/782] Loss: 0.5814 | Acc: 80.03%\n",
      "Train Epoch [60/100] Batch [19/782] Loss: 0.6287 | Acc: 79.85%\n",
      "Train Epoch [60/100] Batch [20/782] Loss: 0.3829 | Acc: 80.31%\n",
      "Train Epoch [60/100] Batch [21/782] Loss: 0.4180 | Acc: 80.58%\n",
      "Train Epoch [60/100] Batch [22/782] Loss: 0.5461 | Acc: 80.33%\n",
      "Train Epoch [60/100] Batch [23/782] Loss: 0.4837 | Acc: 80.30%\n",
      "Train Epoch [60/100] Batch [24/782] Loss: 0.4850 | Acc: 80.47%\n",
      "Train Epoch [60/100] Batch [25/782] Loss: 0.5262 | Acc: 80.75%\n",
      "Train Epoch [60/100] Batch [26/782] Loss: 0.6159 | Acc: 80.77%\n",
      "Train Epoch [60/100] Batch [27/782] Loss: 0.4816 | Acc: 80.67%\n",
      "Train Epoch [60/100] Batch [28/782] Loss: 0.4800 | Acc: 80.69%\n",
      "Train Epoch [60/100] Batch [29/782] Loss: 0.6679 | Acc: 80.55%\n",
      "Train Epoch [60/100] Batch [30/782] Loss: 0.9107 | Acc: 80.26%\n",
      "Train Epoch [60/100] Batch [31/782] Loss: 0.6402 | Acc: 80.24%\n",
      "Train Epoch [60/100] Batch [32/782] Loss: 0.5297 | Acc: 80.13%\n",
      "Train Epoch [60/100] Batch [33/782] Loss: 0.5284 | Acc: 80.26%\n",
      "Train Epoch [60/100] Batch [34/782] Loss: 0.8069 | Acc: 80.01%\n",
      "Train Epoch [60/100] Batch [35/782] Loss: 0.5486 | Acc: 80.04%\n",
      "Train Epoch [60/100] Batch [36/782] Loss: 0.4848 | Acc: 80.08%\n",
      "Train Epoch [60/100] Batch [37/782] Loss: 0.8192 | Acc: 79.81%\n",
      "Train Epoch [60/100] Batch [38/782] Loss: 0.7536 | Acc: 79.73%\n",
      "Train Epoch [60/100] Batch [39/782] Loss: 0.4952 | Acc: 79.93%\n",
      "Train Epoch [60/100] Batch [40/782] Loss: 0.5684 | Acc: 80.00%\n",
      "Train Epoch [60/100] Batch [41/782] Loss: 0.5080 | Acc: 80.14%\n",
      "Train Epoch [60/100] Batch [42/782] Loss: 0.4789 | Acc: 80.17%\n",
      "Train Epoch [60/100] Batch [43/782] Loss: 0.5744 | Acc: 80.12%\n",
      "Train Epoch [60/100] Batch [44/782] Loss: 0.5271 | Acc: 80.22%\n",
      "Train Epoch [60/100] Batch [45/782] Loss: 0.4394 | Acc: 80.24%\n",
      "Train Epoch [60/100] Batch [46/782] Loss: 0.4981 | Acc: 80.30%\n",
      "Train Epoch [60/100] Batch [47/782] Loss: 0.5741 | Acc: 80.19%\n",
      "Train Epoch [60/100] Batch [48/782] Loss: 0.6759 | Acc: 80.14%\n",
      "Train Epoch [60/100] Batch [49/782] Loss: 0.3978 | Acc: 80.33%\n",
      "Train Epoch [60/100] Batch [50/782] Loss: 0.5909 | Acc: 80.28%\n",
      "Train Epoch [60/100] Batch [51/782] Loss: 0.6394 | Acc: 80.18%\n",
      "Train Epoch [60/100] Batch [52/782] Loss: 0.6040 | Acc: 80.23%\n",
      "Train Epoch [60/100] Batch [53/782] Loss: 0.3098 | Acc: 80.37%\n",
      "Train Epoch [60/100] Batch [54/782] Loss: 0.4986 | Acc: 80.50%\n",
      "Train Epoch [60/100] Batch [55/782] Loss: 0.4711 | Acc: 80.60%\n",
      "Train Epoch [60/100] Batch [56/782] Loss: 0.3579 | Acc: 80.69%\n",
      "Train Epoch [60/100] Batch [57/782] Loss: 0.5897 | Acc: 80.65%\n",
      "Train Epoch [60/100] Batch [58/782] Loss: 0.5073 | Acc: 80.71%\n",
      "Train Epoch [60/100] Batch [59/782] Loss: 0.7641 | Acc: 80.48%\n",
      "Train Epoch [60/100] Batch [60/782] Loss: 0.5749 | Acc: 80.49%\n",
      "Train Epoch [60/100] Batch [61/782] Loss: 0.8372 | Acc: 80.40%\n",
      "Train Epoch [60/100] Batch [62/782] Loss: 0.6125 | Acc: 80.39%\n",
      "Train Epoch [60/100] Batch [63/782] Loss: 0.7220 | Acc: 80.36%\n",
      "Train Epoch [60/100] Batch [64/782] Loss: 0.7760 | Acc: 80.25%\n",
      "Train Epoch [60/100] Batch [65/782] Loss: 0.5367 | Acc: 80.31%\n",
      "Train Epoch [60/100] Batch [66/782] Loss: 0.5069 | Acc: 80.28%\n",
      "Train Epoch [60/100] Batch [67/782] Loss: 0.6503 | Acc: 80.22%\n",
      "Train Epoch [60/100] Batch [68/782] Loss: 0.6308 | Acc: 80.24%\n",
      "Train Epoch [60/100] Batch [69/782] Loss: 0.5701 | Acc: 80.23%\n",
      "Train Epoch [60/100] Batch [70/782] Loss: 0.6347 | Acc: 80.22%\n",
      "Train Epoch [60/100] Batch [71/782] Loss: 0.6705 | Acc: 80.22%\n",
      "Train Epoch [60/100] Batch [72/782] Loss: 0.7541 | Acc: 80.16%\n",
      "Train Epoch [60/100] Batch [73/782] Loss: 0.4839 | Acc: 80.24%\n",
      "Train Epoch [60/100] Batch [74/782] Loss: 0.5329 | Acc: 80.28%\n",
      "Train Epoch [60/100] Batch [75/782] Loss: 0.5201 | Acc: 80.29%\n",
      "Train Epoch [60/100] Batch [76/782] Loss: 0.5806 | Acc: 80.26%\n",
      "Train Epoch [60/100] Batch [77/782] Loss: 0.4050 | Acc: 80.34%\n",
      "Train Epoch [60/100] Batch [78/782] Loss: 0.6261 | Acc: 80.31%\n",
      "Train Epoch [60/100] Batch [79/782] Loss: 0.6358 | Acc: 80.32%\n",
      "Train Epoch [60/100] Batch [80/782] Loss: 0.6703 | Acc: 80.25%\n",
      "Train Epoch [60/100] Batch [81/782] Loss: 0.3868 | Acc: 80.32%\n",
      "Train Epoch [60/100] Batch [82/782] Loss: 0.7346 | Acc: 80.22%\n",
      "Train Epoch [60/100] Batch [83/782] Loss: 0.7314 | Acc: 80.12%\n",
      "Train Epoch [60/100] Batch [84/782] Loss: 0.4973 | Acc: 80.15%\n",
      "Train Epoch [60/100] Batch [85/782] Loss: 0.5771 | Acc: 80.20%\n",
      "Train Epoch [60/100] Batch [86/782] Loss: 0.6847 | Acc: 80.16%\n",
      "Train Epoch [60/100] Batch [87/782] Loss: 0.5166 | Acc: 80.19%\n",
      "Train Epoch [60/100] Batch [88/782] Loss: 0.8066 | Acc: 80.11%\n",
      "Train Epoch [60/100] Batch [89/782] Loss: 0.6036 | Acc: 80.09%\n",
      "Train Epoch [60/100] Batch [90/782] Loss: 0.6011 | Acc: 80.14%\n",
      "Train Epoch [60/100] Batch [91/782] Loss: 0.6590 | Acc: 80.12%\n",
      "Train Epoch [60/100] Batch [92/782] Loss: 0.6591 | Acc: 80.08%\n",
      "Train Epoch [60/100] Batch [93/782] Loss: 0.6302 | Acc: 80.06%\n",
      "Train Epoch [60/100] Batch [94/782] Loss: 0.5151 | Acc: 80.02%\n",
      "Train Epoch [60/100] Batch [95/782] Loss: 0.3869 | Acc: 80.08%\n",
      "Train Epoch [60/100] Batch [96/782] Loss: 0.5287 | Acc: 80.05%\n",
      "Train Epoch [60/100] Batch [97/782] Loss: 0.6885 | Acc: 79.99%\n",
      "Train Epoch [60/100] Batch [98/782] Loss: 0.5797 | Acc: 79.97%\n",
      "Train Epoch [60/100] Batch [99/782] Loss: 0.3972 | Acc: 80.03%\n",
      "Train Epoch [60/100] Batch [100/782] Loss: 0.5878 | Acc: 80.02%\n",
      "Train Epoch [60/100] Batch [101/782] Loss: 0.4244 | Acc: 80.03%\n",
      "Train Epoch [60/100] Batch [102/782] Loss: 0.8041 | Acc: 79.90%\n",
      "Train Epoch [60/100] Batch [103/782] Loss: 0.6113 | Acc: 79.84%\n",
      "Train Epoch [60/100] Batch [104/782] Loss: 0.5711 | Acc: 79.78%\n",
      "Train Epoch [60/100] Batch [105/782] Loss: 0.4416 | Acc: 79.82%\n",
      "Train Epoch [60/100] Batch [106/782] Loss: 0.4979 | Acc: 79.86%\n",
      "Train Epoch [60/100] Batch [107/782] Loss: 0.5982 | Acc: 79.86%\n",
      "Train Epoch [60/100] Batch [108/782] Loss: 0.6774 | Acc: 79.80%\n",
      "Train Epoch [60/100] Batch [109/782] Loss: 0.5841 | Acc: 79.74%\n",
      "Train Epoch [60/100] Batch [110/782] Loss: 0.7627 | Acc: 79.69%\n",
      "Train Epoch [60/100] Batch [111/782] Loss: 0.5890 | Acc: 79.70%\n",
      "Train Epoch [60/100] Batch [112/782] Loss: 0.4816 | Acc: 79.76%\n",
      "Train Epoch [60/100] Batch [113/782] Loss: 0.6362 | Acc: 79.70%\n",
      "Train Epoch [60/100] Batch [114/782] Loss: 0.7392 | Acc: 79.65%\n",
      "Train Epoch [60/100] Batch [115/782] Loss: 0.6248 | Acc: 79.65%\n",
      "Train Epoch [60/100] Batch [116/782] Loss: 0.6859 | Acc: 79.59%\n",
      "Train Epoch [60/100] Batch [117/782] Loss: 0.6315 | Acc: 79.57%\n",
      "Train Epoch [60/100] Batch [118/782] Loss: 0.8442 | Acc: 79.48%\n",
      "Train Epoch [60/100] Batch [119/782] Loss: 0.7857 | Acc: 79.41%\n",
      "Train Epoch [60/100] Batch [120/782] Loss: 0.4963 | Acc: 79.43%\n",
      "Train Epoch [60/100] Batch [121/782] Loss: 0.5794 | Acc: 79.44%\n",
      "Train Epoch [60/100] Batch [122/782] Loss: 0.5726 | Acc: 79.43%\n",
      "Train Epoch [60/100] Batch [123/782] Loss: 0.4796 | Acc: 79.42%\n",
      "Train Epoch [60/100] Batch [124/782] Loss: 0.3663 | Acc: 79.47%\n",
      "Train Epoch [60/100] Batch [125/782] Loss: 0.6410 | Acc: 79.44%\n",
      "Train Epoch [60/100] Batch [126/782] Loss: 0.6707 | Acc: 79.45%\n",
      "Train Epoch [60/100] Batch [127/782] Loss: 0.5072 | Acc: 79.48%\n",
      "Train Epoch [60/100] Batch [128/782] Loss: 0.6255 | Acc: 79.48%\n",
      "Train Epoch [60/100] Batch [129/782] Loss: 0.8472 | Acc: 79.40%\n",
      "Train Epoch [60/100] Batch [130/782] Loss: 0.5305 | Acc: 79.41%\n",
      "Train Epoch [60/100] Batch [131/782] Loss: 0.4403 | Acc: 79.44%\n",
      "Train Epoch [60/100] Batch [132/782] Loss: 0.4908 | Acc: 79.49%\n",
      "Train Epoch [60/100] Batch [133/782] Loss: 0.5226 | Acc: 79.46%\n",
      "Train Epoch [60/100] Batch [134/782] Loss: 0.6592 | Acc: 79.42%\n",
      "Train Epoch [60/100] Batch [135/782] Loss: 0.5866 | Acc: 79.42%\n",
      "Train Epoch [60/100] Batch [136/782] Loss: 0.6203 | Acc: 79.42%\n",
      "Train Epoch [60/100] Batch [137/782] Loss: 0.7154 | Acc: 79.37%\n",
      "Train Epoch [60/100] Batch [138/782] Loss: 0.4905 | Acc: 79.40%\n",
      "Train Epoch [60/100] Batch [139/782] Loss: 0.7139 | Acc: 79.40%\n",
      "Train Epoch [60/100] Batch [140/782] Loss: 0.7998 | Acc: 79.34%\n",
      "Train Epoch [60/100] Batch [141/782] Loss: 0.4171 | Acc: 79.34%\n",
      "Train Epoch [60/100] Batch [142/782] Loss: 0.8839 | Acc: 79.25%\n",
      "Train Epoch [60/100] Batch [143/782] Loss: 0.7238 | Acc: 79.17%\n",
      "Train Epoch [60/100] Batch [144/782] Loss: 0.7811 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [145/782] Loss: 0.5950 | Acc: 79.15%\n",
      "Train Epoch [60/100] Batch [146/782] Loss: 0.7863 | Acc: 79.09%\n",
      "Train Epoch [60/100] Batch [147/782] Loss: 0.5239 | Acc: 79.11%\n",
      "Train Epoch [60/100] Batch [148/782] Loss: 0.7240 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [149/782] Loss: 0.4342 | Acc: 79.11%\n",
      "Train Epoch [60/100] Batch [150/782] Loss: 0.6360 | Acc: 79.15%\n",
      "Train Epoch [60/100] Batch [151/782] Loss: 0.8571 | Acc: 79.10%\n",
      "Train Epoch [60/100] Batch [152/782] Loss: 0.8292 | Acc: 79.05%\n",
      "Train Epoch [60/100] Batch [153/782] Loss: 0.3908 | Acc: 79.10%\n",
      "Train Epoch [60/100] Batch [154/782] Loss: 0.5973 | Acc: 79.10%\n",
      "Train Epoch [60/100] Batch [155/782] Loss: 0.6949 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [156/782] Loss: 0.3712 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [157/782] Loss: 0.5674 | Acc: 79.14%\n",
      "Train Epoch [60/100] Batch [158/782] Loss: 0.5512 | Acc: 79.15%\n",
      "Train Epoch [60/100] Batch [159/782] Loss: 0.5439 | Acc: 79.16%\n",
      "Train Epoch [60/100] Batch [160/782] Loss: 0.5493 | Acc: 79.18%\n",
      "Train Epoch [60/100] Batch [161/782] Loss: 0.5221 | Acc: 79.17%\n",
      "Train Epoch [60/100] Batch [162/782] Loss: 0.5891 | Acc: 79.19%\n",
      "Train Epoch [60/100] Batch [163/782] Loss: 0.6989 | Acc: 79.19%\n",
      "Train Epoch [60/100] Batch [164/782] Loss: 0.4612 | Acc: 79.21%\n",
      "Train Epoch [60/100] Batch [165/782] Loss: 0.7262 | Acc: 79.20%\n",
      "Train Epoch [60/100] Batch [166/782] Loss: 0.7382 | Acc: 79.17%\n",
      "Train Epoch [60/100] Batch [167/782] Loss: 0.6950 | Acc: 79.14%\n",
      "Train Epoch [60/100] Batch [168/782] Loss: 0.5877 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [169/782] Loss: 0.5168 | Acc: 79.14%\n",
      "Train Epoch [60/100] Batch [170/782] Loss: 0.5706 | Acc: 79.16%\n",
      "Train Epoch [60/100] Batch [171/782] Loss: 0.6462 | Acc: 79.14%\n",
      "Train Epoch [60/100] Batch [172/782] Loss: 0.4586 | Acc: 79.15%\n",
      "Train Epoch [60/100] Batch [173/782] Loss: 0.6084 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [174/782] Loss: 0.7440 | Acc: 79.06%\n",
      "Train Epoch [60/100] Batch [175/782] Loss: 0.6058 | Acc: 79.05%\n",
      "Train Epoch [60/100] Batch [176/782] Loss: 0.7276 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [177/782] Loss: 0.8376 | Acc: 78.97%\n",
      "Train Epoch [60/100] Batch [178/782] Loss: 0.6213 | Acc: 78.96%\n",
      "Train Epoch [60/100] Batch [179/782] Loss: 0.5207 | Acc: 79.00%\n",
      "Train Epoch [60/100] Batch [180/782] Loss: 0.5366 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [181/782] Loss: 0.4468 | Acc: 79.05%\n",
      "Train Epoch [60/100] Batch [182/782] Loss: 0.7495 | Acc: 79.01%\n",
      "Train Epoch [60/100] Batch [183/782] Loss: 0.5503 | Acc: 79.02%\n",
      "Train Epoch [60/100] Batch [184/782] Loss: 0.5428 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [185/782] Loss: 0.7651 | Acc: 78.99%\n",
      "Train Epoch [60/100] Batch [186/782] Loss: 0.4772 | Acc: 79.02%\n",
      "Train Epoch [60/100] Batch [187/782] Loss: 0.5123 | Acc: 79.02%\n",
      "Train Epoch [60/100] Batch [188/782] Loss: 0.4934 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [189/782] Loss: 0.4320 | Acc: 79.07%\n",
      "Train Epoch [60/100] Batch [190/782] Loss: 0.4134 | Acc: 79.11%\n",
      "Train Epoch [60/100] Batch [191/782] Loss: 0.4501 | Acc: 79.12%\n",
      "Train Epoch [60/100] Batch [192/782] Loss: 0.5762 | Acc: 79.10%\n",
      "Train Epoch [60/100] Batch [193/782] Loss: 0.3876 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [194/782] Loss: 0.4022 | Acc: 79.16%\n",
      "Train Epoch [60/100] Batch [195/782] Loss: 0.6370 | Acc: 79.16%\n",
      "Train Epoch [60/100] Batch [196/782] Loss: 0.6053 | Acc: 79.15%\n",
      "Train Epoch [60/100] Batch [197/782] Loss: 0.4851 | Acc: 79.16%\n",
      "Train Epoch [60/100] Batch [198/782] Loss: 0.6030 | Acc: 79.14%\n",
      "Train Epoch [60/100] Batch [199/782] Loss: 0.6099 | Acc: 79.12%\n",
      "Train Epoch [60/100] Batch [200/782] Loss: 0.5418 | Acc: 79.13%\n",
      "Train Epoch [60/100] Batch [201/782] Loss: 0.7082 | Acc: 79.11%\n",
      "Train Epoch [60/100] Batch [202/782] Loss: 0.5992 | Acc: 79.09%\n",
      "Train Epoch [60/100] Batch [203/782] Loss: 0.5915 | Acc: 79.08%\n",
      "Train Epoch [60/100] Batch [204/782] Loss: 0.6348 | Acc: 79.09%\n",
      "Train Epoch [60/100] Batch [205/782] Loss: 0.8672 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [206/782] Loss: 0.5674 | Acc: 79.06%\n",
      "Train Epoch [60/100] Batch [207/782] Loss: 0.5855 | Acc: 79.08%\n",
      "Train Epoch [60/100] Batch [208/782] Loss: 0.5360 | Acc: 79.07%\n",
      "Train Epoch [60/100] Batch [209/782] Loss: 0.8874 | Acc: 79.01%\n",
      "Train Epoch [60/100] Batch [210/782] Loss: 0.5036 | Acc: 79.03%\n",
      "Train Epoch [60/100] Batch [211/782] Loss: 0.4681 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [212/782] Loss: 0.7623 | Acc: 79.01%\n",
      "Train Epoch [60/100] Batch [213/782] Loss: 0.6260 | Acc: 79.02%\n",
      "Train Epoch [60/100] Batch [214/782] Loss: 0.7832 | Acc: 78.99%\n",
      "Train Epoch [60/100] Batch [215/782] Loss: 0.4919 | Acc: 79.03%\n",
      "Train Epoch [60/100] Batch [216/782] Loss: 0.7250 | Acc: 78.99%\n",
      "Train Epoch [60/100] Batch [217/782] Loss: 0.4068 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [218/782] Loss: 0.7393 | Acc: 79.04%\n",
      "Train Epoch [60/100] Batch [219/782] Loss: 0.7068 | Acc: 78.97%\n",
      "Train Epoch [60/100] Batch [220/782] Loss: 0.6158 | Acc: 78.94%\n",
      "Train Epoch [60/100] Batch [221/782] Loss: 0.7013 | Acc: 78.92%\n",
      "Train Epoch [60/100] Batch [222/782] Loss: 0.3416 | Acc: 78.96%\n",
      "Train Epoch [60/100] Batch [223/782] Loss: 0.5705 | Acc: 78.94%\n",
      "Train Epoch [60/100] Batch [224/782] Loss: 0.6399 | Acc: 78.93%\n",
      "Train Epoch [60/100] Batch [225/782] Loss: 0.5712 | Acc: 78.92%\n",
      "Train Epoch [60/100] Batch [226/782] Loss: 0.5689 | Acc: 78.95%\n",
      "Train Epoch [60/100] Batch [227/782] Loss: 0.8336 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [228/782] Loss: 0.4724 | Acc: 78.92%\n",
      "Train Epoch [60/100] Batch [229/782] Loss: 1.1035 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [230/782] Loss: 0.5257 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [231/782] Loss: 0.6246 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [232/782] Loss: 0.5324 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [233/782] Loss: 0.5123 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [234/782] Loss: 0.6336 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [235/782] Loss: 0.5662 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [236/782] Loss: 0.7790 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [237/782] Loss: 0.4281 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [238/782] Loss: 0.5921 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [239/782] Loss: 0.6754 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [240/782] Loss: 0.6055 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [241/782] Loss: 0.5653 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [242/782] Loss: 0.6447 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [243/782] Loss: 0.6570 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [244/782] Loss: 0.6849 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [245/782] Loss: 0.6489 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [246/782] Loss: 0.4033 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [247/782] Loss: 0.7963 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [248/782] Loss: 0.3919 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [249/782] Loss: 0.7111 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [250/782] Loss: 0.5559 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [251/782] Loss: 0.9277 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [252/782] Loss: 0.6320 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [253/782] Loss: 0.8801 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [254/782] Loss: 0.3581 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [255/782] Loss: 0.6013 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [256/782] Loss: 0.5008 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [257/782] Loss: 0.6735 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [258/782] Loss: 0.7311 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [259/782] Loss: 0.4344 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [260/782] Loss: 0.7309 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [261/782] Loss: 0.6823 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [262/782] Loss: 0.4402 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [263/782] Loss: 0.6329 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [264/782] Loss: 0.4429 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [265/782] Loss: 0.4882 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [266/782] Loss: 0.5923 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [267/782] Loss: 0.6177 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [268/782] Loss: 0.5594 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [269/782] Loss: 0.4668 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [270/782] Loss: 0.4692 | Acc: 78.89%\n",
      "Train Epoch [60/100] Batch [271/782] Loss: 0.4114 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [272/782] Loss: 0.7104 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [273/782] Loss: 0.4499 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [274/782] Loss: 0.7127 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [275/782] Loss: 0.4342 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [276/782] Loss: 0.6385 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [277/782] Loss: 0.7281 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [278/782] Loss: 0.6578 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [279/782] Loss: 0.5306 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [280/782] Loss: 0.4077 | Acc: 78.93%\n",
      "Train Epoch [60/100] Batch [281/782] Loss: 0.3901 | Acc: 78.94%\n",
      "Train Epoch [60/100] Batch [282/782] Loss: 0.7013 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [283/782] Loss: 0.6376 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [284/782] Loss: 0.7607 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [285/782] Loss: 0.5353 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [286/782] Loss: 0.7025 | Acc: 78.92%\n",
      "Train Epoch [60/100] Batch [287/782] Loss: 0.6503 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [288/782] Loss: 0.6285 | Acc: 78.90%\n",
      "Train Epoch [60/100] Batch [289/782] Loss: 0.4520 | Acc: 78.91%\n",
      "Train Epoch [60/100] Batch [290/782] Loss: 0.4527 | Acc: 78.94%\n",
      "Train Epoch [60/100] Batch [291/782] Loss: 0.7240 | Acc: 78.92%\n",
      "Train Epoch [60/100] Batch [292/782] Loss: 0.8990 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [293/782] Loss: 0.5595 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [294/782] Loss: 0.5605 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [295/782] Loss: 0.5136 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [296/782] Loss: 0.6978 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [297/782] Loss: 0.7882 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [298/782] Loss: 0.6923 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [299/782] Loss: 0.4841 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [300/782] Loss: 0.7713 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [301/782] Loss: 0.5518 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [302/782] Loss: 0.7141 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [303/782] Loss: 0.5692 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [304/782] Loss: 0.5358 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [305/782] Loss: 0.4735 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [306/782] Loss: 0.5458 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [307/782] Loss: 0.6072 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [308/782] Loss: 0.6714 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [309/782] Loss: 0.7236 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [310/782] Loss: 0.5831 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [311/782] Loss: 0.7404 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [312/782] Loss: 0.7449 | Acc: 78.79%\n",
      "Train Epoch [60/100] Batch [313/782] Loss: 0.6593 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [314/782] Loss: 0.4822 | Acc: 78.79%\n",
      "Train Epoch [60/100] Batch [315/782] Loss: 0.5675 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [316/782] Loss: 0.4334 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [317/782] Loss: 0.4223 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [318/782] Loss: 0.4902 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [319/782] Loss: 0.7629 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [320/782] Loss: 0.5562 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [321/782] Loss: 0.7149 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [322/782] Loss: 0.7194 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [323/782] Loss: 0.6285 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [324/782] Loss: 0.3467 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [325/782] Loss: 0.6020 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [326/782] Loss: 0.4572 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [327/782] Loss: 0.4922 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [328/782] Loss: 0.4733 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [329/782] Loss: 0.6692 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [330/782] Loss: 0.4535 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [331/782] Loss: 0.5501 | Acc: 78.89%\n",
      "Train Epoch [60/100] Batch [332/782] Loss: 0.5873 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [333/782] Loss: 0.6066 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [334/782] Loss: 0.6563 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [335/782] Loss: 0.5325 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [336/782] Loss: 0.4761 | Acc: 78.88%\n",
      "Train Epoch [60/100] Batch [337/782] Loss: 0.7554 | Acc: 78.87%\n",
      "Train Epoch [60/100] Batch [338/782] Loss: 0.6999 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [339/782] Loss: 0.4547 | Acc: 78.86%\n",
      "Train Epoch [60/100] Batch [340/782] Loss: 0.7580 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [341/782] Loss: 0.6314 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [342/782] Loss: 0.5570 | Acc: 78.85%\n",
      "Train Epoch [60/100] Batch [343/782] Loss: 0.6212 | Acc: 78.84%\n",
      "Train Epoch [60/100] Batch [344/782] Loss: 0.7084 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [345/782] Loss: 0.7169 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [346/782] Loss: 0.5464 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [347/782] Loss: 0.5987 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [348/782] Loss: 0.3985 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [349/782] Loss: 0.4814 | Acc: 78.83%\n",
      "Train Epoch [60/100] Batch [350/782] Loss: 0.6418 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [351/782] Loss: 0.8979 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [352/782] Loss: 0.4514 | Acc: 78.79%\n",
      "Train Epoch [60/100] Batch [353/782] Loss: 0.8392 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [354/782] Loss: 0.6282 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [355/782] Loss: 0.6318 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [356/782] Loss: 0.5453 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [357/782] Loss: 0.7306 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [358/782] Loss: 0.6648 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [359/782] Loss: 0.6149 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [360/782] Loss: 0.6315 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [361/782] Loss: 0.3880 | Acc: 78.79%\n",
      "Train Epoch [60/100] Batch [362/782] Loss: 0.4834 | Acc: 78.81%\n",
      "Train Epoch [60/100] Batch [363/782] Loss: 0.4294 | Acc: 78.82%\n",
      "Train Epoch [60/100] Batch [364/782] Loss: 0.8871 | Acc: 78.80%\n",
      "Train Epoch [60/100] Batch [365/782] Loss: 0.7220 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [366/782] Loss: 0.7063 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [367/782] Loss: 0.6500 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [368/782] Loss: 0.7060 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [369/782] Loss: 0.5637 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [370/782] Loss: 0.8119 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [371/782] Loss: 0.6324 | Acc: 78.75%\n",
      "Train Epoch [60/100] Batch [372/782] Loss: 0.5485 | Acc: 78.75%\n",
      "Train Epoch [60/100] Batch [373/782] Loss: 0.5850 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [374/782] Loss: 0.6122 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [375/782] Loss: 0.6390 | Acc: 78.75%\n",
      "Train Epoch [60/100] Batch [376/782] Loss: 0.5926 | Acc: 78.75%\n",
      "Train Epoch [60/100] Batch [377/782] Loss: 0.5983 | Acc: 78.75%\n",
      "Train Epoch [60/100] Batch [378/782] Loss: 0.4027 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [379/782] Loss: 0.7637 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [380/782] Loss: 0.5742 | Acc: 78.77%\n",
      "Train Epoch [60/100] Batch [381/782] Loss: 0.4637 | Acc: 78.78%\n",
      "Train Epoch [60/100] Batch [382/782] Loss: 0.7965 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [383/782] Loss: 0.5570 | Acc: 78.76%\n",
      "Train Epoch [60/100] Batch [384/782] Loss: 0.8291 | Acc: 78.74%\n",
      "Train Epoch [60/100] Batch [385/782] Loss: 0.8840 | Acc: 78.72%\n",
      "Train Epoch [60/100] Batch [386/782] Loss: 0.6755 | Acc: 78.70%\n",
      "Train Epoch [60/100] Batch [387/782] Loss: 0.6112 | Acc: 78.69%\n",
      "Train Epoch [60/100] Batch [388/782] Loss: 0.8559 | Acc: 78.66%\n",
      "Train Epoch [60/100] Batch [389/782] Loss: 0.8138 | Acc: 78.65%\n",
      "Train Epoch [60/100] Batch [390/782] Loss: 0.7327 | Acc: 78.64%\n",
      "Train Epoch [60/100] Batch [391/782] Loss: 0.6551 | Acc: 78.63%\n",
      "Train Epoch [60/100] Batch [392/782] Loss: 0.8647 | Acc: 78.61%\n",
      "Train Epoch [60/100] Batch [393/782] Loss: 0.4856 | Acc: 78.61%\n",
      "Train Epoch [60/100] Batch [394/782] Loss: 0.5856 | Acc: 78.61%\n",
      "Train Epoch [60/100] Batch [395/782] Loss: 0.6133 | Acc: 78.61%\n",
      "Train Epoch [60/100] Batch [396/782] Loss: 0.7186 | Acc: 78.60%\n",
      "Train Epoch [60/100] Batch [397/782] Loss: 0.7041 | Acc: 78.60%\n",
      "Train Epoch [60/100] Batch [398/782] Loss: 0.7307 | Acc: 78.58%\n",
      "Train Epoch [60/100] Batch [399/782] Loss: 0.5890 | Acc: 78.59%\n",
      "Train Epoch [60/100] Batch [400/782] Loss: 0.5713 | Acc: 78.59%\n",
      "Train Epoch [60/100] Batch [401/782] Loss: 0.4999 | Acc: 78.60%\n",
      "Train Epoch [60/100] Batch [402/782] Loss: 0.6223 | Acc: 78.60%\n",
      "Train Epoch [60/100] Batch [403/782] Loss: 0.7004 | Acc: 78.59%\n",
      "Train Epoch [60/100] Batch [404/782] Loss: 0.5618 | Acc: 78.60%\n",
      "Train Epoch [60/100] Batch [405/782] Loss: 0.5536 | Acc: 78.61%\n",
      "Train Epoch [60/100] Batch [406/782] Loss: 0.8845 | Acc: 78.59%\n",
      "Train Epoch [60/100] Batch [407/782] Loss: 0.5920 | Acc: 78.59%\n",
      "Train Epoch [60/100] Batch [408/782] Loss: 0.6118 | Acc: 78.58%\n",
      "Train Epoch [60/100] Batch [409/782] Loss: 0.5421 | Acc: 78.58%\n",
      "Train Epoch [60/100] Batch [410/782] Loss: 0.5926 | Acc: 78.58%\n",
      "Train Epoch [60/100] Batch [411/782] Loss: 0.5758 | Acc: 78.58%\n",
      "Train Epoch [60/100] Batch [412/782] Loss: 0.7317 | Acc: 78.57%\n",
      "Train Epoch [60/100] Batch [413/782] Loss: 0.8281 | Acc: 78.54%\n",
      "Train Epoch [60/100] Batch [414/782] Loss: 0.8014 | Acc: 78.52%\n",
      "Train Epoch [60/100] Batch [415/782] Loss: 0.5255 | Acc: 78.52%\n",
      "Train Epoch [60/100] Batch [416/782] Loss: 0.6182 | Acc: 78.52%\n",
      "Train Epoch [60/100] Batch [417/782] Loss: 0.5715 | Acc: 78.53%\n",
      "Train Epoch [60/100] Batch [418/782] Loss: 0.7053 | Acc: 78.52%\n",
      "Train Epoch [60/100] Batch [419/782] Loss: 0.8475 | Acc: 78.49%\n",
      "Train Epoch [60/100] Batch [420/782] Loss: 0.6186 | Acc: 78.49%\n",
      "Train Epoch [60/100] Batch [421/782] Loss: 0.7028 | Acc: 78.48%\n",
      "Train Epoch [60/100] Batch [422/782] Loss: 0.6665 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [423/782] Loss: 0.8103 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [424/782] Loss: 0.7420 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [425/782] Loss: 0.7545 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [426/782] Loss: 0.4742 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [427/782] Loss: 0.5334 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [428/782] Loss: 0.5411 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [429/782] Loss: 0.4818 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [430/782] Loss: 0.8007 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [431/782] Loss: 0.6914 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [432/782] Loss: 0.6252 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [433/782] Loss: 0.4986 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [434/782] Loss: 0.6013 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [435/782] Loss: 0.8349 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [436/782] Loss: 0.7015 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [437/782] Loss: 0.6014 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [438/782] Loss: 0.5491 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [439/782] Loss: 0.4767 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [440/782] Loss: 0.7796 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [441/782] Loss: 0.4499 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [442/782] Loss: 0.6190 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [443/782] Loss: 0.4802 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [444/782] Loss: 0.4844 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [445/782] Loss: 0.5206 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [446/782] Loss: 0.6083 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [447/782] Loss: 0.6634 | Acc: 78.48%\n",
      "Train Epoch [60/100] Batch [448/782] Loss: 0.5996 | Acc: 78.47%\n",
      "Train Epoch [60/100] Batch [449/782] Loss: 0.7143 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [450/782] Loss: 0.8475 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [451/782] Loss: 0.7861 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [452/782] Loss: 0.3922 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [453/782] Loss: 0.6848 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [454/782] Loss: 0.6734 | Acc: 78.39%\n",
      "Train Epoch [60/100] Batch [455/782] Loss: 0.6066 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [456/782] Loss: 0.5169 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [457/782] Loss: 0.6655 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [458/782] Loss: 0.5481 | Acc: 78.39%\n",
      "Train Epoch [60/100] Batch [459/782] Loss: 0.6611 | Acc: 78.39%\n",
      "Train Epoch [60/100] Batch [460/782] Loss: 0.5399 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [461/782] Loss: 0.3344 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [462/782] Loss: 0.5085 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [463/782] Loss: 0.5393 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [464/782] Loss: 0.5693 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [465/782] Loss: 0.5957 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [466/782] Loss: 0.6535 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [467/782] Loss: 0.5941 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [468/782] Loss: 0.4890 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [469/782] Loss: 0.6903 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [470/782] Loss: 0.5698 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [471/782] Loss: 0.6235 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [472/782] Loss: 0.6978 | Acc: 78.46%\n",
      "Train Epoch [60/100] Batch [473/782] Loss: 0.7093 | Acc: 78.45%\n",
      "Train Epoch [60/100] Batch [474/782] Loss: 0.7836 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [475/782] Loss: 0.3388 | Acc: 78.44%\n",
      "Train Epoch [60/100] Batch [476/782] Loss: 0.7611 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [477/782] Loss: 0.4906 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [478/782] Loss: 0.6247 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [479/782] Loss: 0.7085 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [480/782] Loss: 0.7829 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [481/782] Loss: 0.5301 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [482/782] Loss: 0.6033 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [483/782] Loss: 0.5580 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [484/782] Loss: 0.6137 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [485/782] Loss: 0.4996 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [486/782] Loss: 0.5166 | Acc: 78.43%\n",
      "Train Epoch [60/100] Batch [487/782] Loss: 0.7139 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [488/782] Loss: 0.6807 | Acc: 78.41%\n",
      "Train Epoch [60/100] Batch [489/782] Loss: 0.6430 | Acc: 78.42%\n",
      "Train Epoch [60/100] Batch [490/782] Loss: 0.6577 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [491/782] Loss: 0.5273 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [492/782] Loss: 0.5459 | Acc: 78.40%\n",
      "Train Epoch [60/100] Batch [493/782] Loss: 0.7709 | Acc: 78.38%\n",
      "Train Epoch [60/100] Batch [494/782] Loss: 0.6538 | Acc: 78.37%\n",
      "Train Epoch [60/100] Batch [495/782] Loss: 0.7551 | Acc: 78.35%\n",
      "Train Epoch [60/100] Batch [496/782] Loss: 0.6533 | Acc: 78.33%\n",
      "Train Epoch [60/100] Batch [497/782] Loss: 0.7521 | Acc: 78.32%\n",
      "Train Epoch [60/100] Batch [498/782] Loss: 0.4553 | Acc: 78.33%\n",
      "Train Epoch [60/100] Batch [499/782] Loss: 0.5496 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [500/782] Loss: 0.6355 | Acc: 78.33%\n",
      "Train Epoch [60/100] Batch [501/782] Loss: 0.6122 | Acc: 78.33%\n",
      "Train Epoch [60/100] Batch [502/782] Loss: 0.5195 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [503/782] Loss: 0.6435 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [504/782] Loss: 0.5340 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [505/782] Loss: 0.6007 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [506/782] Loss: 0.4193 | Acc: 78.35%\n",
      "Train Epoch [60/100] Batch [507/782] Loss: 0.6213 | Acc: 78.35%\n",
      "Train Epoch [60/100] Batch [508/782] Loss: 0.6709 | Acc: 78.35%\n",
      "Train Epoch [60/100] Batch [509/782] Loss: 0.5715 | Acc: 78.35%\n",
      "Train Epoch [60/100] Batch [510/782] Loss: 0.6482 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [511/782] Loss: 0.5108 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [512/782] Loss: 0.6726 | Acc: 78.34%\n",
      "Train Epoch [60/100] Batch [513/782] Loss: 0.8400 | Acc: 78.32%\n",
      "Train Epoch [60/100] Batch [514/782] Loss: 0.7497 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [515/782] Loss: 0.8017 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [516/782] Loss: 0.4075 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [517/782] Loss: 0.5284 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [518/782] Loss: 0.5869 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [519/782] Loss: 0.5909 | Acc: 78.31%\n",
      "Train Epoch [60/100] Batch [520/782] Loss: 0.5761 | Acc: 78.32%\n",
      "Train Epoch [60/100] Batch [521/782] Loss: 0.6028 | Acc: 78.31%\n",
      "Train Epoch [60/100] Batch [522/782] Loss: 0.6662 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [523/782] Loss: 0.5283 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [524/782] Loss: 0.7167 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [525/782] Loss: 0.5526 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [526/782] Loss: 0.7298 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [527/782] Loss: 0.6980 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [528/782] Loss: 0.4913 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [529/782] Loss: 0.5891 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [530/782] Loss: 0.5265 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [531/782] Loss: 0.6609 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [532/782] Loss: 0.6439 | Acc: 78.27%\n",
      "Train Epoch [60/100] Batch [533/782] Loss: 0.6704 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [534/782] Loss: 0.6533 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [535/782] Loss: 0.5403 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [536/782] Loss: 0.5539 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [537/782] Loss: 0.4570 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [538/782] Loss: 0.4306 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [539/782] Loss: 0.5124 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [540/782] Loss: 0.5693 | Acc: 78.30%\n",
      "Train Epoch [60/100] Batch [541/782] Loss: 0.7471 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [542/782] Loss: 0.5808 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [543/782] Loss: 0.6002 | Acc: 78.29%\n",
      "Train Epoch [60/100] Batch [544/782] Loss: 0.7456 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [545/782] Loss: 0.6532 | Acc: 78.28%\n",
      "Train Epoch [60/100] Batch [546/782] Loss: 0.7445 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [547/782] Loss: 0.6120 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [548/782] Loss: 0.9067 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [549/782] Loss: 0.7990 | Acc: 78.24%\n",
      "Train Epoch [60/100] Batch [550/782] Loss: 0.5490 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [551/782] Loss: 0.4362 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [552/782] Loss: 0.6023 | Acc: 78.26%\n",
      "Train Epoch [60/100] Batch [553/782] Loss: 0.5261 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [554/782] Loss: 0.6716 | Acc: 78.25%\n",
      "Train Epoch [60/100] Batch [555/782] Loss: 0.6003 | Acc: 78.23%\n",
      "Train Epoch [60/100] Batch [556/782] Loss: 0.5856 | Acc: 78.24%\n",
      "Train Epoch [60/100] Batch [557/782] Loss: 0.8073 | Acc: 78.22%\n",
      "Train Epoch [60/100] Batch [558/782] Loss: 0.7048 | Acc: 78.21%\n",
      "Train Epoch [60/100] Batch [559/782] Loss: 0.6689 | Acc: 78.21%\n",
      "Train Epoch [60/100] Batch [560/782] Loss: 0.6291 | Acc: 78.21%\n",
      "Train Epoch [60/100] Batch [561/782] Loss: 0.5354 | Acc: 78.21%\n",
      "Train Epoch [60/100] Batch [562/782] Loss: 0.7093 | Acc: 78.21%\n",
      "Train Epoch [60/100] Batch [563/782] Loss: 0.9634 | Acc: 78.20%\n",
      "Train Epoch [60/100] Batch [564/782] Loss: 0.4356 | Acc: 78.20%\n",
      "Train Epoch [60/100] Batch [565/782] Loss: 0.6330 | Acc: 78.20%\n",
      "Train Epoch [60/100] Batch [566/782] Loss: 0.6047 | Acc: 78.20%\n",
      "Train Epoch [60/100] Batch [567/782] Loss: 0.6883 | Acc: 78.19%\n",
      "Train Epoch [60/100] Batch [568/782] Loss: 0.6411 | Acc: 78.19%\n",
      "Train Epoch [60/100] Batch [569/782] Loss: 0.7969 | Acc: 78.17%\n",
      "Train Epoch [60/100] Batch [570/782] Loss: 0.6182 | Acc: 78.18%\n",
      "Train Epoch [60/100] Batch [571/782] Loss: 0.7012 | Acc: 78.18%\n",
      "Train Epoch [60/100] Batch [572/782] Loss: 0.6593 | Acc: 78.18%\n",
      "Train Epoch [60/100] Batch [573/782] Loss: 0.5293 | Acc: 78.19%\n",
      "Train Epoch [60/100] Batch [574/782] Loss: 0.3999 | Acc: 78.19%\n",
      "Train Epoch [60/100] Batch [575/782] Loss: 0.7906 | Acc: 78.17%\n",
      "Train Epoch [60/100] Batch [576/782] Loss: 0.7187 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [577/782] Loss: 0.4840 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [578/782] Loss: 0.9611 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [579/782] Loss: 0.4633 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [580/782] Loss: 0.8605 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [581/782] Loss: 0.5271 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [582/782] Loss: 0.5885 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [583/782] Loss: 0.6416 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [584/782] Loss: 0.6964 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [585/782] Loss: 0.6444 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [586/782] Loss: 0.4703 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [587/782] Loss: 0.6911 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [588/782] Loss: 0.7509 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [589/782] Loss: 0.5984 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [590/782] Loss: 0.5992 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [591/782] Loss: 0.7129 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [592/782] Loss: 0.4956 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [593/782] Loss: 0.7635 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [594/782] Loss: 0.7115 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [595/782] Loss: 0.8777 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [596/782] Loss: 0.6616 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [597/782] Loss: 0.3140 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [598/782] Loss: 0.6931 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [599/782] Loss: 0.6641 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [600/782] Loss: 0.4246 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [601/782] Loss: 0.6773 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [602/782] Loss: 0.6377 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [603/782] Loss: 0.5029 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [604/782] Loss: 0.4627 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [605/782] Loss: 0.5515 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [606/782] Loss: 0.3763 | Acc: 78.17%\n",
      "Train Epoch [60/100] Batch [607/782] Loss: 0.9621 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [608/782] Loss: 0.7066 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [609/782] Loss: 0.7951 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [610/782] Loss: 0.5277 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [611/782] Loss: 0.4558 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [612/782] Loss: 0.7970 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [613/782] Loss: 0.5798 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [614/782] Loss: 0.5708 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [615/782] Loss: 0.6061 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [616/782] Loss: 0.5372 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [617/782] Loss: 0.7628 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [618/782] Loss: 0.6388 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [619/782] Loss: 0.7299 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [620/782] Loss: 0.5814 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [621/782] Loss: 0.7249 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [622/782] Loss: 0.4266 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [623/782] Loss: 0.5576 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [624/782] Loss: 0.6472 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [625/782] Loss: 0.8435 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [626/782] Loss: 0.5300 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [627/782] Loss: 0.7524 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [628/782] Loss: 0.5609 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [629/782] Loss: 0.4566 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [630/782] Loss: 0.6735 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [631/782] Loss: 0.5972 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [632/782] Loss: 0.6287 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [633/782] Loss: 0.4210 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [634/782] Loss: 0.7870 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [635/782] Loss: 0.4100 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [636/782] Loss: 0.5806 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [637/782] Loss: 0.5630 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [638/782] Loss: 0.7168 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [639/782] Loss: 0.5228 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [640/782] Loss: 0.5351 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [641/782] Loss: 0.5352 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [642/782] Loss: 0.7017 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [643/782] Loss: 0.8555 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [644/782] Loss: 0.5404 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [645/782] Loss: 0.7549 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [646/782] Loss: 0.6947 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [647/782] Loss: 0.6917 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [648/782] Loss: 0.6556 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [649/782] Loss: 0.5919 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [650/782] Loss: 0.7212 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [651/782] Loss: 0.5329 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [652/782] Loss: 0.7677 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [653/782] Loss: 0.5690 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [654/782] Loss: 0.4386 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [655/782] Loss: 0.6124 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [656/782] Loss: 0.5775 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [657/782] Loss: 0.5600 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [658/782] Loss: 0.8268 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [659/782] Loss: 0.4574 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [660/782] Loss: 0.5447 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [661/782] Loss: 0.5225 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [662/782] Loss: 0.6218 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [663/782] Loss: 0.4645 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [664/782] Loss: 0.6265 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [665/782] Loss: 0.7398 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [666/782] Loss: 0.5714 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [667/782] Loss: 0.5481 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [668/782] Loss: 0.5760 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [669/782] Loss: 0.6498 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [670/782] Loss: 0.8501 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [671/782] Loss: 0.6076 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [672/782] Loss: 0.5623 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [673/782] Loss: 0.4574 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [674/782] Loss: 0.5909 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [675/782] Loss: 0.4874 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [676/782] Loss: 0.6217 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [677/782] Loss: 0.4807 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [678/782] Loss: 0.5819 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [679/782] Loss: 0.5587 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [680/782] Loss: 0.5784 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [681/782] Loss: 0.6563 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [682/782] Loss: 0.8816 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [683/782] Loss: 0.4789 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [684/782] Loss: 0.6222 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [685/782] Loss: 0.6015 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [686/782] Loss: 0.6770 | Acc: 78.14%\n",
      "Train Epoch [60/100] Batch [687/782] Loss: 0.4123 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [688/782] Loss: 0.6204 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [689/782] Loss: 0.6687 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [690/782] Loss: 0.6619 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [691/782] Loss: 0.5625 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [692/782] Loss: 0.6109 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [693/782] Loss: 0.5854 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [694/782] Loss: 0.6423 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [695/782] Loss: 0.5676 | Acc: 78.16%\n",
      "Train Epoch [60/100] Batch [696/782] Loss: 0.7409 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [697/782] Loss: 0.6305 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [698/782] Loss: 0.5442 | Acc: 78.15%\n",
      "Train Epoch [60/100] Batch [699/782] Loss: 0.7423 | Acc: 78.13%\n",
      "Train Epoch [60/100] Batch [700/782] Loss: 0.7179 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [701/782] Loss: 0.7146 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [702/782] Loss: 0.6927 | Acc: 78.10%\n",
      "Train Epoch [60/100] Batch [703/782] Loss: 0.7118 | Acc: 78.10%\n",
      "Train Epoch [60/100] Batch [704/782] Loss: 0.6440 | Acc: 78.10%\n",
      "Train Epoch [60/100] Batch [705/782] Loss: 0.5444 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [706/782] Loss: 0.6598 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [707/782] Loss: 0.5679 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [708/782] Loss: 0.5548 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [709/782] Loss: 0.5805 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [710/782] Loss: 0.4726 | Acc: 78.12%\n",
      "Train Epoch [60/100] Batch [711/782] Loss: 0.7328 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [712/782] Loss: 0.5786 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [713/782] Loss: 0.5638 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [714/782] Loss: 0.5792 | Acc: 78.11%\n",
      "Train Epoch [60/100] Batch [715/782] Loss: 0.7784 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [716/782] Loss: 0.7142 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [717/782] Loss: 0.4152 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [718/782] Loss: 0.6055 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [719/782] Loss: 0.6769 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [720/782] Loss: 0.5362 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [721/782] Loss: 0.9617 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [722/782] Loss: 0.8616 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [723/782] Loss: 0.6763 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [724/782] Loss: 0.7355 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [725/782] Loss: 0.6871 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [726/782] Loss: 0.6307 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [727/782] Loss: 0.5223 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [728/782] Loss: 0.6149 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [729/782] Loss: 0.6823 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [730/782] Loss: 0.4159 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [731/782] Loss: 0.7184 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [732/782] Loss: 0.7569 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [733/782] Loss: 0.4611 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [734/782] Loss: 0.7668 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [735/782] Loss: 0.6863 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [736/782] Loss: 0.6303 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [737/782] Loss: 0.3673 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [738/782] Loss: 0.5476 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [739/782] Loss: 0.3982 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [740/782] Loss: 0.6232 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [741/782] Loss: 0.8114 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [742/782] Loss: 0.5392 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [743/782] Loss: 0.7670 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [744/782] Loss: 0.8220 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [745/782] Loss: 0.7030 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [746/782] Loss: 0.6872 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [747/782] Loss: 0.6828 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [748/782] Loss: 0.5813 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [749/782] Loss: 0.5805 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [750/782] Loss: 0.6099 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [751/782] Loss: 0.5582 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [752/782] Loss: 0.6108 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [753/782] Loss: 0.5809 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [754/782] Loss: 0.6828 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [755/782] Loss: 0.6247 | Acc: 78.06%\n",
      "Train Epoch [60/100] Batch [756/782] Loss: 0.6725 | Acc: 78.05%\n",
      "Train Epoch [60/100] Batch [757/782] Loss: 0.5049 | Acc: 78.06%\n",
      "Train Epoch [60/100] Batch [758/782] Loss: 0.5962 | Acc: 78.06%\n",
      "Train Epoch [60/100] Batch [759/782] Loss: 0.5414 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [760/782] Loss: 0.6133 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [761/782] Loss: 0.4854 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [762/782] Loss: 0.6138 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [763/782] Loss: 0.5418 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [764/782] Loss: 0.6541 | Acc: 78.09%\n",
      "Train Epoch [60/100] Batch [765/782] Loss: 0.8202 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [766/782] Loss: 0.5425 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [767/782] Loss: 0.6666 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [768/782] Loss: 0.5410 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [769/782] Loss: 0.7071 | Acc: 78.06%\n",
      "Train Epoch [60/100] Batch [770/782] Loss: 0.7924 | Acc: 78.06%\n",
      "Train Epoch [60/100] Batch [771/782] Loss: 0.3824 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [772/782] Loss: 0.5173 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [773/782] Loss: 0.7120 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [774/782] Loss: 0.4946 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [775/782] Loss: 0.5366 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [776/782] Loss: 0.5435 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [777/782] Loss: 0.6789 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [778/782] Loss: 0.6011 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [779/782] Loss: 0.7200 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [780/782] Loss: 0.6502 | Acc: 78.07%\n",
      "Train Epoch [60/100] Batch [781/782] Loss: 0.4400 | Acc: 78.08%\n",
      "Train Epoch [60/100] Batch [782/782] Loss: 0.5439 | Acc: 78.08%\n",
      "Epoch 60 completed in 29.74s.\n",
      "Test Epoch [60/100] Loss: 0.8760 | Acc: 72.95% | Inference Time: 8.51s\n",
      "Epoch 60 results saved to CSV.\n",
      "Epoch 61/100\n",
      "Train Epoch [61/100] Batch [1/782] Loss: 0.5774 | Acc: 79.69%\n",
      "Train Epoch [61/100] Batch [2/782] Loss: 0.4795 | Acc: 82.03%\n",
      "Train Epoch [61/100] Batch [3/782] Loss: 0.4672 | Acc: 82.81%\n",
      "Train Epoch [61/100] Batch [4/782] Loss: 0.6749 | Acc: 80.86%\n",
      "Train Epoch [61/100] Batch [5/782] Loss: 0.5891 | Acc: 80.31%\n",
      "Train Epoch [61/100] Batch [6/782] Loss: 0.5492 | Acc: 80.73%\n",
      "Train Epoch [61/100] Batch [7/782] Loss: 0.6953 | Acc: 80.13%\n",
      "Train Epoch [61/100] Batch [8/782] Loss: 0.5671 | Acc: 79.88%\n",
      "Train Epoch [61/100] Batch [9/782] Loss: 0.6054 | Acc: 80.56%\n",
      "Train Epoch [61/100] Batch [10/782] Loss: 0.6398 | Acc: 80.47%\n",
      "Train Epoch [61/100] Batch [11/782] Loss: 0.5328 | Acc: 80.40%\n",
      "Train Epoch [61/100] Batch [12/782] Loss: 0.7222 | Acc: 79.69%\n",
      "Train Epoch [61/100] Batch [13/782] Loss: 0.6068 | Acc: 79.57%\n",
      "Train Epoch [61/100] Batch [14/782] Loss: 0.5424 | Acc: 79.80%\n",
      "Train Epoch [61/100] Batch [15/782] Loss: 0.6620 | Acc: 79.69%\n",
      "Train Epoch [61/100] Batch [16/782] Loss: 0.5753 | Acc: 79.49%\n",
      "Train Epoch [61/100] Batch [17/782] Loss: 0.6862 | Acc: 79.23%\n",
      "Train Epoch [61/100] Batch [18/782] Loss: 0.6216 | Acc: 79.17%\n",
      "Train Epoch [61/100] Batch [19/782] Loss: 0.4275 | Acc: 79.69%\n",
      "Train Epoch [61/100] Batch [20/782] Loss: 0.7152 | Acc: 79.38%\n",
      "Train Epoch [61/100] Batch [21/782] Loss: 0.6215 | Acc: 79.17%\n",
      "Train Epoch [61/100] Batch [22/782] Loss: 0.6697 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [23/782] Loss: 0.7073 | Acc: 78.60%\n",
      "Train Epoch [61/100] Batch [24/782] Loss: 0.4970 | Acc: 78.65%\n",
      "Train Epoch [61/100] Batch [25/782] Loss: 0.7338 | Acc: 78.44%\n",
      "Train Epoch [61/100] Batch [26/782] Loss: 0.4833 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [27/782] Loss: 0.6147 | Acc: 78.53%\n",
      "Train Epoch [61/100] Batch [28/782] Loss: 0.6770 | Acc: 78.52%\n",
      "Train Epoch [61/100] Batch [29/782] Loss: 0.7175 | Acc: 78.29%\n",
      "Train Epoch [61/100] Batch [30/782] Loss: 0.3962 | Acc: 78.49%\n",
      "Train Epoch [61/100] Batch [31/782] Loss: 0.6160 | Acc: 78.53%\n",
      "Train Epoch [61/100] Batch [32/782] Loss: 0.5729 | Acc: 78.56%\n",
      "Train Epoch [61/100] Batch [33/782] Loss: 0.6302 | Acc: 78.65%\n",
      "Train Epoch [61/100] Batch [34/782] Loss: 0.6790 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [35/782] Loss: 0.7925 | Acc: 78.44%\n",
      "Train Epoch [61/100] Batch [36/782] Loss: 0.5024 | Acc: 78.39%\n",
      "Train Epoch [61/100] Batch [37/782] Loss: 0.5716 | Acc: 78.38%\n",
      "Train Epoch [61/100] Batch [38/782] Loss: 0.6095 | Acc: 78.33%\n",
      "Train Epoch [61/100] Batch [39/782] Loss: 0.4560 | Acc: 78.41%\n",
      "Train Epoch [61/100] Batch [40/782] Loss: 0.4774 | Acc: 78.59%\n",
      "Train Epoch [61/100] Batch [41/782] Loss: 0.6167 | Acc: 78.58%\n",
      "Train Epoch [61/100] Batch [42/782] Loss: 0.4478 | Acc: 78.68%\n",
      "Train Epoch [61/100] Batch [43/782] Loss: 0.5950 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [44/782] Loss: 0.6442 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [45/782] Loss: 0.5893 | Acc: 78.68%\n",
      "Train Epoch [61/100] Batch [46/782] Loss: 0.8993 | Acc: 78.50%\n",
      "Train Epoch [61/100] Batch [47/782] Loss: 0.6818 | Acc: 78.49%\n",
      "Train Epoch [61/100] Batch [48/782] Loss: 0.7147 | Acc: 78.32%\n",
      "Train Epoch [61/100] Batch [49/782] Loss: 0.5930 | Acc: 78.38%\n",
      "Train Epoch [61/100] Batch [50/782] Loss: 0.8204 | Acc: 78.25%\n",
      "Train Epoch [61/100] Batch [51/782] Loss: 0.6796 | Acc: 78.12%\n",
      "Train Epoch [61/100] Batch [52/782] Loss: 0.6918 | Acc: 78.06%\n",
      "Train Epoch [61/100] Batch [53/782] Loss: 0.6392 | Acc: 77.95%\n",
      "Train Epoch [61/100] Batch [54/782] Loss: 0.6290 | Acc: 77.98%\n",
      "Train Epoch [61/100] Batch [55/782] Loss: 0.5773 | Acc: 78.04%\n",
      "Train Epoch [61/100] Batch [56/782] Loss: 0.6793 | Acc: 78.07%\n",
      "Train Epoch [61/100] Batch [57/782] Loss: 0.4034 | Acc: 78.26%\n",
      "Train Epoch [61/100] Batch [58/782] Loss: 0.7435 | Acc: 78.07%\n",
      "Train Epoch [61/100] Batch [59/782] Loss: 0.6544 | Acc: 78.07%\n",
      "Train Epoch [61/100] Batch [60/782] Loss: 0.6179 | Acc: 78.07%\n",
      "Train Epoch [61/100] Batch [61/782] Loss: 0.4050 | Acc: 78.23%\n",
      "Train Epoch [61/100] Batch [62/782] Loss: 0.6276 | Acc: 78.23%\n",
      "Train Epoch [61/100] Batch [63/782] Loss: 0.5700 | Acc: 78.17%\n",
      "Train Epoch [61/100] Batch [64/782] Loss: 0.5680 | Acc: 78.20%\n",
      "Train Epoch [61/100] Batch [65/782] Loss: 0.6009 | Acc: 78.12%\n",
      "Train Epoch [61/100] Batch [66/782] Loss: 0.4494 | Acc: 78.20%\n",
      "Train Epoch [61/100] Batch [67/782] Loss: 0.5751 | Acc: 78.19%\n",
      "Train Epoch [61/100] Batch [68/782] Loss: 0.4182 | Acc: 78.31%\n",
      "Train Epoch [61/100] Batch [69/782] Loss: 0.5523 | Acc: 78.33%\n",
      "Train Epoch [61/100] Batch [70/782] Loss: 0.3793 | Acc: 78.42%\n",
      "Train Epoch [61/100] Batch [71/782] Loss: 0.7564 | Acc: 78.35%\n",
      "Train Epoch [61/100] Batch [72/782] Loss: 0.5702 | Acc: 78.36%\n",
      "Train Epoch [61/100] Batch [73/782] Loss: 0.6508 | Acc: 78.25%\n",
      "Train Epoch [61/100] Batch [74/782] Loss: 0.7587 | Acc: 78.25%\n",
      "Train Epoch [61/100] Batch [75/782] Loss: 0.4278 | Acc: 78.33%\n",
      "Train Epoch [61/100] Batch [76/782] Loss: 0.5845 | Acc: 78.33%\n",
      "Train Epoch [61/100] Batch [77/782] Loss: 0.5160 | Acc: 78.37%\n",
      "Train Epoch [61/100] Batch [78/782] Loss: 0.4598 | Acc: 78.43%\n",
      "Train Epoch [61/100] Batch [79/782] Loss: 0.4431 | Acc: 78.50%\n",
      "Train Epoch [61/100] Batch [80/782] Loss: 0.6132 | Acc: 78.50%\n",
      "Train Epoch [61/100] Batch [81/782] Loss: 0.5575 | Acc: 78.57%\n",
      "Train Epoch [61/100] Batch [82/782] Loss: 0.5129 | Acc: 78.56%\n",
      "Train Epoch [61/100] Batch [83/782] Loss: 0.5386 | Acc: 78.58%\n",
      "Train Epoch [61/100] Batch [84/782] Loss: 0.7688 | Acc: 78.52%\n",
      "Train Epoch [61/100] Batch [85/782] Loss: 0.4649 | Acc: 78.58%\n",
      "Train Epoch [61/100] Batch [86/782] Loss: 0.5881 | Acc: 78.60%\n",
      "Train Epoch [61/100] Batch [87/782] Loss: 0.4698 | Acc: 78.65%\n",
      "Train Epoch [61/100] Batch [88/782] Loss: 0.5361 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [89/782] Loss: 0.5870 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [90/782] Loss: 0.6269 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [91/782] Loss: 0.3957 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [92/782] Loss: 0.6476 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [93/782] Loss: 0.3994 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [94/782] Loss: 0.5831 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [95/782] Loss: 0.5627 | Acc: 78.90%\n",
      "Train Epoch [61/100] Batch [96/782] Loss: 0.6436 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [97/782] Loss: 1.0227 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [98/782] Loss: 0.6402 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [99/782] Loss: 0.5764 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [100/782] Loss: 0.5854 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [101/782] Loss: 0.5286 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [102/782] Loss: 0.5207 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [103/782] Loss: 0.6650 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [104/782] Loss: 0.6033 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [105/782] Loss: 0.8709 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [106/782] Loss: 0.6453 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [107/782] Loss: 0.7978 | Acc: 78.59%\n",
      "Train Epoch [61/100] Batch [108/782] Loss: 0.7321 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [109/782] Loss: 0.6817 | Acc: 78.60%\n",
      "Train Epoch [61/100] Batch [110/782] Loss: 0.5974 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [111/782] Loss: 0.5283 | Acc: 78.65%\n",
      "Train Epoch [61/100] Batch [112/782] Loss: 0.7920 | Acc: 78.59%\n",
      "Train Epoch [61/100] Batch [113/782] Loss: 0.6061 | Acc: 78.58%\n",
      "Train Epoch [61/100] Batch [114/782] Loss: 0.5265 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [115/782] Loss: 0.4619 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [116/782] Loss: 0.5919 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [117/782] Loss: 0.5491 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [118/782] Loss: 0.6631 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [119/782] Loss: 0.6612 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [120/782] Loss: 0.6798 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [121/782] Loss: 0.6990 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [122/782] Loss: 0.7842 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [123/782] Loss: 0.6638 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [124/782] Loss: 0.4681 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [125/782] Loss: 0.6649 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [126/782] Loss: 0.6707 | Acc: 78.67%\n",
      "Train Epoch [61/100] Batch [127/782] Loss: 0.7794 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [128/782] Loss: 0.6665 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [129/782] Loss: 0.7096 | Acc: 78.61%\n",
      "Train Epoch [61/100] Batch [130/782] Loss: 0.5000 | Acc: 78.62%\n",
      "Train Epoch [61/100] Batch [131/782] Loss: 0.6631 | Acc: 78.59%\n",
      "Train Epoch [61/100] Batch [132/782] Loss: 0.4616 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [133/782] Loss: 0.7039 | Acc: 78.62%\n",
      "Train Epoch [61/100] Batch [134/782] Loss: 0.5954 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [135/782] Loss: 0.7744 | Acc: 78.59%\n",
      "Train Epoch [61/100] Batch [136/782] Loss: 0.5139 | Acc: 78.61%\n",
      "Train Epoch [61/100] Batch [137/782] Loss: 0.3887 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [138/782] Loss: 0.5837 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [139/782] Loss: 0.5885 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [140/782] Loss: 0.4489 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [141/782] Loss: 0.5400 | Acc: 78.67%\n",
      "Train Epoch [61/100] Batch [142/782] Loss: 0.4897 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [143/782] Loss: 0.6053 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [144/782] Loss: 0.4816 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [145/782] Loss: 0.8326 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [146/782] Loss: 0.6233 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [147/782] Loss: 0.5282 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [148/782] Loss: 0.5935 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [149/782] Loss: 0.6768 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [150/782] Loss: 0.6216 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [151/782] Loss: 0.4367 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [152/782] Loss: 0.5931 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [153/782] Loss: 0.4693 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [154/782] Loss: 0.6181 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [155/782] Loss: 0.5964 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [156/782] Loss: 0.7902 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [157/782] Loss: 0.5002 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [158/782] Loss: 0.6830 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [159/782] Loss: 0.5618 | Acc: 78.68%\n",
      "Train Epoch [61/100] Batch [160/782] Loss: 0.7144 | Acc: 78.67%\n",
      "Train Epoch [61/100] Batch [161/782] Loss: 0.3379 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [162/782] Loss: 0.4154 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [163/782] Loss: 0.5127 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [164/782] Loss: 0.5443 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [165/782] Loss: 0.5621 | Acc: 78.89%\n",
      "Train Epoch [61/100] Batch [166/782] Loss: 0.5788 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [167/782] Loss: 0.6959 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [168/782] Loss: 0.5011 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [169/782] Loss: 0.5150 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [170/782] Loss: 0.5488 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [171/782] Loss: 0.7553 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [172/782] Loss: 0.4443 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [173/782] Loss: 0.4732 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [174/782] Loss: 0.5768 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [175/782] Loss: 0.5358 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [176/782] Loss: 0.6692 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [177/782] Loss: 0.7507 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [178/782] Loss: 0.7927 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [179/782] Loss: 0.7182 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [180/782] Loss: 0.6146 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [181/782] Loss: 0.7119 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [182/782] Loss: 0.6284 | Acc: 78.67%\n",
      "Train Epoch [61/100] Batch [183/782] Loss: 0.5088 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [184/782] Loss: 0.5010 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [185/782] Loss: 0.5810 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [186/782] Loss: 0.5552 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [187/782] Loss: 0.5448 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [188/782] Loss: 0.6332 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [189/782] Loss: 0.5829 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [190/782] Loss: 0.6714 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [191/782] Loss: 0.7523 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [192/782] Loss: 0.5593 | Acc: 78.68%\n",
      "Train Epoch [61/100] Batch [193/782] Loss: 0.5916 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [194/782] Loss: 0.6195 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [195/782] Loss: 0.5449 | Acc: 78.65%\n",
      "Train Epoch [61/100] Batch [196/782] Loss: 0.4527 | Acc: 78.68%\n",
      "Train Epoch [61/100] Batch [197/782] Loss: 0.4354 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [198/782] Loss: 0.8491 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [199/782] Loss: 0.7214 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [200/782] Loss: 0.5754 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [201/782] Loss: 0.4717 | Acc: 78.66%\n",
      "Train Epoch [61/100] Batch [202/782] Loss: 0.7100 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [203/782] Loss: 0.5339 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [204/782] Loss: 0.5609 | Acc: 78.63%\n",
      "Train Epoch [61/100] Batch [205/782] Loss: 0.6451 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [206/782] Loss: 0.6291 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [207/782] Loss: 0.6858 | Acc: 78.61%\n",
      "Train Epoch [61/100] Batch [208/782] Loss: 0.5823 | Acc: 78.61%\n",
      "Train Epoch [61/100] Batch [209/782] Loss: 0.3844 | Acc: 78.64%\n",
      "Train Epoch [61/100] Batch [210/782] Loss: 0.3785 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [211/782] Loss: 0.6251 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [212/782] Loss: 0.3548 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [213/782] Loss: 0.8150 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [214/782] Loss: 0.4394 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [215/782] Loss: 0.4730 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [216/782] Loss: 0.6805 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [217/782] Loss: 0.5898 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [218/782] Loss: 0.7680 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [219/782] Loss: 0.5012 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [220/782] Loss: 0.4656 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [221/782] Loss: 0.3978 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [222/782] Loss: 0.7661 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [223/782] Loss: 0.5149 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [224/782] Loss: 0.4224 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [225/782] Loss: 0.6587 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [226/782] Loss: 0.3845 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [227/782] Loss: 0.3699 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [228/782] Loss: 0.5594 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [229/782] Loss: 0.5217 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [230/782] Loss: 0.7158 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [231/782] Loss: 0.6333 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [232/782] Loss: 0.4738 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [233/782] Loss: 0.5033 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [234/782] Loss: 0.5580 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [235/782] Loss: 0.5547 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [236/782] Loss: 0.4403 | Acc: 78.91%\n",
      "Train Epoch [61/100] Batch [237/782] Loss: 0.8215 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [238/782] Loss: 0.8451 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [239/782] Loss: 1.0855 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [240/782] Loss: 0.6410 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [241/782] Loss: 0.5934 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [242/782] Loss: 0.5521 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [243/782] Loss: 0.6052 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [244/782] Loss: 0.6632 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [245/782] Loss: 0.8320 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [246/782] Loss: 0.6033 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [247/782] Loss: 0.6167 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [248/782] Loss: 0.5121 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [249/782] Loss: 0.5496 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [250/782] Loss: 0.5798 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [251/782] Loss: 0.6911 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [252/782] Loss: 0.4727 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [253/782] Loss: 0.7811 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [254/782] Loss: 0.5771 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [255/782] Loss: 0.6678 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [256/782] Loss: 0.5421 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [257/782] Loss: 0.6397 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [258/782] Loss: 0.5778 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [259/782] Loss: 0.5022 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [260/782] Loss: 0.5527 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [261/782] Loss: 0.7711 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [262/782] Loss: 0.4994 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [263/782] Loss: 0.8644 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [264/782] Loss: 0.7834 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [265/782] Loss: 0.5317 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [266/782] Loss: 0.4787 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [267/782] Loss: 0.4898 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [268/782] Loss: 0.8809 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [269/782] Loss: 0.4935 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [270/782] Loss: 0.5836 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [271/782] Loss: 0.5448 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [272/782] Loss: 0.7081 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [273/782] Loss: 0.7778 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [274/782] Loss: 0.8266 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [275/782] Loss: 0.5525 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [276/782] Loss: 0.5615 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [277/782] Loss: 0.5707 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [278/782] Loss: 0.3308 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [279/782] Loss: 0.5191 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [280/782] Loss: 0.4651 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [281/782] Loss: 0.4823 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [282/782] Loss: 0.6137 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [283/782] Loss: 0.6805 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [284/782] Loss: 0.7263 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [285/782] Loss: 0.5452 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [286/782] Loss: 0.7266 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [287/782] Loss: 0.6858 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [288/782] Loss: 0.5383 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [289/782] Loss: 0.6405 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [290/782] Loss: 0.7402 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [291/782] Loss: 0.6114 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [292/782] Loss: 0.5855 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [293/782] Loss: 0.6127 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [294/782] Loss: 0.5697 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [295/782] Loss: 0.5453 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [296/782] Loss: 0.4287 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [297/782] Loss: 0.5979 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [298/782] Loss: 0.4389 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [299/782] Loss: 0.5659 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [300/782] Loss: 0.5719 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [301/782] Loss: 0.5553 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [302/782] Loss: 0.6518 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [303/782] Loss: 0.7095 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [304/782] Loss: 0.6196 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [305/782] Loss: 0.5018 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [306/782] Loss: 0.5953 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [307/782] Loss: 0.6890 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [308/782] Loss: 0.4656 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [309/782] Loss: 0.9166 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [310/782] Loss: 0.7396 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [311/782] Loss: 0.7886 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [312/782] Loss: 0.3756 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [313/782] Loss: 0.3771 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [314/782] Loss: 0.6273 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [315/782] Loss: 0.6053 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [316/782] Loss: 0.6564 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [317/782] Loss: 0.5077 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [318/782] Loss: 0.3671 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [319/782] Loss: 0.3156 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [320/782] Loss: 0.8346 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [321/782] Loss: 0.5991 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [322/782] Loss: 0.6018 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [323/782] Loss: 0.6235 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [324/782] Loss: 0.3633 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [325/782] Loss: 0.5905 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [326/782] Loss: 0.7725 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [327/782] Loss: 0.4617 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [328/782] Loss: 0.5931 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [329/782] Loss: 0.5852 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [330/782] Loss: 0.6027 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [331/782] Loss: 0.3646 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [332/782] Loss: 0.7128 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [333/782] Loss: 0.4482 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [334/782] Loss: 0.5106 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [335/782] Loss: 0.5533 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [336/782] Loss: 0.5449 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [337/782] Loss: 0.5723 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [338/782] Loss: 0.7556 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [339/782] Loss: 0.4384 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [340/782] Loss: 0.6836 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [341/782] Loss: 0.6872 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [342/782] Loss: 0.8870 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [343/782] Loss: 0.7334 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [344/782] Loss: 0.5603 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [345/782] Loss: 0.6111 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [346/782] Loss: 0.6148 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [347/782] Loss: 0.5497 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [348/782] Loss: 0.5976 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [349/782] Loss: 0.6154 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [350/782] Loss: 0.3654 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [351/782] Loss: 0.5712 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [352/782] Loss: 0.7293 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [353/782] Loss: 0.8095 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [354/782] Loss: 0.6020 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [355/782] Loss: 0.4860 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [356/782] Loss: 0.5450 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [357/782] Loss: 0.6497 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [358/782] Loss: 0.5088 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [359/782] Loss: 0.5970 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [360/782] Loss: 0.5723 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [361/782] Loss: 0.4077 | Acc: 78.89%\n",
      "Train Epoch [61/100] Batch [362/782] Loss: 0.6569 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [363/782] Loss: 0.6610 | Acc: 78.89%\n",
      "Train Epoch [61/100] Batch [364/782] Loss: 0.7027 | Acc: 78.88%\n",
      "Train Epoch [61/100] Batch [365/782] Loss: 0.5647 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [366/782] Loss: 0.7522 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [367/782] Loss: 0.7815 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [368/782] Loss: 0.7075 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [369/782] Loss: 0.5010 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [370/782] Loss: 0.4158 | Acc: 78.89%\n",
      "Train Epoch [61/100] Batch [371/782] Loss: 0.5971 | Acc: 78.87%\n",
      "Train Epoch [61/100] Batch [372/782] Loss: 0.6405 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [373/782] Loss: 0.5749 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [374/782] Loss: 0.5501 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [375/782] Loss: 0.6836 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [376/782] Loss: 0.8406 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [377/782] Loss: 0.5647 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [378/782] Loss: 0.3660 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [379/782] Loss: 0.7066 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [380/782] Loss: 0.6844 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [381/782] Loss: 0.6128 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [382/782] Loss: 0.4637 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [383/782] Loss: 0.5474 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [384/782] Loss: 0.6591 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [385/782] Loss: 0.4343 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [386/782] Loss: 0.4752 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [387/782] Loss: 0.4579 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [388/782] Loss: 0.5682 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [389/782] Loss: 0.4560 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [390/782] Loss: 0.6890 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [391/782] Loss: 0.7135 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [392/782] Loss: 0.4527 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [393/782] Loss: 0.7173 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [394/782] Loss: 0.6260 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [395/782] Loss: 0.7668 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [396/782] Loss: 0.4894 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [397/782] Loss: 0.5663 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [398/782] Loss: 0.5900 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [399/782] Loss: 0.7591 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [400/782] Loss: 0.4532 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [401/782] Loss: 0.6835 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [402/782] Loss: 0.5556 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [403/782] Loss: 0.3443 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [404/782] Loss: 0.5355 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [405/782] Loss: 0.5484 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [406/782] Loss: 0.5858 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [407/782] Loss: 0.4345 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [408/782] Loss: 0.6321 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [409/782] Loss: 0.6531 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [410/782] Loss: 0.6874 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [411/782] Loss: 0.5150 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [412/782] Loss: 0.5626 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [413/782] Loss: 0.5577 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [414/782] Loss: 0.5314 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [415/782] Loss: 0.5211 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [416/782] Loss: 0.7031 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [417/782] Loss: 0.4642 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [418/782] Loss: 0.5826 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [419/782] Loss: 0.5276 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [420/782] Loss: 0.5903 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [421/782] Loss: 0.6573 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [422/782] Loss: 0.7331 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [423/782] Loss: 0.4946 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [424/782] Loss: 0.6471 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [425/782] Loss: 0.5841 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [426/782] Loss: 0.7909 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [427/782] Loss: 0.5306 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [428/782] Loss: 0.6171 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [429/782] Loss: 0.5190 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [430/782] Loss: 0.5174 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [431/782] Loss: 0.7399 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [432/782] Loss: 0.6350 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [433/782] Loss: 0.6331 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [434/782] Loss: 0.6307 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [435/782] Loss: 0.6390 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [436/782] Loss: 0.5025 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [437/782] Loss: 0.5330 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [438/782] Loss: 0.5845 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [439/782] Loss: 0.6256 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [440/782] Loss: 0.3716 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [441/782] Loss: 0.4506 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [442/782] Loss: 0.8020 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [443/782] Loss: 0.4877 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [444/782] Loss: 0.5762 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [445/782] Loss: 0.7637 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [446/782] Loss: 0.5912 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [447/782] Loss: 0.4477 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [448/782] Loss: 0.5778 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [449/782] Loss: 0.5168 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [450/782] Loss: 0.5930 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [451/782] Loss: 0.7592 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [452/782] Loss: 0.5821 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [453/782] Loss: 0.5072 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [454/782] Loss: 0.6820 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [455/782] Loss: 0.6055 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [456/782] Loss: 0.6699 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [457/782] Loss: 0.5280 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [458/782] Loss: 0.7047 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [459/782] Loss: 0.5071 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [460/782] Loss: 0.8354 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [461/782] Loss: 0.6904 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [462/782] Loss: 0.4719 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [463/782] Loss: 0.5940 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [464/782] Loss: 0.6814 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [465/782] Loss: 0.6020 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [466/782] Loss: 0.7294 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [467/782] Loss: 0.6012 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [468/782] Loss: 0.5756 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [469/782] Loss: 0.3495 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [470/782] Loss: 0.5828 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [471/782] Loss: 0.4731 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [472/782] Loss: 0.6471 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [473/782] Loss: 0.6889 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [474/782] Loss: 0.6882 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [475/782] Loss: 0.6099 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [476/782] Loss: 0.5725 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [477/782] Loss: 0.5691 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [478/782] Loss: 0.5455 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [479/782] Loss: 0.5945 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [480/782] Loss: 0.5553 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [481/782] Loss: 0.4231 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [482/782] Loss: 0.6960 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [483/782] Loss: 0.5468 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [484/782] Loss: 0.6749 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [485/782] Loss: 0.5628 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [486/782] Loss: 0.6284 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [487/782] Loss: 0.4335 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [488/782] Loss: 0.5734 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [489/782] Loss: 0.6150 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [490/782] Loss: 0.6458 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [491/782] Loss: 0.4081 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [492/782] Loss: 0.7057 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [493/782] Loss: 0.7527 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [494/782] Loss: 0.4633 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [495/782] Loss: 0.5083 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [496/782] Loss: 0.4124 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [497/782] Loss: 0.4501 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [498/782] Loss: 0.5487 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [499/782] Loss: 0.5516 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [500/782] Loss: 0.7699 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [501/782] Loss: 0.8615 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [502/782] Loss: 0.4885 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [503/782] Loss: 0.4572 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [504/782] Loss: 0.7303 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [505/782] Loss: 0.4616 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [506/782] Loss: 0.5086 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [507/782] Loss: 0.4715 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [508/782] Loss: 0.6380 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [509/782] Loss: 0.5418 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [510/782] Loss: 0.6405 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [511/782] Loss: 0.4286 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [512/782] Loss: 0.4133 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [513/782] Loss: 0.4827 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [514/782] Loss: 0.5793 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [515/782] Loss: 0.4634 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [516/782] Loss: 0.6205 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [517/782] Loss: 0.5663 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [518/782] Loss: 0.5427 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [519/782] Loss: 0.3516 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [520/782] Loss: 0.5182 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [521/782] Loss: 0.5764 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [522/782] Loss: 0.6891 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [523/782] Loss: 0.5447 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [524/782] Loss: 0.4512 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [525/782] Loss: 0.7140 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [526/782] Loss: 0.5457 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [527/782] Loss: 0.5741 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [528/782] Loss: 0.3809 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [529/782] Loss: 0.5189 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [530/782] Loss: 0.6559 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [531/782] Loss: 0.5773 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [532/782] Loss: 0.6739 | Acc: 78.85%\n",
      "Train Epoch [61/100] Batch [533/782] Loss: 0.3421 | Acc: 78.86%\n",
      "Train Epoch [61/100] Batch [534/782] Loss: 0.7914 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [535/782] Loss: 0.5558 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [536/782] Loss: 0.8313 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [537/782] Loss: 0.7358 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [538/782] Loss: 0.5416 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [539/782] Loss: 0.6032 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [540/782] Loss: 0.6260 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [541/782] Loss: 0.5711 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [542/782] Loss: 0.8588 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [543/782] Loss: 0.5211 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [544/782] Loss: 0.6417 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [545/782] Loss: 0.7130 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [546/782] Loss: 0.5329 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [547/782] Loss: 0.5259 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [548/782] Loss: 0.5114 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [549/782] Loss: 0.4670 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [550/782] Loss: 0.5257 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [551/782] Loss: 0.5116 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [552/782] Loss: 0.7057 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [553/782] Loss: 0.6946 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [554/782] Loss: 0.6743 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [555/782] Loss: 0.5333 | Acc: 78.82%\n",
      "Train Epoch [61/100] Batch [556/782] Loss: 0.6943 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [557/782] Loss: 0.7052 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [558/782] Loss: 0.8226 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [559/782] Loss: 0.4632 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [560/782] Loss: 0.5538 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [561/782] Loss: 0.6066 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [562/782] Loss: 0.5635 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [563/782] Loss: 0.5809 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [564/782] Loss: 0.4642 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [565/782] Loss: 0.4330 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [566/782] Loss: 0.6777 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [567/782] Loss: 0.5509 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [568/782] Loss: 0.5155 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [569/782] Loss: 0.4088 | Acc: 78.84%\n",
      "Train Epoch [61/100] Batch [570/782] Loss: 0.5858 | Acc: 78.83%\n",
      "Train Epoch [61/100] Batch [571/782] Loss: 0.7629 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [572/782] Loss: 0.6661 | Acc: 78.81%\n",
      "Train Epoch [61/100] Batch [573/782] Loss: 0.6343 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [574/782] Loss: 0.4417 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [575/782] Loss: 0.5947 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [576/782] Loss: 0.6125 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [577/782] Loss: 0.6467 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [578/782] Loss: 0.6363 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [579/782] Loss: 0.5970 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [580/782] Loss: 0.5200 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [581/782] Loss: 0.6406 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [582/782] Loss: 0.4188 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [583/782] Loss: 0.5258 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [584/782] Loss: 0.5972 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [585/782] Loss: 0.5616 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [586/782] Loss: 0.6941 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [587/782] Loss: 0.5923 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [588/782] Loss: 0.7426 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [589/782] Loss: 0.4775 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [590/782] Loss: 0.5568 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [591/782] Loss: 0.8778 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [592/782] Loss: 0.4066 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [593/782] Loss: 0.6980 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [594/782] Loss: 0.4822 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [595/782] Loss: 0.6779 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [596/782] Loss: 0.6516 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [597/782] Loss: 0.6281 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [598/782] Loss: 0.4856 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [599/782] Loss: 0.6246 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [600/782] Loss: 0.5500 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [601/782] Loss: 0.6842 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [602/782] Loss: 0.4823 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [603/782] Loss: 0.7008 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [604/782] Loss: 0.5267 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [605/782] Loss: 0.7369 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [606/782] Loss: 0.6093 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [607/782] Loss: 0.6895 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [608/782] Loss: 0.5121 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [609/782] Loss: 0.8066 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [610/782] Loss: 0.4592 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [611/782] Loss: 0.5713 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [612/782] Loss: 0.5044 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [613/782] Loss: 0.5005 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [614/782] Loss: 0.6459 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [615/782] Loss: 0.7136 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [616/782] Loss: 0.4854 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [617/782] Loss: 0.4156 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [618/782] Loss: 0.7297 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [619/782] Loss: 0.7852 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [620/782] Loss: 0.6507 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [621/782] Loss: 0.4641 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [622/782] Loss: 0.6487 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [623/782] Loss: 0.4593 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [624/782] Loss: 0.6018 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [625/782] Loss: 0.4328 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [626/782] Loss: 0.6585 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [627/782] Loss: 0.8904 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [628/782] Loss: 0.5477 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [629/782] Loss: 0.5993 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [630/782] Loss: 0.7399 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [631/782] Loss: 0.6363 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [632/782] Loss: 0.7209 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [633/782] Loss: 0.6488 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [634/782] Loss: 0.4861 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [635/782] Loss: 0.7477 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [636/782] Loss: 0.5051 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [637/782] Loss: 0.7085 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [638/782] Loss: 0.5911 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [639/782] Loss: 0.8146 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [640/782] Loss: 0.6440 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [641/782] Loss: 0.5269 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [642/782] Loss: 0.5736 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [643/782] Loss: 0.6991 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [644/782] Loss: 0.5241 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [645/782] Loss: 0.3946 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [646/782] Loss: 0.6215 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [647/782] Loss: 0.5212 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [648/782] Loss: 0.6540 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [649/782] Loss: 0.4897 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [650/782] Loss: 0.6996 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [651/782] Loss: 0.4542 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [652/782] Loss: 0.5050 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [653/782] Loss: 0.5828 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [654/782] Loss: 0.5404 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [655/782] Loss: 0.4822 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [656/782] Loss: 0.6002 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [657/782] Loss: 0.5932 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [658/782] Loss: 0.7307 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [659/782] Loss: 0.5126 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [660/782] Loss: 0.6648 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [661/782] Loss: 0.5547 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [662/782] Loss: 0.6579 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [663/782] Loss: 0.6710 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [664/782] Loss: 0.4773 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [665/782] Loss: 0.5722 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [666/782] Loss: 0.5919 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [667/782] Loss: 0.4686 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [668/782] Loss: 0.6267 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [669/782] Loss: 0.5772 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [670/782] Loss: 0.6181 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [671/782] Loss: 0.6035 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [672/782] Loss: 0.6512 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [673/782] Loss: 0.5051 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [674/782] Loss: 0.4945 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [675/782] Loss: 0.6325 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [676/782] Loss: 0.6059 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [677/782] Loss: 0.6586 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [678/782] Loss: 0.4108 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [679/782] Loss: 0.7030 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [680/782] Loss: 0.8216 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [681/782] Loss: 0.5880 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [682/782] Loss: 0.5322 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [683/782] Loss: 0.8712 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [684/782] Loss: 0.4582 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [685/782] Loss: 0.5919 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [686/782] Loss: 0.6506 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [687/782] Loss: 0.6982 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [688/782] Loss: 0.5508 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [689/782] Loss: 0.6240 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [690/782] Loss: 0.4401 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [691/782] Loss: 0.6589 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [692/782] Loss: 0.5072 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [693/782] Loss: 0.6117 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [694/782] Loss: 0.5367 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [695/782] Loss: 0.4200 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [696/782] Loss: 0.5559 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [697/782] Loss: 0.5187 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [698/782] Loss: 0.4063 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [699/782] Loss: 0.5052 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [700/782] Loss: 0.5924 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [701/782] Loss: 0.7902 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [702/782] Loss: 0.6257 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [703/782] Loss: 0.4542 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [704/782] Loss: 0.4089 | Acc: 78.80%\n",
      "Train Epoch [61/100] Batch [705/782] Loss: 0.5013 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [706/782] Loss: 0.7406 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [707/782] Loss: 0.6402 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [708/782] Loss: 0.6877 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [709/782] Loss: 0.8043 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [710/782] Loss: 0.5083 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [711/782] Loss: 0.6624 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [712/782] Loss: 0.5003 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [713/782] Loss: 0.7354 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [714/782] Loss: 0.6472 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [715/782] Loss: 0.7261 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [716/782] Loss: 0.5189 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [717/782] Loss: 0.5738 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [718/782] Loss: 0.6630 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [719/782] Loss: 0.6879 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [720/782] Loss: 0.7176 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [721/782] Loss: 0.6184 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [722/782] Loss: 0.5014 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [723/782] Loss: 0.6381 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [724/782] Loss: 0.5273 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [725/782] Loss: 0.5797 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [726/782] Loss: 0.7345 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [727/782] Loss: 0.3985 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [728/782] Loss: 0.5989 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [729/782] Loss: 0.6800 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [730/782] Loss: 0.5751 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [731/782] Loss: 0.7989 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [732/782] Loss: 0.5030 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [733/782] Loss: 0.6273 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [734/782] Loss: 0.6128 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [735/782] Loss: 0.5860 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [736/782] Loss: 0.4634 | Acc: 78.79%\n",
      "Train Epoch [61/100] Batch [737/782] Loss: 0.8513 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [738/782] Loss: 0.8121 | Acc: 78.78%\n",
      "Train Epoch [61/100] Batch [739/782] Loss: 0.6110 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [740/782] Loss: 0.5835 | Acc: 78.77%\n",
      "Train Epoch [61/100] Batch [741/782] Loss: 0.6990 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [742/782] Loss: 0.7154 | Acc: 78.75%\n",
      "Train Epoch [61/100] Batch [743/782] Loss: 0.5292 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [744/782] Loss: 0.5892 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [745/782] Loss: 0.4200 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [746/782] Loss: 0.5421 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [747/782] Loss: 0.5922 | Acc: 78.76%\n",
      "Train Epoch [61/100] Batch [748/782] Loss: 0.9639 | Acc: 78.74%\n",
      "Train Epoch [61/100] Batch [749/782] Loss: 0.6533 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [750/782] Loss: 0.7375 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [751/782] Loss: 0.7169 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [752/782] Loss: 0.5285 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [753/782] Loss: 0.7304 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [754/782] Loss: 0.6086 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [755/782] Loss: 0.4844 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [756/782] Loss: 0.5788 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [757/782] Loss: 0.3497 | Acc: 78.73%\n",
      "Train Epoch [61/100] Batch [758/782] Loss: 0.6690 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [759/782] Loss: 0.5355 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [760/782] Loss: 0.6509 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [761/782] Loss: 0.5378 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [762/782] Loss: 1.0023 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [763/782] Loss: 0.5248 | Acc: 78.72%\n",
      "Train Epoch [61/100] Batch [764/782] Loss: 0.6275 | Acc: 78.71%\n",
      "Train Epoch [61/100] Batch [765/782] Loss: 0.9219 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [766/782] Loss: 0.6262 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [767/782] Loss: 0.8955 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [768/782] Loss: 0.6016 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [769/782] Loss: 0.5756 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [770/782] Loss: 0.5408 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [771/782] Loss: 0.6248 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [772/782] Loss: 0.4687 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [773/782] Loss: 0.4958 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [774/782] Loss: 0.5687 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [775/782] Loss: 0.5085 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [776/782] Loss: 0.7287 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [777/782] Loss: 0.7297 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [778/782] Loss: 0.5688 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [779/782] Loss: 0.7074 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [780/782] Loss: 0.4959 | Acc: 78.70%\n",
      "Train Epoch [61/100] Batch [781/782] Loss: 0.6424 | Acc: 78.69%\n",
      "Train Epoch [61/100] Batch [782/782] Loss: 0.4980 | Acc: 78.69%\n",
      "Epoch 61 completed in 29.84s.\n",
      "Test Epoch [61/100] Loss: 0.8729 | Acc: 72.77% | Inference Time: 8.63s\n",
      "Epoch 61 results saved to CSV.\n",
      "Epoch 62/100\n",
      "Train Epoch [62/100] Batch [1/782] Loss: 0.5900 | Acc: 79.69%\n",
      "Train Epoch [62/100] Batch [2/782] Loss: 0.4377 | Acc: 83.59%\n",
      "Train Epoch [62/100] Batch [3/782] Loss: 0.5663 | Acc: 83.33%\n",
      "Train Epoch [62/100] Batch [4/782] Loss: 0.5299 | Acc: 83.20%\n",
      "Train Epoch [62/100] Batch [5/782] Loss: 0.5571 | Acc: 82.50%\n",
      "Train Epoch [62/100] Batch [6/782] Loss: 0.5445 | Acc: 83.07%\n",
      "Train Epoch [62/100] Batch [7/782] Loss: 0.6579 | Acc: 81.92%\n",
      "Train Epoch [62/100] Batch [8/782] Loss: 0.4956 | Acc: 81.64%\n",
      "Train Epoch [62/100] Batch [9/782] Loss: 0.6773 | Acc: 81.08%\n",
      "Train Epoch [62/100] Batch [10/782] Loss: 0.5133 | Acc: 80.94%\n",
      "Train Epoch [62/100] Batch [11/782] Loss: 0.4748 | Acc: 80.82%\n",
      "Train Epoch [62/100] Batch [12/782] Loss: 0.6842 | Acc: 80.34%\n",
      "Train Epoch [62/100] Batch [13/782] Loss: 0.5611 | Acc: 80.53%\n",
      "Train Epoch [62/100] Batch [14/782] Loss: 0.6420 | Acc: 80.02%\n",
      "Train Epoch [62/100] Batch [15/782] Loss: 0.5179 | Acc: 80.00%\n",
      "Train Epoch [62/100] Batch [16/782] Loss: 0.5618 | Acc: 79.98%\n",
      "Train Epoch [62/100] Batch [17/782] Loss: 0.3652 | Acc: 80.88%\n",
      "Train Epoch [62/100] Batch [18/782] Loss: 0.6254 | Acc: 80.64%\n",
      "Train Epoch [62/100] Batch [19/782] Loss: 0.5901 | Acc: 80.35%\n",
      "Train Epoch [62/100] Batch [20/782] Loss: 0.5774 | Acc: 79.92%\n",
      "Train Epoch [62/100] Batch [21/782] Loss: 0.5697 | Acc: 79.69%\n",
      "Train Epoch [62/100] Batch [22/782] Loss: 0.5327 | Acc: 79.55%\n",
      "Train Epoch [62/100] Batch [23/782] Loss: 0.4980 | Acc: 79.82%\n",
      "Train Epoch [62/100] Batch [24/782] Loss: 0.5630 | Acc: 79.82%\n",
      "Train Epoch [62/100] Batch [25/782] Loss: 0.5454 | Acc: 79.88%\n",
      "Train Epoch [62/100] Batch [26/782] Loss: 0.3720 | Acc: 80.05%\n",
      "Train Epoch [62/100] Batch [27/782] Loss: 0.5061 | Acc: 80.21%\n",
      "Train Epoch [62/100] Batch [28/782] Loss: 0.6095 | Acc: 80.25%\n",
      "Train Epoch [62/100] Batch [29/782] Loss: 0.4968 | Acc: 80.23%\n",
      "Train Epoch [62/100] Batch [30/782] Loss: 0.3945 | Acc: 80.42%\n",
      "Train Epoch [62/100] Batch [31/782] Loss: 0.6705 | Acc: 80.29%\n",
      "Train Epoch [62/100] Batch [32/782] Loss: 0.5552 | Acc: 80.27%\n",
      "Train Epoch [62/100] Batch [33/782] Loss: 0.4551 | Acc: 80.45%\n",
      "Train Epoch [62/100] Batch [34/782] Loss: 0.5207 | Acc: 80.47%\n",
      "Train Epoch [62/100] Batch [35/782] Loss: 0.6345 | Acc: 80.40%\n",
      "Train Epoch [62/100] Batch [36/782] Loss: 0.6982 | Acc: 80.30%\n",
      "Train Epoch [62/100] Batch [37/782] Loss: 0.5308 | Acc: 80.32%\n",
      "Train Epoch [62/100] Batch [38/782] Loss: 0.6940 | Acc: 80.22%\n",
      "Train Epoch [62/100] Batch [39/782] Loss: 0.5437 | Acc: 80.29%\n",
      "Train Epoch [62/100] Batch [40/782] Loss: 0.5809 | Acc: 80.35%\n",
      "Train Epoch [62/100] Batch [41/782] Loss: 0.4651 | Acc: 80.41%\n",
      "Train Epoch [62/100] Batch [42/782] Loss: 0.6918 | Acc: 80.32%\n",
      "Train Epoch [62/100] Batch [43/782] Loss: 0.5404 | Acc: 80.45%\n",
      "Train Epoch [62/100] Batch [44/782] Loss: 0.4667 | Acc: 80.58%\n",
      "Train Epoch [62/100] Batch [45/782] Loss: 0.5842 | Acc: 80.49%\n",
      "Train Epoch [62/100] Batch [46/782] Loss: 0.6800 | Acc: 80.40%\n",
      "Train Epoch [62/100] Batch [47/782] Loss: 0.7260 | Acc: 80.32%\n",
      "Train Epoch [62/100] Batch [48/782] Loss: 0.7751 | Acc: 80.11%\n",
      "Train Epoch [62/100] Batch [49/782] Loss: 0.7575 | Acc: 79.91%\n",
      "Train Epoch [62/100] Batch [50/782] Loss: 0.5528 | Acc: 79.94%\n",
      "Train Epoch [62/100] Batch [51/782] Loss: 0.4666 | Acc: 79.96%\n",
      "Train Epoch [62/100] Batch [52/782] Loss: 0.6409 | Acc: 79.87%\n",
      "Train Epoch [62/100] Batch [53/782] Loss: 0.5475 | Acc: 79.81%\n",
      "Train Epoch [62/100] Batch [54/782] Loss: 0.5316 | Acc: 79.86%\n",
      "Train Epoch [62/100] Batch [55/782] Loss: 0.5539 | Acc: 79.80%\n",
      "Train Epoch [62/100] Batch [56/782] Loss: 0.4355 | Acc: 79.80%\n",
      "Train Epoch [62/100] Batch [57/782] Loss: 0.5076 | Acc: 79.74%\n",
      "Train Epoch [62/100] Batch [58/782] Loss: 0.5791 | Acc: 79.71%\n",
      "Train Epoch [62/100] Batch [59/782] Loss: 0.5869 | Acc: 79.77%\n",
      "Train Epoch [62/100] Batch [60/782] Loss: 0.4698 | Acc: 79.84%\n",
      "Train Epoch [62/100] Batch [61/782] Loss: 0.5477 | Acc: 79.92%\n",
      "Train Epoch [62/100] Batch [62/782] Loss: 0.5774 | Acc: 79.94%\n",
      "Train Epoch [62/100] Batch [63/782] Loss: 0.4541 | Acc: 80.08%\n",
      "Train Epoch [62/100] Batch [64/782] Loss: 0.4874 | Acc: 80.10%\n",
      "Train Epoch [62/100] Batch [65/782] Loss: 0.4480 | Acc: 80.19%\n",
      "Train Epoch [62/100] Batch [66/782] Loss: 0.5135 | Acc: 80.18%\n",
      "Train Epoch [62/100] Batch [67/782] Loss: 0.6872 | Acc: 80.15%\n",
      "Train Epoch [62/100] Batch [68/782] Loss: 0.3449 | Acc: 80.26%\n",
      "Train Epoch [62/100] Batch [69/782] Loss: 0.4652 | Acc: 80.28%\n",
      "Train Epoch [62/100] Batch [70/782] Loss: 0.4522 | Acc: 80.38%\n",
      "Train Epoch [62/100] Batch [71/782] Loss: 0.5315 | Acc: 80.41%\n",
      "Train Epoch [62/100] Batch [72/782] Loss: 0.8371 | Acc: 80.21%\n",
      "Train Epoch [62/100] Batch [73/782] Loss: 0.6508 | Acc: 80.12%\n",
      "Train Epoch [62/100] Batch [74/782] Loss: 0.3928 | Acc: 80.15%\n",
      "Train Epoch [62/100] Batch [75/782] Loss: 0.5012 | Acc: 80.19%\n",
      "Train Epoch [62/100] Batch [76/782] Loss: 0.6980 | Acc: 80.12%\n",
      "Train Epoch [62/100] Batch [77/782] Loss: 0.4251 | Acc: 80.15%\n",
      "Train Epoch [62/100] Batch [78/782] Loss: 0.4865 | Acc: 80.11%\n",
      "Train Epoch [62/100] Batch [79/782] Loss: 0.8019 | Acc: 80.00%\n",
      "Train Epoch [62/100] Batch [80/782] Loss: 0.6708 | Acc: 79.94%\n",
      "Train Epoch [62/100] Batch [81/782] Loss: 0.6780 | Acc: 79.94%\n",
      "Train Epoch [62/100] Batch [82/782] Loss: 0.4577 | Acc: 80.03%\n",
      "Train Epoch [62/100] Batch [83/782] Loss: 0.5940 | Acc: 80.05%\n",
      "Train Epoch [62/100] Batch [84/782] Loss: 0.8444 | Acc: 79.99%\n",
      "Train Epoch [62/100] Batch [85/782] Loss: 0.6006 | Acc: 80.00%\n",
      "Train Epoch [62/100] Batch [86/782] Loss: 0.5006 | Acc: 79.98%\n",
      "Train Epoch [62/100] Batch [87/782] Loss: 0.6942 | Acc: 79.94%\n",
      "Train Epoch [62/100] Batch [88/782] Loss: 0.7523 | Acc: 79.90%\n",
      "Train Epoch [62/100] Batch [89/782] Loss: 0.6478 | Acc: 79.93%\n",
      "Train Epoch [62/100] Batch [90/782] Loss: 0.5255 | Acc: 79.91%\n",
      "Train Epoch [62/100] Batch [91/782] Loss: 0.4574 | Acc: 80.01%\n",
      "Train Epoch [62/100] Batch [92/782] Loss: 0.5212 | Acc: 80.04%\n",
      "Train Epoch [62/100] Batch [93/782] Loss: 0.6350 | Acc: 80.01%\n",
      "Train Epoch [62/100] Batch [94/782] Loss: 0.6354 | Acc: 79.97%\n",
      "Train Epoch [62/100] Batch [95/782] Loss: 0.6664 | Acc: 79.87%\n",
      "Train Epoch [62/100] Batch [96/782] Loss: 0.5568 | Acc: 79.83%\n",
      "Train Epoch [62/100] Batch [97/782] Loss: 0.4636 | Acc: 79.91%\n",
      "Train Epoch [62/100] Batch [98/782] Loss: 0.6032 | Acc: 79.85%\n",
      "Train Epoch [62/100] Batch [99/782] Loss: 0.8398 | Acc: 79.77%\n",
      "Train Epoch [62/100] Batch [100/782] Loss: 0.5002 | Acc: 79.81%\n",
      "Train Epoch [62/100] Batch [101/782] Loss: 0.8408 | Acc: 79.75%\n",
      "Train Epoch [62/100] Batch [102/782] Loss: 0.5593 | Acc: 79.79%\n",
      "Train Epoch [62/100] Batch [103/782] Loss: 0.6372 | Acc: 79.78%\n",
      "Train Epoch [62/100] Batch [104/782] Loss: 0.5745 | Acc: 79.78%\n",
      "Train Epoch [62/100] Batch [105/782] Loss: 0.6773 | Acc: 79.72%\n",
      "Train Epoch [62/100] Batch [106/782] Loss: 0.4043 | Acc: 79.73%\n",
      "Train Epoch [62/100] Batch [107/782] Loss: 0.6489 | Acc: 79.70%\n",
      "Train Epoch [62/100] Batch [108/782] Loss: 0.7379 | Acc: 79.69%\n",
      "Train Epoch [62/100] Batch [109/782] Loss: 0.5954 | Acc: 79.67%\n",
      "Train Epoch [62/100] Batch [110/782] Loss: 0.5551 | Acc: 79.60%\n",
      "Train Epoch [62/100] Batch [111/782] Loss: 0.6957 | Acc: 79.55%\n",
      "Train Epoch [62/100] Batch [112/782] Loss: 0.5994 | Acc: 79.51%\n",
      "Train Epoch [62/100] Batch [113/782] Loss: 0.5261 | Acc: 79.54%\n",
      "Train Epoch [62/100] Batch [114/782] Loss: 0.6582 | Acc: 79.50%\n",
      "Train Epoch [62/100] Batch [115/782] Loss: 0.6209 | Acc: 79.46%\n",
      "Train Epoch [62/100] Batch [116/782] Loss: 0.6025 | Acc: 79.43%\n",
      "Train Epoch [62/100] Batch [117/782] Loss: 0.6389 | Acc: 79.42%\n",
      "Train Epoch [62/100] Batch [118/782] Loss: 0.5992 | Acc: 79.41%\n",
      "Train Epoch [62/100] Batch [119/782] Loss: 0.5680 | Acc: 79.36%\n",
      "Train Epoch [62/100] Batch [120/782] Loss: 0.5032 | Acc: 79.41%\n",
      "Train Epoch [62/100] Batch [121/782] Loss: 0.6225 | Acc: 79.39%\n",
      "Train Epoch [62/100] Batch [122/782] Loss: 0.5999 | Acc: 79.39%\n",
      "Train Epoch [62/100] Batch [123/782] Loss: 0.5443 | Acc: 79.42%\n",
      "Train Epoch [62/100] Batch [124/782] Loss: 0.7698 | Acc: 79.36%\n",
      "Train Epoch [62/100] Batch [125/782] Loss: 0.6364 | Acc: 79.36%\n",
      "Train Epoch [62/100] Batch [126/782] Loss: 0.5187 | Acc: 79.41%\n",
      "Train Epoch [62/100] Batch [127/782] Loss: 0.5180 | Acc: 79.45%\n",
      "Train Epoch [62/100] Batch [128/782] Loss: 0.6575 | Acc: 79.41%\n",
      "Train Epoch [62/100] Batch [129/782] Loss: 0.7979 | Acc: 79.32%\n",
      "Train Epoch [62/100] Batch [130/782] Loss: 0.7941 | Acc: 79.25%\n",
      "Train Epoch [62/100] Batch [131/782] Loss: 0.7349 | Acc: 79.17%\n",
      "Train Epoch [62/100] Batch [132/782] Loss: 0.5368 | Acc: 79.20%\n",
      "Train Epoch [62/100] Batch [133/782] Loss: 0.6686 | Acc: 79.18%\n",
      "Train Epoch [62/100] Batch [134/782] Loss: 0.7717 | Acc: 79.15%\n",
      "Train Epoch [62/100] Batch [135/782] Loss: 0.5363 | Acc: 79.20%\n",
      "Train Epoch [62/100] Batch [136/782] Loss: 0.5446 | Acc: 79.22%\n",
      "Train Epoch [62/100] Batch [137/782] Loss: 0.5061 | Acc: 79.27%\n",
      "Train Epoch [62/100] Batch [138/782] Loss: 0.4612 | Acc: 79.31%\n",
      "Train Epoch [62/100] Batch [139/782] Loss: 0.6492 | Acc: 79.32%\n",
      "Train Epoch [62/100] Batch [140/782] Loss: 0.5581 | Acc: 79.30%\n",
      "Train Epoch [62/100] Batch [141/782] Loss: 0.3995 | Acc: 79.36%\n",
      "Train Epoch [62/100] Batch [142/782] Loss: 0.7149 | Acc: 79.28%\n",
      "Train Epoch [62/100] Batch [143/782] Loss: 0.4519 | Acc: 79.31%\n",
      "Train Epoch [62/100] Batch [144/782] Loss: 0.6482 | Acc: 79.28%\n",
      "Train Epoch [62/100] Batch [145/782] Loss: 0.5536 | Acc: 79.31%\n",
      "Train Epoch [62/100] Batch [146/782] Loss: 0.5142 | Acc: 79.31%\n",
      "Train Epoch [62/100] Batch [147/782] Loss: 0.7629 | Acc: 79.27%\n",
      "Train Epoch [62/100] Batch [148/782] Loss: 0.6645 | Acc: 79.27%\n",
      "Train Epoch [62/100] Batch [149/782] Loss: 0.5383 | Acc: 79.28%\n",
      "Train Epoch [62/100] Batch [150/782] Loss: 0.8418 | Acc: 79.16%\n",
      "Train Epoch [62/100] Batch [151/782] Loss: 0.6135 | Acc: 79.17%\n",
      "Train Epoch [62/100] Batch [152/782] Loss: 0.5885 | Acc: 79.18%\n",
      "Train Epoch [62/100] Batch [153/782] Loss: 0.6371 | Acc: 79.20%\n",
      "Train Epoch [62/100] Batch [154/782] Loss: 0.6632 | Acc: 79.14%\n",
      "Train Epoch [62/100] Batch [155/782] Loss: 0.7132 | Acc: 79.12%\n",
      "Train Epoch [62/100] Batch [156/782] Loss: 0.7269 | Acc: 79.08%\n",
      "Train Epoch [62/100] Batch [157/782] Loss: 0.5359 | Acc: 79.08%\n",
      "Train Epoch [62/100] Batch [158/782] Loss: 0.6909 | Acc: 79.06%\n",
      "Train Epoch [62/100] Batch [159/782] Loss: 0.5845 | Acc: 79.08%\n",
      "Train Epoch [62/100] Batch [160/782] Loss: 0.5419 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [161/782] Loss: 0.5946 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [162/782] Loss: 0.6008 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [163/782] Loss: 0.4583 | Acc: 79.15%\n",
      "Train Epoch [62/100] Batch [164/782] Loss: 0.3741 | Acc: 79.21%\n",
      "Train Epoch [62/100] Batch [165/782] Loss: 0.4481 | Acc: 79.23%\n",
      "Train Epoch [62/100] Batch [166/782] Loss: 0.8059 | Acc: 79.14%\n",
      "Train Epoch [62/100] Batch [167/782] Loss: 0.6069 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [168/782] Loss: 0.5503 | Acc: 79.12%\n",
      "Train Epoch [62/100] Batch [169/782] Loss: 0.5894 | Acc: 79.12%\n",
      "Train Epoch [62/100] Batch [170/782] Loss: 0.6764 | Acc: 79.14%\n",
      "Train Epoch [62/100] Batch [171/782] Loss: 0.5463 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [172/782] Loss: 0.3895 | Acc: 79.17%\n",
      "Train Epoch [62/100] Batch [173/782] Loss: 0.6128 | Acc: 79.17%\n",
      "Train Epoch [62/100] Batch [174/782] Loss: 0.6025 | Acc: 79.13%\n",
      "Train Epoch [62/100] Batch [175/782] Loss: 0.4260 | Acc: 79.15%\n",
      "Train Epoch [62/100] Batch [176/782] Loss: 0.5901 | Acc: 79.15%\n",
      "Train Epoch [62/100] Batch [177/782] Loss: 0.6666 | Acc: 79.18%\n",
      "Train Epoch [62/100] Batch [178/782] Loss: 0.5250 | Acc: 79.20%\n",
      "Train Epoch [62/100] Batch [179/782] Loss: 0.6414 | Acc: 79.18%\n",
      "Train Epoch [62/100] Batch [180/782] Loss: 0.6809 | Acc: 79.16%\n",
      "Train Epoch [62/100] Batch [181/782] Loss: 0.7999 | Acc: 79.13%\n",
      "Train Epoch [62/100] Batch [182/782] Loss: 0.5983 | Acc: 79.10%\n",
      "Train Epoch [62/100] Batch [183/782] Loss: 0.4891 | Acc: 79.10%\n",
      "Train Epoch [62/100] Batch [184/782] Loss: 0.4935 | Acc: 79.10%\n",
      "Train Epoch [62/100] Batch [185/782] Loss: 0.4209 | Acc: 79.14%\n",
      "Train Epoch [62/100] Batch [186/782] Loss: 0.7346 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [187/782] Loss: 0.5257 | Acc: 79.12%\n",
      "Train Epoch [62/100] Batch [188/782] Loss: 0.6144 | Acc: 79.11%\n",
      "Train Epoch [62/100] Batch [189/782] Loss: 0.7608 | Acc: 79.07%\n",
      "Train Epoch [62/100] Batch [190/782] Loss: 0.5518 | Acc: 79.06%\n",
      "Train Epoch [62/100] Batch [191/782] Loss: 0.6032 | Acc: 79.03%\n",
      "Train Epoch [62/100] Batch [192/782] Loss: 0.4679 | Acc: 79.05%\n",
      "Train Epoch [62/100] Batch [193/782] Loss: 0.6899 | Acc: 79.05%\n",
      "Train Epoch [62/100] Batch [194/782] Loss: 0.6535 | Acc: 79.02%\n",
      "Train Epoch [62/100] Batch [195/782] Loss: 0.6171 | Acc: 79.01%\n",
      "Train Epoch [62/100] Batch [196/782] Loss: 0.4734 | Acc: 79.02%\n",
      "Train Epoch [62/100] Batch [197/782] Loss: 0.7131 | Acc: 78.98%\n",
      "Train Epoch [62/100] Batch [198/782] Loss: 0.7630 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [199/782] Loss: 0.5008 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [200/782] Loss: 0.6885 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [201/782] Loss: 0.6106 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [202/782] Loss: 0.7341 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [203/782] Loss: 0.7556 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [204/782] Loss: 0.6403 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [205/782] Loss: 0.5918 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [206/782] Loss: 0.4940 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [207/782] Loss: 0.4991 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [208/782] Loss: 0.3764 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [209/782] Loss: 0.4633 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [210/782] Loss: 0.6724 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [211/782] Loss: 0.4754 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [212/782] Loss: 0.7366 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [213/782] Loss: 0.5890 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [214/782] Loss: 0.5049 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [215/782] Loss: 0.3895 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [216/782] Loss: 0.7102 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [217/782] Loss: 0.5051 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [218/782] Loss: 0.4991 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [219/782] Loss: 0.6473 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [220/782] Loss: 0.4989 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [221/782] Loss: 0.6426 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [222/782] Loss: 0.5628 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [223/782] Loss: 0.4875 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [224/782] Loss: 0.6488 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [225/782] Loss: 0.5084 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [226/782] Loss: 0.7408 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [227/782] Loss: 0.8530 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [228/782] Loss: 0.6336 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [229/782] Loss: 0.6404 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [230/782] Loss: 0.4515 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [231/782] Loss: 0.5081 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [232/782] Loss: 0.6645 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [233/782] Loss: 0.8150 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [234/782] Loss: 0.5596 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [235/782] Loss: 0.6787 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [236/782] Loss: 0.6287 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [237/782] Loss: 0.4287 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [238/782] Loss: 0.6301 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [239/782] Loss: 0.6032 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [240/782] Loss: 0.5610 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [241/782] Loss: 0.5759 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [242/782] Loss: 0.5020 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [243/782] Loss: 0.6599 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [244/782] Loss: 0.8010 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [245/782] Loss: 0.6521 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [246/782] Loss: 0.5419 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [247/782] Loss: 0.4981 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [248/782] Loss: 0.5902 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [249/782] Loss: 0.5603 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [250/782] Loss: 0.4136 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [251/782] Loss: 0.4184 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [252/782] Loss: 0.5998 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [253/782] Loss: 0.6592 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [254/782] Loss: 0.6954 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [255/782] Loss: 0.7109 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [256/782] Loss: 0.6424 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [257/782] Loss: 0.5898 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [258/782] Loss: 0.5782 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [259/782] Loss: 0.7007 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [260/782] Loss: 0.5634 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [261/782] Loss: 0.4006 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [262/782] Loss: 0.4746 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [263/782] Loss: 0.5704 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [264/782] Loss: 0.5031 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [265/782] Loss: 0.4978 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [266/782] Loss: 0.6679 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [267/782] Loss: 0.6026 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [268/782] Loss: 0.6795 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [269/782] Loss: 0.6555 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [270/782] Loss: 0.4908 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [271/782] Loss: 0.4624 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [272/782] Loss: 0.6455 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [273/782] Loss: 0.6131 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [274/782] Loss: 0.5222 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [275/782] Loss: 0.6835 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [276/782] Loss: 0.6504 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [277/782] Loss: 0.4497 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [278/782] Loss: 0.5108 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [279/782] Loss: 0.5508 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [280/782] Loss: 0.5574 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [281/782] Loss: 0.6085 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [282/782] Loss: 0.7199 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [283/782] Loss: 0.3995 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [284/782] Loss: 0.7225 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [285/782] Loss: 0.7589 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [286/782] Loss: 0.5654 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [287/782] Loss: 0.7094 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [288/782] Loss: 0.9681 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [289/782] Loss: 0.7076 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [290/782] Loss: 0.5447 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [291/782] Loss: 0.6840 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [292/782] Loss: 0.4629 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [293/782] Loss: 0.6297 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [294/782] Loss: 0.3431 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [295/782] Loss: 0.6164 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [296/782] Loss: 0.6837 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [297/782] Loss: 0.6437 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [298/782] Loss: 0.6119 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [299/782] Loss: 0.6272 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [300/782] Loss: 0.5204 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [301/782] Loss: 0.7514 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [302/782] Loss: 0.6766 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [303/782] Loss: 0.5883 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [304/782] Loss: 0.5237 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [305/782] Loss: 0.5154 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [306/782] Loss: 0.4524 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [307/782] Loss: 0.6118 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [308/782] Loss: 0.5484 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [309/782] Loss: 0.5745 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [310/782] Loss: 0.6417 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [311/782] Loss: 0.5252 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [312/782] Loss: 0.5987 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [313/782] Loss: 0.5233 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [314/782] Loss: 0.7391 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [315/782] Loss: 0.4430 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [316/782] Loss: 0.4394 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [317/782] Loss: 0.6777 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [318/782] Loss: 0.5822 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [319/782] Loss: 0.6644 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [320/782] Loss: 0.5453 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [321/782] Loss: 0.5417 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [322/782] Loss: 0.4590 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [323/782] Loss: 0.5472 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [324/782] Loss: 0.5284 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [325/782] Loss: 0.8051 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [326/782] Loss: 0.4309 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [327/782] Loss: 0.6576 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [328/782] Loss: 0.6650 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [329/782] Loss: 0.6571 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [330/782] Loss: 0.4390 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [331/782] Loss: 0.6318 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [332/782] Loss: 0.4009 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [333/782] Loss: 0.6582 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [334/782] Loss: 0.6148 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [335/782] Loss: 0.5346 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [336/782] Loss: 0.5793 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [337/782] Loss: 0.5345 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [338/782] Loss: 0.6243 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [339/782] Loss: 0.4206 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [340/782] Loss: 0.8899 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [341/782] Loss: 0.6022 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [342/782] Loss: 0.5255 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [343/782] Loss: 0.5190 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [344/782] Loss: 0.3992 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [345/782] Loss: 0.6992 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [346/782] Loss: 0.5726 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [347/782] Loss: 0.4168 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [348/782] Loss: 0.5811 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [349/782] Loss: 0.4079 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [350/782] Loss: 0.6439 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [351/782] Loss: 0.5938 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [352/782] Loss: 0.6894 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [353/782] Loss: 0.5617 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [354/782] Loss: 0.4506 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [355/782] Loss: 0.5594 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [356/782] Loss: 0.4384 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [357/782] Loss: 0.7984 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [358/782] Loss: 0.6841 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [359/782] Loss: 0.3588 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [360/782] Loss: 0.5816 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [361/782] Loss: 0.6189 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [362/782] Loss: 0.9638 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [363/782] Loss: 0.4860 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [364/782] Loss: 0.6013 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [365/782] Loss: 0.6904 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [366/782] Loss: 0.8141 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [367/782] Loss: 0.5083 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [368/782] Loss: 0.6710 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [369/782] Loss: 0.4649 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [370/782] Loss: 0.6461 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [371/782] Loss: 0.8310 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [372/782] Loss: 0.5297 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [373/782] Loss: 0.7619 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [374/782] Loss: 0.4762 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [375/782] Loss: 0.6484 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [376/782] Loss: 0.5811 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [377/782] Loss: 0.5456 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [378/782] Loss: 0.4708 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [379/782] Loss: 0.5403 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [380/782] Loss: 0.7369 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [381/782] Loss: 0.7427 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [382/782] Loss: 0.5008 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [383/782] Loss: 0.7633 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [384/782] Loss: 0.7611 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [385/782] Loss: 0.4787 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [386/782] Loss: 0.6273 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [387/782] Loss: 0.6057 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [388/782] Loss: 0.5646 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [389/782] Loss: 0.3691 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [390/782] Loss: 0.7090 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [391/782] Loss: 0.8180 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [392/782] Loss: 0.6580 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [393/782] Loss: 0.7053 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [394/782] Loss: 0.4277 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [395/782] Loss: 0.8562 | Acc: 78.57%\n",
      "Train Epoch [62/100] Batch [396/782] Loss: 0.3886 | Acc: 78.58%\n",
      "Train Epoch [62/100] Batch [397/782] Loss: 0.4214 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [398/782] Loss: 0.4902 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [399/782] Loss: 0.5574 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [400/782] Loss: 0.6560 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [401/782] Loss: 0.6518 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [402/782] Loss: 0.6349 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [403/782] Loss: 0.6276 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [404/782] Loss: 0.5933 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [405/782] Loss: 0.4521 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [406/782] Loss: 0.7446 | Acc: 78.58%\n",
      "Train Epoch [62/100] Batch [407/782] Loss: 0.7627 | Acc: 78.57%\n",
      "Train Epoch [62/100] Batch [408/782] Loss: 0.6610 | Acc: 78.56%\n",
      "Train Epoch [62/100] Batch [409/782] Loss: 0.8016 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [410/782] Loss: 0.7448 | Acc: 78.53%\n",
      "Train Epoch [62/100] Batch [411/782] Loss: 0.4731 | Acc: 78.54%\n",
      "Train Epoch [62/100] Batch [412/782] Loss: 0.4700 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [413/782] Loss: 0.6180 | Acc: 78.54%\n",
      "Train Epoch [62/100] Batch [414/782] Loss: 0.4493 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [415/782] Loss: 0.6658 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [416/782] Loss: 0.6120 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [417/782] Loss: 0.8156 | Acc: 78.53%\n",
      "Train Epoch [62/100] Batch [418/782] Loss: 0.4722 | Acc: 78.55%\n",
      "Train Epoch [62/100] Batch [419/782] Loss: 0.5671 | Acc: 78.57%\n",
      "Train Epoch [62/100] Batch [420/782] Loss: 0.4120 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [421/782] Loss: 0.6051 | Acc: 78.58%\n",
      "Train Epoch [62/100] Batch [422/782] Loss: 0.6459 | Acc: 78.58%\n",
      "Train Epoch [62/100] Batch [423/782] Loss: 0.4597 | Acc: 78.59%\n",
      "Train Epoch [62/100] Batch [424/782] Loss: 0.4583 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [425/782] Loss: 0.6200 | Acc: 78.58%\n",
      "Train Epoch [62/100] Batch [426/782] Loss: 0.4055 | Acc: 78.60%\n",
      "Train Epoch [62/100] Batch [427/782] Loss: 0.4217 | Acc: 78.61%\n",
      "Train Epoch [62/100] Batch [428/782] Loss: 0.5634 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [429/782] Loss: 0.5347 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [430/782] Loss: 0.4771 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [431/782] Loss: 0.6187 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [432/782] Loss: 0.4354 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [433/782] Loss: 0.5737 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [434/782] Loss: 0.5545 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [435/782] Loss: 0.5208 | Acc: 78.64%\n",
      "Train Epoch [62/100] Batch [436/782] Loss: 0.6376 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [437/782] Loss: 0.6322 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [438/782] Loss: 0.6216 | Acc: 78.62%\n",
      "Train Epoch [62/100] Batch [439/782] Loss: 0.5951 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [440/782] Loss: 0.6233 | Acc: 78.63%\n",
      "Train Epoch [62/100] Batch [441/782] Loss: 0.5344 | Acc: 78.65%\n",
      "Train Epoch [62/100] Batch [442/782] Loss: 0.3514 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [443/782] Loss: 0.6031 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [444/782] Loss: 0.3330 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [445/782] Loss: 0.6325 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [446/782] Loss: 0.6042 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [447/782] Loss: 0.6000 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [448/782] Loss: 0.5062 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [449/782] Loss: 0.3974 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [450/782] Loss: 0.5951 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [451/782] Loss: 0.7858 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [452/782] Loss: 0.5864 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [453/782] Loss: 0.6179 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [454/782] Loss: 0.3933 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [455/782] Loss: 0.4453 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [456/782] Loss: 0.4932 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [457/782] Loss: 0.7090 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [458/782] Loss: 0.6383 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [459/782] Loss: 0.5590 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [460/782] Loss: 0.5916 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [461/782] Loss: 0.7378 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [462/782] Loss: 0.5851 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [463/782] Loss: 0.6790 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [464/782] Loss: 0.8339 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [465/782] Loss: 0.6107 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [466/782] Loss: 0.6677 | Acc: 78.66%\n",
      "Train Epoch [62/100] Batch [467/782] Loss: 0.4985 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [468/782] Loss: 0.5444 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [469/782] Loss: 0.5740 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [470/782] Loss: 0.5706 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [471/782] Loss: 0.3364 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [472/782] Loss: 0.5259 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [473/782] Loss: 0.4187 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [474/782] Loss: 0.6812 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [475/782] Loss: 0.6227 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [476/782] Loss: 0.6734 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [477/782] Loss: 0.8403 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [478/782] Loss: 0.4969 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [479/782] Loss: 0.4237 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [480/782] Loss: 0.5652 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [481/782] Loss: 0.7305 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [482/782] Loss: 0.2951 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [483/782] Loss: 0.6383 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [484/782] Loss: 0.5583 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [485/782] Loss: 0.5034 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [486/782] Loss: 0.5729 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [487/782] Loss: 0.5040 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [488/782] Loss: 0.5620 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [489/782] Loss: 0.4903 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [490/782] Loss: 0.4937 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [491/782] Loss: 0.8423 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [492/782] Loss: 0.7216 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [493/782] Loss: 0.5644 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [494/782] Loss: 0.6222 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [495/782] Loss: 0.6777 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [496/782] Loss: 0.5692 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [497/782] Loss: 0.6276 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [498/782] Loss: 0.6239 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [499/782] Loss: 0.5781 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [500/782] Loss: 0.4245 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [501/782] Loss: 0.8851 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [502/782] Loss: 0.8289 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [503/782] Loss: 0.8680 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [504/782] Loss: 0.5901 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [505/782] Loss: 0.7519 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [506/782] Loss: 0.6229 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [507/782] Loss: 0.5424 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [508/782] Loss: 0.7234 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [509/782] Loss: 0.5738 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [510/782] Loss: 0.8557 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [511/782] Loss: 0.6256 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [512/782] Loss: 0.4073 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [513/782] Loss: 0.6838 | Acc: 78.67%\n",
      "Train Epoch [62/100] Batch [514/782] Loss: 0.5298 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [515/782] Loss: 0.5561 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [516/782] Loss: 0.5349 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [517/782] Loss: 0.6916 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [518/782] Loss: 0.6631 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [519/782] Loss: 0.5464 | Acc: 78.69%\n",
      "Train Epoch [62/100] Batch [520/782] Loss: 0.6682 | Acc: 78.68%\n",
      "Train Epoch [62/100] Batch [521/782] Loss: 0.3749 | Acc: 78.70%\n",
      "Train Epoch [62/100] Batch [522/782] Loss: 0.3917 | Acc: 78.71%\n",
      "Train Epoch [62/100] Batch [523/782] Loss: 0.4494 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [524/782] Loss: 0.6633 | Acc: 78.72%\n",
      "Train Epoch [62/100] Batch [525/782] Loss: 0.3843 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [526/782] Loss: 0.4924 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [527/782] Loss: 0.5515 | Acc: 78.74%\n",
      "Train Epoch [62/100] Batch [528/782] Loss: 0.7204 | Acc: 78.73%\n",
      "Train Epoch [62/100] Batch [529/782] Loss: 0.4146 | Acc: 78.75%\n",
      "Train Epoch [62/100] Batch [530/782] Loss: 0.4785 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [531/782] Loss: 0.6380 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [532/782] Loss: 0.4017 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [533/782] Loss: 0.7059 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [534/782] Loss: 0.5070 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [535/782] Loss: 0.5528 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [536/782] Loss: 0.5073 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [537/782] Loss: 0.4346 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [538/782] Loss: 0.5350 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [539/782] Loss: 0.4748 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [540/782] Loss: 0.5915 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [541/782] Loss: 0.6647 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [542/782] Loss: 0.6765 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [543/782] Loss: 0.6578 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [544/782] Loss: 0.6608 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [545/782] Loss: 0.7550 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [546/782] Loss: 0.5586 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [547/782] Loss: 0.6257 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [548/782] Loss: 0.4227 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [549/782] Loss: 0.4413 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [550/782] Loss: 0.2993 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [551/782] Loss: 0.5877 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [552/782] Loss: 0.6227 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [553/782] Loss: 0.5644 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [554/782] Loss: 0.5403 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [555/782] Loss: 0.5695 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [556/782] Loss: 0.5118 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [557/782] Loss: 0.6039 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [558/782] Loss: 0.4055 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [559/782] Loss: 0.8100 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [560/782] Loss: 0.3248 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [561/782] Loss: 0.7352 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [562/782] Loss: 0.4982 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [563/782] Loss: 0.6563 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [564/782] Loss: 0.5431 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [565/782] Loss: 0.6826 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [566/782] Loss: 0.6373 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [567/782] Loss: 0.5189 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [568/782] Loss: 0.6062 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [569/782] Loss: 0.7469 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [570/782] Loss: 0.5756 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [571/782] Loss: 0.4194 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [572/782] Loss: 0.6089 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [573/782] Loss: 0.4608 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [574/782] Loss: 0.7159 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [575/782] Loss: 0.4738 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [576/782] Loss: 0.3377 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [577/782] Loss: 0.6878 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [578/782] Loss: 0.7026 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [579/782] Loss: 0.6335 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [580/782] Loss: 0.6414 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [581/782] Loss: 0.6464 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [582/782] Loss: 0.4593 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [583/782] Loss: 0.6175 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [584/782] Loss: 0.4560 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [585/782] Loss: 0.6566 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [586/782] Loss: 0.4921 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [587/782] Loss: 0.5065 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [588/782] Loss: 0.6118 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [589/782] Loss: 0.5793 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [590/782] Loss: 0.4203 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [591/782] Loss: 0.6812 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [592/782] Loss: 0.4464 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [593/782] Loss: 0.4540 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [594/782] Loss: 0.5855 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [595/782] Loss: 0.6499 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [596/782] Loss: 0.3571 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [597/782] Loss: 0.6394 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [598/782] Loss: 0.6730 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [599/782] Loss: 0.8119 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [600/782] Loss: 0.4515 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [601/782] Loss: 0.5679 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [602/782] Loss: 0.5972 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [603/782] Loss: 0.7138 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [604/782] Loss: 0.5095 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [605/782] Loss: 0.6533 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [606/782] Loss: 0.5751 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [607/782] Loss: 0.6268 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [608/782] Loss: 0.5459 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [609/782] Loss: 0.4510 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [610/782] Loss: 0.6225 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [611/782] Loss: 0.7323 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [612/782] Loss: 0.7102 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [613/782] Loss: 0.6177 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [614/782] Loss: 0.6475 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [615/782] Loss: 0.6093 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [616/782] Loss: 0.7786 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [617/782] Loss: 0.6369 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [618/782] Loss: 0.6273 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [619/782] Loss: 0.4167 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [620/782] Loss: 0.4756 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [621/782] Loss: 0.5113 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [622/782] Loss: 0.6375 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [623/782] Loss: 0.7045 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [624/782] Loss: 0.5551 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [625/782] Loss: 0.5263 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [626/782] Loss: 0.7214 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [627/782] Loss: 0.5781 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [628/782] Loss: 0.5264 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [629/782] Loss: 0.8687 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [630/782] Loss: 0.4629 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [631/782] Loss: 0.5695 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [632/782] Loss: 0.6932 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [633/782] Loss: 0.6272 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [634/782] Loss: 0.6726 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [635/782] Loss: 0.4102 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [636/782] Loss: 0.7836 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [637/782] Loss: 0.4847 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [638/782] Loss: 0.7576 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [639/782] Loss: 0.5358 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [640/782] Loss: 0.8852 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [641/782] Loss: 0.6144 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [642/782] Loss: 0.7155 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [643/782] Loss: 0.5860 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [644/782] Loss: 0.5273 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [645/782] Loss: 0.3411 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [646/782] Loss: 0.7099 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [647/782] Loss: 0.3951 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [648/782] Loss: 0.4679 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [649/782] Loss: 0.5618 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [650/782] Loss: 0.5407 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [651/782] Loss: 0.6621 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [652/782] Loss: 0.5082 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [653/782] Loss: 0.6453 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [654/782] Loss: 0.3998 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [655/782] Loss: 0.5953 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [656/782] Loss: 0.7431 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [657/782] Loss: 0.3413 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [658/782] Loss: 0.8173 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [659/782] Loss: 0.5557 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [660/782] Loss: 0.4338 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [661/782] Loss: 0.5888 | Acc: 78.98%\n",
      "Train Epoch [62/100] Batch [662/782] Loss: 0.4946 | Acc: 78.98%\n",
      "Train Epoch [62/100] Batch [663/782] Loss: 0.5578 | Acc: 78.98%\n",
      "Train Epoch [62/100] Batch [664/782] Loss: 0.5617 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [665/782] Loss: 0.6090 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [666/782] Loss: 0.6088 | Acc: 78.96%\n",
      "Train Epoch [62/100] Batch [667/782] Loss: 0.4630 | Acc: 78.97%\n",
      "Train Epoch [62/100] Batch [668/782] Loss: 1.0290 | Acc: 78.95%\n",
      "Train Epoch [62/100] Batch [669/782] Loss: 0.7935 | Acc: 78.94%\n",
      "Train Epoch [62/100] Batch [670/782] Loss: 0.8435 | Acc: 78.93%\n",
      "Train Epoch [62/100] Batch [671/782] Loss: 0.7998 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [672/782] Loss: 0.5740 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [673/782] Loss: 0.7471 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [674/782] Loss: 0.6933 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [675/782] Loss: 0.5327 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [676/782] Loss: 0.6188 | Acc: 78.92%\n",
      "Train Epoch [62/100] Batch [677/782] Loss: 0.6131 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [678/782] Loss: 0.5196 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [679/782] Loss: 0.6159 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [680/782] Loss: 0.4393 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [681/782] Loss: 0.6587 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [682/782] Loss: 0.5226 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [683/782] Loss: 0.6408 | Acc: 78.90%\n",
      "Train Epoch [62/100] Batch [684/782] Loss: 0.4795 | Acc: 78.91%\n",
      "Train Epoch [62/100] Batch [685/782] Loss: 0.7681 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [686/782] Loss: 0.5972 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [687/782] Loss: 0.7963 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [688/782] Loss: 0.3459 | Acc: 78.89%\n",
      "Train Epoch [62/100] Batch [689/782] Loss: 0.7275 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [690/782] Loss: 0.8073 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [691/782] Loss: 0.4817 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [692/782] Loss: 0.5844 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [693/782] Loss: 0.4608 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [694/782] Loss: 0.7500 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [695/782] Loss: 0.5915 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [696/782] Loss: 0.6980 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [697/782] Loss: 0.6378 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [698/782] Loss: 0.5976 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [699/782] Loss: 0.7437 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [700/782] Loss: 0.8502 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [701/782] Loss: 0.6649 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [702/782] Loss: 0.6277 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [703/782] Loss: 0.5239 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [704/782] Loss: 0.6333 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [705/782] Loss: 0.5836 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [706/782] Loss: 0.6861 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [707/782] Loss: 0.4985 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [708/782] Loss: 0.5076 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [709/782] Loss: 0.4401 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [710/782] Loss: 0.6325 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [711/782] Loss: 0.5689 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [712/782] Loss: 0.4141 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [713/782] Loss: 0.4430 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [714/782] Loss: 0.5420 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [715/782] Loss: 0.5220 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [716/782] Loss: 0.7192 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [717/782] Loss: 0.5453 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [718/782] Loss: 0.4291 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [719/782] Loss: 0.5898 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [720/782] Loss: 0.4658 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [721/782] Loss: 0.6284 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [722/782] Loss: 0.5919 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [723/782] Loss: 0.7836 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [724/782] Loss: 0.6390 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [725/782] Loss: 0.6878 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [726/782] Loss: 0.4241 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [727/782] Loss: 0.5490 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [728/782] Loss: 0.5615 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [729/782] Loss: 0.4802 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [730/782] Loss: 0.7780 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [731/782] Loss: 0.4871 | Acc: 78.88%\n",
      "Train Epoch [62/100] Batch [732/782] Loss: 0.6350 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [733/782] Loss: 0.6966 | Acc: 78.87%\n",
      "Train Epoch [62/100] Batch [734/782] Loss: 0.6108 | Acc: 78.86%\n",
      "Train Epoch [62/100] Batch [735/782] Loss: 0.8290 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [736/782] Loss: 0.8764 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [737/782] Loss: 0.5313 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [738/782] Loss: 0.5642 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [739/782] Loss: 0.3840 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [740/782] Loss: 0.6360 | Acc: 78.85%\n",
      "Train Epoch [62/100] Batch [741/782] Loss: 0.8250 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [742/782] Loss: 0.5075 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [743/782] Loss: 0.5007 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [744/782] Loss: 0.6342 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [745/782] Loss: 0.6651 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [746/782] Loss: 0.4892 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [747/782] Loss: 0.4437 | Acc: 78.84%\n",
      "Train Epoch [62/100] Batch [748/782] Loss: 0.8995 | Acc: 78.83%\n",
      "Train Epoch [62/100] Batch [749/782] Loss: 0.7216 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [750/782] Loss: 0.5484 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [751/782] Loss: 0.5857 | Acc: 78.82%\n",
      "Train Epoch [62/100] Batch [752/782] Loss: 0.6194 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [753/782] Loss: 0.7148 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [754/782] Loss: 0.7832 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [755/782] Loss: 0.4679 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [756/782] Loss: 0.7254 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [757/782] Loss: 0.5191 | Acc: 78.81%\n",
      "Train Epoch [62/100] Batch [758/782] Loss: 0.6576 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [759/782] Loss: 0.6295 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [760/782] Loss: 0.5722 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [761/782] Loss: 0.5253 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [762/782] Loss: 0.6256 | Acc: 78.80%\n",
      "Train Epoch [62/100] Batch [763/782] Loss: 0.7489 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [764/782] Loss: 0.7038 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [765/782] Loss: 0.5883 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [766/782] Loss: 0.6669 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [767/782] Loss: 0.5328 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [768/782] Loss: 0.4649 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [769/782] Loss: 0.6593 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [770/782] Loss: 0.7510 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [771/782] Loss: 0.5127 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [772/782] Loss: 0.5770 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [773/782] Loss: 0.5750 | Acc: 78.79%\n",
      "Train Epoch [62/100] Batch [774/782] Loss: 0.6393 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [775/782] Loss: 0.6153 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [776/782] Loss: 0.6234 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [777/782] Loss: 0.7386 | Acc: 78.76%\n",
      "Train Epoch [62/100] Batch [778/782] Loss: 0.5419 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [779/782] Loss: 0.5767 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [780/782] Loss: 0.4944 | Acc: 78.77%\n",
      "Train Epoch [62/100] Batch [781/782] Loss: 0.5796 | Acc: 78.78%\n",
      "Train Epoch [62/100] Batch [782/782] Loss: 0.3639 | Acc: 78.78%\n",
      "Epoch 62 completed in 29.93s.\n",
      "Test Epoch [62/100] Loss: 0.8752 | Acc: 72.77% | Inference Time: 8.17s\n",
      "Epoch 62 results saved to CSV.\n",
      "Epoch 63/100\n",
      "Train Epoch [63/100] Batch [1/782] Loss: 0.4685 | Acc: 79.69%\n",
      "Train Epoch [63/100] Batch [2/782] Loss: 0.4598 | Acc: 80.47%\n",
      "Train Epoch [63/100] Batch [3/782] Loss: 0.7863 | Acc: 79.69%\n",
      "Train Epoch [63/100] Batch [4/782] Loss: 0.5430 | Acc: 80.86%\n",
      "Train Epoch [63/100] Batch [5/782] Loss: 0.5710 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [6/782] Loss: 0.4639 | Acc: 79.95%\n",
      "Train Epoch [63/100] Batch [7/782] Loss: 0.4613 | Acc: 81.47%\n",
      "Train Epoch [63/100] Batch [8/782] Loss: 0.5899 | Acc: 81.05%\n",
      "Train Epoch [63/100] Batch [9/782] Loss: 0.3902 | Acc: 82.12%\n",
      "Train Epoch [63/100] Batch [10/782] Loss: 0.6902 | Acc: 81.09%\n",
      "Train Epoch [63/100] Batch [11/782] Loss: 0.6265 | Acc: 80.97%\n",
      "Train Epoch [63/100] Batch [12/782] Loss: 0.3686 | Acc: 81.51%\n",
      "Train Epoch [63/100] Batch [13/782] Loss: 0.3950 | Acc: 81.49%\n",
      "Train Epoch [63/100] Batch [14/782] Loss: 0.5961 | Acc: 81.25%\n",
      "Train Epoch [63/100] Batch [15/782] Loss: 0.4544 | Acc: 81.46%\n",
      "Train Epoch [63/100] Batch [16/782] Loss: 0.5397 | Acc: 81.45%\n",
      "Train Epoch [63/100] Batch [17/782] Loss: 0.5828 | Acc: 81.43%\n",
      "Train Epoch [63/100] Batch [18/782] Loss: 0.5726 | Acc: 81.25%\n",
      "Train Epoch [63/100] Batch [19/782] Loss: 0.4685 | Acc: 81.17%\n",
      "Train Epoch [63/100] Batch [20/782] Loss: 0.7119 | Acc: 80.78%\n",
      "Train Epoch [63/100] Batch [21/782] Loss: 0.6584 | Acc: 80.58%\n",
      "Train Epoch [63/100] Batch [22/782] Loss: 0.7811 | Acc: 80.04%\n",
      "Train Epoch [63/100] Batch [23/782] Loss: 0.5075 | Acc: 80.10%\n",
      "Train Epoch [63/100] Batch [24/782] Loss: 0.5220 | Acc: 80.08%\n",
      "Train Epoch [63/100] Batch [25/782] Loss: 0.3964 | Acc: 80.38%\n",
      "Train Epoch [63/100] Batch [26/782] Loss: 0.4833 | Acc: 80.65%\n",
      "Train Epoch [63/100] Batch [27/782] Loss: 0.6563 | Acc: 80.44%\n",
      "Train Epoch [63/100] Batch [28/782] Loss: 0.7031 | Acc: 80.30%\n",
      "Train Epoch [63/100] Batch [29/782] Loss: 0.4410 | Acc: 80.33%\n",
      "Train Epoch [63/100] Batch [30/782] Loss: 0.6204 | Acc: 80.10%\n",
      "Train Epoch [63/100] Batch [31/782] Loss: 0.5551 | Acc: 80.09%\n",
      "Train Epoch [63/100] Batch [32/782] Loss: 0.5128 | Acc: 80.18%\n",
      "Train Epoch [63/100] Batch [33/782] Loss: 0.4896 | Acc: 80.30%\n",
      "Train Epoch [63/100] Batch [34/782] Loss: 0.6145 | Acc: 80.19%\n",
      "Train Epoch [63/100] Batch [35/782] Loss: 0.4913 | Acc: 80.31%\n",
      "Train Epoch [63/100] Batch [36/782] Loss: 0.6102 | Acc: 80.25%\n",
      "Train Epoch [63/100] Batch [37/782] Loss: 0.8616 | Acc: 80.11%\n",
      "Train Epoch [63/100] Batch [38/782] Loss: 0.5322 | Acc: 80.22%\n",
      "Train Epoch [63/100] Batch [39/782] Loss: 0.6353 | Acc: 80.25%\n",
      "Train Epoch [63/100] Batch [40/782] Loss: 0.4796 | Acc: 80.31%\n",
      "Train Epoch [63/100] Batch [41/782] Loss: 0.5020 | Acc: 80.45%\n",
      "Train Epoch [63/100] Batch [42/782] Loss: 0.4190 | Acc: 80.62%\n",
      "Train Epoch [63/100] Batch [43/782] Loss: 0.4604 | Acc: 80.63%\n",
      "Train Epoch [63/100] Batch [44/782] Loss: 0.4316 | Acc: 80.65%\n",
      "Train Epoch [63/100] Batch [45/782] Loss: 0.4316 | Acc: 80.69%\n",
      "Train Epoch [63/100] Batch [46/782] Loss: 0.5816 | Acc: 80.81%\n",
      "Train Epoch [63/100] Batch [47/782] Loss: 0.6846 | Acc: 80.75%\n",
      "Train Epoch [63/100] Batch [48/782] Loss: 0.6645 | Acc: 80.70%\n",
      "Train Epoch [63/100] Batch [49/782] Loss: 0.7017 | Acc: 80.64%\n",
      "Train Epoch [63/100] Batch [50/782] Loss: 0.5185 | Acc: 80.66%\n",
      "Train Epoch [63/100] Batch [51/782] Loss: 0.5779 | Acc: 80.64%\n",
      "Train Epoch [63/100] Batch [52/782] Loss: 0.4495 | Acc: 80.71%\n",
      "Train Epoch [63/100] Batch [53/782] Loss: 0.5333 | Acc: 80.72%\n",
      "Train Epoch [63/100] Batch [54/782] Loss: 0.5094 | Acc: 80.64%\n",
      "Train Epoch [63/100] Batch [55/782] Loss: 0.5417 | Acc: 80.62%\n",
      "Train Epoch [63/100] Batch [56/782] Loss: 0.7277 | Acc: 80.66%\n",
      "Train Epoch [63/100] Batch [57/782] Loss: 0.5761 | Acc: 80.59%\n",
      "Train Epoch [63/100] Batch [58/782] Loss: 0.4713 | Acc: 80.66%\n",
      "Train Epoch [63/100] Batch [59/782] Loss: 0.6411 | Acc: 80.69%\n",
      "Train Epoch [63/100] Batch [60/782] Loss: 0.4551 | Acc: 80.76%\n",
      "Train Epoch [63/100] Batch [61/782] Loss: 0.5391 | Acc: 80.84%\n",
      "Train Epoch [63/100] Batch [62/782] Loss: 0.5078 | Acc: 80.85%\n",
      "Train Epoch [63/100] Batch [63/782] Loss: 0.4813 | Acc: 80.90%\n",
      "Train Epoch [63/100] Batch [64/782] Loss: 0.5513 | Acc: 80.86%\n",
      "Train Epoch [63/100] Batch [65/782] Loss: 0.5277 | Acc: 80.84%\n",
      "Train Epoch [63/100] Batch [66/782] Loss: 0.6958 | Acc: 80.82%\n",
      "Train Epoch [63/100] Batch [67/782] Loss: 0.7045 | Acc: 80.64%\n",
      "Train Epoch [63/100] Batch [68/782] Loss: 0.6124 | Acc: 80.58%\n",
      "Train Epoch [63/100] Batch [69/782] Loss: 0.5238 | Acc: 80.59%\n",
      "Train Epoch [63/100] Batch [70/782] Loss: 0.5715 | Acc: 80.54%\n",
      "Train Epoch [63/100] Batch [71/782] Loss: 0.5932 | Acc: 80.46%\n",
      "Train Epoch [63/100] Batch [72/782] Loss: 0.7223 | Acc: 80.32%\n",
      "Train Epoch [63/100] Batch [73/782] Loss: 0.6066 | Acc: 80.27%\n",
      "Train Epoch [63/100] Batch [74/782] Loss: 0.6257 | Acc: 80.24%\n",
      "Train Epoch [63/100] Batch [75/782] Loss: 0.5372 | Acc: 80.21%\n",
      "Train Epoch [63/100] Batch [76/782] Loss: 0.6646 | Acc: 80.14%\n",
      "Train Epoch [63/100] Batch [77/782] Loss: 0.6123 | Acc: 80.09%\n",
      "Train Epoch [63/100] Batch [78/782] Loss: 0.5227 | Acc: 80.11%\n",
      "Train Epoch [63/100] Batch [79/782] Loss: 0.6818 | Acc: 79.96%\n",
      "Train Epoch [63/100] Batch [80/782] Loss: 0.5408 | Acc: 79.96%\n",
      "Train Epoch [63/100] Batch [81/782] Loss: 0.4933 | Acc: 80.03%\n",
      "Train Epoch [63/100] Batch [82/782] Loss: 0.5263 | Acc: 80.01%\n",
      "Train Epoch [63/100] Batch [83/782] Loss: 0.6036 | Acc: 79.99%\n",
      "Train Epoch [63/100] Batch [84/782] Loss: 0.6775 | Acc: 79.95%\n",
      "Train Epoch [63/100] Batch [85/782] Loss: 0.8432 | Acc: 79.85%\n",
      "Train Epoch [63/100] Batch [86/782] Loss: 0.4759 | Acc: 79.87%\n",
      "Train Epoch [63/100] Batch [87/782] Loss: 0.5851 | Acc: 79.85%\n",
      "Train Epoch [63/100] Batch [88/782] Loss: 0.6783 | Acc: 79.81%\n",
      "Train Epoch [63/100] Batch [89/782] Loss: 0.4683 | Acc: 79.86%\n",
      "Train Epoch [63/100] Batch [90/782] Loss: 0.5558 | Acc: 79.84%\n",
      "Train Epoch [63/100] Batch [91/782] Loss: 0.7537 | Acc: 79.70%\n",
      "Train Epoch [63/100] Batch [92/782] Loss: 0.6957 | Acc: 79.60%\n",
      "Train Epoch [63/100] Batch [93/782] Loss: 0.6010 | Acc: 79.57%\n",
      "Train Epoch [63/100] Batch [94/782] Loss: 0.4974 | Acc: 79.60%\n",
      "Train Epoch [63/100] Batch [95/782] Loss: 0.4005 | Acc: 79.64%\n",
      "Train Epoch [63/100] Batch [96/782] Loss: 0.4744 | Acc: 79.65%\n",
      "Train Epoch [63/100] Batch [97/782] Loss: 0.5239 | Acc: 79.64%\n",
      "Train Epoch [63/100] Batch [98/782] Loss: 0.6153 | Acc: 79.61%\n",
      "Train Epoch [63/100] Batch [99/782] Loss: 0.4809 | Acc: 79.61%\n",
      "Train Epoch [63/100] Batch [100/782] Loss: 0.6114 | Acc: 79.58%\n",
      "Train Epoch [63/100] Batch [101/782] Loss: 0.8006 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [102/782] Loss: 0.7010 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [103/782] Loss: 0.5304 | Acc: 79.48%\n",
      "Train Epoch [63/100] Batch [104/782] Loss: 0.5647 | Acc: 79.49%\n",
      "Train Epoch [63/100] Batch [105/782] Loss: 0.6107 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [106/782] Loss: 0.5740 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [107/782] Loss: 0.7515 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [108/782] Loss: 0.7249 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [109/782] Loss: 0.5966 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [110/782] Loss: 0.5571 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [111/782] Loss: 0.5215 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [112/782] Loss: 0.7470 | Acc: 79.20%\n",
      "Train Epoch [63/100] Batch [113/782] Loss: 0.6316 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [114/782] Loss: 0.4962 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [115/782] Loss: 0.4380 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [116/782] Loss: 0.5508 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [117/782] Loss: 0.6494 | Acc: 79.21%\n",
      "Train Epoch [63/100] Batch [118/782] Loss: 0.4864 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [119/782] Loss: 0.6646 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [120/782] Loss: 0.7087 | Acc: 79.14%\n",
      "Train Epoch [63/100] Batch [121/782] Loss: 0.4260 | Acc: 79.20%\n",
      "Train Epoch [63/100] Batch [122/782] Loss: 0.5092 | Acc: 79.18%\n",
      "Train Epoch [63/100] Batch [123/782] Loss: 0.6054 | Acc: 79.20%\n",
      "Train Epoch [63/100] Batch [124/782] Loss: 0.5799 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [125/782] Loss: 0.4232 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [126/782] Loss: 0.7239 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [127/782] Loss: 0.5084 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [128/782] Loss: 0.5536 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [129/782] Loss: 0.5329 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [130/782] Loss: 0.5345 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [131/782] Loss: 0.5564 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [132/782] Loss: 0.3649 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [133/782] Loss: 0.7227 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [134/782] Loss: 0.5057 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [135/782] Loss: 0.7862 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [136/782] Loss: 0.3631 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [137/782] Loss: 0.7137 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [138/782] Loss: 0.5925 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [139/782] Loss: 0.5836 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [140/782] Loss: 0.3701 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [141/782] Loss: 0.3665 | Acc: 79.48%\n",
      "Train Epoch [63/100] Batch [142/782] Loss: 0.6272 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [143/782] Loss: 0.6705 | Acc: 79.47%\n",
      "Train Epoch [63/100] Batch [144/782] Loss: 0.5232 | Acc: 79.51%\n",
      "Train Epoch [63/100] Batch [145/782] Loss: 0.5245 | Acc: 79.54%\n",
      "Train Epoch [63/100] Batch [146/782] Loss: 0.6391 | Acc: 79.55%\n",
      "Train Epoch [63/100] Batch [147/782] Loss: 0.6317 | Acc: 79.53%\n",
      "Train Epoch [63/100] Batch [148/782] Loss: 0.6182 | Acc: 79.53%\n",
      "Train Epoch [63/100] Batch [149/782] Loss: 0.5641 | Acc: 79.52%\n",
      "Train Epoch [63/100] Batch [150/782] Loss: 0.6185 | Acc: 79.48%\n",
      "Train Epoch [63/100] Batch [151/782] Loss: 0.6945 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [152/782] Loss: 0.6398 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [153/782] Loss: 0.5638 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [154/782] Loss: 0.4782 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [155/782] Loss: 0.8315 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [156/782] Loss: 0.4897 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [157/782] Loss: 0.5773 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [158/782] Loss: 0.5974 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [159/782] Loss: 0.6128 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [160/782] Loss: 0.5879 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [161/782] Loss: 0.4728 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [162/782] Loss: 0.4722 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [163/782] Loss: 0.4993 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [164/782] Loss: 0.5774 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [165/782] Loss: 0.6034 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [166/782] Loss: 0.6058 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [167/782] Loss: 0.4102 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [168/782] Loss: 0.5792 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [169/782] Loss: 0.4068 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [170/782] Loss: 0.6009 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [171/782] Loss: 0.7427 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [172/782] Loss: 0.5577 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [173/782] Loss: 0.4509 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [174/782] Loss: 0.6331 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [175/782] Loss: 0.4122 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [176/782] Loss: 0.5203 | Acc: 79.46%\n",
      "Train Epoch [63/100] Batch [177/782] Loss: 0.7117 | Acc: 79.47%\n",
      "Train Epoch [63/100] Batch [178/782] Loss: 0.6358 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [179/782] Loss: 0.4654 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [180/782] Loss: 0.4970 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [181/782] Loss: 0.8202 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [182/782] Loss: 0.8552 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [183/782] Loss: 0.5379 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [184/782] Loss: 0.8222 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [185/782] Loss: 0.5359 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [186/782] Loss: 0.5491 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [187/782] Loss: 0.6706 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [188/782] Loss: 0.7722 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [189/782] Loss: 0.4137 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [190/782] Loss: 0.5488 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [191/782] Loss: 0.8021 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [192/782] Loss: 0.5713 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [193/782] Loss: 0.6580 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [194/782] Loss: 0.4745 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [195/782] Loss: 0.4028 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [196/782] Loss: 0.5875 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [197/782] Loss: 0.5291 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [198/782] Loss: 0.4321 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [199/782] Loss: 0.4409 | Acc: 79.45%\n",
      "Train Epoch [63/100] Batch [200/782] Loss: 0.5775 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [201/782] Loss: 0.5135 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [202/782] Loss: 0.5570 | Acc: 79.43%\n",
      "Train Epoch [63/100] Batch [203/782] Loss: 0.7651 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [204/782] Loss: 0.5009 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [205/782] Loss: 0.5162 | Acc: 79.44%\n",
      "Train Epoch [63/100] Batch [206/782] Loss: 0.7030 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [207/782] Loss: 0.6431 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [208/782] Loss: 0.6159 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [209/782] Loss: 0.5461 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [210/782] Loss: 0.8007 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [211/782] Loss: 0.7677 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [212/782] Loss: 0.5050 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [213/782] Loss: 0.6132 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [214/782] Loss: 0.7023 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [215/782] Loss: 0.6079 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [216/782] Loss: 0.6075 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [217/782] Loss: 0.6928 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [218/782] Loss: 0.7922 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [219/782] Loss: 0.6196 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [220/782] Loss: 0.6336 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [221/782] Loss: 0.4391 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [222/782] Loss: 0.6842 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [223/782] Loss: 0.7210 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [224/782] Loss: 0.6422 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [225/782] Loss: 0.3986 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [226/782] Loss: 0.4738 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [227/782] Loss: 0.5521 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [228/782] Loss: 0.5767 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [229/782] Loss: 0.5019 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [230/782] Loss: 0.5690 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [231/782] Loss: 0.3424 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [232/782] Loss: 0.6590 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [233/782] Loss: 0.5708 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [234/782] Loss: 0.5798 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [235/782] Loss: 0.5761 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [236/782] Loss: 0.3732 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [237/782] Loss: 0.5484 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [238/782] Loss: 0.8961 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [239/782] Loss: 0.4183 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [240/782] Loss: 0.5662 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [241/782] Loss: 0.6148 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [242/782] Loss: 0.6748 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [243/782] Loss: 0.7693 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [244/782] Loss: 0.6550 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [245/782] Loss: 0.6745 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [246/782] Loss: 0.5198 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [247/782] Loss: 0.4881 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [248/782] Loss: 0.5900 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [249/782] Loss: 0.4486 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [250/782] Loss: 0.7191 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [251/782] Loss: 0.4805 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [252/782] Loss: 0.5545 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [253/782] Loss: 0.6055 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [254/782] Loss: 0.6177 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [255/782] Loss: 0.4883 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [256/782] Loss: 0.6161 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [257/782] Loss: 0.5715 | Acc: 79.21%\n",
      "Train Epoch [63/100] Batch [258/782] Loss: 0.6849 | Acc: 79.20%\n",
      "Train Epoch [63/100] Batch [259/782] Loss: 0.4256 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [260/782] Loss: 0.4271 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [261/782] Loss: 0.4282 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [262/782] Loss: 0.5933 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [263/782] Loss: 0.3722 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [264/782] Loss: 0.7528 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [265/782] Loss: 0.5821 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [266/782] Loss: 0.4506 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [267/782] Loss: 0.4080 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [268/782] Loss: 0.6921 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [269/782] Loss: 0.6000 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [270/782] Loss: 0.4997 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [271/782] Loss: 0.6174 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [272/782] Loss: 0.5648 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [273/782] Loss: 0.3852 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [274/782] Loss: 0.5315 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [275/782] Loss: 0.4704 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [276/782] Loss: 0.5544 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [277/782] Loss: 0.6339 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [278/782] Loss: 0.4737 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [279/782] Loss: 0.5611 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [280/782] Loss: 0.6576 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [281/782] Loss: 0.6982 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [282/782] Loss: 0.5717 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [283/782] Loss: 0.5156 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [284/782] Loss: 0.3898 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [285/782] Loss: 0.3297 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [286/782] Loss: 0.4484 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [287/782] Loss: 0.5855 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [288/782] Loss: 0.5871 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [289/782] Loss: 0.5034 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [290/782] Loss: 0.5505 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [291/782] Loss: 0.5714 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [292/782] Loss: 0.6112 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [293/782] Loss: 0.7493 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [294/782] Loss: 0.5119 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [295/782] Loss: 0.5604 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [296/782] Loss: 0.6735 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [297/782] Loss: 0.7122 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [298/782] Loss: 0.4973 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [299/782] Loss: 0.5681 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [300/782] Loss: 0.5787 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [301/782] Loss: 0.5747 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [302/782] Loss: 0.6183 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [303/782] Loss: 0.6897 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [304/782] Loss: 0.3221 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [305/782] Loss: 0.5654 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [306/782] Loss: 0.6861 | Acc: 79.43%\n",
      "Train Epoch [63/100] Batch [307/782] Loss: 0.8649 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [308/782] Loss: 0.6956 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [309/782] Loss: 0.6284 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [310/782] Loss: 0.5906 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [311/782] Loss: 0.6975 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [312/782] Loss: 0.3233 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [313/782] Loss: 0.7979 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [314/782] Loss: 0.8898 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [315/782] Loss: 0.4042 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [316/782] Loss: 0.3489 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [317/782] Loss: 0.7146 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [318/782] Loss: 0.7015 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [319/782] Loss: 0.6270 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [320/782] Loss: 0.4590 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [321/782] Loss: 0.4789 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [322/782] Loss: 0.7067 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [323/782] Loss: 0.4474 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [324/782] Loss: 0.7462 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [325/782] Loss: 0.4201 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [326/782] Loss: 0.3749 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [327/782] Loss: 0.5047 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [328/782] Loss: 0.6153 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [329/782] Loss: 0.6744 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [330/782] Loss: 0.5926 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [331/782] Loss: 0.6073 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [332/782] Loss: 0.5629 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [333/782] Loss: 0.5914 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [334/782] Loss: 0.4860 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [335/782] Loss: 0.6144 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [336/782] Loss: 0.5047 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [337/782] Loss: 0.3890 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [338/782] Loss: 0.6330 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [339/782] Loss: 0.5389 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [340/782] Loss: 0.7016 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [341/782] Loss: 0.8640 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [342/782] Loss: 0.3846 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [343/782] Loss: 0.5926 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [344/782] Loss: 0.5172 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [345/782] Loss: 0.6228 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [346/782] Loss: 0.5545 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [347/782] Loss: 0.5583 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [348/782] Loss: 0.5214 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [349/782] Loss: 0.5833 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [350/782] Loss: 0.7157 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [351/782] Loss: 0.5133 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [352/782] Loss: 0.4690 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [353/782] Loss: 0.5356 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [354/782] Loss: 0.4783 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [355/782] Loss: 0.5174 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [356/782] Loss: 0.6443 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [357/782] Loss: 0.6191 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [358/782] Loss: 0.5510 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [359/782] Loss: 0.5406 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [360/782] Loss: 0.4732 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [361/782] Loss: 0.5000 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [362/782] Loss: 0.5549 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [363/782] Loss: 0.7528 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [364/782] Loss: 0.4829 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [365/782] Loss: 0.5485 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [366/782] Loss: 0.5192 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [367/782] Loss: 0.6536 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [368/782] Loss: 0.4430 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [369/782] Loss: 0.4758 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [370/782] Loss: 0.6674 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [371/782] Loss: 0.4386 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [372/782] Loss: 0.6403 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [373/782] Loss: 0.6754 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [374/782] Loss: 0.7262 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [375/782] Loss: 0.4503 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [376/782] Loss: 0.4715 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [377/782] Loss: 0.6819 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [378/782] Loss: 0.5760 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [379/782] Loss: 0.5696 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [380/782] Loss: 0.6238 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [381/782] Loss: 0.7310 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [382/782] Loss: 0.3738 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [383/782] Loss: 0.5731 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [384/782] Loss: 0.6114 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [385/782] Loss: 0.5437 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [386/782] Loss: 0.4793 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [387/782] Loss: 0.5336 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [388/782] Loss: 0.8982 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [389/782] Loss: 0.6087 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [390/782] Loss: 0.4595 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [391/782] Loss: 0.7766 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [392/782] Loss: 0.5401 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [393/782] Loss: 0.5467 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [394/782] Loss: 0.4286 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [395/782] Loss: 0.7073 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [396/782] Loss: 0.6719 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [397/782] Loss: 0.6672 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [398/782] Loss: 0.5096 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [399/782] Loss: 0.5454 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [400/782] Loss: 0.6326 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [401/782] Loss: 0.4709 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [402/782] Loss: 0.4756 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [403/782] Loss: 0.5585 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [404/782] Loss: 0.6573 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [405/782] Loss: 0.5544 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [406/782] Loss: 0.5152 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [407/782] Loss: 0.5895 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [408/782] Loss: 0.4626 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [409/782] Loss: 0.7876 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [410/782] Loss: 0.4779 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [411/782] Loss: 0.7520 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [412/782] Loss: 0.4961 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [413/782] Loss: 0.6929 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [414/782] Loss: 0.5586 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [415/782] Loss: 0.5096 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [416/782] Loss: 0.4110 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [417/782] Loss: 0.6741 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [418/782] Loss: 0.6794 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [419/782] Loss: 0.5370 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [420/782] Loss: 0.3196 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [421/782] Loss: 0.4964 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [422/782] Loss: 0.5685 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [423/782] Loss: 0.4528 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [424/782] Loss: 0.5551 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [425/782] Loss: 0.5190 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [426/782] Loss: 0.7657 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [427/782] Loss: 0.7363 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [428/782] Loss: 0.5171 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [429/782] Loss: 0.6045 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [430/782] Loss: 0.4172 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [431/782] Loss: 0.8410 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [432/782] Loss: 0.4876 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [433/782] Loss: 0.5361 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [434/782] Loss: 0.4776 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [435/782] Loss: 0.5100 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [436/782] Loss: 0.6367 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [437/782] Loss: 0.5662 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [438/782] Loss: 0.3807 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [439/782] Loss: 0.4411 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [440/782] Loss: 0.5828 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [441/782] Loss: 0.6815 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [442/782] Loss: 0.3894 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [443/782] Loss: 0.4547 | Acc: 79.41%\n",
      "Train Epoch [63/100] Batch [444/782] Loss: 0.5035 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [445/782] Loss: 0.5425 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [446/782] Loss: 0.6368 | Acc: 79.42%\n",
      "Train Epoch [63/100] Batch [447/782] Loss: 0.8073 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [448/782] Loss: 0.5757 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [449/782] Loss: 0.4911 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [450/782] Loss: 0.7046 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [451/782] Loss: 0.7209 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [452/782] Loss: 0.8258 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [453/782] Loss: 0.6592 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [454/782] Loss: 0.4411 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [455/782] Loss: 0.6355 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [456/782] Loss: 0.6426 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [457/782] Loss: 0.5005 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [458/782] Loss: 0.8444 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [459/782] Loss: 0.5595 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [460/782] Loss: 0.5835 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [461/782] Loss: 0.5945 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [462/782] Loss: 0.5945 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [463/782] Loss: 0.8823 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [464/782] Loss: 0.5527 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [465/782] Loss: 0.6831 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [466/782] Loss: 0.5575 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [467/782] Loss: 0.6936 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [468/782] Loss: 0.5869 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [469/782] Loss: 0.6985 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [470/782] Loss: 0.4059 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [471/782] Loss: 0.5262 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [472/782] Loss: 0.6032 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [473/782] Loss: 0.7685 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [474/782] Loss: 0.8496 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [475/782] Loss: 0.8317 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [476/782] Loss: 0.6513 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [477/782] Loss: 0.5101 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [478/782] Loss: 0.6477 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [479/782] Loss: 0.5668 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [480/782] Loss: 0.6271 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [481/782] Loss: 0.5310 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [482/782] Loss: 0.5722 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [483/782] Loss: 0.6490 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [484/782] Loss: 0.4806 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [485/782] Loss: 0.7475 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [486/782] Loss: 0.5198 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [487/782] Loss: 0.5922 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [488/782] Loss: 0.6687 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [489/782] Loss: 0.4682 | Acc: 79.23%\n",
      "Train Epoch [63/100] Batch [490/782] Loss: 0.5291 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [491/782] Loss: 0.7833 | Acc: 79.23%\n",
      "Train Epoch [63/100] Batch [492/782] Loss: 0.4313 | Acc: 79.23%\n",
      "Train Epoch [63/100] Batch [493/782] Loss: 0.5035 | Acc: 79.22%\n",
      "Train Epoch [63/100] Batch [494/782] Loss: 0.2843 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [495/782] Loss: 0.5167 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [496/782] Loss: 0.4982 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [497/782] Loss: 0.5449 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [498/782] Loss: 0.4871 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [499/782] Loss: 0.4438 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [500/782] Loss: 0.6139 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [501/782] Loss: 0.6273 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [502/782] Loss: 0.5407 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [503/782] Loss: 0.6995 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [504/782] Loss: 0.6658 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [505/782] Loss: 0.5834 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [506/782] Loss: 0.5969 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [507/782] Loss: 0.5376 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [508/782] Loss: 0.5294 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [509/782] Loss: 0.7122 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [510/782] Loss: 0.4719 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [511/782] Loss: 0.7018 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [512/782] Loss: 0.7203 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [513/782] Loss: 0.5202 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [514/782] Loss: 0.5592 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [515/782] Loss: 0.5817 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [516/782] Loss: 0.4816 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [517/782] Loss: 0.6908 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [518/782] Loss: 0.5714 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [519/782] Loss: 0.7219 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [520/782] Loss: 0.3929 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [521/782] Loss: 0.4914 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [522/782] Loss: 0.7310 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [523/782] Loss: 0.4883 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [524/782] Loss: 0.6207 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [525/782] Loss: 0.4857 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [526/782] Loss: 0.4347 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [527/782] Loss: 0.3916 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [528/782] Loss: 0.4541 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [529/782] Loss: 0.5420 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [530/782] Loss: 0.5006 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [531/782] Loss: 0.5325 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [532/782] Loss: 0.5209 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [533/782] Loss: 0.4283 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [534/782] Loss: 0.4836 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [535/782] Loss: 0.6081 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [536/782] Loss: 0.4177 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [537/782] Loss: 0.6218 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [538/782] Loss: 0.7425 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [539/782] Loss: 0.5269 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [540/782] Loss: 0.5616 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [541/782] Loss: 0.4349 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [542/782] Loss: 0.5263 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [543/782] Loss: 0.4677 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [544/782] Loss: 0.6880 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [545/782] Loss: 0.6922 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [546/782] Loss: 0.8434 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [547/782] Loss: 0.5033 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [548/782] Loss: 0.5099 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [549/782] Loss: 0.4882 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [550/782] Loss: 0.7086 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [551/782] Loss: 0.5966 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [552/782] Loss: 0.6772 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [553/782] Loss: 0.7244 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [554/782] Loss: 0.5685 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [555/782] Loss: 0.4737 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [556/782] Loss: 0.6774 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [557/782] Loss: 0.5622 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [558/782] Loss: 0.4450 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [559/782] Loss: 0.6425 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [560/782] Loss: 0.4488 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [561/782] Loss: 0.8175 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [562/782] Loss: 0.5985 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [563/782] Loss: 0.7125 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [564/782] Loss: 0.4495 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [565/782] Loss: 0.7032 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [566/782] Loss: 0.6343 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [567/782] Loss: 0.4338 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [568/782] Loss: 0.6652 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [569/782] Loss: 0.7322 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [570/782] Loss: 0.7451 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [571/782] Loss: 0.7092 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [572/782] Loss: 0.7292 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [573/782] Loss: 0.6077 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [574/782] Loss: 0.5925 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [575/782] Loss: 0.4713 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [576/782] Loss: 0.5001 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [577/782] Loss: 0.4090 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [578/782] Loss: 0.5071 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [579/782] Loss: 0.4647 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [580/782] Loss: 0.4332 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [581/782] Loss: 0.3643 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [582/782] Loss: 0.5505 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [583/782] Loss: 0.6189 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [584/782] Loss: 0.4288 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [585/782] Loss: 0.5073 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [586/782] Loss: 0.8747 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [587/782] Loss: 0.5551 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [588/782] Loss: 0.4186 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [589/782] Loss: 0.8708 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [590/782] Loss: 0.6105 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [591/782] Loss: 0.4693 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [592/782] Loss: 0.7470 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [593/782] Loss: 0.6024 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [594/782] Loss: 0.6672 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [595/782] Loss: 0.6914 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [596/782] Loss: 0.4861 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [597/782] Loss: 0.7004 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [598/782] Loss: 0.5530 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [599/782] Loss: 0.5637 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [600/782] Loss: 0.5705 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [601/782] Loss: 0.5965 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [602/782] Loss: 0.4102 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [603/782] Loss: 0.7079 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [604/782] Loss: 0.8182 | Acc: 79.23%\n",
      "Train Epoch [63/100] Batch [605/782] Loss: 0.3476 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [606/782] Loss: 0.4359 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [607/782] Loss: 0.7778 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [608/782] Loss: 0.5715 | Acc: 79.24%\n",
      "Train Epoch [63/100] Batch [609/782] Loss: 0.5422 | Acc: 79.25%\n",
      "Train Epoch [63/100] Batch [610/782] Loss: 0.4435 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [611/782] Loss: 0.5471 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [612/782] Loss: 0.3621 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [613/782] Loss: 0.4472 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [614/782] Loss: 0.6592 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [615/782] Loss: 0.7153 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [616/782] Loss: 0.6878 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [617/782] Loss: 0.4901 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [618/782] Loss: 0.4938 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [619/782] Loss: 0.5547 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [620/782] Loss: 0.5438 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [621/782] Loss: 0.6123 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [622/782] Loss: 0.6457 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [623/782] Loss: 0.5492 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [624/782] Loss: 0.5641 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [625/782] Loss: 0.5361 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [626/782] Loss: 0.3447 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [627/782] Loss: 0.5721 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [628/782] Loss: 0.5645 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [629/782] Loss: 0.4517 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [630/782] Loss: 0.7115 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [631/782] Loss: 0.5664 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [632/782] Loss: 0.6572 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [633/782] Loss: 0.5155 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [634/782] Loss: 0.3921 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [635/782] Loss: 0.4270 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [636/782] Loss: 0.5762 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [637/782] Loss: 0.5610 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [638/782] Loss: 0.7048 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [639/782] Loss: 0.6401 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [640/782] Loss: 0.7208 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [641/782] Loss: 0.6157 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [642/782] Loss: 0.6114 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [643/782] Loss: 0.6870 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [644/782] Loss: 0.7046 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [645/782] Loss: 0.5966 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [646/782] Loss: 0.5715 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [647/782] Loss: 0.5145 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [648/782] Loss: 0.5294 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [649/782] Loss: 0.7123 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [650/782] Loss: 0.4647 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [651/782] Loss: 0.5066 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [652/782] Loss: 0.6742 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [653/782] Loss: 0.6485 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [654/782] Loss: 0.4914 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [655/782] Loss: 0.3741 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [656/782] Loss: 0.5875 | Acc: 79.34%\n",
      "Train Epoch [63/100] Batch [657/782] Loss: 0.2275 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [658/782] Loss: 0.3985 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [659/782] Loss: 0.6919 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [660/782] Loss: 0.3724 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [661/782] Loss: 0.4588 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [662/782] Loss: 0.7323 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [663/782] Loss: 0.6558 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [664/782] Loss: 0.6948 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [665/782] Loss: 0.7601 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [666/782] Loss: 0.7316 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [667/782] Loss: 0.7944 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [668/782] Loss: 0.5697 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [669/782] Loss: 0.5192 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [670/782] Loss: 0.5068 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [671/782] Loss: 0.7077 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [672/782] Loss: 0.3930 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [673/782] Loss: 0.6809 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [674/782] Loss: 0.6213 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [675/782] Loss: 0.4847 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [676/782] Loss: 0.3526 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [677/782] Loss: 0.7725 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [678/782] Loss: 0.6680 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [679/782] Loss: 0.5567 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [680/782] Loss: 0.6006 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [681/782] Loss: 0.6596 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [682/782] Loss: 0.4721 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [683/782] Loss: 0.5868 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [684/782] Loss: 0.4071 | Acc: 79.40%\n",
      "Train Epoch [63/100] Batch [685/782] Loss: 0.4975 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [686/782] Loss: 0.5301 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [687/782] Loss: 0.6862 | Acc: 79.39%\n",
      "Train Epoch [63/100] Batch [688/782] Loss: 0.7246 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [689/782] Loss: 0.5537 | Acc: 79.38%\n",
      "Train Epoch [63/100] Batch [690/782] Loss: 0.6421 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [691/782] Loss: 0.7682 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [692/782] Loss: 0.7789 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [693/782] Loss: 0.3680 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [694/782] Loss: 0.5422 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [695/782] Loss: 0.6807 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [696/782] Loss: 0.5281 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [697/782] Loss: 0.6765 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [698/782] Loss: 0.6293 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [699/782] Loss: 0.5540 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [700/782] Loss: 0.6373 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [701/782] Loss: 0.5986 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [702/782] Loss: 0.6141 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [703/782] Loss: 0.3863 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [704/782] Loss: 0.7603 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [705/782] Loss: 0.6594 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [706/782] Loss: 0.5088 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [707/782] Loss: 0.6066 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [708/782] Loss: 0.4646 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [709/782] Loss: 0.4242 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [710/782] Loss: 0.5714 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [711/782] Loss: 0.5480 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [712/782] Loss: 0.6228 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [713/782] Loss: 0.4700 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [714/782] Loss: 0.5444 | Acc: 79.37%\n",
      "Train Epoch [63/100] Batch [715/782] Loss: 0.7679 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [716/782] Loss: 0.8181 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [717/782] Loss: 0.6179 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [718/782] Loss: 0.5752 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [719/782] Loss: 0.5443 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [720/782] Loss: 0.7241 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [721/782] Loss: 0.5487 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [722/782] Loss: 0.4434 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [723/782] Loss: 0.6789 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [724/782] Loss: 0.5425 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [725/782] Loss: 0.6877 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [726/782] Loss: 0.7114 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [727/782] Loss: 0.4386 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [728/782] Loss: 0.4823 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [729/782] Loss: 0.6158 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [730/782] Loss: 0.5728 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [731/782] Loss: 0.6469 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [732/782] Loss: 0.4872 | Acc: 79.36%\n",
      "Train Epoch [63/100] Batch [733/782] Loss: 0.8294 | Acc: 79.35%\n",
      "Train Epoch [63/100] Batch [734/782] Loss: 0.8791 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [735/782] Loss: 0.7190 | Acc: 79.33%\n",
      "Train Epoch [63/100] Batch [736/782] Loss: 0.7352 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [737/782] Loss: 0.6056 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [738/782] Loss: 0.5671 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [739/782] Loss: 0.4944 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [740/782] Loss: 0.7188 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [741/782] Loss: 0.6176 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [742/782] Loss: 0.5501 | Acc: 79.32%\n",
      "Train Epoch [63/100] Batch [743/782] Loss: 0.8780 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [744/782] Loss: 0.5415 | Acc: 79.31%\n",
      "Train Epoch [63/100] Batch [745/782] Loss: 0.7457 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [746/782] Loss: 0.5788 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [747/782] Loss: 0.6704 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [748/782] Loss: 0.5275 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [749/782] Loss: 0.6515 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [750/782] Loss: 0.5804 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [751/782] Loss: 0.6317 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [752/782] Loss: 0.3765 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [753/782] Loss: 0.8456 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [754/782] Loss: 0.4776 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [755/782] Loss: 0.3521 | Acc: 79.30%\n",
      "Train Epoch [63/100] Batch [756/782] Loss: 0.6952 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [757/782] Loss: 0.8366 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [758/782] Loss: 0.5631 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [759/782] Loss: 0.5522 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [760/782] Loss: 0.7510 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [761/782] Loss: 0.4934 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [762/782] Loss: 0.5450 | Acc: 79.29%\n",
      "Train Epoch [63/100] Batch [763/782] Loss: 0.6866 | Acc: 79.28%\n",
      "Train Epoch [63/100] Batch [764/782] Loss: 0.7788 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [765/782] Loss: 0.6407 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [766/782] Loss: 0.6493 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [767/782] Loss: 0.4493 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [768/782] Loss: 0.7808 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [769/782] Loss: 0.5718 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [770/782] Loss: 0.6385 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [771/782] Loss: 0.6486 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [772/782] Loss: 0.5139 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [773/782] Loss: 0.6244 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [774/782] Loss: 0.4125 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [775/782] Loss: 0.6880 | Acc: 79.27%\n",
      "Train Epoch [63/100] Batch [776/782] Loss: 0.6398 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [777/782] Loss: 0.6628 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [778/782] Loss: 0.6613 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [779/782] Loss: 0.5681 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [780/782] Loss: 0.5265 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [781/782] Loss: 0.6320 | Acc: 79.26%\n",
      "Train Epoch [63/100] Batch [782/782] Loss: 0.8785 | Acc: 79.25%\n",
      "Epoch 63 completed in 29.48s.\n",
      "Test Epoch [63/100] Loss: 0.8778 | Acc: 72.83% | Inference Time: 8.31s\n",
      "Epoch 63 results saved to CSV.\n",
      "Epoch 64/100\n",
      "Train Epoch [64/100] Batch [1/782] Loss: 0.6670 | Acc: 76.56%\n",
      "Train Epoch [64/100] Batch [2/782] Loss: 0.5339 | Acc: 82.03%\n",
      "Train Epoch [64/100] Batch [3/782] Loss: 0.6849 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [4/782] Loss: 0.6284 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [5/782] Loss: 0.7764 | Acc: 77.50%\n",
      "Train Epoch [64/100] Batch [6/782] Loss: 0.6445 | Acc: 77.60%\n",
      "Train Epoch [64/100] Batch [7/782] Loss: 0.6325 | Acc: 77.68%\n",
      "Train Epoch [64/100] Batch [8/782] Loss: 0.5723 | Acc: 77.54%\n",
      "Train Epoch [64/100] Batch [9/782] Loss: 0.4682 | Acc: 78.12%\n",
      "Train Epoch [64/100] Batch [10/782] Loss: 0.9080 | Acc: 77.19%\n",
      "Train Epoch [64/100] Batch [11/782] Loss: 0.5637 | Acc: 77.56%\n",
      "Train Epoch [64/100] Batch [12/782] Loss: 0.5531 | Acc: 77.60%\n",
      "Train Epoch [64/100] Batch [13/782] Loss: 0.6313 | Acc: 77.52%\n",
      "Train Epoch [64/100] Batch [14/782] Loss: 0.5916 | Acc: 77.34%\n",
      "Train Epoch [64/100] Batch [15/782] Loss: 0.6116 | Acc: 77.40%\n",
      "Train Epoch [64/100] Batch [16/782] Loss: 0.6506 | Acc: 77.25%\n",
      "Train Epoch [64/100] Batch [17/782] Loss: 0.6141 | Acc: 77.67%\n",
      "Train Epoch [64/100] Batch [18/782] Loss: 0.3929 | Acc: 78.39%\n",
      "Train Epoch [64/100] Batch [19/782] Loss: 0.7409 | Acc: 78.04%\n",
      "Train Epoch [64/100] Batch [20/782] Loss: 0.5662 | Acc: 78.12%\n",
      "Train Epoch [64/100] Batch [21/782] Loss: 0.4594 | Acc: 78.50%\n",
      "Train Epoch [64/100] Batch [22/782] Loss: 0.4792 | Acc: 78.69%\n",
      "Train Epoch [64/100] Batch [23/782] Loss: 0.3629 | Acc: 79.01%\n",
      "Train Epoch [64/100] Batch [24/782] Loss: 0.6670 | Acc: 78.65%\n",
      "Train Epoch [64/100] Batch [25/782] Loss: 0.6426 | Acc: 78.62%\n",
      "Train Epoch [64/100] Batch [26/782] Loss: 0.6673 | Acc: 78.55%\n",
      "Train Epoch [64/100] Batch [27/782] Loss: 0.3599 | Acc: 78.70%\n",
      "Train Epoch [64/100] Batch [28/782] Loss: 0.8193 | Acc: 78.35%\n",
      "Train Epoch [64/100] Batch [29/782] Loss: 0.6898 | Acc: 78.23%\n",
      "Train Epoch [64/100] Batch [30/782] Loss: 0.6683 | Acc: 78.18%\n",
      "Train Epoch [64/100] Batch [31/782] Loss: 0.5558 | Acc: 78.12%\n",
      "Train Epoch [64/100] Batch [32/782] Loss: 0.6832 | Acc: 77.78%\n",
      "Train Epoch [64/100] Batch [33/782] Loss: 0.5312 | Acc: 77.94%\n",
      "Train Epoch [64/100] Batch [34/782] Loss: 0.5577 | Acc: 78.12%\n",
      "Train Epoch [64/100] Batch [35/782] Loss: 0.6034 | Acc: 77.95%\n",
      "Train Epoch [64/100] Batch [36/782] Loss: 0.5079 | Acc: 77.99%\n",
      "Train Epoch [64/100] Batch [37/782] Loss: 0.5168 | Acc: 78.00%\n",
      "Train Epoch [64/100] Batch [38/782] Loss: 0.6567 | Acc: 77.96%\n",
      "Train Epoch [64/100] Batch [39/782] Loss: 0.5487 | Acc: 77.96%\n",
      "Train Epoch [64/100] Batch [40/782] Loss: 0.4867 | Acc: 78.09%\n",
      "Train Epoch [64/100] Batch [41/782] Loss: 0.5927 | Acc: 78.05%\n",
      "Train Epoch [64/100] Batch [42/782] Loss: 0.8819 | Acc: 77.86%\n",
      "Train Epoch [64/100] Batch [43/782] Loss: 0.6143 | Acc: 77.91%\n",
      "Train Epoch [64/100] Batch [44/782] Loss: 0.5134 | Acc: 78.12%\n",
      "Train Epoch [64/100] Batch [45/782] Loss: 0.3061 | Acc: 78.51%\n",
      "Train Epoch [64/100] Batch [46/782] Loss: 0.4925 | Acc: 78.53%\n",
      "Train Epoch [64/100] Batch [47/782] Loss: 0.4791 | Acc: 78.59%\n",
      "Train Epoch [64/100] Batch [48/782] Loss: 0.6371 | Acc: 78.55%\n",
      "Train Epoch [64/100] Batch [49/782] Loss: 0.6390 | Acc: 78.67%\n",
      "Train Epoch [64/100] Batch [50/782] Loss: 0.4610 | Acc: 78.75%\n",
      "Train Epoch [64/100] Batch [51/782] Loss: 0.4349 | Acc: 78.83%\n",
      "Train Epoch [64/100] Batch [52/782] Loss: 0.6349 | Acc: 78.82%\n",
      "Train Epoch [64/100] Batch [53/782] Loss: 0.7231 | Acc: 78.71%\n",
      "Train Epoch [64/100] Batch [54/782] Loss: 0.5353 | Acc: 78.67%\n",
      "Train Epoch [64/100] Batch [55/782] Loss: 0.4777 | Acc: 78.81%\n",
      "Train Epoch [64/100] Batch [56/782] Loss: 0.4870 | Acc: 78.85%\n",
      "Train Epoch [64/100] Batch [57/782] Loss: 0.5101 | Acc: 78.95%\n",
      "Train Epoch [64/100] Batch [58/782] Loss: 0.5350 | Acc: 79.07%\n",
      "Train Epoch [64/100] Batch [59/782] Loss: 0.4590 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [60/782] Loss: 0.5809 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [61/782] Loss: 0.5614 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [62/782] Loss: 0.5403 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [63/782] Loss: 0.4809 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [64/782] Loss: 0.4620 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [65/782] Loss: 0.4762 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [66/782] Loss: 0.6956 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [67/782] Loss: 0.5692 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [68/782] Loss: 0.5213 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [69/782] Loss: 0.6304 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [70/782] Loss: 0.5409 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [71/782] Loss: 0.4734 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [72/782] Loss: 0.6691 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [73/782] Loss: 0.4290 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [74/782] Loss: 0.4435 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [75/782] Loss: 0.4820 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [76/782] Loss: 0.6993 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [77/782] Loss: 0.6376 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [78/782] Loss: 0.9829 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [79/782] Loss: 0.4849 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [80/782] Loss: 0.6394 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [81/782] Loss: 0.3667 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [82/782] Loss: 0.6442 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [83/782] Loss: 0.4945 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [84/782] Loss: 0.4827 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [85/782] Loss: 0.5074 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [86/782] Loss: 0.6790 | Acc: 79.27%\n",
      "Train Epoch [64/100] Batch [87/782] Loss: 0.5851 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [88/782] Loss: 0.4146 | Acc: 79.28%\n",
      "Train Epoch [64/100] Batch [89/782] Loss: 0.5540 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [90/782] Loss: 0.4481 | Acc: 79.27%\n",
      "Train Epoch [64/100] Batch [91/782] Loss: 0.5293 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [92/782] Loss: 0.5925 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [93/782] Loss: 0.5995 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [94/782] Loss: 0.5181 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [95/782] Loss: 0.4767 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [96/782] Loss: 0.4580 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [97/782] Loss: 0.8005 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [98/782] Loss: 0.4181 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [99/782] Loss: 0.7047 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [100/782] Loss: 0.5031 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [101/782] Loss: 0.6906 | Acc: 79.27%\n",
      "Train Epoch [64/100] Batch [102/782] Loss: 0.5138 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [103/782] Loss: 0.5699 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [104/782] Loss: 0.6474 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [105/782] Loss: 0.5214 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [106/782] Loss: 0.5129 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [107/782] Loss: 0.4023 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [108/782] Loss: 0.6336 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [109/782] Loss: 0.8115 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [110/782] Loss: 0.6081 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [111/782] Loss: 0.4359 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [112/782] Loss: 0.5158 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [113/782] Loss: 0.3634 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [114/782] Loss: 0.5415 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [115/782] Loss: 0.4827 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [116/782] Loss: 0.4510 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [117/782] Loss: 0.5570 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [118/782] Loss: 0.4681 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [119/782] Loss: 0.5130 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [120/782] Loss: 0.5996 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [121/782] Loss: 0.5386 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [122/782] Loss: 0.3859 | Acc: 79.62%\n",
      "Train Epoch [64/100] Batch [123/782] Loss: 0.4615 | Acc: 79.65%\n",
      "Train Epoch [64/100] Batch [124/782] Loss: 0.4829 | Acc: 79.66%\n",
      "Train Epoch [64/100] Batch [125/782] Loss: 0.6110 | Acc: 79.62%\n",
      "Train Epoch [64/100] Batch [126/782] Loss: 0.5759 | Acc: 79.65%\n",
      "Train Epoch [64/100] Batch [127/782] Loss: 0.4696 | Acc: 79.65%\n",
      "Train Epoch [64/100] Batch [128/782] Loss: 0.5802 | Acc: 79.60%\n",
      "Train Epoch [64/100] Batch [129/782] Loss: 0.5942 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [130/782] Loss: 0.6989 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [131/782] Loss: 0.5500 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [132/782] Loss: 0.4601 | Acc: 79.65%\n",
      "Train Epoch [64/100] Batch [133/782] Loss: 0.4785 | Acc: 79.63%\n",
      "Train Epoch [64/100] Batch [134/782] Loss: 0.6157 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [135/782] Loss: 0.5405 | Acc: 79.63%\n",
      "Train Epoch [64/100] Batch [136/782] Loss: 0.3633 | Acc: 79.69%\n",
      "Train Epoch [64/100] Batch [137/782] Loss: 0.5252 | Acc: 79.66%\n",
      "Train Epoch [64/100] Batch [138/782] Loss: 0.7615 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [139/782] Loss: 0.7578 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [140/782] Loss: 0.5513 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [141/782] Loss: 0.8632 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [142/782] Loss: 0.4277 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [143/782] Loss: 0.7327 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [144/782] Loss: 0.6000 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [145/782] Loss: 0.5707 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [146/782] Loss: 0.5496 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [147/782] Loss: 0.5379 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [148/782] Loss: 0.5052 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [149/782] Loss: 0.3059 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [150/782] Loss: 0.3657 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [151/782] Loss: 0.6503 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [152/782] Loss: 0.8153 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [153/782] Loss: 0.5848 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [154/782] Loss: 0.4779 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [155/782] Loss: 0.6352 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [156/782] Loss: 0.6263 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [157/782] Loss: 0.5496 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [158/782] Loss: 0.5185 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [159/782] Loss: 0.7469 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [160/782] Loss: 0.4633 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [161/782] Loss: 0.5104 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [162/782] Loss: 0.5362 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [163/782] Loss: 0.5386 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [164/782] Loss: 0.6144 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [165/782] Loss: 0.6925 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [166/782] Loss: 0.7286 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [167/782] Loss: 0.4536 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [168/782] Loss: 0.5935 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [169/782] Loss: 0.3871 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [170/782] Loss: 0.6259 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [171/782] Loss: 0.6376 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [172/782] Loss: 0.5456 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [173/782] Loss: 0.7064 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [174/782] Loss: 0.6256 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [175/782] Loss: 0.4427 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [176/782] Loss: 0.6002 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [177/782] Loss: 0.5084 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [178/782] Loss: 0.7699 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [179/782] Loss: 0.6504 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [180/782] Loss: 0.4987 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [181/782] Loss: 0.5811 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [182/782] Loss: 0.5787 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [183/782] Loss: 0.4945 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [184/782] Loss: 0.5950 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [185/782] Loss: 0.5462 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [186/782] Loss: 0.5214 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [187/782] Loss: 0.4292 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [188/782] Loss: 0.6163 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [189/782] Loss: 0.4478 | Acc: 79.60%\n",
      "Train Epoch [64/100] Batch [190/782] Loss: 0.5605 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [191/782] Loss: 0.5565 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [192/782] Loss: 0.7401 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [193/782] Loss: 0.6987 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [194/782] Loss: 0.6702 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [195/782] Loss: 0.4058 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [196/782] Loss: 0.5967 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [197/782] Loss: 0.4774 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [198/782] Loss: 0.6148 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [199/782] Loss: 0.5053 | Acc: 79.62%\n",
      "Train Epoch [64/100] Batch [200/782] Loss: 0.5747 | Acc: 79.63%\n",
      "Train Epoch [64/100] Batch [201/782] Loss: 0.4556 | Acc: 79.67%\n",
      "Train Epoch [64/100] Batch [202/782] Loss: 0.6484 | Acc: 79.67%\n",
      "Train Epoch [64/100] Batch [203/782] Loss: 0.8650 | Acc: 79.63%\n",
      "Train Epoch [64/100] Batch [204/782] Loss: 0.6767 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [205/782] Loss: 0.7022 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [206/782] Loss: 0.7059 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [207/782] Loss: 0.5827 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [208/782] Loss: 0.8767 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [209/782] Loss: 0.4386 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [210/782] Loss: 0.6050 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [211/782] Loss: 0.5744 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [212/782] Loss: 0.3959 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [213/782] Loss: 0.4131 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [214/782] Loss: 0.8086 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [215/782] Loss: 0.6740 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [216/782] Loss: 0.5208 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [217/782] Loss: 0.6623 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [218/782] Loss: 0.6518 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [219/782] Loss: 0.3704 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [220/782] Loss: 0.6319 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [221/782] Loss: 0.6185 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [222/782] Loss: 0.3474 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [223/782] Loss: 0.2960 | Acc: 79.60%\n",
      "Train Epoch [64/100] Batch [224/782] Loss: 0.6251 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [225/782] Loss: 0.5763 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [226/782] Loss: 0.6835 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [227/782] Loss: 0.5616 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [228/782] Loss: 0.5486 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [229/782] Loss: 0.5251 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [230/782] Loss: 0.5845 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [231/782] Loss: 0.6322 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [232/782] Loss: 0.4163 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [233/782] Loss: 0.5826 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [234/782] Loss: 0.5194 | Acc: 79.61%\n",
      "Train Epoch [64/100] Batch [235/782] Loss: 0.5716 | Acc: 79.62%\n",
      "Train Epoch [64/100] Batch [236/782] Loss: 0.7251 | Acc: 79.59%\n",
      "Train Epoch [64/100] Batch [237/782] Loss: 0.3725 | Acc: 79.60%\n",
      "Train Epoch [64/100] Batch [238/782] Loss: 0.6789 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [239/782] Loss: 0.5149 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [240/782] Loss: 0.4988 | Acc: 79.60%\n",
      "Train Epoch [64/100] Batch [241/782] Loss: 0.6203 | Acc: 79.58%\n",
      "Train Epoch [64/100] Batch [242/782] Loss: 0.6198 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [243/782] Loss: 0.5483 | Acc: 79.57%\n",
      "Train Epoch [64/100] Batch [244/782] Loss: 0.5533 | Acc: 79.56%\n",
      "Train Epoch [64/100] Batch [245/782] Loss: 0.5662 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [246/782] Loss: 0.6504 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [247/782] Loss: 0.5312 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [248/782] Loss: 0.6063 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [249/782] Loss: 0.5948 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [250/782] Loss: 0.5620 | Acc: 79.55%\n",
      "Train Epoch [64/100] Batch [251/782] Loss: 0.7002 | Acc: 79.54%\n",
      "Train Epoch [64/100] Batch [252/782] Loss: 0.6218 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [253/782] Loss: 0.5999 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [254/782] Loss: 0.6788 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [255/782] Loss: 0.3770 | Acc: 79.53%\n",
      "Train Epoch [64/100] Batch [256/782] Loss: 0.6504 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [257/782] Loss: 0.8151 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [258/782] Loss: 0.6147 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [259/782] Loss: 0.5089 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [260/782] Loss: 0.5551 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [261/782] Loss: 0.6270 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [262/782] Loss: 0.5992 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [263/782] Loss: 0.6578 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [264/782] Loss: 0.5336 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [265/782] Loss: 0.4493 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [266/782] Loss: 0.7746 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [267/782] Loss: 0.3961 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [268/782] Loss: 0.5356 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [269/782] Loss: 0.6593 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [270/782] Loss: 0.6627 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [271/782] Loss: 0.5912 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [272/782] Loss: 0.4649 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [273/782] Loss: 0.6012 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [274/782] Loss: 0.6061 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [275/782] Loss: 0.7053 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [276/782] Loss: 0.5875 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [277/782] Loss: 0.4715 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [278/782] Loss: 0.4139 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [279/782] Loss: 0.4745 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [280/782] Loss: 0.6711 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [281/782] Loss: 0.5323 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [282/782] Loss: 0.4905 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [283/782] Loss: 0.5614 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [284/782] Loss: 0.6905 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [285/782] Loss: 0.3935 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [286/782] Loss: 0.9183 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [287/782] Loss: 0.5152 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [288/782] Loss: 0.7073 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [289/782] Loss: 0.6948 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [290/782] Loss: 0.5198 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [291/782] Loss: 0.5036 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [292/782] Loss: 0.5827 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [293/782] Loss: 0.5831 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [294/782] Loss: 0.7170 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [295/782] Loss: 0.4107 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [296/782] Loss: 0.7648 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [297/782] Loss: 0.6811 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [298/782] Loss: 0.7664 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [299/782] Loss: 0.5819 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [300/782] Loss: 0.8154 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [301/782] Loss: 0.5030 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [302/782] Loss: 0.7467 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [303/782] Loss: 0.4290 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [304/782] Loss: 0.4098 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [305/782] Loss: 0.5212 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [306/782] Loss: 0.5121 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [307/782] Loss: 0.6313 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [308/782] Loss: 0.3635 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [309/782] Loss: 0.4917 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [310/782] Loss: 0.4076 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [311/782] Loss: 0.5133 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [312/782] Loss: 0.4590 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [313/782] Loss: 0.7815 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [314/782] Loss: 0.4473 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [315/782] Loss: 0.5494 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [316/782] Loss: 0.5172 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [317/782] Loss: 0.6355 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [318/782] Loss: 0.6052 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [319/782] Loss: 0.6902 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [320/782] Loss: 0.4905 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [321/782] Loss: 0.5698 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [322/782] Loss: 0.7968 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [323/782] Loss: 0.6467 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [324/782] Loss: 0.5962 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [325/782] Loss: 0.5181 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [326/782] Loss: 0.4461 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [327/782] Loss: 0.4903 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [328/782] Loss: 0.5979 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [329/782] Loss: 0.3075 | Acc: 79.50%\n",
      "Train Epoch [64/100] Batch [330/782] Loss: 0.5972 | Acc: 79.52%\n",
      "Train Epoch [64/100] Batch [331/782] Loss: 0.5820 | Acc: 79.51%\n",
      "Train Epoch [64/100] Batch [332/782] Loss: 0.6291 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [333/782] Loss: 0.5711 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [334/782] Loss: 0.6085 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [335/782] Loss: 0.5264 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [336/782] Loss: 0.5027 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [337/782] Loss: 0.8368 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [338/782] Loss: 0.5555 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [339/782] Loss: 0.5004 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [340/782] Loss: 0.5855 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [341/782] Loss: 0.6975 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [342/782] Loss: 0.6412 | Acc: 79.46%\n",
      "Train Epoch [64/100] Batch [343/782] Loss: 0.6102 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [344/782] Loss: 0.5063 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [345/782] Loss: 0.4963 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [346/782] Loss: 0.7433 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [347/782] Loss: 0.5835 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [348/782] Loss: 0.5903 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [349/782] Loss: 0.5207 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [350/782] Loss: 0.5462 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [351/782] Loss: 0.7208 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [352/782] Loss: 0.3149 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [353/782] Loss: 0.3881 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [354/782] Loss: 0.6599 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [355/782] Loss: 0.5320 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [356/782] Loss: 0.4861 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [357/782] Loss: 0.4510 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [358/782] Loss: 0.4504 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [359/782] Loss: 0.5089 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [360/782] Loss: 0.7210 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [361/782] Loss: 0.5750 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [362/782] Loss: 0.5826 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [363/782] Loss: 0.5225 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [364/782] Loss: 0.6228 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [365/782] Loss: 0.5546 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [366/782] Loss: 0.4591 | Acc: 79.41%\n",
      "Train Epoch [64/100] Batch [367/782] Loss: 0.7314 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [368/782] Loss: 0.7197 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [369/782] Loss: 0.4986 | Acc: 79.39%\n",
      "Train Epoch [64/100] Batch [370/782] Loss: 0.5816 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [371/782] Loss: 0.4415 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [372/782] Loss: 0.3949 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [373/782] Loss: 0.4260 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [374/782] Loss: 0.3464 | Acc: 79.47%\n",
      "Train Epoch [64/100] Batch [375/782] Loss: 0.4977 | Acc: 79.49%\n",
      "Train Epoch [64/100] Batch [376/782] Loss: 0.7729 | Acc: 79.48%\n",
      "Train Epoch [64/100] Batch [377/782] Loss: 0.7806 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [378/782] Loss: 0.5307 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [379/782] Loss: 0.7994 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [380/782] Loss: 0.5283 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [381/782] Loss: 0.4522 | Acc: 79.44%\n",
      "Train Epoch [64/100] Batch [382/782] Loss: 0.6433 | Acc: 79.45%\n",
      "Train Epoch [64/100] Batch [383/782] Loss: 0.7246 | Acc: 79.43%\n",
      "Train Epoch [64/100] Batch [384/782] Loss: 0.6242 | Acc: 79.42%\n",
      "Train Epoch [64/100] Batch [385/782] Loss: 0.6451 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [386/782] Loss: 0.5956 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [387/782] Loss: 0.7141 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [388/782] Loss: 0.7169 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [389/782] Loss: 0.4942 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [390/782] Loss: 0.6110 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [391/782] Loss: 0.6473 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [392/782] Loss: 0.4909 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [393/782] Loss: 0.5418 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [394/782] Loss: 0.7925 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [395/782] Loss: 0.4708 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [396/782] Loss: 0.5651 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [397/782] Loss: 0.5989 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [398/782] Loss: 0.5002 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [399/782] Loss: 0.5918 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [400/782] Loss: 0.4679 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [401/782] Loss: 0.5124 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [402/782] Loss: 0.5202 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [403/782] Loss: 0.3436 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [404/782] Loss: 0.5789 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [405/782] Loss: 0.5554 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [406/782] Loss: 0.6183 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [407/782] Loss: 0.5063 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [408/782] Loss: 0.6177 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [409/782] Loss: 0.4184 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [410/782] Loss: 0.6625 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [411/782] Loss: 0.3803 | Acc: 79.38%\n",
      "Train Epoch [64/100] Batch [412/782] Loss: 0.7072 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [413/782] Loss: 0.6972 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [414/782] Loss: 0.5115 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [415/782] Loss: 0.6471 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [416/782] Loss: 0.4783 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [417/782] Loss: 0.5811 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [418/782] Loss: 0.2952 | Acc: 79.40%\n",
      "Train Epoch [64/100] Batch [419/782] Loss: 0.9412 | Acc: 79.37%\n",
      "Train Epoch [64/100] Batch [420/782] Loss: 0.8262 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [421/782] Loss: 0.8137 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [422/782] Loss: 0.4601 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [423/782] Loss: 0.6821 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [424/782] Loss: 0.3033 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [425/782] Loss: 0.4478 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [426/782] Loss: 0.5246 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [427/782] Loss: 0.9229 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [428/782] Loss: 0.4828 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [429/782] Loss: 0.5694 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [430/782] Loss: 0.6349 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [431/782] Loss: 0.5092 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [432/782] Loss: 0.6806 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [433/782] Loss: 0.6515 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [434/782] Loss: 0.6086 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [435/782] Loss: 0.5418 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [436/782] Loss: 0.6487 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [437/782] Loss: 0.7276 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [438/782] Loss: 0.4352 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [439/782] Loss: 0.5264 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [440/782] Loss: 0.6325 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [441/782] Loss: 0.5322 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [442/782] Loss: 0.4386 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [443/782] Loss: 0.6040 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [444/782] Loss: 0.6010 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [445/782] Loss: 0.5895 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [446/782] Loss: 0.6640 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [447/782] Loss: 0.4995 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [448/782] Loss: 0.5829 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [449/782] Loss: 0.6018 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [450/782] Loss: 0.5918 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [451/782] Loss: 0.5316 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [452/782] Loss: 0.5677 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [453/782] Loss: 0.5871 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [454/782] Loss: 0.7423 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [455/782] Loss: 0.5174 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [456/782] Loss: 0.4569 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [457/782] Loss: 0.4560 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [458/782] Loss: 0.4802 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [459/782] Loss: 0.4975 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [460/782] Loss: 0.5312 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [461/782] Loss: 0.6346 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [462/782] Loss: 0.4633 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [463/782] Loss: 0.5480 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [464/782] Loss: 0.4648 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [465/782] Loss: 0.4588 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [466/782] Loss: 0.4882 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [467/782] Loss: 0.7206 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [468/782] Loss: 0.5684 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [469/782] Loss: 0.6455 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [470/782] Loss: 0.6472 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [471/782] Loss: 0.6858 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [472/782] Loss: 0.6686 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [473/782] Loss: 0.3222 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [474/782] Loss: 0.4702 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [475/782] Loss: 0.4986 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [476/782] Loss: 0.5751 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [477/782] Loss: 0.4534 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [478/782] Loss: 0.5455 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [479/782] Loss: 0.8269 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [480/782] Loss: 0.6290 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [481/782] Loss: 0.4449 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [482/782] Loss: 0.5866 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [483/782] Loss: 0.4883 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [484/782] Loss: 0.4887 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [485/782] Loss: 0.7774 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [486/782] Loss: 0.4780 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [487/782] Loss: 0.6464 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [488/782] Loss: 0.7274 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [489/782] Loss: 0.6325 | Acc: 79.32%\n",
      "Train Epoch [64/100] Batch [490/782] Loss: 0.3328 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [491/782] Loss: 0.5906 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [492/782] Loss: 0.5206 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [493/782] Loss: 0.7148 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [494/782] Loss: 0.4434 | Acc: 79.35%\n",
      "Train Epoch [64/100] Batch [495/782] Loss: 0.5118 | Acc: 79.36%\n",
      "Train Epoch [64/100] Batch [496/782] Loss: 0.6639 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [497/782] Loss: 0.6381 | Acc: 79.33%\n",
      "Train Epoch [64/100] Batch [498/782] Loss: 0.4392 | Acc: 79.34%\n",
      "Train Epoch [64/100] Batch [499/782] Loss: 0.8918 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [500/782] Loss: 0.5579 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [501/782] Loss: 0.6217 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [502/782] Loss: 0.5561 | Acc: 79.31%\n",
      "Train Epoch [64/100] Batch [503/782] Loss: 0.7457 | Acc: 79.30%\n",
      "Train Epoch [64/100] Batch [504/782] Loss: 0.6840 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [505/782] Loss: 0.5757 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [506/782] Loss: 0.4909 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [507/782] Loss: 0.5884 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [508/782] Loss: 0.7853 | Acc: 79.28%\n",
      "Train Epoch [64/100] Batch [509/782] Loss: 0.7122 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [510/782] Loss: 0.5971 | Acc: 79.29%\n",
      "Train Epoch [64/100] Batch [511/782] Loss: 0.7691 | Acc: 79.28%\n",
      "Train Epoch [64/100] Batch [512/782] Loss: 0.8350 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [513/782] Loss: 0.6473 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [514/782] Loss: 0.7626 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [515/782] Loss: 0.6363 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [516/782] Loss: 0.4795 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [517/782] Loss: 0.6836 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [518/782] Loss: 0.7009 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [519/782] Loss: 0.5789 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [520/782] Loss: 0.6284 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [521/782] Loss: 0.8512 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [522/782] Loss: 0.6160 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [523/782] Loss: 0.7421 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [524/782] Loss: 0.4803 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [525/782] Loss: 0.5296 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [526/782] Loss: 0.5594 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [527/782] Loss: 0.5277 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [528/782] Loss: 0.5996 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [529/782] Loss: 0.6215 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [530/782] Loss: 0.4278 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [531/782] Loss: 0.6792 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [532/782] Loss: 0.5686 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [533/782] Loss: 0.3962 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [534/782] Loss: 0.5170 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [535/782] Loss: 0.5451 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [536/782] Loss: 0.5321 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [537/782] Loss: 0.7378 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [538/782] Loss: 0.7746 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [539/782] Loss: 0.5198 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [540/782] Loss: 0.7067 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [541/782] Loss: 0.6705 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [542/782] Loss: 0.3906 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [543/782] Loss: 0.5412 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [544/782] Loss: 0.4176 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [545/782] Loss: 0.4715 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [546/782] Loss: 0.7780 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [547/782] Loss: 0.5660 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [548/782] Loss: 0.4639 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [549/782] Loss: 0.4010 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [550/782] Loss: 0.5325 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [551/782] Loss: 0.5842 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [552/782] Loss: 0.5860 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [553/782] Loss: 0.6528 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [554/782] Loss: 0.6354 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [555/782] Loss: 0.5856 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [556/782] Loss: 0.6342 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [557/782] Loss: 0.6775 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [558/782] Loss: 0.6176 | Acc: 79.15%\n",
      "Train Epoch [64/100] Batch [559/782] Loss: 0.3968 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [560/782] Loss: 0.3677 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [561/782] Loss: 0.4000 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [562/782] Loss: 0.5233 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [563/782] Loss: 0.5151 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [564/782] Loss: 0.6691 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [565/782] Loss: 0.4681 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [566/782] Loss: 0.8415 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [567/782] Loss: 0.4583 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [568/782] Loss: 0.6940 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [569/782] Loss: 0.3017 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [570/782] Loss: 0.5707 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [571/782] Loss: 0.5530 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [572/782] Loss: 0.6643 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [573/782] Loss: 0.7240 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [574/782] Loss: 0.6851 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [575/782] Loss: 0.4531 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [576/782] Loss: 0.6552 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [577/782] Loss: 0.6486 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [578/782] Loss: 0.5012 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [579/782] Loss: 0.5220 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [580/782] Loss: 0.5924 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [581/782] Loss: 0.5011 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [582/782] Loss: 0.6140 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [583/782] Loss: 0.6299 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [584/782] Loss: 0.5983 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [585/782] Loss: 0.6003 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [586/782] Loss: 0.6524 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [587/782] Loss: 0.4179 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [588/782] Loss: 0.3999 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [589/782] Loss: 0.4253 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [590/782] Loss: 0.4526 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [591/782] Loss: 0.4951 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [592/782] Loss: 0.6368 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [593/782] Loss: 0.6314 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [594/782] Loss: 0.7085 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [595/782] Loss: 0.5678 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [596/782] Loss: 0.6784 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [597/782] Loss: 0.9569 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [598/782] Loss: 0.5992 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [599/782] Loss: 0.7831 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [600/782] Loss: 0.4288 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [601/782] Loss: 0.4953 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [602/782] Loss: 0.3164 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [603/782] Loss: 0.7660 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [604/782] Loss: 0.6440 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [605/782] Loss: 0.7278 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [606/782] Loss: 0.5573 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [607/782] Loss: 0.4774 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [608/782] Loss: 0.7770 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [609/782] Loss: 0.3246 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [610/782] Loss: 0.5293 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [611/782] Loss: 0.5890 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [612/782] Loss: 0.6428 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [613/782] Loss: 0.7074 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [614/782] Loss: 0.4959 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [615/782] Loss: 0.6346 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [616/782] Loss: 0.7272 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [617/782] Loss: 0.5972 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [618/782] Loss: 0.5142 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [619/782] Loss: 0.6162 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [620/782] Loss: 0.4280 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [621/782] Loss: 0.5307 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [622/782] Loss: 0.7022 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [623/782] Loss: 0.6962 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [624/782] Loss: 0.5337 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [625/782] Loss: 0.4521 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [626/782] Loss: 0.7225 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [627/782] Loss: 0.5797 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [628/782] Loss: 0.5476 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [629/782] Loss: 0.4865 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [630/782] Loss: 0.4409 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [631/782] Loss: 0.6534 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [632/782] Loss: 0.6434 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [633/782] Loss: 0.3858 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [634/782] Loss: 0.6449 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [635/782] Loss: 0.4894 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [636/782] Loss: 0.4898 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [637/782] Loss: 0.7813 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [638/782] Loss: 0.4039 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [639/782] Loss: 0.5921 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [640/782] Loss: 0.6080 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [641/782] Loss: 0.3921 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [642/782] Loss: 0.3296 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [643/782] Loss: 0.6558 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [644/782] Loss: 0.6448 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [645/782] Loss: 0.4440 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [646/782] Loss: 0.5626 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [647/782] Loss: 0.7361 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [648/782] Loss: 0.5100 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [649/782] Loss: 0.6520 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [650/782] Loss: 0.6143 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [651/782] Loss: 0.5485 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [652/782] Loss: 0.4446 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [653/782] Loss: 0.4718 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [654/782] Loss: 0.7958 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [655/782] Loss: 0.4421 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [656/782] Loss: 0.4778 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [657/782] Loss: 0.5873 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [658/782] Loss: 0.5677 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [659/782] Loss: 0.6170 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [660/782] Loss: 0.4239 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [661/782] Loss: 0.7901 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [662/782] Loss: 0.5393 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [663/782] Loss: 0.3828 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [664/782] Loss: 0.5777 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [665/782] Loss: 0.5802 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [666/782] Loss: 0.4716 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [667/782] Loss: 0.6372 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [668/782] Loss: 0.4339 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [669/782] Loss: 0.4898 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [670/782] Loss: 0.5669 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [671/782] Loss: 0.7021 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [672/782] Loss: 0.5531 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [673/782] Loss: 0.6049 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [674/782] Loss: 0.6569 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [675/782] Loss: 0.6808 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [676/782] Loss: 0.7603 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [677/782] Loss: 0.6111 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [678/782] Loss: 0.4545 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [679/782] Loss: 0.5340 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [680/782] Loss: 0.5408 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [681/782] Loss: 0.7054 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [682/782] Loss: 0.5282 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [683/782] Loss: 0.5478 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [684/782] Loss: 0.5547 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [685/782] Loss: 0.6647 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [686/782] Loss: 0.5510 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [687/782] Loss: 0.5549 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [688/782] Loss: 0.6993 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [689/782] Loss: 0.5489 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [690/782] Loss: 0.6471 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [691/782] Loss: 0.5847 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [692/782] Loss: 0.6147 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [693/782] Loss: 0.4706 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [694/782] Loss: 0.6394 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [695/782] Loss: 0.7432 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [696/782] Loss: 0.5675 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [697/782] Loss: 0.4064 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [698/782] Loss: 0.4399 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [699/782] Loss: 0.6443 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [700/782] Loss: 0.4745 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [701/782] Loss: 0.6984 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [702/782] Loss: 0.4488 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [703/782] Loss: 0.4363 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [704/782] Loss: 0.5533 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [705/782] Loss: 0.6301 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [706/782] Loss: 0.7619 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [707/782] Loss: 0.4040 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [708/782] Loss: 0.4304 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [709/782] Loss: 0.5275 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [710/782] Loss: 0.6302 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [711/782] Loss: 0.4828 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [712/782] Loss: 0.5052 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [713/782] Loss: 0.7067 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [714/782] Loss: 0.5050 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [715/782] Loss: 0.4830 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [716/782] Loss: 0.6182 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [717/782] Loss: 0.7465 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [718/782] Loss: 0.8206 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [719/782] Loss: 0.5168 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [720/782] Loss: 0.5600 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [721/782] Loss: 0.4986 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [722/782] Loss: 0.6209 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [723/782] Loss: 0.7291 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [724/782] Loss: 0.6777 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [725/782] Loss: 0.7678 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [726/782] Loss: 0.4246 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [727/782] Loss: 0.4379 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [728/782] Loss: 0.6251 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [729/782] Loss: 0.7090 | Acc: 79.16%\n",
      "Train Epoch [64/100] Batch [730/782] Loss: 0.5716 | Acc: 79.17%\n",
      "Train Epoch [64/100] Batch [731/782] Loss: 0.4279 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [732/782] Loss: 0.5496 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [733/782] Loss: 0.3735 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [734/782] Loss: 0.6334 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [735/782] Loss: 0.5428 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [736/782] Loss: 0.5697 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [737/782] Loss: 0.5851 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [738/782] Loss: 0.5581 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [739/782] Loss: 0.6197 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [740/782] Loss: 0.7230 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [741/782] Loss: 0.5184 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [742/782] Loss: 0.5394 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [743/782] Loss: 0.6051 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [744/782] Loss: 0.4563 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [745/782] Loss: 0.6736 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [746/782] Loss: 0.6031 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [747/782] Loss: 0.5698 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [748/782] Loss: 0.4766 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [749/782] Loss: 0.6188 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [750/782] Loss: 0.6567 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [751/782] Loss: 0.6336 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [752/782] Loss: 0.4917 | Acc: 79.18%\n",
      "Train Epoch [64/100] Batch [753/782] Loss: 0.5040 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [754/782] Loss: 0.5294 | Acc: 79.19%\n",
      "Train Epoch [64/100] Batch [755/782] Loss: 0.4017 | Acc: 79.20%\n",
      "Train Epoch [64/100] Batch [756/782] Loss: 0.4312 | Acc: 79.21%\n",
      "Train Epoch [64/100] Batch [757/782] Loss: 0.5175 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [758/782] Loss: 0.6379 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [759/782] Loss: 0.4838 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [760/782] Loss: 0.6038 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [761/782] Loss: 0.3368 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [762/782] Loss: 0.8385 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [763/782] Loss: 0.6809 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [764/782] Loss: 0.6735 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [765/782] Loss: 0.4828 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [766/782] Loss: 0.6252 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [767/782] Loss: 0.5362 | Acc: 79.22%\n",
      "Train Epoch [64/100] Batch [768/782] Loss: 0.5566 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [769/782] Loss: 0.4785 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [770/782] Loss: 0.5656 | Acc: 79.23%\n",
      "Train Epoch [64/100] Batch [771/782] Loss: 0.6144 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [772/782] Loss: 0.4573 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [773/782] Loss: 0.5296 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [774/782] Loss: 0.6277 | Acc: 79.24%\n",
      "Train Epoch [64/100] Batch [775/782] Loss: 0.4586 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [776/782] Loss: 0.4930 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [777/782] Loss: 0.4831 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [778/782] Loss: 0.8508 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [779/782] Loss: 0.5528 | Acc: 79.26%\n",
      "Train Epoch [64/100] Batch [780/782] Loss: 0.6317 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [781/782] Loss: 0.6253 | Acc: 79.25%\n",
      "Train Epoch [64/100] Batch [782/782] Loss: 0.5089 | Acc: 79.25%\n",
      "Epoch 64 completed in 29.98s.\n",
      "Test Epoch [64/100] Loss: 0.9036 | Acc: 72.46% | Inference Time: 8.33s\n",
      "Epoch 64 results saved to CSV.\n",
      "Epoch 65/100\n",
      "Train Epoch [65/100] Batch [1/782] Loss: 0.6827 | Acc: 76.56%\n",
      "Train Epoch [65/100] Batch [2/782] Loss: 0.5489 | Acc: 77.34%\n",
      "Train Epoch [65/100] Batch [3/782] Loss: 0.5712 | Acc: 78.65%\n",
      "Train Epoch [65/100] Batch [4/782] Loss: 0.4769 | Acc: 80.47%\n",
      "Train Epoch [65/100] Batch [5/782] Loss: 0.5699 | Acc: 78.75%\n",
      "Train Epoch [65/100] Batch [6/782] Loss: 0.4106 | Acc: 79.95%\n",
      "Train Epoch [65/100] Batch [7/782] Loss: 0.5192 | Acc: 80.58%\n",
      "Train Epoch [65/100] Batch [8/782] Loss: 0.7040 | Acc: 80.47%\n",
      "Train Epoch [65/100] Batch [9/782] Loss: 0.7381 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [10/782] Loss: 0.5176 | Acc: 80.31%\n",
      "Train Epoch [65/100] Batch [11/782] Loss: 0.5882 | Acc: 80.11%\n",
      "Train Epoch [65/100] Batch [12/782] Loss: 0.4312 | Acc: 80.47%\n",
      "Train Epoch [65/100] Batch [13/782] Loss: 0.5165 | Acc: 80.53%\n",
      "Train Epoch [65/100] Batch [14/782] Loss: 0.6173 | Acc: 80.13%\n",
      "Train Epoch [65/100] Batch [15/782] Loss: 0.4528 | Acc: 80.21%\n",
      "Train Epoch [65/100] Batch [16/782] Loss: 0.6283 | Acc: 79.98%\n",
      "Train Epoch [65/100] Batch [17/782] Loss: 0.4256 | Acc: 80.33%\n",
      "Train Epoch [65/100] Batch [18/782] Loss: 0.6362 | Acc: 80.03%\n",
      "Train Epoch [65/100] Batch [19/782] Loss: 0.3987 | Acc: 80.43%\n",
      "Train Epoch [65/100] Batch [20/782] Loss: 0.6755 | Acc: 80.08%\n",
      "Train Epoch [65/100] Batch [21/782] Loss: 0.4964 | Acc: 80.13%\n",
      "Train Epoch [65/100] Batch [22/782] Loss: 0.4626 | Acc: 80.18%\n",
      "Train Epoch [65/100] Batch [23/782] Loss: 0.5280 | Acc: 80.03%\n",
      "Train Epoch [65/100] Batch [24/782] Loss: 0.5949 | Acc: 80.01%\n",
      "Train Epoch [65/100] Batch [25/782] Loss: 0.5182 | Acc: 80.31%\n",
      "Train Epoch [65/100] Batch [26/782] Loss: 0.6024 | Acc: 80.11%\n",
      "Train Epoch [65/100] Batch [27/782] Loss: 0.3980 | Acc: 80.32%\n",
      "Train Epoch [65/100] Batch [28/782] Loss: 0.6147 | Acc: 80.13%\n",
      "Train Epoch [65/100] Batch [29/782] Loss: 0.5460 | Acc: 80.12%\n",
      "Train Epoch [65/100] Batch [30/782] Loss: 0.7132 | Acc: 80.10%\n",
      "Train Epoch [65/100] Batch [31/782] Loss: 0.5739 | Acc: 80.09%\n",
      "Train Epoch [65/100] Batch [32/782] Loss: 0.5334 | Acc: 79.98%\n",
      "Train Epoch [65/100] Batch [33/782] Loss: 0.4902 | Acc: 80.21%\n",
      "Train Epoch [65/100] Batch [34/782] Loss: 0.5472 | Acc: 80.15%\n",
      "Train Epoch [65/100] Batch [35/782] Loss: 0.5172 | Acc: 80.09%\n",
      "Train Epoch [65/100] Batch [36/782] Loss: 0.6237 | Acc: 80.03%\n",
      "Train Epoch [65/100] Batch [37/782] Loss: 0.6186 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [38/782] Loss: 0.5523 | Acc: 79.98%\n",
      "Train Epoch [65/100] Batch [39/782] Loss: 0.5788 | Acc: 79.93%\n",
      "Train Epoch [65/100] Batch [40/782] Loss: 0.5596 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [41/782] Loss: 0.5392 | Acc: 79.92%\n",
      "Train Epoch [65/100] Batch [42/782] Loss: 0.5199 | Acc: 79.99%\n",
      "Train Epoch [65/100] Batch [43/782] Loss: 0.5697 | Acc: 80.05%\n",
      "Train Epoch [65/100] Batch [44/782] Loss: 0.4691 | Acc: 80.15%\n",
      "Train Epoch [65/100] Batch [45/782] Loss: 0.6325 | Acc: 80.07%\n",
      "Train Epoch [65/100] Batch [46/782] Loss: 0.8107 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [47/782] Loss: 0.6402 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [48/782] Loss: 0.4594 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [49/782] Loss: 0.4279 | Acc: 79.88%\n",
      "Train Epoch [65/100] Batch [50/782] Loss: 0.5469 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [51/782] Loss: 0.6695 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [52/782] Loss: 0.5415 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [53/782] Loss: 0.7027 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [54/782] Loss: 0.4647 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [55/782] Loss: 0.4528 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [56/782] Loss: 0.6131 | Acc: 79.52%\n",
      "Train Epoch [65/100] Batch [57/782] Loss: 0.5697 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [58/782] Loss: 0.6902 | Acc: 79.45%\n",
      "Train Epoch [65/100] Batch [59/782] Loss: 0.5945 | Acc: 79.42%\n",
      "Train Epoch [65/100] Batch [60/782] Loss: 0.5654 | Acc: 79.43%\n",
      "Train Epoch [65/100] Batch [61/782] Loss: 0.3889 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [62/782] Loss: 0.5775 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [63/782] Loss: 0.6483 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [64/782] Loss: 0.5898 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [65/782] Loss: 0.4517 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [66/782] Loss: 0.5930 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [67/782] Loss: 0.5855 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [68/782] Loss: 0.6988 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [69/782] Loss: 0.5651 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [70/782] Loss: 0.8028 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [71/782] Loss: 0.7009 | Acc: 79.51%\n",
      "Train Epoch [65/100] Batch [72/782] Loss: 0.5163 | Acc: 79.51%\n",
      "Train Epoch [65/100] Batch [73/782] Loss: 0.4967 | Acc: 79.52%\n",
      "Train Epoch [65/100] Batch [74/782] Loss: 0.6007 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [75/782] Loss: 0.5225 | Acc: 79.50%\n",
      "Train Epoch [65/100] Batch [76/782] Loss: 0.5223 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [77/782] Loss: 0.8026 | Acc: 79.50%\n",
      "Train Epoch [65/100] Batch [78/782] Loss: 0.6246 | Acc: 79.47%\n",
      "Train Epoch [65/100] Batch [79/782] Loss: 0.4973 | Acc: 79.47%\n",
      "Train Epoch [65/100] Batch [80/782] Loss: 0.5619 | Acc: 79.49%\n",
      "Train Epoch [65/100] Batch [81/782] Loss: 0.4836 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [82/782] Loss: 0.4919 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [83/782] Loss: 0.3947 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [84/782] Loss: 0.4953 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [85/782] Loss: 0.4584 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [86/782] Loss: 0.4540 | Acc: 79.85%\n",
      "Train Epoch [65/100] Batch [87/782] Loss: 0.3990 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [88/782] Loss: 0.5175 | Acc: 79.95%\n",
      "Train Epoch [65/100] Batch [89/782] Loss: 0.7538 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [90/782] Loss: 0.3428 | Acc: 80.00%\n",
      "Train Epoch [65/100] Batch [91/782] Loss: 0.2823 | Acc: 80.10%\n",
      "Train Epoch [65/100] Batch [92/782] Loss: 0.5667 | Acc: 80.10%\n",
      "Train Epoch [65/100] Batch [93/782] Loss: 0.3989 | Acc: 80.17%\n",
      "Train Epoch [65/100] Batch [94/782] Loss: 0.5076 | Acc: 80.20%\n",
      "Train Epoch [65/100] Batch [95/782] Loss: 0.5837 | Acc: 80.15%\n",
      "Train Epoch [65/100] Batch [96/782] Loss: 0.6327 | Acc: 80.16%\n",
      "Train Epoch [65/100] Batch [97/782] Loss: 0.6672 | Acc: 80.12%\n",
      "Train Epoch [65/100] Batch [98/782] Loss: 0.6865 | Acc: 80.04%\n",
      "Train Epoch [65/100] Batch [99/782] Loss: 0.5311 | Acc: 80.02%\n",
      "Train Epoch [65/100] Batch [100/782] Loss: 0.3752 | Acc: 80.11%\n",
      "Train Epoch [65/100] Batch [101/782] Loss: 0.5843 | Acc: 80.07%\n",
      "Train Epoch [65/100] Batch [102/782] Loss: 0.5447 | Acc: 80.02%\n",
      "Train Epoch [65/100] Batch [103/782] Loss: 0.5800 | Acc: 80.01%\n",
      "Train Epoch [65/100] Batch [104/782] Loss: 0.4317 | Acc: 80.05%\n",
      "Train Epoch [65/100] Batch [105/782] Loss: 0.8077 | Acc: 79.97%\n",
      "Train Epoch [65/100] Batch [106/782] Loss: 0.4600 | Acc: 80.03%\n",
      "Train Epoch [65/100] Batch [107/782] Loss: 0.4549 | Acc: 80.05%\n",
      "Train Epoch [65/100] Batch [108/782] Loss: 0.4866 | Acc: 80.06%\n",
      "Train Epoch [65/100] Batch [109/782] Loss: 0.7215 | Acc: 80.03%\n",
      "Train Epoch [65/100] Batch [110/782] Loss: 0.5277 | Acc: 80.07%\n",
      "Train Epoch [65/100] Batch [111/782] Loss: 0.5106 | Acc: 80.12%\n",
      "Train Epoch [65/100] Batch [112/782] Loss: 0.5734 | Acc: 80.12%\n",
      "Train Epoch [65/100] Batch [113/782] Loss: 0.5283 | Acc: 80.12%\n",
      "Train Epoch [65/100] Batch [114/782] Loss: 0.5815 | Acc: 80.08%\n",
      "Train Epoch [65/100] Batch [115/782] Loss: 0.4961 | Acc: 80.08%\n",
      "Train Epoch [65/100] Batch [116/782] Loss: 0.6240 | Acc: 80.05%\n",
      "Train Epoch [65/100] Batch [117/782] Loss: 0.6766 | Acc: 80.01%\n",
      "Train Epoch [65/100] Batch [118/782] Loss: 0.8283 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [119/782] Loss: 0.6261 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [120/782] Loss: 0.7909 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [121/782] Loss: 0.6367 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [122/782] Loss: 0.6609 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [123/782] Loss: 0.6214 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [124/782] Loss: 0.8621 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [125/782] Loss: 0.3900 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [126/782] Loss: 0.6425 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [127/782] Loss: 0.4864 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [128/782] Loss: 0.3459 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [129/782] Loss: 0.3694 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [130/782] Loss: 0.5922 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [131/782] Loss: 0.6974 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [132/782] Loss: 0.5471 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [133/782] Loss: 0.3916 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [134/782] Loss: 0.5975 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [135/782] Loss: 0.5374 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [136/782] Loss: 0.7368 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [137/782] Loss: 0.6608 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [138/782] Loss: 0.6191 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [139/782] Loss: 0.6181 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [140/782] Loss: 0.2890 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [141/782] Loss: 0.5906 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [142/782] Loss: 0.5139 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [143/782] Loss: 0.3918 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [144/782] Loss: 0.4049 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [145/782] Loss: 0.5777 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [146/782] Loss: 0.3680 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [147/782] Loss: 0.7451 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [148/782] Loss: 0.5598 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [149/782] Loss: 0.6208 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [150/782] Loss: 0.4511 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [151/782] Loss: 0.4780 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [152/782] Loss: 0.4604 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [153/782] Loss: 0.5863 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [154/782] Loss: 0.6132 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [155/782] Loss: 0.4486 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [156/782] Loss: 0.4156 | Acc: 79.91%\n",
      "Train Epoch [65/100] Batch [157/782] Loss: 0.5890 | Acc: 79.91%\n",
      "Train Epoch [65/100] Batch [158/782] Loss: 0.4939 | Acc: 79.92%\n",
      "Train Epoch [65/100] Batch [159/782] Loss: 0.4587 | Acc: 79.93%\n",
      "Train Epoch [65/100] Batch [160/782] Loss: 0.5446 | Acc: 79.91%\n",
      "Train Epoch [65/100] Batch [161/782] Loss: 0.7862 | Acc: 79.88%\n",
      "Train Epoch [65/100] Batch [162/782] Loss: 0.5943 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [163/782] Loss: 0.5017 | Acc: 79.91%\n",
      "Train Epoch [65/100] Batch [164/782] Loss: 0.6509 | Acc: 79.87%\n",
      "Train Epoch [65/100] Batch [165/782] Loss: 0.4733 | Acc: 79.88%\n",
      "Train Epoch [65/100] Batch [166/782] Loss: 0.4151 | Acc: 79.89%\n",
      "Train Epoch [65/100] Batch [167/782] Loss: 0.4492 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [168/782] Loss: 0.5221 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [169/782] Loss: 0.6747 | Acc: 79.87%\n",
      "Train Epoch [65/100] Batch [170/782] Loss: 0.7676 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [171/782] Loss: 0.6312 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [172/782] Loss: 0.6974 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [173/782] Loss: 0.7480 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [174/782] Loss: 0.3983 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [175/782] Loss: 0.5134 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [176/782] Loss: 0.4976 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [177/782] Loss: 0.7129 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [178/782] Loss: 0.5454 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [179/782] Loss: 0.4613 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [180/782] Loss: 0.5200 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [181/782] Loss: 0.5361 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [182/782] Loss: 0.9248 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [183/782] Loss: 0.5236 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [184/782] Loss: 0.6334 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [185/782] Loss: 0.4498 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [186/782] Loss: 0.5158 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [187/782] Loss: 0.5803 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [188/782] Loss: 0.5737 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [189/782] Loss: 0.5083 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [190/782] Loss: 0.4492 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [191/782] Loss: 0.6206 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [192/782] Loss: 0.5779 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [193/782] Loss: 0.5125 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [194/782] Loss: 0.7413 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [195/782] Loss: 0.6692 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [196/782] Loss: 0.4262 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [197/782] Loss: 0.7122 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [198/782] Loss: 0.4965 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [199/782] Loss: 0.5137 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [200/782] Loss: 0.7413 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [201/782] Loss: 0.7007 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [202/782] Loss: 0.5803 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [203/782] Loss: 0.6205 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [204/782] Loss: 0.4910 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [205/782] Loss: 0.5812 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [206/782] Loss: 0.6827 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [207/782] Loss: 0.6149 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [208/782] Loss: 0.3781 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [209/782] Loss: 0.7436 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [210/782] Loss: 0.6567 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [211/782] Loss: 0.5790 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [212/782] Loss: 0.5181 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [213/782] Loss: 0.6172 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [214/782] Loss: 0.4938 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [215/782] Loss: 0.5398 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [216/782] Loss: 0.6669 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [217/782] Loss: 0.6234 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [218/782] Loss: 0.5967 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [219/782] Loss: 0.5309 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [220/782] Loss: 0.6403 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [221/782] Loss: 0.5467 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [222/782] Loss: 0.6000 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [223/782] Loss: 0.6457 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [224/782] Loss: 0.4239 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [225/782] Loss: 0.5010 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [226/782] Loss: 0.6232 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [227/782] Loss: 0.6343 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [228/782] Loss: 0.4995 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [229/782] Loss: 0.5843 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [230/782] Loss: 0.5555 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [231/782] Loss: 0.3648 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [232/782] Loss: 0.6005 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [233/782] Loss: 0.5695 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [234/782] Loss: 0.5374 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [235/782] Loss: 0.6194 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [236/782] Loss: 0.7777 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [237/782] Loss: 0.3793 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [238/782] Loss: 0.5298 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [239/782] Loss: 0.5718 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [240/782] Loss: 0.6775 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [241/782] Loss: 0.4906 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [242/782] Loss: 0.3062 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [243/782] Loss: 0.5192 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [244/782] Loss: 0.5067 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [245/782] Loss: 0.4968 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [246/782] Loss: 0.6883 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [247/782] Loss: 0.5012 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [248/782] Loss: 0.5149 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [249/782] Loss: 0.6251 | Acc: 79.82%\n",
      "Train Epoch [65/100] Batch [250/782] Loss: 0.7680 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [251/782] Loss: 0.4068 | Acc: 79.85%\n",
      "Train Epoch [65/100] Batch [252/782] Loss: 0.5516 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [253/782] Loss: 0.5239 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [254/782] Loss: 0.6710 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [255/782] Loss: 0.5064 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [256/782] Loss: 0.6068 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [257/782] Loss: 0.5005 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [258/782] Loss: 0.4098 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [259/782] Loss: 0.3964 | Acc: 79.87%\n",
      "Train Epoch [65/100] Batch [260/782] Loss: 0.4807 | Acc: 79.86%\n",
      "Train Epoch [65/100] Batch [261/782] Loss: 0.5189 | Acc: 79.85%\n",
      "Train Epoch [65/100] Batch [262/782] Loss: 0.7566 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [263/782] Loss: 0.4395 | Acc: 79.85%\n",
      "Train Epoch [65/100] Batch [264/782] Loss: 0.6090 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [265/782] Loss: 0.6933 | Acc: 79.83%\n",
      "Train Epoch [65/100] Batch [266/782] Loss: 0.6544 | Acc: 79.85%\n",
      "Train Epoch [65/100] Batch [267/782] Loss: 0.4996 | Acc: 79.87%\n",
      "Train Epoch [65/100] Batch [268/782] Loss: 0.4722 | Acc: 79.88%\n",
      "Train Epoch [65/100] Batch [269/782] Loss: 0.5029 | Acc: 79.90%\n",
      "Train Epoch [65/100] Batch [270/782] Loss: 0.8967 | Acc: 79.84%\n",
      "Train Epoch [65/100] Batch [271/782] Loss: 0.7449 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [272/782] Loss: 0.5858 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [273/782] Loss: 0.6848 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [274/782] Loss: 0.3238 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [275/782] Loss: 0.8615 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [276/782] Loss: 0.6186 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [277/782] Loss: 0.5116 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [278/782] Loss: 0.5157 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [279/782] Loss: 0.7627 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [280/782] Loss: 0.6170 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [281/782] Loss: 0.5288 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [282/782] Loss: 0.4838 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [283/782] Loss: 0.5292 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [284/782] Loss: 0.4807 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [285/782] Loss: 0.7840 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [286/782] Loss: 0.6122 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [287/782] Loss: 0.6320 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [288/782] Loss: 0.4052 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [289/782] Loss: 0.6207 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [290/782] Loss: 0.5719 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [291/782] Loss: 0.5025 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [292/782] Loss: 0.4706 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [293/782] Loss: 0.7171 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [294/782] Loss: 0.7226 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [295/782] Loss: 0.6295 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [296/782] Loss: 0.6508 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [297/782] Loss: 0.5125 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [298/782] Loss: 0.4907 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [299/782] Loss: 0.8413 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [300/782] Loss: 0.7209 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [301/782] Loss: 0.6028 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [302/782] Loss: 0.4152 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [303/782] Loss: 0.5367 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [304/782] Loss: 0.4256 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [305/782] Loss: 0.8455 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [306/782] Loss: 0.5169 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [307/782] Loss: 0.5580 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [308/782] Loss: 0.4483 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [309/782] Loss: 0.5430 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [310/782] Loss: 0.5846 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [311/782] Loss: 0.6640 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [312/782] Loss: 0.6365 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [313/782] Loss: 0.8421 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [314/782] Loss: 0.5239 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [315/782] Loss: 0.3878 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [316/782] Loss: 0.5587 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [317/782] Loss: 0.5265 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [318/782] Loss: 0.5163 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [319/782] Loss: 0.4956 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [320/782] Loss: 0.5141 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [321/782] Loss: 0.5099 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [322/782] Loss: 0.3697 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [323/782] Loss: 0.9205 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [324/782] Loss: 0.7397 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [325/782] Loss: 0.6139 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [326/782] Loss: 0.6720 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [327/782] Loss: 0.4425 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [328/782] Loss: 0.5237 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [329/782] Loss: 0.5139 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [330/782] Loss: 0.7929 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [331/782] Loss: 0.7166 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [332/782] Loss: 0.7370 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [333/782] Loss: 0.5745 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [334/782] Loss: 0.5280 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [335/782] Loss: 0.3207 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [336/782] Loss: 0.5975 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [337/782] Loss: 0.5942 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [338/782] Loss: 0.6193 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [339/782] Loss: 0.6422 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [340/782] Loss: 0.6243 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [341/782] Loss: 0.5176 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [342/782] Loss: 0.6494 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [343/782] Loss: 0.6886 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [344/782] Loss: 0.6987 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [345/782] Loss: 0.6203 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [346/782] Loss: 0.5889 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [347/782] Loss: 0.4912 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [348/782] Loss: 0.4447 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [349/782] Loss: 0.6744 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [350/782] Loss: 0.6151 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [351/782] Loss: 0.3376 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [352/782] Loss: 0.9191 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [353/782] Loss: 0.4810 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [354/782] Loss: 0.7094 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [355/782] Loss: 0.6875 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [356/782] Loss: 0.4026 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [357/782] Loss: 0.4128 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [358/782] Loss: 0.6994 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [359/782] Loss: 0.4817 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [360/782] Loss: 0.3772 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [361/782] Loss: 0.5045 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [362/782] Loss: 0.4061 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [363/782] Loss: 0.7440 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [364/782] Loss: 0.6161 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [365/782] Loss: 0.5440 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [366/782] Loss: 0.4941 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [367/782] Loss: 0.5768 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [368/782] Loss: 0.7282 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [369/782] Loss: 0.6698 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [370/782] Loss: 0.5758 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [371/782] Loss: 0.5823 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [372/782] Loss: 0.6566 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [373/782] Loss: 0.4716 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [374/782] Loss: 0.4388 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [375/782] Loss: 0.8087 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [376/782] Loss: 0.5871 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [377/782] Loss: 0.5936 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [378/782] Loss: 0.5059 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [379/782] Loss: 0.5743 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [380/782] Loss: 0.6163 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [381/782] Loss: 0.3195 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [382/782] Loss: 0.5625 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [383/782] Loss: 0.5568 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [384/782] Loss: 0.4537 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [385/782] Loss: 0.7319 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [386/782] Loss: 0.7505 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [387/782] Loss: 0.4763 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [388/782] Loss: 0.7502 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [389/782] Loss: 0.5556 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [390/782] Loss: 0.5933 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [391/782] Loss: 0.6227 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [392/782] Loss: 0.5373 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [393/782] Loss: 0.5960 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [394/782] Loss: 0.4357 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [395/782] Loss: 0.3968 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [396/782] Loss: 0.5506 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [397/782] Loss: 0.7117 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [398/782] Loss: 0.4827 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [399/782] Loss: 0.5432 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [400/782] Loss: 0.6441 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [401/782] Loss: 0.4304 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [402/782] Loss: 0.6507 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [403/782] Loss: 0.7307 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [404/782] Loss: 0.5284 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [405/782] Loss: 0.4955 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [406/782] Loss: 0.5810 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [407/782] Loss: 0.5297 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [408/782] Loss: 0.5315 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [409/782] Loss: 0.4925 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [410/782] Loss: 0.4941 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [411/782] Loss: 0.5701 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [412/782] Loss: 0.6404 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [413/782] Loss: 0.6979 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [414/782] Loss: 0.5886 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [415/782] Loss: 0.4429 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [416/782] Loss: 0.7474 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [417/782] Loss: 0.4239 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [418/782] Loss: 0.6441 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [419/782] Loss: 0.4270 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [420/782] Loss: 0.5861 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [421/782] Loss: 0.6848 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [422/782] Loss: 0.4202 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [423/782] Loss: 0.3907 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [424/782] Loss: 0.5899 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [425/782] Loss: 0.5471 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [426/782] Loss: 0.4832 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [427/782] Loss: 0.5448 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [428/782] Loss: 0.5510 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [429/782] Loss: 0.3662 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [430/782] Loss: 0.5963 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [431/782] Loss: 0.4800 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [432/782] Loss: 0.5280 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [433/782] Loss: 0.5730 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [434/782] Loss: 0.3831 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [435/782] Loss: 0.6877 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [436/782] Loss: 0.4290 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [437/782] Loss: 0.6298 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [438/782] Loss: 0.4452 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [439/782] Loss: 0.4711 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [440/782] Loss: 0.4102 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [441/782] Loss: 0.5053 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [442/782] Loss: 0.5107 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [443/782] Loss: 0.3696 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [444/782] Loss: 0.6312 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [445/782] Loss: 0.6201 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [446/782] Loss: 0.5631 | Acc: 79.81%\n",
      "Train Epoch [65/100] Batch [447/782] Loss: 0.5892 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [448/782] Loss: 0.5468 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [449/782] Loss: 0.5355 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [450/782] Loss: 0.5806 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [451/782] Loss: 0.6182 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [452/782] Loss: 0.4880 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [453/782] Loss: 0.5315 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [454/782] Loss: 0.5177 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [455/782] Loss: 0.6134 | Acc: 79.80%\n",
      "Train Epoch [65/100] Batch [456/782] Loss: 0.7154 | Acc: 79.79%\n",
      "Train Epoch [65/100] Batch [457/782] Loss: 0.7438 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [458/782] Loss: 0.5917 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [459/782] Loss: 0.6738 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [460/782] Loss: 0.5128 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [461/782] Loss: 0.5684 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [462/782] Loss: 0.4341 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [463/782] Loss: 0.8306 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [464/782] Loss: 0.6323 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [465/782] Loss: 0.3762 | Acc: 79.78%\n",
      "Train Epoch [65/100] Batch [466/782] Loss: 0.8918 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [467/782] Loss: 0.7608 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [468/782] Loss: 0.5820 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [469/782] Loss: 0.4392 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [470/782] Loss: 0.6271 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [471/782] Loss: 0.6742 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [472/782] Loss: 0.5779 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [473/782] Loss: 0.4895 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [474/782] Loss: 0.6641 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [475/782] Loss: 0.8460 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [476/782] Loss: 0.7766 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [477/782] Loss: 0.7855 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [478/782] Loss: 0.6876 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [479/782] Loss: 0.5077 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [480/782] Loss: 0.4074 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [481/782] Loss: 0.4389 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [482/782] Loss: 0.5000 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [483/782] Loss: 0.6390 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [484/782] Loss: 0.3796 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [485/782] Loss: 0.6169 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [486/782] Loss: 0.5746 | Acc: 79.74%\n",
      "Train Epoch [65/100] Batch [487/782] Loss: 0.5811 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [488/782] Loss: 0.4993 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [489/782] Loss: 0.6360 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [490/782] Loss: 0.6063 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [491/782] Loss: 0.5393 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [492/782] Loss: 0.6576 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [493/782] Loss: 0.6629 | Acc: 79.75%\n",
      "Train Epoch [65/100] Batch [494/782] Loss: 0.5510 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [495/782] Loss: 0.5696 | Acc: 79.76%\n",
      "Train Epoch [65/100] Batch [496/782] Loss: 0.6531 | Acc: 79.77%\n",
      "Train Epoch [65/100] Batch [497/782] Loss: 0.8528 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [498/782] Loss: 0.5043 | Acc: 79.73%\n",
      "Train Epoch [65/100] Batch [499/782] Loss: 0.7058 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [500/782] Loss: 0.7594 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [501/782] Loss: 0.6260 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [502/782] Loss: 0.6137 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [503/782] Loss: 0.4810 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [504/782] Loss: 0.5641 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [505/782] Loss: 0.3547 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [506/782] Loss: 0.6219 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [507/782] Loss: 0.4446 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [508/782] Loss: 0.5645 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [509/782] Loss: 0.4623 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [510/782] Loss: 0.6044 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [511/782] Loss: 0.5963 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [512/782] Loss: 0.6628 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [513/782] Loss: 0.5435 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [514/782] Loss: 0.6098 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [515/782] Loss: 0.7593 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [516/782] Loss: 0.6118 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [517/782] Loss: 0.6560 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [518/782] Loss: 0.6048 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [519/782] Loss: 0.5825 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [520/782] Loss: 0.4898 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [521/782] Loss: 0.4818 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [522/782] Loss: 0.3916 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [523/782] Loss: 0.5787 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [524/782] Loss: 0.8553 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [525/782] Loss: 0.5753 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [526/782] Loss: 0.6414 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [527/782] Loss: 0.4402 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [528/782] Loss: 0.7075 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [529/782] Loss: 0.5100 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [530/782] Loss: 0.5476 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [531/782] Loss: 0.4045 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [532/782] Loss: 0.6211 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [533/782] Loss: 0.5592 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [534/782] Loss: 0.5178 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [535/782] Loss: 0.4381 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [536/782] Loss: 0.6659 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [537/782] Loss: 0.4389 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [538/782] Loss: 0.5160 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [539/782] Loss: 0.6279 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [540/782] Loss: 0.5287 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [541/782] Loss: 0.6195 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [542/782] Loss: 0.3903 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [543/782] Loss: 0.8072 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [544/782] Loss: 0.5392 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [545/782] Loss: 0.4664 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [546/782] Loss: 0.7248 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [547/782] Loss: 0.4560 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [548/782] Loss: 0.5638 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [549/782] Loss: 0.4999 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [550/782] Loss: 0.5496 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [551/782] Loss: 0.4851 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [552/782] Loss: 0.6771 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [553/782] Loss: 0.7773 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [554/782] Loss: 0.5896 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [555/782] Loss: 0.5967 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [556/782] Loss: 0.6362 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [557/782] Loss: 0.5876 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [558/782] Loss: 0.5404 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [559/782] Loss: 0.5966 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [560/782] Loss: 0.5986 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [561/782] Loss: 0.5626 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [562/782] Loss: 0.5516 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [563/782] Loss: 0.5590 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [564/782] Loss: 0.5928 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [565/782] Loss: 0.3133 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [566/782] Loss: 0.5842 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [567/782] Loss: 0.6420 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [568/782] Loss: 0.5075 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [569/782] Loss: 0.5083 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [570/782] Loss: 0.6383 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [571/782] Loss: 0.4324 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [572/782] Loss: 0.4186 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [573/782] Loss: 0.8051 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [574/782] Loss: 0.4338 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [575/782] Loss: 0.5060 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [576/782] Loss: 0.6929 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [577/782] Loss: 0.4453 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [578/782] Loss: 0.5496 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [579/782] Loss: 0.6504 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [580/782] Loss: 0.5137 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [581/782] Loss: 0.5869 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [582/782] Loss: 0.3954 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [583/782] Loss: 0.5189 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [584/782] Loss: 0.4455 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [585/782] Loss: 0.6629 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [586/782] Loss: 0.6911 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [587/782] Loss: 0.5232 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [588/782] Loss: 0.4249 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [589/782] Loss: 0.7130 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [590/782] Loss: 0.5679 | Acc: 79.72%\n",
      "Train Epoch [65/100] Batch [591/782] Loss: 0.5425 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [592/782] Loss: 0.6152 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [593/782] Loss: 0.6121 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [594/782] Loss: 0.6069 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [595/782] Loss: 0.5863 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [596/782] Loss: 0.5991 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [597/782] Loss: 0.5863 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [598/782] Loss: 0.6127 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [599/782] Loss: 0.5364 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [600/782] Loss: 0.6285 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [601/782] Loss: 0.6552 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [602/782] Loss: 0.8132 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [603/782] Loss: 0.7103 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [604/782] Loss: 0.6429 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [605/782] Loss: 0.5699 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [606/782] Loss: 0.4705 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [607/782] Loss: 0.5054 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [608/782] Loss: 0.4627 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [609/782] Loss: 0.6958 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [610/782] Loss: 0.5802 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [611/782] Loss: 0.6465 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [612/782] Loss: 0.6347 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [613/782] Loss: 0.4950 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [614/782] Loss: 0.6054 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [615/782] Loss: 0.4748 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [616/782] Loss: 0.5079 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [617/782] Loss: 0.5960 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [618/782] Loss: 0.4998 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [619/782] Loss: 0.5397 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [620/782] Loss: 0.7595 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [621/782] Loss: 0.6855 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [622/782] Loss: 0.5539 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [623/782] Loss: 0.7319 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [624/782] Loss: 0.4818 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [625/782] Loss: 0.5626 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [626/782] Loss: 0.6036 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [627/782] Loss: 0.6547 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [628/782] Loss: 0.5920 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [629/782] Loss: 0.6535 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [630/782] Loss: 0.4215 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [631/782] Loss: 0.6384 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [632/782] Loss: 0.4861 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [633/782] Loss: 0.5977 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [634/782] Loss: 0.6276 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [635/782] Loss: 0.5418 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [636/782] Loss: 0.4890 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [637/782] Loss: 0.8170 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [638/782] Loss: 0.6127 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [639/782] Loss: 0.6428 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [640/782] Loss: 0.7429 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [641/782] Loss: 0.5459 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [642/782] Loss: 0.4353 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [643/782] Loss: 0.6817 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [644/782] Loss: 0.6026 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [645/782] Loss: 0.5874 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [646/782] Loss: 0.4891 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [647/782] Loss: 0.6765 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [648/782] Loss: 0.6022 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [649/782] Loss: 0.5762 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [650/782] Loss: 0.5644 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [651/782] Loss: 0.6122 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [652/782] Loss: 0.5731 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [653/782] Loss: 0.6618 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [654/782] Loss: 0.4622 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [655/782] Loss: 0.7554 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [656/782] Loss: 0.3882 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [657/782] Loss: 0.6371 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [658/782] Loss: 0.4950 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [659/782] Loss: 0.8126 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [660/782] Loss: 0.5196 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [661/782] Loss: 0.5728 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [662/782] Loss: 0.5354 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [663/782] Loss: 0.3647 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [664/782] Loss: 0.5573 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [665/782] Loss: 0.8228 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [666/782] Loss: 0.5189 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [667/782] Loss: 0.5119 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [668/782] Loss: 0.5186 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [669/782] Loss: 0.4748 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [670/782] Loss: 0.5075 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [671/782] Loss: 0.7794 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [672/782] Loss: 0.6155 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [673/782] Loss: 0.4564 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [674/782] Loss: 0.4716 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [675/782] Loss: 0.6303 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [676/782] Loss: 0.5076 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [677/782] Loss: 0.5287 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [678/782] Loss: 0.5917 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [679/782] Loss: 0.4918 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [680/782] Loss: 0.7401 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [681/782] Loss: 0.5649 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [682/782] Loss: 0.4908 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [683/782] Loss: 0.5041 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [684/782] Loss: 0.5568 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [685/782] Loss: 0.4548 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [686/782] Loss: 0.5519 | Acc: 79.54%\n",
      "Train Epoch [65/100] Batch [687/782] Loss: 0.4346 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [688/782] Loss: 0.2925 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [689/782] Loss: 0.3544 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [690/782] Loss: 0.5762 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [691/782] Loss: 0.4268 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [692/782] Loss: 0.6327 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [693/782] Loss: 0.8888 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [694/782] Loss: 0.5297 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [695/782] Loss: 0.7603 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [696/782] Loss: 0.5549 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [697/782] Loss: 0.5421 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [698/782] Loss: 0.5927 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [699/782] Loss: 0.5263 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [700/782] Loss: 0.5896 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [701/782] Loss: 0.4731 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [702/782] Loss: 0.5779 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [703/782] Loss: 0.6231 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [704/782] Loss: 0.5973 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [705/782] Loss: 0.4466 | Acc: 79.55%\n",
      "Train Epoch [65/100] Batch [706/782] Loss: 0.4413 | Acc: 79.56%\n",
      "Train Epoch [65/100] Batch [707/782] Loss: 0.4499 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [708/782] Loss: 0.6606 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [709/782] Loss: 0.4601 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [710/782] Loss: 0.4426 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [711/782] Loss: 0.5799 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [712/782] Loss: 0.5335 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [713/782] Loss: 0.6562 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [714/782] Loss: 0.4095 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [715/782] Loss: 0.8196 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [716/782] Loss: 0.5901 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [717/782] Loss: 0.5606 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [718/782] Loss: 0.6512 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [719/782] Loss: 0.4976 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [720/782] Loss: 0.5745 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [721/782] Loss: 0.5371 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [722/782] Loss: 0.4787 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [723/782] Loss: 0.6170 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [724/782] Loss: 0.6196 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [725/782] Loss: 0.5694 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [726/782] Loss: 0.6865 | Acc: 79.57%\n",
      "Train Epoch [65/100] Batch [727/782] Loss: 0.5277 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [728/782] Loss: 0.6369 | Acc: 79.58%\n",
      "Train Epoch [65/100] Batch [729/782] Loss: 0.4828 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [730/782] Loss: 0.5266 | Acc: 79.59%\n",
      "Train Epoch [65/100] Batch [731/782] Loss: 0.3337 | Acc: 79.60%\n",
      "Train Epoch [65/100] Batch [732/782] Loss: 0.5175 | Acc: 79.61%\n",
      "Train Epoch [65/100] Batch [733/782] Loss: 0.4427 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [734/782] Loss: 0.6654 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [735/782] Loss: 0.5180 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [736/782] Loss: 0.6615 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [737/782] Loss: 0.5091 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [738/782] Loss: 0.6664 | Acc: 79.62%\n",
      "Train Epoch [65/100] Batch [739/782] Loss: 0.5261 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [740/782] Loss: 0.5628 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [741/782] Loss: 0.6262 | Acc: 79.63%\n",
      "Train Epoch [65/100] Batch [742/782] Loss: 0.4642 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [743/782] Loss: 0.5300 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [744/782] Loss: 0.5524 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [745/782] Loss: 0.5843 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [746/782] Loss: 0.5475 | Acc: 79.64%\n",
      "Train Epoch [65/100] Batch [747/782] Loss: 0.3853 | Acc: 79.65%\n",
      "Train Epoch [65/100] Batch [748/782] Loss: 0.5546 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [749/782] Loss: 0.5859 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [750/782] Loss: 0.4861 | Acc: 79.66%\n",
      "Train Epoch [65/100] Batch [751/782] Loss: 0.3827 | Acc: 79.67%\n",
      "Train Epoch [65/100] Batch [752/782] Loss: 0.4512 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [753/782] Loss: 0.5139 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [754/782] Loss: 0.7480 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [755/782] Loss: 0.5009 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [756/782] Loss: 0.4047 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [757/782] Loss: 0.4241 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [758/782] Loss: 0.5626 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [759/782] Loss: 0.5530 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [760/782] Loss: 0.4975 | Acc: 79.71%\n",
      "Train Epoch [65/100] Batch [761/782] Loss: 0.8412 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [762/782] Loss: 0.4623 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [763/782] Loss: 0.5021 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [764/782] Loss: 0.6859 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [765/782] Loss: 0.7749 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [766/782] Loss: 0.6044 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [767/782] Loss: 0.5924 | Acc: 79.68%\n",
      "Train Epoch [65/100] Batch [768/782] Loss: 0.6419 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [769/782] Loss: 0.4532 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [770/782] Loss: 0.6619 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [771/782] Loss: 0.4665 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [772/782] Loss: 0.6709 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [773/782] Loss: 0.5518 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [774/782] Loss: 0.6946 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [775/782] Loss: 0.4918 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [776/782] Loss: 0.5555 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [777/782] Loss: 0.4558 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [778/782] Loss: 0.4095 | Acc: 79.70%\n",
      "Train Epoch [65/100] Batch [779/782] Loss: 0.7346 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [780/782] Loss: 0.5780 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [781/782] Loss: 0.7005 | Acc: 79.69%\n",
      "Train Epoch [65/100] Batch [782/782] Loss: 0.7441 | Acc: 79.69%\n",
      "Epoch 65 completed in 29.35s.\n",
      "Test Epoch [65/100] Loss: 0.8995 | Acc: 72.62% | Inference Time: 8.35s\n",
      "Epoch 65 results saved to CSV.\n",
      "Epoch 66/100\n",
      "Train Epoch [66/100] Batch [1/782] Loss: 0.3949 | Acc: 81.25%\n",
      "Train Epoch [66/100] Batch [2/782] Loss: 0.6661 | Acc: 78.12%\n",
      "Train Epoch [66/100] Batch [3/782] Loss: 0.5485 | Acc: 79.17%\n",
      "Train Epoch [66/100] Batch [4/782] Loss: 0.7472 | Acc: 76.56%\n",
      "Train Epoch [66/100] Batch [5/782] Loss: 0.6576 | Acc: 76.56%\n",
      "Train Epoch [66/100] Batch [6/782] Loss: 0.5534 | Acc: 77.08%\n",
      "Train Epoch [66/100] Batch [7/782] Loss: 0.5972 | Acc: 77.01%\n",
      "Train Epoch [66/100] Batch [8/782] Loss: 0.6967 | Acc: 76.76%\n",
      "Train Epoch [66/100] Batch [9/782] Loss: 0.6065 | Acc: 77.26%\n",
      "Train Epoch [66/100] Batch [10/782] Loss: 0.5268 | Acc: 77.66%\n",
      "Train Epoch [66/100] Batch [11/782] Loss: 0.4815 | Acc: 77.41%\n",
      "Train Epoch [66/100] Batch [12/782] Loss: 0.3427 | Acc: 77.99%\n",
      "Train Epoch [66/100] Batch [13/782] Loss: 0.7066 | Acc: 77.76%\n",
      "Train Epoch [66/100] Batch [14/782] Loss: 0.6116 | Acc: 77.79%\n",
      "Train Epoch [66/100] Batch [15/782] Loss: 0.3265 | Acc: 78.65%\n",
      "Train Epoch [66/100] Batch [16/782] Loss: 0.4409 | Acc: 78.91%\n",
      "Train Epoch [66/100] Batch [17/782] Loss: 0.6604 | Acc: 78.58%\n",
      "Train Epoch [66/100] Batch [18/782] Loss: 0.4037 | Acc: 78.73%\n",
      "Train Epoch [66/100] Batch [19/782] Loss: 0.3907 | Acc: 79.19%\n",
      "Train Epoch [66/100] Batch [20/782] Loss: 0.5090 | Acc: 79.22%\n",
      "Train Epoch [66/100] Batch [21/782] Loss: 0.4025 | Acc: 79.61%\n",
      "Train Epoch [66/100] Batch [22/782] Loss: 0.6402 | Acc: 79.62%\n",
      "Train Epoch [66/100] Batch [23/782] Loss: 0.5984 | Acc: 79.82%\n",
      "Train Epoch [66/100] Batch [24/782] Loss: 0.6625 | Acc: 79.49%\n",
      "Train Epoch [66/100] Batch [25/782] Loss: 0.4542 | Acc: 79.81%\n",
      "Train Epoch [66/100] Batch [26/782] Loss: 0.6311 | Acc: 79.69%\n",
      "Train Epoch [66/100] Batch [27/782] Loss: 0.6092 | Acc: 79.57%\n",
      "Train Epoch [66/100] Batch [28/782] Loss: 0.5687 | Acc: 79.52%\n",
      "Train Epoch [66/100] Batch [29/782] Loss: 0.5906 | Acc: 79.53%\n",
      "Train Epoch [66/100] Batch [30/782] Loss: 0.6177 | Acc: 79.43%\n",
      "Train Epoch [66/100] Batch [31/782] Loss: 0.6362 | Acc: 79.28%\n",
      "Train Epoch [66/100] Batch [32/782] Loss: 0.4613 | Acc: 79.39%\n",
      "Train Epoch [66/100] Batch [33/782] Loss: 0.5144 | Acc: 79.40%\n",
      "Train Epoch [66/100] Batch [34/782] Loss: 0.5194 | Acc: 79.32%\n",
      "Train Epoch [66/100] Batch [35/782] Loss: 0.4773 | Acc: 79.42%\n",
      "Train Epoch [66/100] Batch [36/782] Loss: 0.5416 | Acc: 79.51%\n",
      "Train Epoch [66/100] Batch [37/782] Loss: 0.7049 | Acc: 79.35%\n",
      "Train Epoch [66/100] Batch [38/782] Loss: 0.5299 | Acc: 79.28%\n",
      "Train Epoch [66/100] Batch [39/782] Loss: 0.4893 | Acc: 79.33%\n",
      "Train Epoch [66/100] Batch [40/782] Loss: 0.5480 | Acc: 79.49%\n",
      "Train Epoch [66/100] Batch [41/782] Loss: 0.4907 | Acc: 79.54%\n",
      "Train Epoch [66/100] Batch [42/782] Loss: 0.6303 | Acc: 79.50%\n",
      "Train Epoch [66/100] Batch [43/782] Loss: 0.5892 | Acc: 79.40%\n",
      "Train Epoch [66/100] Batch [44/782] Loss: 0.4877 | Acc: 79.44%\n",
      "Train Epoch [66/100] Batch [45/782] Loss: 0.4410 | Acc: 79.48%\n",
      "Train Epoch [66/100] Batch [46/782] Loss: 0.4236 | Acc: 79.62%\n",
      "Train Epoch [66/100] Batch [47/782] Loss: 0.4324 | Acc: 79.65%\n",
      "Train Epoch [66/100] Batch [48/782] Loss: 0.5320 | Acc: 79.69%\n",
      "Train Epoch [66/100] Batch [49/782] Loss: 0.8045 | Acc: 79.50%\n",
      "Train Epoch [66/100] Batch [50/782] Loss: 0.6680 | Acc: 79.56%\n",
      "Train Epoch [66/100] Batch [51/782] Loss: 0.4300 | Acc: 79.63%\n",
      "Train Epoch [66/100] Batch [52/782] Loss: 0.5071 | Acc: 79.66%\n",
      "Train Epoch [66/100] Batch [53/782] Loss: 0.4986 | Acc: 79.72%\n",
      "Train Epoch [66/100] Batch [54/782] Loss: 0.6246 | Acc: 79.69%\n",
      "Train Epoch [66/100] Batch [55/782] Loss: 0.4174 | Acc: 79.83%\n",
      "Train Epoch [66/100] Batch [56/782] Loss: 0.5251 | Acc: 79.88%\n",
      "Train Epoch [66/100] Batch [57/782] Loss: 0.6652 | Acc: 79.80%\n",
      "Train Epoch [66/100] Batch [58/782] Loss: 0.4724 | Acc: 79.88%\n",
      "Train Epoch [66/100] Batch [59/782] Loss: 0.5934 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [60/782] Loss: 0.6100 | Acc: 79.87%\n",
      "Train Epoch [66/100] Batch [61/782] Loss: 0.6185 | Acc: 79.82%\n",
      "Train Epoch [66/100] Batch [62/782] Loss: 0.6697 | Acc: 79.71%\n",
      "Train Epoch [66/100] Batch [63/782] Loss: 0.4964 | Acc: 79.79%\n",
      "Train Epoch [66/100] Batch [64/782] Loss: 0.6389 | Acc: 79.76%\n",
      "Train Epoch [66/100] Batch [65/782] Loss: 0.6737 | Acc: 79.71%\n",
      "Train Epoch [66/100] Batch [66/782] Loss: 0.5671 | Acc: 79.71%\n",
      "Train Epoch [66/100] Batch [67/782] Loss: 0.4819 | Acc: 79.83%\n",
      "Train Epoch [66/100] Batch [68/782] Loss: 0.5471 | Acc: 79.85%\n",
      "Train Epoch [66/100] Batch [69/782] Loss: 0.3909 | Acc: 79.91%\n",
      "Train Epoch [66/100] Batch [70/782] Loss: 0.5091 | Acc: 79.87%\n",
      "Train Epoch [66/100] Batch [71/782] Loss: 0.5354 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [72/782] Loss: 0.4871 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [73/782] Loss: 0.4466 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [74/782] Loss: 0.6568 | Acc: 79.86%\n",
      "Train Epoch [66/100] Batch [75/782] Loss: 0.4403 | Acc: 79.88%\n",
      "Train Epoch [66/100] Batch [76/782] Loss: 0.5871 | Acc: 79.87%\n",
      "Train Epoch [66/100] Batch [77/782] Loss: 0.8303 | Acc: 79.79%\n",
      "Train Epoch [66/100] Batch [78/782] Loss: 0.5334 | Acc: 79.75%\n",
      "Train Epoch [66/100] Batch [79/782] Loss: 0.5065 | Acc: 79.77%\n",
      "Train Epoch [66/100] Batch [80/782] Loss: 0.6189 | Acc: 79.77%\n",
      "Train Epoch [66/100] Batch [81/782] Loss: 0.4783 | Acc: 79.80%\n",
      "Train Epoch [66/100] Batch [82/782] Loss: 0.4151 | Acc: 79.86%\n",
      "Train Epoch [66/100] Batch [83/782] Loss: 0.5743 | Acc: 79.89%\n",
      "Train Epoch [66/100] Batch [84/782] Loss: 0.4634 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [85/782] Loss: 0.5271 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [86/782] Loss: 0.6506 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [87/782] Loss: 0.6552 | Acc: 79.90%\n",
      "Train Epoch [66/100] Batch [88/782] Loss: 0.4637 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [89/782] Loss: 0.3535 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [90/782] Loss: 0.5044 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [91/782] Loss: 0.4659 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [92/782] Loss: 0.5981 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [93/782] Loss: 0.4745 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [94/782] Loss: 0.4406 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [95/782] Loss: 0.3938 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [96/782] Loss: 0.5478 | Acc: 80.26%\n",
      "Train Epoch [66/100] Batch [97/782] Loss: 0.5423 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [98/782] Loss: 0.5493 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [99/782] Loss: 0.5179 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [100/782] Loss: 0.7687 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [101/782] Loss: 0.5197 | Acc: 80.29%\n",
      "Train Epoch [66/100] Batch [102/782] Loss: 0.4283 | Acc: 80.32%\n",
      "Train Epoch [66/100] Batch [103/782] Loss: 0.4601 | Acc: 80.37%\n",
      "Train Epoch [66/100] Batch [104/782] Loss: 0.6664 | Acc: 80.33%\n",
      "Train Epoch [66/100] Batch [105/782] Loss: 0.6516 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [106/782] Loss: 0.4970 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [107/782] Loss: 0.4023 | Acc: 80.37%\n",
      "Train Epoch [66/100] Batch [108/782] Loss: 0.5204 | Acc: 80.35%\n",
      "Train Epoch [66/100] Batch [109/782] Loss: 0.4872 | Acc: 80.38%\n",
      "Train Epoch [66/100] Batch [110/782] Loss: 0.5567 | Acc: 80.36%\n",
      "Train Epoch [66/100] Batch [111/782] Loss: 0.5910 | Acc: 80.29%\n",
      "Train Epoch [66/100] Batch [112/782] Loss: 0.5538 | Acc: 80.34%\n",
      "Train Epoch [66/100] Batch [113/782] Loss: 0.5855 | Acc: 80.34%\n",
      "Train Epoch [66/100] Batch [114/782] Loss: 0.6166 | Acc: 80.29%\n",
      "Train Epoch [66/100] Batch [115/782] Loss: 0.6012 | Acc: 80.29%\n",
      "Train Epoch [66/100] Batch [116/782] Loss: 0.5840 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [117/782] Loss: 0.5547 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [118/782] Loss: 0.6494 | Acc: 80.30%\n",
      "Train Epoch [66/100] Batch [119/782] Loss: 0.7226 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [120/782] Loss: 0.6573 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [121/782] Loss: 0.6647 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [122/782] Loss: 0.8508 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [123/782] Loss: 0.5881 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [124/782] Loss: 0.5600 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [125/782] Loss: 0.5945 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [126/782] Loss: 0.5096 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [127/782] Loss: 0.3619 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [128/782] Loss: 0.6452 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [129/782] Loss: 0.6621 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [130/782] Loss: 0.6971 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [131/782] Loss: 0.6239 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [132/782] Loss: 0.3325 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [133/782] Loss: 0.3341 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [134/782] Loss: 0.6010 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [135/782] Loss: 0.3254 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [136/782] Loss: 0.7917 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [137/782] Loss: 0.6238 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [138/782] Loss: 0.6447 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [139/782] Loss: 0.4897 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [140/782] Loss: 0.6624 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [141/782] Loss: 0.5335 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [142/782] Loss: 0.8263 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [143/782] Loss: 0.5173 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [144/782] Loss: 0.6629 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [145/782] Loss: 0.5512 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [146/782] Loss: 0.5695 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [147/782] Loss: 0.6858 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [148/782] Loss: 0.5039 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [149/782] Loss: 0.4240 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [150/782] Loss: 0.3839 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [151/782] Loss: 0.4832 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [152/782] Loss: 0.5428 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [153/782] Loss: 0.4580 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [154/782] Loss: 0.6756 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [155/782] Loss: 0.7335 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [156/782] Loss: 0.4463 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [157/782] Loss: 0.6533 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [158/782] Loss: 0.4766 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [159/782] Loss: 0.4390 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [160/782] Loss: 0.5499 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [161/782] Loss: 0.6292 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [162/782] Loss: 0.4910 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [163/782] Loss: 0.5462 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [164/782] Loss: 0.6265 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [165/782] Loss: 0.5191 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [166/782] Loss: 0.6675 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [167/782] Loss: 0.4560 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [168/782] Loss: 0.5653 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [169/782] Loss: 0.5597 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [170/782] Loss: 0.8334 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [171/782] Loss: 0.6402 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [172/782] Loss: 0.6927 | Acc: 79.91%\n",
      "Train Epoch [66/100] Batch [173/782] Loss: 0.4016 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [174/782] Loss: 0.7045 | Acc: 79.91%\n",
      "Train Epoch [66/100] Batch [175/782] Loss: 0.4341 | Acc: 79.92%\n",
      "Train Epoch [66/100] Batch [176/782] Loss: 0.5590 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [177/782] Loss: 0.5700 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [178/782] Loss: 0.4343 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [179/782] Loss: 0.3895 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [180/782] Loss: 0.5224 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [181/782] Loss: 0.5313 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [182/782] Loss: 0.4314 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [183/782] Loss: 0.5353 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [184/782] Loss: 0.5431 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [185/782] Loss: 0.4960 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [186/782] Loss: 0.6196 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [187/782] Loss: 0.6116 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [188/782] Loss: 0.4780 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [189/782] Loss: 0.5074 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [190/782] Loss: 0.6006 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [191/782] Loss: 0.5313 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [192/782] Loss: 0.3528 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [193/782] Loss: 0.6959 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [194/782] Loss: 0.5926 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [195/782] Loss: 0.4584 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [196/782] Loss: 0.4528 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [197/782] Loss: 0.5522 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [198/782] Loss: 0.7074 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [199/782] Loss: 0.4580 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [200/782] Loss: 0.6725 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [201/782] Loss: 0.5839 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [202/782] Loss: 0.7372 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [203/782] Loss: 0.6732 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [204/782] Loss: 0.4556 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [205/782] Loss: 0.3497 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [206/782] Loss: 0.3673 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [207/782] Loss: 0.6285 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [208/782] Loss: 0.4510 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [209/782] Loss: 0.5681 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [210/782] Loss: 0.6017 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [211/782] Loss: 0.4578 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [212/782] Loss: 0.5114 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [213/782] Loss: 0.5583 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [214/782] Loss: 0.5615 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [215/782] Loss: 0.6016 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [216/782] Loss: 0.7192 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [217/782] Loss: 0.5445 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [218/782] Loss: 0.6309 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [219/782] Loss: 0.7749 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [220/782] Loss: 0.4601 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [221/782] Loss: 0.5565 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [222/782] Loss: 0.5613 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [223/782] Loss: 0.6743 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [224/782] Loss: 0.5611 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [225/782] Loss: 0.5006 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [226/782] Loss: 0.6999 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [227/782] Loss: 0.5107 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [228/782] Loss: 0.5887 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [229/782] Loss: 0.5850 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [230/782] Loss: 0.3600 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [231/782] Loss: 0.7320 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [232/782] Loss: 0.4294 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [233/782] Loss: 0.4769 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [234/782] Loss: 0.5118 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [235/782] Loss: 0.5793 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [236/782] Loss: 0.5156 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [237/782] Loss: 0.6521 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [238/782] Loss: 0.5268 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [239/782] Loss: 0.5232 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [240/782] Loss: 0.4689 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [241/782] Loss: 0.6921 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [242/782] Loss: 0.5842 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [243/782] Loss: 0.6308 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [244/782] Loss: 0.5086 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [245/782] Loss: 0.3229 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [246/782] Loss: 0.5130 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [247/782] Loss: 0.6509 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [248/782] Loss: 0.4420 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [249/782] Loss: 0.5469 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [250/782] Loss: 0.3590 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [251/782] Loss: 0.6244 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [252/782] Loss: 0.6320 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [253/782] Loss: 0.6498 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [254/782] Loss: 0.7156 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [255/782] Loss: 0.6733 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [256/782] Loss: 0.6140 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [257/782] Loss: 0.4286 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [258/782] Loss: 0.4128 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [259/782] Loss: 0.6072 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [260/782] Loss: 0.5264 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [261/782] Loss: 0.5207 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [262/782] Loss: 0.5933 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [263/782] Loss: 0.3583 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [264/782] Loss: 0.4729 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [265/782] Loss: 0.5096 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [266/782] Loss: 0.5674 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [267/782] Loss: 0.6476 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [268/782] Loss: 0.6225 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [269/782] Loss: 0.6240 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [270/782] Loss: 0.4373 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [271/782] Loss: 0.5032 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [272/782] Loss: 0.5427 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [273/782] Loss: 0.4391 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [274/782] Loss: 0.6359 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [275/782] Loss: 0.5489 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [276/782] Loss: 0.6087 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [277/782] Loss: 0.5442 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [278/782] Loss: 0.4528 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [279/782] Loss: 0.6164 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [280/782] Loss: 0.5609 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [281/782] Loss: 0.6103 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [282/782] Loss: 0.9095 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [283/782] Loss: 0.4473 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [284/782] Loss: 0.4720 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [285/782] Loss: 0.4848 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [286/782] Loss: 0.6981 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [287/782] Loss: 0.4335 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [288/782] Loss: 0.5732 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [289/782] Loss: 0.4241 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [290/782] Loss: 0.5933 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [291/782] Loss: 0.6244 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [292/782] Loss: 0.6098 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [293/782] Loss: 0.4356 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [294/782] Loss: 0.5285 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [295/782] Loss: 0.6224 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [296/782] Loss: 0.6003 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [297/782] Loss: 0.5881 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [298/782] Loss: 0.7150 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [299/782] Loss: 0.5649 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [300/782] Loss: 0.5775 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [301/782] Loss: 0.4666 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [302/782] Loss: 0.4606 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [303/782] Loss: 0.7250 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [304/782] Loss: 0.5184 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [305/782] Loss: 0.6588 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [306/782] Loss: 0.5732 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [307/782] Loss: 0.3975 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [308/782] Loss: 0.5801 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [309/782] Loss: 0.5107 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [310/782] Loss: 0.4948 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [311/782] Loss: 0.5963 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [312/782] Loss: 0.5383 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [313/782] Loss: 0.5940 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [314/782] Loss: 0.5711 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [315/782] Loss: 0.6943 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [316/782] Loss: 0.4529 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [317/782] Loss: 0.3802 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [318/782] Loss: 0.4479 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [319/782] Loss: 0.6813 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [320/782] Loss: 0.6968 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [321/782] Loss: 0.4582 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [322/782] Loss: 0.4998 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [323/782] Loss: 0.3436 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [324/782] Loss: 0.4953 | Acc: 80.21%\n",
      "Train Epoch [66/100] Batch [325/782] Loss: 0.5275 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [326/782] Loss: 0.3573 | Acc: 80.25%\n",
      "Train Epoch [66/100] Batch [327/782] Loss: 0.4396 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [328/782] Loss: 0.4617 | Acc: 80.28%\n",
      "Train Epoch [66/100] Batch [329/782] Loss: 0.6301 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [330/782] Loss: 0.6688 | Acc: 80.26%\n",
      "Train Epoch [66/100] Batch [331/782] Loss: 0.5572 | Acc: 80.25%\n",
      "Train Epoch [66/100] Batch [332/782] Loss: 0.4411 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [333/782] Loss: 0.4317 | Acc: 80.29%\n",
      "Train Epoch [66/100] Batch [334/782] Loss: 0.7587 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [335/782] Loss: 0.6312 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [336/782] Loss: 0.5005 | Acc: 80.27%\n",
      "Train Epoch [66/100] Batch [337/782] Loss: 0.5643 | Acc: 80.26%\n",
      "Train Epoch [66/100] Batch [338/782] Loss: 0.5507 | Acc: 80.26%\n",
      "Train Epoch [66/100] Batch [339/782] Loss: 0.8116 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [340/782] Loss: 0.5415 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [341/782] Loss: 0.5290 | Acc: 80.24%\n",
      "Train Epoch [66/100] Batch [342/782] Loss: 0.6209 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [343/782] Loss: 0.4878 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [344/782] Loss: 0.3851 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [345/782] Loss: 0.5222 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [346/782] Loss: 0.6294 | Acc: 80.23%\n",
      "Train Epoch [66/100] Batch [347/782] Loss: 0.7383 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [348/782] Loss: 0.7367 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [349/782] Loss: 0.5276 | Acc: 80.22%\n",
      "Train Epoch [66/100] Batch [350/782] Loss: 0.7528 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [351/782] Loss: 0.7186 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [352/782] Loss: 0.5756 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [353/782] Loss: 0.6785 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [354/782] Loss: 0.3986 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [355/782] Loss: 0.4847 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [356/782] Loss: 0.7067 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [357/782] Loss: 0.4970 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [358/782] Loss: 0.4744 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [359/782] Loss: 0.5834 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [360/782] Loss: 0.5115 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [361/782] Loss: 0.4093 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [362/782] Loss: 0.5640 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [363/782] Loss: 0.6497 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [364/782] Loss: 0.6825 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [365/782] Loss: 0.4941 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [366/782] Loss: 0.5660 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [367/782] Loss: 0.4482 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [368/782] Loss: 0.6608 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [369/782] Loss: 0.3872 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [370/782] Loss: 0.6853 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [371/782] Loss: 0.6468 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [372/782] Loss: 0.4723 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [373/782] Loss: 0.4428 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [374/782] Loss: 0.5978 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [375/782] Loss: 0.5258 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [376/782] Loss: 0.5646 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [377/782] Loss: 0.4508 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [378/782] Loss: 0.5204 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [379/782] Loss: 0.4357 | Acc: 80.19%\n",
      "Train Epoch [66/100] Batch [380/782] Loss: 0.5721 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [381/782] Loss: 0.5507 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [382/782] Loss: 0.6212 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [383/782] Loss: 0.6215 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [384/782] Loss: 0.4335 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [385/782] Loss: 0.3630 | Acc: 80.20%\n",
      "Train Epoch [66/100] Batch [386/782] Loss: 0.6544 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [387/782] Loss: 0.8389 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [388/782] Loss: 0.5710 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [389/782] Loss: 0.6117 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [390/782] Loss: 0.5104 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [391/782] Loss: 0.6013 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [392/782] Loss: 0.6389 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [393/782] Loss: 0.5465 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [394/782] Loss: 0.4416 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [395/782] Loss: 0.5017 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [396/782] Loss: 0.6301 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [397/782] Loss: 0.6450 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [398/782] Loss: 0.5113 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [399/782] Loss: 0.7204 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [400/782] Loss: 0.5221 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [401/782] Loss: 0.6142 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [402/782] Loss: 0.5181 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [403/782] Loss: 0.3424 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [404/782] Loss: 0.6731 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [405/782] Loss: 0.6058 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [406/782] Loss: 0.5040 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [407/782] Loss: 0.5462 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [408/782] Loss: 0.5281 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [409/782] Loss: 0.5628 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [410/782] Loss: 0.5734 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [411/782] Loss: 0.6141 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [412/782] Loss: 0.5765 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [413/782] Loss: 0.6247 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [414/782] Loss: 0.4612 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [415/782] Loss: 0.8167 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [416/782] Loss: 0.6873 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [417/782] Loss: 0.5728 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [418/782] Loss: 0.5885 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [419/782] Loss: 0.6243 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [420/782] Loss: 0.5055 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [421/782] Loss: 0.6309 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [422/782] Loss: 0.4522 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [423/782] Loss: 0.5695 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [424/782] Loss: 0.4307 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [425/782] Loss: 0.6598 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [426/782] Loss: 0.4842 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [427/782] Loss: 0.4332 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [428/782] Loss: 0.7136 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [429/782] Loss: 0.5492 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [430/782] Loss: 0.4695 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [431/782] Loss: 0.7391 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [432/782] Loss: 0.4901 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [433/782] Loss: 0.5361 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [434/782] Loss: 0.5275 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [435/782] Loss: 0.5480 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [436/782] Loss: 0.4817 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [437/782] Loss: 0.5662 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [438/782] Loss: 0.5529 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [439/782] Loss: 0.6485 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [440/782] Loss: 0.6799 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [441/782] Loss: 0.5649 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [442/782] Loss: 0.6799 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [443/782] Loss: 0.4866 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [444/782] Loss: 0.6286 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [445/782] Loss: 0.4854 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [446/782] Loss: 0.8302 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [447/782] Loss: 0.5395 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [448/782] Loss: 0.4027 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [449/782] Loss: 0.5672 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [450/782] Loss: 0.3553 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [451/782] Loss: 0.4772 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [452/782] Loss: 0.5236 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [453/782] Loss: 0.5467 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [454/782] Loss: 0.4930 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [455/782] Loss: 0.5999 | Acc: 80.11%\n",
      "Train Epoch [66/100] Batch [456/782] Loss: 0.2327 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [457/782] Loss: 0.5891 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [458/782] Loss: 0.4250 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [459/782] Loss: 0.6500 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [460/782] Loss: 0.4386 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [461/782] Loss: 0.6307 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [462/782] Loss: 0.5739 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [463/782] Loss: 0.6613 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [464/782] Loss: 0.5247 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [465/782] Loss: 0.5850 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [466/782] Loss: 0.5013 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [467/782] Loss: 0.6616 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [468/782] Loss: 0.6418 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [469/782] Loss: 0.3522 | Acc: 80.15%\n",
      "Train Epoch [66/100] Batch [470/782] Loss: 0.5843 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [471/782] Loss: 0.3800 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [472/782] Loss: 0.6252 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [473/782] Loss: 0.4792 | Acc: 80.17%\n",
      "Train Epoch [66/100] Batch [474/782] Loss: 0.3829 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [475/782] Loss: 0.5186 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [476/782] Loss: 0.5483 | Acc: 80.18%\n",
      "Train Epoch [66/100] Batch [477/782] Loss: 0.7637 | Acc: 80.16%\n",
      "Train Epoch [66/100] Batch [478/782] Loss: 0.9600 | Acc: 80.14%\n",
      "Train Epoch [66/100] Batch [479/782] Loss: 0.7850 | Acc: 80.13%\n",
      "Train Epoch [66/100] Batch [480/782] Loss: 0.6225 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [481/782] Loss: 0.4993 | Acc: 80.12%\n",
      "Train Epoch [66/100] Batch [482/782] Loss: 0.7699 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [483/782] Loss: 0.5153 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [484/782] Loss: 0.6192 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [485/782] Loss: 0.6411 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [486/782] Loss: 0.7467 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [487/782] Loss: 0.4039 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [488/782] Loss: 0.4332 | Acc: 80.10%\n",
      "Train Epoch [66/100] Batch [489/782] Loss: 0.6691 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [490/782] Loss: 0.6295 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [491/782] Loss: 0.7105 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [492/782] Loss: 0.5646 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [493/782] Loss: 0.6042 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [494/782] Loss: 0.5795 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [495/782] Loss: 0.5739 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [496/782] Loss: 0.6257 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [497/782] Loss: 0.5220 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [498/782] Loss: 0.5540 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [499/782] Loss: 0.5524 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [500/782] Loss: 0.5375 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [501/782] Loss: 0.6113 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [502/782] Loss: 0.5490 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [503/782] Loss: 0.7235 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [504/782] Loss: 0.5064 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [505/782] Loss: 0.6786 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [506/782] Loss: 0.7604 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [507/782] Loss: 0.4454 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [508/782] Loss: 0.8556 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [509/782] Loss: 0.4320 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [510/782] Loss: 0.5098 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [511/782] Loss: 0.5116 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [512/782] Loss: 0.4432 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [513/782] Loss: 0.3555 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [514/782] Loss: 0.2699 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [515/782] Loss: 0.5789 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [516/782] Loss: 0.7747 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [517/782] Loss: 0.3971 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [518/782] Loss: 0.5943 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [519/782] Loss: 0.6431 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [520/782] Loss: 0.6007 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [521/782] Loss: 0.4765 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [522/782] Loss: 0.6743 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [523/782] Loss: 0.5701 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [524/782] Loss: 0.4669 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [525/782] Loss: 0.6695 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [526/782] Loss: 0.4097 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [527/782] Loss: 0.5877 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [528/782] Loss: 0.5484 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [529/782] Loss: 0.4922 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [530/782] Loss: 0.5420 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [531/782] Loss: 0.4002 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [532/782] Loss: 0.5568 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [533/782] Loss: 0.3344 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [534/782] Loss: 0.3671 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [535/782] Loss: 0.5807 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [536/782] Loss: 0.6370 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [537/782] Loss: 0.3168 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [538/782] Loss: 0.5220 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [539/782] Loss: 0.5503 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [540/782] Loss: 0.5504 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [541/782] Loss: 0.7223 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [542/782] Loss: 0.6562 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [543/782] Loss: 0.5833 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [544/782] Loss: 0.5063 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [545/782] Loss: 0.4639 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [546/782] Loss: 0.4659 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [547/782] Loss: 0.5174 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [548/782] Loss: 0.6727 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [549/782] Loss: 0.4292 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [550/782] Loss: 0.4913 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [551/782] Loss: 0.7288 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [552/782] Loss: 0.5439 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [553/782] Loss: 0.5708 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [554/782] Loss: 0.8409 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [555/782] Loss: 0.4287 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [556/782] Loss: 0.4575 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [557/782] Loss: 0.4523 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [558/782] Loss: 0.6196 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [559/782] Loss: 0.4116 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [560/782] Loss: 0.6895 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [561/782] Loss: 0.6891 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [562/782] Loss: 0.6348 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [563/782] Loss: 0.5625 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [564/782] Loss: 0.4927 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [565/782] Loss: 0.6219 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [566/782] Loss: 0.5661 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [567/782] Loss: 0.5800 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [568/782] Loss: 0.7015 | Acc: 80.07%\n",
      "Train Epoch [66/100] Batch [569/782] Loss: 0.5080 | Acc: 80.08%\n",
      "Train Epoch [66/100] Batch [570/782] Loss: 0.4843 | Acc: 80.09%\n",
      "Train Epoch [66/100] Batch [571/782] Loss: 0.9303 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [572/782] Loss: 0.5174 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [573/782] Loss: 0.7174 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [574/782] Loss: 0.5230 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [575/782] Loss: 0.6466 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [576/782] Loss: 0.6404 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [577/782] Loss: 0.5166 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [578/782] Loss: 0.5110 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [579/782] Loss: 0.4853 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [580/782] Loss: 0.5861 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [581/782] Loss: 0.4088 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [582/782] Loss: 0.6992 | Acc: 80.06%\n",
      "Train Epoch [66/100] Batch [583/782] Loss: 0.5326 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [584/782] Loss: 0.5956 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [585/782] Loss: 0.5730 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [586/782] Loss: 0.4790 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [587/782] Loss: 0.5236 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [588/782] Loss: 0.6848 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [589/782] Loss: 0.5504 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [590/782] Loss: 0.5746 | Acc: 80.05%\n",
      "Train Epoch [66/100] Batch [591/782] Loss: 0.5808 | Acc: 80.04%\n",
      "Train Epoch [66/100] Batch [592/782] Loss: 0.6173 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [593/782] Loss: 0.5830 | Acc: 80.03%\n",
      "Train Epoch [66/100] Batch [594/782] Loss: 0.7539 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [595/782] Loss: 0.6138 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [596/782] Loss: 0.4803 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [597/782] Loss: 0.7529 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [598/782] Loss: 0.7642 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [599/782] Loss: 0.6654 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [600/782] Loss: 0.8423 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [601/782] Loss: 0.6555 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [602/782] Loss: 0.6904 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [603/782] Loss: 0.4148 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [604/782] Loss: 0.6265 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [605/782] Loss: 0.5935 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [606/782] Loss: 0.6064 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [607/782] Loss: 0.6217 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [608/782] Loss: 0.4863 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [609/782] Loss: 0.5967 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [610/782] Loss: 0.5536 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [611/782] Loss: 0.4699 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [612/782] Loss: 0.5289 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [613/782] Loss: 0.5661 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [614/782] Loss: 0.4058 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [615/782] Loss: 0.7136 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [616/782] Loss: 0.5361 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [617/782] Loss: 0.5614 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [618/782] Loss: 0.7244 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [619/782] Loss: 0.4840 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [620/782] Loss: 0.5832 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [621/782] Loss: 0.3893 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [622/782] Loss: 0.8606 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [623/782] Loss: 0.5082 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [624/782] Loss: 0.6767 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [625/782] Loss: 0.4606 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [626/782] Loss: 0.6691 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [627/782] Loss: 0.9407 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [628/782] Loss: 0.4285 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [629/782] Loss: 0.5890 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [630/782] Loss: 0.3678 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [631/782] Loss: 0.4896 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [632/782] Loss: 0.6717 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [633/782] Loss: 0.4012 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [634/782] Loss: 0.4995 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [635/782] Loss: 0.5340 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [636/782] Loss: 0.5275 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [637/782] Loss: 0.4838 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [638/782] Loss: 0.5660 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [639/782] Loss: 0.5010 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [640/782] Loss: 0.6197 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [641/782] Loss: 0.4740 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [642/782] Loss: 0.5856 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [643/782] Loss: 0.5918 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [644/782] Loss: 0.6545 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [645/782] Loss: 0.5502 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [646/782] Loss: 0.5364 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [647/782] Loss: 0.5736 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [648/782] Loss: 0.5119 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [649/782] Loss: 0.4790 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [650/782] Loss: 0.3891 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [651/782] Loss: 0.5610 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [652/782] Loss: 0.5024 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [653/782] Loss: 0.6333 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [654/782] Loss: 0.6611 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [655/782] Loss: 0.6659 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [656/782] Loss: 0.5765 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [657/782] Loss: 0.4661 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [658/782] Loss: 0.5061 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [659/782] Loss: 0.3034 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [660/782] Loss: 0.7436 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [661/782] Loss: 0.5245 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [662/782] Loss: 0.7019 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [663/782] Loss: 0.3831 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [664/782] Loss: 0.5310 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [665/782] Loss: 0.6168 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [666/782] Loss: 0.6551 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [667/782] Loss: 0.6104 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [668/782] Loss: 0.4372 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [669/782] Loss: 0.5557 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [670/782] Loss: 0.4866 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [671/782] Loss: 0.6106 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [672/782] Loss: 0.6324 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [673/782] Loss: 0.4257 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [674/782] Loss: 0.9552 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [675/782] Loss: 0.5895 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [676/782] Loss: 0.4245 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [677/782] Loss: 0.7059 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [678/782] Loss: 0.5468 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [679/782] Loss: 0.5178 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [680/782] Loss: 0.4440 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [681/782] Loss: 0.4676 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [682/782] Loss: 0.3973 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [683/782] Loss: 0.5945 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [684/782] Loss: 0.5707 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [685/782] Loss: 0.8196 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [686/782] Loss: 0.4296 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [687/782] Loss: 0.4820 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [688/782] Loss: 0.8617 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [689/782] Loss: 0.7222 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [690/782] Loss: 0.6598 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [691/782] Loss: 0.6679 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [692/782] Loss: 0.5306 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [693/782] Loss: 0.3449 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [694/782] Loss: 0.4761 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [695/782] Loss: 0.6194 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [696/782] Loss: 0.5392 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [697/782] Loss: 0.6477 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [698/782] Loss: 0.6339 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [699/782] Loss: 0.7516 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [700/782] Loss: 0.5453 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [701/782] Loss: 0.5613 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [702/782] Loss: 0.6793 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [703/782] Loss: 0.5973 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [704/782] Loss: 0.4875 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [705/782] Loss: 0.4890 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [706/782] Loss: 0.4777 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [707/782] Loss: 0.5910 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [708/782] Loss: 0.6922 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [709/782] Loss: 0.4797 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [710/782] Loss: 0.5597 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [711/782] Loss: 0.5681 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [712/782] Loss: 0.5800 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [713/782] Loss: 0.6004 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [714/782] Loss: 0.4700 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [715/782] Loss: 0.7254 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [716/782] Loss: 0.4852 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [717/782] Loss: 0.7173 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [718/782] Loss: 0.6589 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [719/782] Loss: 0.4819 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [720/782] Loss: 0.5419 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [721/782] Loss: 0.5934 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [722/782] Loss: 0.4049 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [723/782] Loss: 0.5982 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [724/782] Loss: 0.5918 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [725/782] Loss: 0.8388 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [726/782] Loss: 0.6530 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [727/782] Loss: 0.5278 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [728/782] Loss: 0.5338 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [729/782] Loss: 0.6134 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [730/782] Loss: 0.5659 | Acc: 79.94%\n",
      "Train Epoch [66/100] Batch [731/782] Loss: 0.5295 | Acc: 79.93%\n",
      "Train Epoch [66/100] Batch [732/782] Loss: 0.2749 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [733/782] Loss: 0.4738 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [734/782] Loss: 0.4802 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [735/782] Loss: 0.5384 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [736/782] Loss: 0.6610 | Acc: 79.95%\n",
      "Train Epoch [66/100] Batch [737/782] Loss: 0.5121 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [738/782] Loss: 0.5194 | Acc: 79.96%\n",
      "Train Epoch [66/100] Batch [739/782] Loss: 0.4609 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [740/782] Loss: 0.4888 | Acc: 79.97%\n",
      "Train Epoch [66/100] Batch [741/782] Loss: 0.5543 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [742/782] Loss: 0.4245 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [743/782] Loss: 0.6018 | Acc: 79.98%\n",
      "Train Epoch [66/100] Batch [744/782] Loss: 0.5142 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [745/782] Loss: 0.4333 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [746/782] Loss: 0.7122 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [747/782] Loss: 0.6250 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [748/782] Loss: 0.4662 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [749/782] Loss: 0.3878 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [750/782] Loss: 0.4968 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [751/782] Loss: 0.5935 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [752/782] Loss: 0.8328 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [753/782] Loss: 0.3631 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [754/782] Loss: 0.6322 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [755/782] Loss: 0.5428 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [756/782] Loss: 0.6636 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [757/782] Loss: 0.5810 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [758/782] Loss: 0.5987 | Acc: 79.99%\n",
      "Train Epoch [66/100] Batch [759/782] Loss: 0.4170 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [760/782] Loss: 0.3639 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [761/782] Loss: 0.4318 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [762/782] Loss: 0.4815 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [763/782] Loss: 0.6552 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [764/782] Loss: 0.7288 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [765/782] Loss: 0.7235 | Acc: 80.00%\n",
      "Train Epoch [66/100] Batch [766/782] Loss: 0.4805 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [767/782] Loss: 0.6854 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [768/782] Loss: 0.4736 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [769/782] Loss: 0.4925 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [770/782] Loss: 0.6687 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [771/782] Loss: 0.4781 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [772/782] Loss: 0.7237 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [773/782] Loss: 0.5457 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [774/782] Loss: 0.5291 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [775/782] Loss: 0.5908 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [776/782] Loss: 0.6185 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [777/782] Loss: 0.4651 | Acc: 80.02%\n",
      "Train Epoch [66/100] Batch [778/782] Loss: 0.5723 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [779/782] Loss: 0.7065 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [780/782] Loss: 0.5238 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [781/782] Loss: 0.4834 | Acc: 80.01%\n",
      "Train Epoch [66/100] Batch [782/782] Loss: 0.4466 | Acc: 80.02%\n",
      "Epoch 66 completed in 30.00s.\n",
      "Test Epoch [66/100] Loss: 0.8874 | Acc: 72.70% | Inference Time: 8.35s\n",
      "Epoch 66 results saved to CSV.\n",
      "Epoch 67/100\n",
      "Train Epoch [67/100] Batch [1/782] Loss: 0.5646 | Acc: 79.69%\n",
      "Train Epoch [67/100] Batch [2/782] Loss: 0.7267 | Acc: 77.34%\n",
      "Train Epoch [67/100] Batch [3/782] Loss: 0.4463 | Acc: 79.17%\n",
      "Train Epoch [67/100] Batch [4/782] Loss: 0.7336 | Acc: 78.12%\n",
      "Train Epoch [67/100] Batch [5/782] Loss: 0.4779 | Acc: 79.69%\n",
      "Train Epoch [67/100] Batch [6/782] Loss: 0.3915 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [7/782] Loss: 0.7048 | Acc: 79.91%\n",
      "Train Epoch [67/100] Batch [8/782] Loss: 0.6332 | Acc: 79.10%\n",
      "Train Epoch [67/100] Batch [9/782] Loss: 0.2458 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [10/782] Loss: 0.4830 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [11/782] Loss: 0.4805 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [12/782] Loss: 0.3668 | Acc: 81.51%\n",
      "Train Epoch [67/100] Batch [13/782] Loss: 0.4513 | Acc: 81.37%\n",
      "Train Epoch [67/100] Batch [14/782] Loss: 0.5560 | Acc: 81.25%\n",
      "Train Epoch [67/100] Batch [15/782] Loss: 0.4281 | Acc: 81.67%\n",
      "Train Epoch [67/100] Batch [16/782] Loss: 0.4718 | Acc: 81.64%\n",
      "Train Epoch [67/100] Batch [17/782] Loss: 0.5834 | Acc: 81.53%\n",
      "Train Epoch [67/100] Batch [18/782] Loss: 0.4380 | Acc: 81.60%\n",
      "Train Epoch [67/100] Batch [19/782] Loss: 0.5727 | Acc: 81.66%\n",
      "Train Epoch [67/100] Batch [20/782] Loss: 0.4826 | Acc: 81.64%\n",
      "Train Epoch [67/100] Batch [21/782] Loss: 0.4323 | Acc: 81.92%\n",
      "Train Epoch [67/100] Batch [22/782] Loss: 0.5433 | Acc: 81.96%\n",
      "Train Epoch [67/100] Batch [23/782] Loss: 0.3486 | Acc: 82.20%\n",
      "Train Epoch [67/100] Batch [24/782] Loss: 0.4085 | Acc: 82.49%\n",
      "Train Epoch [67/100] Batch [25/782] Loss: 0.6917 | Acc: 82.38%\n",
      "Train Epoch [67/100] Batch [26/782] Loss: 0.4785 | Acc: 82.33%\n",
      "Train Epoch [67/100] Batch [27/782] Loss: 0.4950 | Acc: 82.29%\n",
      "Train Epoch [67/100] Batch [28/782] Loss: 0.4096 | Acc: 82.37%\n",
      "Train Epoch [67/100] Batch [29/782] Loss: 0.5146 | Acc: 82.44%\n",
      "Train Epoch [67/100] Batch [30/782] Loss: 0.7796 | Acc: 81.93%\n",
      "Train Epoch [67/100] Batch [31/782] Loss: 0.6383 | Acc: 81.60%\n",
      "Train Epoch [67/100] Batch [32/782] Loss: 0.4016 | Acc: 81.69%\n",
      "Train Epoch [67/100] Batch [33/782] Loss: 0.4708 | Acc: 81.72%\n",
      "Train Epoch [67/100] Batch [34/782] Loss: 0.6310 | Acc: 81.57%\n",
      "Train Epoch [67/100] Batch [35/782] Loss: 0.3637 | Acc: 81.74%\n",
      "Train Epoch [67/100] Batch [36/782] Loss: 0.3097 | Acc: 81.90%\n",
      "Train Epoch [67/100] Batch [37/782] Loss: 0.6046 | Acc: 81.71%\n",
      "Train Epoch [67/100] Batch [38/782] Loss: 0.7828 | Acc: 81.54%\n",
      "Train Epoch [67/100] Batch [39/782] Loss: 0.4222 | Acc: 81.61%\n",
      "Train Epoch [67/100] Batch [40/782] Loss: 0.6549 | Acc: 81.56%\n",
      "Train Epoch [67/100] Batch [41/782] Loss: 0.7165 | Acc: 81.33%\n",
      "Train Epoch [67/100] Batch [42/782] Loss: 0.7078 | Acc: 81.29%\n",
      "Train Epoch [67/100] Batch [43/782] Loss: 0.5962 | Acc: 81.29%\n",
      "Train Epoch [67/100] Batch [44/782] Loss: 0.8491 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [45/782] Loss: 0.4406 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [46/782] Loss: 0.5534 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [47/782] Loss: 0.6413 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [48/782] Loss: 0.4888 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [49/782] Loss: 0.7013 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [50/782] Loss: 0.4585 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [51/782] Loss: 0.6565 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [52/782] Loss: 0.5220 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [53/782] Loss: 0.5245 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [54/782] Loss: 0.5388 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [55/782] Loss: 0.4476 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [56/782] Loss: 0.5229 | Acc: 80.89%\n",
      "Train Epoch [67/100] Batch [57/782] Loss: 0.6423 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [58/782] Loss: 0.6358 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [59/782] Loss: 0.4751 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [60/782] Loss: 0.7400 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [61/782] Loss: 0.5466 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [62/782] Loss: 0.5195 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [63/782] Loss: 0.4970 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [64/782] Loss: 0.3695 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [65/782] Loss: 0.3738 | Acc: 80.89%\n",
      "Train Epoch [67/100] Batch [66/782] Loss: 0.4393 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [67/782] Loss: 0.6071 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [68/782] Loss: 0.6431 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [69/782] Loss: 0.4739 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [70/782] Loss: 0.5295 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [71/782] Loss: 0.5700 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [72/782] Loss: 0.6496 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [73/782] Loss: 0.6764 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [74/782] Loss: 0.5014 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [75/782] Loss: 0.5709 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [76/782] Loss: 0.6252 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [77/782] Loss: 0.6866 | Acc: 80.44%\n",
      "Train Epoch [67/100] Batch [78/782] Loss: 0.5478 | Acc: 80.41%\n",
      "Train Epoch [67/100] Batch [79/782] Loss: 0.5661 | Acc: 80.34%\n",
      "Train Epoch [67/100] Batch [80/782] Loss: 0.3042 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [81/782] Loss: 0.4625 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [82/782] Loss: 0.5736 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [83/782] Loss: 0.4444 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [84/782] Loss: 0.4883 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [85/782] Loss: 0.4878 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [86/782] Loss: 0.5623 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [87/782] Loss: 0.5510 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [88/782] Loss: 0.5349 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [89/782] Loss: 0.5144 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [90/782] Loss: 0.5101 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [91/782] Loss: 0.4208 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [92/782] Loss: 0.5032 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [93/782] Loss: 0.5722 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [94/782] Loss: 0.3679 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [95/782] Loss: 0.7209 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [96/782] Loss: 0.5545 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [97/782] Loss: 0.4204 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [98/782] Loss: 0.5208 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [99/782] Loss: 0.6060 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [100/782] Loss: 0.7180 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [101/782] Loss: 0.5486 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [102/782] Loss: 0.4061 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [103/782] Loss: 0.5120 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [104/782] Loss: 0.9779 | Acc: 80.45%\n",
      "Train Epoch [67/100] Batch [105/782] Loss: 0.4886 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [106/782] Loss: 0.5184 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [107/782] Loss: 0.5377 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [108/782] Loss: 0.5634 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [109/782] Loss: 0.5138 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [110/782] Loss: 0.3472 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [111/782] Loss: 0.4368 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [112/782] Loss: 0.6064 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [113/782] Loss: 0.4578 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [114/782] Loss: 0.4970 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [115/782] Loss: 0.6304 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [116/782] Loss: 0.3721 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [117/782] Loss: 0.6107 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [118/782] Loss: 0.3991 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [119/782] Loss: 0.4746 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [120/782] Loss: 0.2561 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [121/782] Loss: 0.4923 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [122/782] Loss: 0.6583 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [123/782] Loss: 0.7977 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [124/782] Loss: 0.3802 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [125/782] Loss: 0.5727 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [126/782] Loss: 0.4496 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [127/782] Loss: 0.7826 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [128/782] Loss: 0.3388 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [129/782] Loss: 0.5123 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [130/782] Loss: 0.4259 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [131/782] Loss: 0.5041 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [132/782] Loss: 0.4600 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [133/782] Loss: 0.4163 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [134/782] Loss: 0.5513 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [135/782] Loss: 0.4593 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [136/782] Loss: 0.5407 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [137/782] Loss: 0.5536 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [138/782] Loss: 0.6227 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [139/782] Loss: 0.4096 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [140/782] Loss: 0.7260 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [141/782] Loss: 0.5181 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [142/782] Loss: 0.7937 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [143/782] Loss: 0.4749 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [144/782] Loss: 0.4246 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [145/782] Loss: 0.5057 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [146/782] Loss: 0.5800 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [147/782] Loss: 0.6444 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [148/782] Loss: 0.5889 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [149/782] Loss: 0.4333 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [150/782] Loss: 0.6180 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [151/782] Loss: 0.3511 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [152/782] Loss: 0.4533 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [153/782] Loss: 0.6805 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [154/782] Loss: 0.5297 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [155/782] Loss: 0.4318 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [156/782] Loss: 0.5717 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [157/782] Loss: 0.3833 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [158/782] Loss: 0.5899 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [159/782] Loss: 0.3560 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [160/782] Loss: 0.6262 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [161/782] Loss: 0.4156 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [162/782] Loss: 0.4259 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [163/782] Loss: 0.5477 | Acc: 80.90%\n",
      "Train Epoch [67/100] Batch [164/782] Loss: 0.6499 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [165/782] Loss: 0.6109 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [166/782] Loss: 0.6247 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [167/782] Loss: 0.3544 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [168/782] Loss: 0.5126 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [169/782] Loss: 0.4070 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [170/782] Loss: 0.6221 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [171/782] Loss: 0.4770 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [172/782] Loss: 0.3312 | Acc: 80.93%\n",
      "Train Epoch [67/100] Batch [173/782] Loss: 0.3997 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [174/782] Loss: 0.5069 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [175/782] Loss: 0.6137 | Acc: 80.96%\n",
      "Train Epoch [67/100] Batch [176/782] Loss: 0.5496 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [177/782] Loss: 0.5634 | Acc: 80.92%\n",
      "Train Epoch [67/100] Batch [178/782] Loss: 0.5778 | Acc: 80.90%\n",
      "Train Epoch [67/100] Batch [179/782] Loss: 0.3640 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [180/782] Loss: 0.6617 | Acc: 80.91%\n",
      "Train Epoch [67/100] Batch [181/782] Loss: 0.7899 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [182/782] Loss: 0.5657 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [183/782] Loss: 0.4918 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [184/782] Loss: 0.6143 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [185/782] Loss: 0.5473 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [186/782] Loss: 0.5681 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [187/782] Loss: 0.5125 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [188/782] Loss: 0.5316 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [189/782] Loss: 0.3880 | Acc: 80.89%\n",
      "Train Epoch [67/100] Batch [190/782] Loss: 0.4045 | Acc: 80.93%\n",
      "Train Epoch [67/100] Batch [191/782] Loss: 0.4624 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [192/782] Loss: 0.6024 | Acc: 80.92%\n",
      "Train Epoch [67/100] Batch [193/782] Loss: 0.5088 | Acc: 80.93%\n",
      "Train Epoch [67/100] Batch [194/782] Loss: 0.5286 | Acc: 80.92%\n",
      "Train Epoch [67/100] Batch [195/782] Loss: 0.5924 | Acc: 80.89%\n",
      "Train Epoch [67/100] Batch [196/782] Loss: 0.4705 | Acc: 80.92%\n",
      "Train Epoch [67/100] Batch [197/782] Loss: 0.4629 | Acc: 80.92%\n",
      "Train Epoch [67/100] Batch [198/782] Loss: 0.5323 | Acc: 80.93%\n",
      "Train Epoch [67/100] Batch [199/782] Loss: 0.5074 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [200/782] Loss: 0.4909 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [201/782] Loss: 0.5786 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [202/782] Loss: 0.7638 | Acc: 80.93%\n",
      "Train Epoch [67/100] Batch [203/782] Loss: 0.4428 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [204/782] Loss: 0.4751 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [205/782] Loss: 0.5654 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [206/782] Loss: 0.4108 | Acc: 81.03%\n",
      "Train Epoch [67/100] Batch [207/782] Loss: 0.5259 | Acc: 81.03%\n",
      "Train Epoch [67/100] Batch [208/782] Loss: 0.5167 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [209/782] Loss: 0.4496 | Acc: 81.03%\n",
      "Train Epoch [67/100] Batch [210/782] Loss: 0.8863 | Acc: 80.96%\n",
      "Train Epoch [67/100] Batch [211/782] Loss: 0.3332 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [212/782] Loss: 0.4476 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [213/782] Loss: 0.5534 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [214/782] Loss: 0.6163 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [215/782] Loss: 0.6725 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [216/782] Loss: 0.6814 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [217/782] Loss: 0.5010 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [218/782] Loss: 0.5632 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [219/782] Loss: 0.7876 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [220/782] Loss: 0.5514 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [221/782] Loss: 0.4844 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [222/782] Loss: 0.5460 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [223/782] Loss: 0.6244 | Acc: 80.91%\n",
      "Train Epoch [67/100] Batch [224/782] Loss: 0.3935 | Acc: 80.96%\n",
      "Train Epoch [67/100] Batch [225/782] Loss: 0.4067 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [226/782] Loss: 0.4370 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [227/782] Loss: 0.4561 | Acc: 81.04%\n",
      "Train Epoch [67/100] Batch [228/782] Loss: 0.6905 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [229/782] Loss: 0.5040 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [230/782] Loss: 0.8354 | Acc: 80.96%\n",
      "Train Epoch [67/100] Batch [231/782] Loss: 0.4858 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [232/782] Loss: 0.7348 | Acc: 80.96%\n",
      "Train Epoch [67/100] Batch [233/782] Loss: 0.5865 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [234/782] Loss: 0.5538 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [235/782] Loss: 0.5029 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [236/782] Loss: 0.4500 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [237/782] Loss: 0.4821 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [238/782] Loss: 0.5751 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [239/782] Loss: 0.5222 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [240/782] Loss: 0.5824 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [241/782] Loss: 0.5359 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [242/782] Loss: 0.6624 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [243/782] Loss: 0.7043 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [244/782] Loss: 0.3948 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [245/782] Loss: 0.5337 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [246/782] Loss: 0.6679 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [247/782] Loss: 0.6210 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [248/782] Loss: 0.6232 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [249/782] Loss: 0.5173 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [250/782] Loss: 0.4946 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [251/782] Loss: 0.4843 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [252/782] Loss: 0.5613 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [253/782] Loss: 0.4908 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [254/782] Loss: 0.5147 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [255/782] Loss: 0.6905 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [256/782] Loss: 0.4440 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [257/782] Loss: 0.4762 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [258/782] Loss: 0.4462 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [259/782] Loss: 0.5911 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [260/782] Loss: 0.4929 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [261/782] Loss: 0.5383 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [262/782] Loss: 0.4351 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [263/782] Loss: 0.5609 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [264/782] Loss: 0.5598 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [265/782] Loss: 0.6044 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [266/782] Loss: 0.3533 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [267/782] Loss: 0.5608 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [268/782] Loss: 0.5255 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [269/782] Loss: 0.3834 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [270/782] Loss: 0.4005 | Acc: 81.04%\n",
      "Train Epoch [67/100] Batch [271/782] Loss: 0.5703 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [272/782] Loss: 0.4737 | Acc: 81.04%\n",
      "Train Epoch [67/100] Batch [273/782] Loss: 0.5146 | Acc: 81.04%\n",
      "Train Epoch [67/100] Batch [274/782] Loss: 0.7730 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [275/782] Loss: 0.5562 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [276/782] Loss: 0.7088 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [277/782] Loss: 0.6998 | Acc: 80.95%\n",
      "Train Epoch [67/100] Batch [278/782] Loss: 0.3804 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [279/782] Loss: 0.5847 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [280/782] Loss: 0.5125 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [281/782] Loss: 0.5113 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [282/782] Loss: 0.4550 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [283/782] Loss: 0.5825 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [284/782] Loss: 0.5722 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [285/782] Loss: 0.4787 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [286/782] Loss: 0.5058 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [287/782] Loss: 0.7166 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [288/782] Loss: 0.5213 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [289/782] Loss: 0.4743 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [290/782] Loss: 0.6409 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [291/782] Loss: 0.6504 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [292/782] Loss: 0.5209 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [293/782] Loss: 0.4691 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [294/782] Loss: 0.4074 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [295/782] Loss: 0.4134 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [296/782] Loss: 0.4118 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [297/782] Loss: 0.5663 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [298/782] Loss: 0.5778 | Acc: 81.00%\n",
      "Train Epoch [67/100] Batch [299/782] Loss: 0.5460 | Acc: 81.01%\n",
      "Train Epoch [67/100] Batch [300/782] Loss: 0.6652 | Acc: 81.02%\n",
      "Train Epoch [67/100] Batch [301/782] Loss: 0.6603 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [302/782] Loss: 0.4635 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [303/782] Loss: 0.5707 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [304/782] Loss: 0.5079 | Acc: 80.99%\n",
      "Train Epoch [67/100] Batch [305/782] Loss: 0.5411 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [306/782] Loss: 0.4927 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [307/782] Loss: 0.5777 | Acc: 80.97%\n",
      "Train Epoch [67/100] Batch [308/782] Loss: 0.6469 | Acc: 80.98%\n",
      "Train Epoch [67/100] Batch [309/782] Loss: 0.8161 | Acc: 80.94%\n",
      "Train Epoch [67/100] Batch [310/782] Loss: 0.8035 | Acc: 80.91%\n",
      "Train Epoch [67/100] Batch [311/782] Loss: 0.5156 | Acc: 80.91%\n",
      "Train Epoch [67/100] Batch [312/782] Loss: 0.6025 | Acc: 80.90%\n",
      "Train Epoch [67/100] Batch [313/782] Loss: 0.5948 | Acc: 80.90%\n",
      "Train Epoch [67/100] Batch [314/782] Loss: 0.7121 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [315/782] Loss: 0.4973 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [316/782] Loss: 0.5816 | Acc: 80.87%\n",
      "Train Epoch [67/100] Batch [317/782] Loss: 0.5341 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [318/782] Loss: 0.6882 | Acc: 80.87%\n",
      "Train Epoch [67/100] Batch [319/782] Loss: 0.4498 | Acc: 80.89%\n",
      "Train Epoch [67/100] Batch [320/782] Loss: 0.5710 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [321/782] Loss: 0.6541 | Acc: 80.87%\n",
      "Train Epoch [67/100] Batch [322/782] Loss: 0.4490 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [323/782] Loss: 0.4500 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [324/782] Loss: 0.6546 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [325/782] Loss: 0.7954 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [326/782] Loss: 0.5093 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [327/782] Loss: 0.3728 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [328/782] Loss: 0.5686 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [329/782] Loss: 0.4996 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [330/782] Loss: 0.5547 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [331/782] Loss: 0.5679 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [332/782] Loss: 0.7316 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [333/782] Loss: 0.6310 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [334/782] Loss: 0.4390 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [335/782] Loss: 0.5302 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [336/782] Loss: 0.3929 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [337/782] Loss: 0.5028 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [338/782] Loss: 0.6178 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [339/782] Loss: 0.5853 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [340/782] Loss: 0.4565 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [341/782] Loss: 0.4200 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [342/782] Loss: 0.5416 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [343/782] Loss: 0.5056 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [344/782] Loss: 0.6157 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [345/782] Loss: 0.6242 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [346/782] Loss: 0.6438 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [347/782] Loss: 0.4518 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [348/782] Loss: 0.3658 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [349/782] Loss: 0.4899 | Acc: 80.86%\n",
      "Train Epoch [67/100] Batch [350/782] Loss: 0.5684 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [351/782] Loss: 0.4422 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [352/782] Loss: 0.4521 | Acc: 80.87%\n",
      "Train Epoch [67/100] Batch [353/782] Loss: 0.4932 | Acc: 80.88%\n",
      "Train Epoch [67/100] Batch [354/782] Loss: 0.7550 | Acc: 80.85%\n",
      "Train Epoch [67/100] Batch [355/782] Loss: 0.7348 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [356/782] Loss: 0.5710 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [357/782] Loss: 0.5607 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [358/782] Loss: 0.3921 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [359/782] Loss: 0.6202 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [360/782] Loss: 0.5906 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [361/782] Loss: 0.4524 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [362/782] Loss: 0.6791 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [363/782] Loss: 0.5344 | Acc: 80.81%\n",
      "Train Epoch [67/100] Batch [364/782] Loss: 0.3270 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [365/782] Loss: 0.4484 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [366/782] Loss: 0.5723 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [367/782] Loss: 0.5486 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [368/782] Loss: 0.4903 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [369/782] Loss: 0.5709 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [370/782] Loss: 0.5151 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [371/782] Loss: 0.5357 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [372/782] Loss: 0.7093 | Acc: 80.83%\n",
      "Train Epoch [67/100] Batch [373/782] Loss: 0.7495 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [374/782] Loss: 0.4313 | Acc: 80.84%\n",
      "Train Epoch [67/100] Batch [375/782] Loss: 0.7616 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [376/782] Loss: 0.8037 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [377/782] Loss: 0.6482 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [378/782] Loss: 0.5355 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [379/782] Loss: 0.5370 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [380/782] Loss: 0.4883 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [381/782] Loss: 0.5722 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [382/782] Loss: 0.4293 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [383/782] Loss: 0.6358 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [384/782] Loss: 0.3824 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [385/782] Loss: 0.3657 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [386/782] Loss: 0.5928 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [387/782] Loss: 0.5904 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [388/782] Loss: 0.4981 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [389/782] Loss: 0.6442 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [390/782] Loss: 0.5630 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [391/782] Loss: 0.4407 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [392/782] Loss: 0.4356 | Acc: 80.80%\n",
      "Train Epoch [67/100] Batch [393/782] Loss: 0.3880 | Acc: 80.82%\n",
      "Train Epoch [67/100] Batch [394/782] Loss: 0.6654 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [395/782] Loss: 0.5775 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [396/782] Loss: 0.5518 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [397/782] Loss: 0.5516 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [398/782] Loss: 0.6000 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [399/782] Loss: 0.4838 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [400/782] Loss: 0.4371 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [401/782] Loss: 0.5317 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [402/782] Loss: 0.6418 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [403/782] Loss: 0.5138 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [404/782] Loss: 0.4358 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [405/782] Loss: 0.5073 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [406/782] Loss: 0.7608 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [407/782] Loss: 0.4650 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [408/782] Loss: 0.5551 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [409/782] Loss: 0.5210 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [410/782] Loss: 0.3877 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [411/782] Loss: 0.4475 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [412/782] Loss: 0.5926 | Acc: 80.76%\n",
      "Train Epoch [67/100] Batch [413/782] Loss: 0.5845 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [414/782] Loss: 0.5615 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [415/782] Loss: 0.3996 | Acc: 80.79%\n",
      "Train Epoch [67/100] Batch [416/782] Loss: 0.6147 | Acc: 80.78%\n",
      "Train Epoch [67/100] Batch [417/782] Loss: 0.5937 | Acc: 80.77%\n",
      "Train Epoch [67/100] Batch [418/782] Loss: 0.7705 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [419/782] Loss: 0.7545 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [420/782] Loss: 0.5597 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [421/782] Loss: 0.4893 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [422/782] Loss: 0.6389 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [423/782] Loss: 0.6051 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [424/782] Loss: 0.3881 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [425/782] Loss: 0.5285 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [426/782] Loss: 0.6323 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [427/782] Loss: 0.5311 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [428/782] Loss: 0.5591 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [429/782] Loss: 0.4009 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [430/782] Loss: 0.3634 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [431/782] Loss: 0.6523 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [432/782] Loss: 0.5662 | Acc: 80.74%\n",
      "Train Epoch [67/100] Batch [433/782] Loss: 0.4377 | Acc: 80.75%\n",
      "Train Epoch [67/100] Batch [434/782] Loss: 0.8055 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [435/782] Loss: 0.4628 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [436/782] Loss: 0.5385 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [437/782] Loss: 0.5639 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [438/782] Loss: 0.4084 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [439/782] Loss: 0.4191 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [440/782] Loss: 0.6982 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [441/782] Loss: 0.7764 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [442/782] Loss: 0.7391 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [443/782] Loss: 0.5648 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [444/782] Loss: 0.4203 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [445/782] Loss: 0.4657 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [446/782] Loss: 0.7389 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [447/782] Loss: 0.6116 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [448/782] Loss: 0.5515 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [449/782] Loss: 0.6523 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [450/782] Loss: 0.8315 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [451/782] Loss: 0.4399 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [452/782] Loss: 0.6465 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [453/782] Loss: 0.5881 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [454/782] Loss: 0.7729 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [455/782] Loss: 0.4734 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [456/782] Loss: 0.3509 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [457/782] Loss: 0.4399 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [458/782] Loss: 0.5887 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [459/782] Loss: 0.7331 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [460/782] Loss: 0.6158 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [461/782] Loss: 0.3840 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [462/782] Loss: 0.3872 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [463/782] Loss: 0.5939 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [464/782] Loss: 0.5403 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [465/782] Loss: 0.5358 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [466/782] Loss: 0.6659 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [467/782] Loss: 0.6673 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [468/782] Loss: 0.5097 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [469/782] Loss: 0.3759 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [470/782] Loss: 0.4736 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [471/782] Loss: 0.8354 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [472/782] Loss: 0.5855 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [473/782] Loss: 0.4971 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [474/782] Loss: 0.7002 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [475/782] Loss: 0.7532 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [476/782] Loss: 0.5672 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [477/782] Loss: 0.7315 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [478/782] Loss: 0.4709 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [479/782] Loss: 0.5705 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [480/782] Loss: 0.6221 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [481/782] Loss: 0.5507 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [482/782] Loss: 0.4801 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [483/782] Loss: 0.5820 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [484/782] Loss: 0.5795 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [485/782] Loss: 0.4812 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [486/782] Loss: 0.4967 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [487/782] Loss: 0.5294 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [488/782] Loss: 0.6093 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [489/782] Loss: 0.4899 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [490/782] Loss: 0.4377 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [491/782] Loss: 0.4530 | Acc: 80.69%\n",
      "Train Epoch [67/100] Batch [492/782] Loss: 0.5085 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [493/782] Loss: 0.5687 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [494/782] Loss: 0.5465 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [495/782] Loss: 0.3937 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [496/782] Loss: 0.5622 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [497/782] Loss: 0.3891 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [498/782] Loss: 0.3692 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [499/782] Loss: 0.5496 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [500/782] Loss: 0.6452 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [501/782] Loss: 0.5658 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [502/782] Loss: 0.5271 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [503/782] Loss: 0.5400 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [504/782] Loss: 0.5339 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [505/782] Loss: 0.5588 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [506/782] Loss: 0.3707 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [507/782] Loss: 0.5107 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [508/782] Loss: 0.4758 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [509/782] Loss: 0.3740 | Acc: 80.73%\n",
      "Train Epoch [67/100] Batch [510/782] Loss: 0.6297 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [511/782] Loss: 0.4996 | Acc: 80.72%\n",
      "Train Epoch [67/100] Batch [512/782] Loss: 0.7931 | Acc: 80.70%\n",
      "Train Epoch [67/100] Batch [513/782] Loss: 0.6013 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [514/782] Loss: 0.7235 | Acc: 80.71%\n",
      "Train Epoch [67/100] Batch [515/782] Loss: 0.7832 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [516/782] Loss: 0.5190 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [517/782] Loss: 0.6515 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [518/782] Loss: 0.6557 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [519/782] Loss: 0.4879 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [520/782] Loss: 0.6058 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [521/782] Loss: 0.5705 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [522/782] Loss: 0.4768 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [523/782] Loss: 0.5774 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [524/782] Loss: 0.5720 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [525/782] Loss: 0.5676 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [526/782] Loss: 0.5646 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [527/782] Loss: 0.5757 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [528/782] Loss: 0.4702 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [529/782] Loss: 0.6134 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [530/782] Loss: 0.4337 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [531/782] Loss: 0.6559 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [532/782] Loss: 0.5847 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [533/782] Loss: 0.4239 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [534/782] Loss: 0.4359 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [535/782] Loss: 0.3825 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [536/782] Loss: 0.6994 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [537/782] Loss: 0.6607 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [538/782] Loss: 0.8900 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [539/782] Loss: 0.4710 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [540/782] Loss: 0.7159 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [541/782] Loss: 0.4863 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [542/782] Loss: 0.4142 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [543/782] Loss: 0.5138 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [544/782] Loss: 0.4408 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [545/782] Loss: 0.3471 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [546/782] Loss: 0.5678 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [547/782] Loss: 0.5304 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [548/782] Loss: 0.5727 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [549/782] Loss: 0.4170 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [550/782] Loss: 0.5272 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [551/782] Loss: 0.4149 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [552/782] Loss: 0.6285 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [553/782] Loss: 0.4733 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [554/782] Loss: 0.3849 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [555/782] Loss: 0.6050 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [556/782] Loss: 0.6100 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [557/782] Loss: 0.6215 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [558/782] Loss: 0.3916 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [559/782] Loss: 0.6765 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [560/782] Loss: 0.4734 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [561/782] Loss: 0.6425 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [562/782] Loss: 0.5124 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [563/782] Loss: 0.3963 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [564/782] Loss: 0.4881 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [565/782] Loss: 0.5428 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [566/782] Loss: 0.5417 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [567/782] Loss: 0.4910 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [568/782] Loss: 0.5385 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [569/782] Loss: 0.5052 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [570/782] Loss: 0.5264 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [571/782] Loss: 0.5975 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [572/782] Loss: 0.6574 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [573/782] Loss: 0.3933 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [574/782] Loss: 0.4930 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [575/782] Loss: 0.4012 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [576/782] Loss: 0.5884 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [577/782] Loss: 0.5500 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [578/782] Loss: 0.8348 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [579/782] Loss: 0.5195 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [580/782] Loss: 0.6021 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [581/782] Loss: 0.5018 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [582/782] Loss: 0.3697 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [583/782] Loss: 0.4670 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [584/782] Loss: 0.5754 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [585/782] Loss: 0.4464 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [586/782] Loss: 0.5777 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [587/782] Loss: 0.5780 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [588/782] Loss: 0.6230 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [589/782] Loss: 0.4435 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [590/782] Loss: 0.4659 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [591/782] Loss: 0.5530 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [592/782] Loss: 0.3862 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [593/782] Loss: 0.6742 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [594/782] Loss: 0.5670 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [595/782] Loss: 0.4646 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [596/782] Loss: 0.7359 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [597/782] Loss: 0.6536 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [598/782] Loss: 0.5269 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [599/782] Loss: 0.4377 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [600/782] Loss: 0.5176 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [601/782] Loss: 0.3906 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [602/782] Loss: 0.4188 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [603/782] Loss: 0.4812 | Acc: 80.68%\n",
      "Train Epoch [67/100] Batch [604/782] Loss: 0.6353 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [605/782] Loss: 0.3912 | Acc: 80.67%\n",
      "Train Epoch [67/100] Batch [606/782] Loss: 0.8933 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [607/782] Loss: 0.5352 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [608/782] Loss: 0.5445 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [609/782] Loss: 0.4645 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [610/782] Loss: 0.6266 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [611/782] Loss: 0.5670 | Acc: 80.66%\n",
      "Train Epoch [67/100] Batch [612/782] Loss: 0.5661 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [613/782] Loss: 0.3553 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [614/782] Loss: 0.6288 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [615/782] Loss: 0.6136 | Acc: 80.65%\n",
      "Train Epoch [67/100] Batch [616/782] Loss: 0.5768 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [617/782] Loss: 0.7228 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [618/782] Loss: 0.6181 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [619/782] Loss: 0.4725 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [620/782] Loss: 0.5224 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [621/782] Loss: 0.7813 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [622/782] Loss: 0.5432 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [623/782] Loss: 0.3672 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [624/782] Loss: 0.4659 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [625/782] Loss: 0.5150 | Acc: 80.64%\n",
      "Train Epoch [67/100] Batch [626/782] Loss: 0.6048 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [627/782] Loss: 0.5433 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [628/782] Loss: 0.5929 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [629/782] Loss: 0.5083 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [630/782] Loss: 0.6410 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [631/782] Loss: 0.7081 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [632/782] Loss: 0.3433 | Acc: 80.63%\n",
      "Train Epoch [67/100] Batch [633/782] Loss: 0.7215 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [634/782] Loss: 0.3825 | Acc: 80.62%\n",
      "Train Epoch [67/100] Batch [635/782] Loss: 0.7752 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [636/782] Loss: 0.5561 | Acc: 80.61%\n",
      "Train Epoch [67/100] Batch [637/782] Loss: 0.6624 | Acc: 80.60%\n",
      "Train Epoch [67/100] Batch [638/782] Loss: 0.8257 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [639/782] Loss: 0.5107 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [640/782] Loss: 0.4114 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [641/782] Loss: 0.8302 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [642/782] Loss: 0.4621 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [643/782] Loss: 0.5981 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [644/782] Loss: 0.5749 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [645/782] Loss: 0.7529 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [646/782] Loss: 0.5693 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [647/782] Loss: 0.6799 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [648/782] Loss: 0.3629 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [649/782] Loss: 0.6685 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [650/782] Loss: 0.4380 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [651/782] Loss: 0.4872 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [652/782] Loss: 0.5293 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [653/782] Loss: 0.3754 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [654/782] Loss: 0.4760 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [655/782] Loss: 0.5892 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [656/782] Loss: 0.7343 | Acc: 80.58%\n",
      "Train Epoch [67/100] Batch [657/782] Loss: 0.4985 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [658/782] Loss: 0.5288 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [659/782] Loss: 0.4465 | Acc: 80.59%\n",
      "Train Epoch [67/100] Batch [660/782] Loss: 0.9220 | Acc: 80.57%\n",
      "Train Epoch [67/100] Batch [661/782] Loss: 0.6521 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [662/782] Loss: 0.6034 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [663/782] Loss: 0.5266 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [664/782] Loss: 0.6213 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [665/782] Loss: 0.4534 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [666/782] Loss: 0.5301 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [667/782] Loss: 0.6381 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [668/782] Loss: 0.5728 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [669/782] Loss: 0.5101 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [670/782] Loss: 0.5298 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [671/782] Loss: 0.6899 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [672/782] Loss: 0.5958 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [673/782] Loss: 0.5146 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [674/782] Loss: 0.4624 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [675/782] Loss: 0.4516 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [676/782] Loss: 0.4283 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [677/782] Loss: 0.3802 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [678/782] Loss: 0.5107 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [679/782] Loss: 0.6852 | Acc: 80.56%\n",
      "Train Epoch [67/100] Batch [680/782] Loss: 0.5688 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [681/782] Loss: 0.5192 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [682/782] Loss: 0.4778 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [683/782] Loss: 0.4772 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [684/782] Loss: 0.5439 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [685/782] Loss: 0.5964 | Acc: 80.55%\n",
      "Train Epoch [67/100] Batch [686/782] Loss: 0.6075 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [687/782] Loss: 0.5368 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [688/782] Loss: 0.7509 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [689/782] Loss: 0.5317 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [690/782] Loss: 0.5393 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [691/782] Loss: 0.5016 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [692/782] Loss: 0.6824 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [693/782] Loss: 0.6671 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [694/782] Loss: 0.8574 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [695/782] Loss: 0.4961 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [696/782] Loss: 0.6365 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [697/782] Loss: 0.4932 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [698/782] Loss: 0.6334 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [699/782] Loss: 0.5485 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [700/782] Loss: 0.5718 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [701/782] Loss: 0.4721 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [702/782] Loss: 0.4915 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [703/782] Loss: 0.7249 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [704/782] Loss: 0.5640 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [705/782] Loss: 0.6550 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [706/782] Loss: 0.6062 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [707/782] Loss: 0.3784 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [708/782] Loss: 0.5049 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [709/782] Loss: 0.5784 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [710/782] Loss: 0.5895 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [711/782] Loss: 0.6563 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [712/782] Loss: 0.4116 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [713/782] Loss: 0.6644 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [714/782] Loss: 0.7867 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [715/782] Loss: 0.4300 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [716/782] Loss: 0.5282 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [717/782] Loss: 0.4610 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [718/782] Loss: 0.5883 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [719/782] Loss: 0.6732 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [720/782] Loss: 0.4412 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [721/782] Loss: 0.4289 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [722/782] Loss: 0.6260 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [723/782] Loss: 0.6490 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [724/782] Loss: 0.4733 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [725/782] Loss: 0.5604 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [726/782] Loss: 0.4355 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [727/782] Loss: 0.5606 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [728/782] Loss: 0.4965 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [729/782] Loss: 0.5502 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [730/782] Loss: 0.4796 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [731/782] Loss: 0.5713 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [732/782] Loss: 0.4824 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [733/782] Loss: 0.6085 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [734/782] Loss: 0.5230 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [735/782] Loss: 0.5109 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [736/782] Loss: 0.5431 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [737/782] Loss: 0.3904 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [738/782] Loss: 0.5887 | Acc: 80.54%\n",
      "Train Epoch [67/100] Batch [739/782] Loss: 0.7374 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [740/782] Loss: 0.4805 | Acc: 80.53%\n",
      "Train Epoch [67/100] Batch [741/782] Loss: 0.6031 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [742/782] Loss: 0.6636 | Acc: 80.52%\n",
      "Train Epoch [67/100] Batch [743/782] Loss: 0.7676 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [744/782] Loss: 0.6472 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [745/782] Loss: 0.5484 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [746/782] Loss: 0.4554 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [747/782] Loss: 0.5829 | Acc: 80.51%\n",
      "Train Epoch [67/100] Batch [748/782] Loss: 0.6689 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [749/782] Loss: 0.5606 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [750/782] Loss: 0.4802 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [751/782] Loss: 0.6386 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [752/782] Loss: 0.4905 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [753/782] Loss: 0.5364 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [754/782] Loss: 0.5971 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [755/782] Loss: 0.5444 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [756/782] Loss: 0.4559 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [757/782] Loss: 0.4378 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [758/782] Loss: 0.5571 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [759/782] Loss: 0.4652 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [760/782] Loss: 0.6437 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [761/782] Loss: 0.4316 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [762/782] Loss: 0.6602 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [763/782] Loss: 0.5495 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [764/782] Loss: 0.5618 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [765/782] Loss: 0.7194 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [766/782] Loss: 1.0104 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [767/782] Loss: 0.5159 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [768/782] Loss: 0.6271 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [769/782] Loss: 0.3942 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [770/782] Loss: 0.5398 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [771/782] Loss: 0.3731 | Acc: 80.50%\n",
      "Train Epoch [67/100] Batch [772/782] Loss: 0.5341 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [773/782] Loss: 0.4531 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [774/782] Loss: 0.6693 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [775/782] Loss: 0.5515 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [776/782] Loss: 0.6535 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [777/782] Loss: 0.6032 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [778/782] Loss: 0.4744 | Acc: 80.48%\n",
      "Train Epoch [67/100] Batch [779/782] Loss: 0.4619 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [780/782] Loss: 0.6579 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [781/782] Loss: 0.5514 | Acc: 80.49%\n",
      "Train Epoch [67/100] Batch [782/782] Loss: 1.0419 | Acc: 80.48%\n",
      "Epoch 67 completed in 29.72s.\n",
      "Test Epoch [67/100] Loss: 0.8850 | Acc: 73.23% | Inference Time: 8.19s\n",
      "Saving best model...\n",
      "Epoch 67 results saved to CSV.\n",
      "Epoch 68/100\n",
      "Train Epoch [68/100] Batch [1/782] Loss: 0.5707 | Acc: 78.12%\n",
      "Train Epoch [68/100] Batch [2/782] Loss: 0.4325 | Acc: 83.59%\n",
      "Train Epoch [68/100] Batch [3/782] Loss: 0.3856 | Acc: 85.42%\n",
      "Train Epoch [68/100] Batch [4/782] Loss: 0.7416 | Acc: 82.81%\n",
      "Train Epoch [68/100] Batch [5/782] Loss: 0.4054 | Acc: 83.44%\n",
      "Train Epoch [68/100] Batch [6/782] Loss: 0.6385 | Acc: 82.03%\n",
      "Train Epoch [68/100] Batch [7/782] Loss: 0.3511 | Acc: 83.48%\n",
      "Train Epoch [68/100] Batch [8/782] Loss: 0.4015 | Acc: 83.98%\n",
      "Train Epoch [68/100] Batch [9/782] Loss: 0.4729 | Acc: 84.20%\n",
      "Train Epoch [68/100] Batch [10/782] Loss: 0.4967 | Acc: 84.38%\n",
      "Train Epoch [68/100] Batch [11/782] Loss: 0.2743 | Acc: 85.09%\n",
      "Train Epoch [68/100] Batch [12/782] Loss: 0.3878 | Acc: 84.90%\n",
      "Train Epoch [68/100] Batch [13/782] Loss: 0.5058 | Acc: 84.50%\n",
      "Train Epoch [68/100] Batch [14/782] Loss: 0.3804 | Acc: 84.82%\n",
      "Train Epoch [68/100] Batch [15/782] Loss: 0.4568 | Acc: 84.79%\n",
      "Train Epoch [68/100] Batch [16/782] Loss: 0.5181 | Acc: 84.86%\n",
      "Train Epoch [68/100] Batch [17/782] Loss: 0.5636 | Acc: 84.74%\n",
      "Train Epoch [68/100] Batch [18/782] Loss: 0.5962 | Acc: 84.46%\n",
      "Train Epoch [68/100] Batch [19/782] Loss: 0.5559 | Acc: 84.13%\n",
      "Train Epoch [68/100] Batch [20/782] Loss: 0.5012 | Acc: 83.83%\n",
      "Train Epoch [68/100] Batch [21/782] Loss: 0.5753 | Acc: 83.48%\n",
      "Train Epoch [68/100] Batch [22/782] Loss: 0.6832 | Acc: 83.03%\n",
      "Train Epoch [68/100] Batch [23/782] Loss: 0.7870 | Acc: 82.68%\n",
      "Train Epoch [68/100] Batch [24/782] Loss: 0.4239 | Acc: 82.75%\n",
      "Train Epoch [68/100] Batch [25/782] Loss: 0.4417 | Acc: 82.75%\n",
      "Train Epoch [68/100] Batch [26/782] Loss: 0.4117 | Acc: 82.87%\n",
      "Train Epoch [68/100] Batch [27/782] Loss: 0.6673 | Acc: 82.58%\n",
      "Train Epoch [68/100] Batch [28/782] Loss: 0.6146 | Acc: 82.37%\n",
      "Train Epoch [68/100] Batch [29/782] Loss: 0.4266 | Acc: 82.33%\n",
      "Train Epoch [68/100] Batch [30/782] Loss: 0.4784 | Acc: 82.24%\n",
      "Train Epoch [68/100] Batch [31/782] Loss: 0.5593 | Acc: 82.21%\n",
      "Train Epoch [68/100] Batch [32/782] Loss: 0.6961 | Acc: 81.98%\n",
      "Train Epoch [68/100] Batch [33/782] Loss: 0.5431 | Acc: 82.01%\n",
      "Train Epoch [68/100] Batch [34/782] Loss: 0.2920 | Acc: 82.31%\n",
      "Train Epoch [68/100] Batch [35/782] Loss: 0.4453 | Acc: 82.37%\n",
      "Train Epoch [68/100] Batch [36/782] Loss: 0.5959 | Acc: 82.03%\n",
      "Train Epoch [68/100] Batch [37/782] Loss: 0.5795 | Acc: 81.97%\n",
      "Train Epoch [68/100] Batch [38/782] Loss: 0.6771 | Acc: 81.78%\n",
      "Train Epoch [68/100] Batch [39/782] Loss: 0.5440 | Acc: 81.85%\n",
      "Train Epoch [68/100] Batch [40/782] Loss: 0.4562 | Acc: 81.91%\n",
      "Train Epoch [68/100] Batch [41/782] Loss: 0.5551 | Acc: 81.82%\n",
      "Train Epoch [68/100] Batch [42/782] Loss: 0.4108 | Acc: 81.92%\n",
      "Train Epoch [68/100] Batch [43/782] Loss: 0.7025 | Acc: 81.80%\n",
      "Train Epoch [68/100] Batch [44/782] Loss: 0.4763 | Acc: 81.89%\n",
      "Train Epoch [68/100] Batch [45/782] Loss: 0.4490 | Acc: 81.91%\n",
      "Train Epoch [68/100] Batch [46/782] Loss: 0.4754 | Acc: 81.90%\n",
      "Train Epoch [68/100] Batch [47/782] Loss: 0.5836 | Acc: 81.78%\n",
      "Train Epoch [68/100] Batch [48/782] Loss: 0.6247 | Acc: 81.64%\n",
      "Train Epoch [68/100] Batch [49/782] Loss: 0.2964 | Acc: 81.79%\n",
      "Train Epoch [68/100] Batch [50/782] Loss: 0.5933 | Acc: 81.81%\n",
      "Train Epoch [68/100] Batch [51/782] Loss: 0.7384 | Acc: 81.59%\n",
      "Train Epoch [68/100] Batch [52/782] Loss: 0.5019 | Acc: 81.58%\n",
      "Train Epoch [68/100] Batch [53/782] Loss: 0.4086 | Acc: 81.69%\n",
      "Train Epoch [68/100] Batch [54/782] Loss: 0.4267 | Acc: 81.66%\n",
      "Train Epoch [68/100] Batch [55/782] Loss: 0.4532 | Acc: 81.73%\n",
      "Train Epoch [68/100] Batch [56/782] Loss: 0.6472 | Acc: 81.58%\n",
      "Train Epoch [68/100] Batch [57/782] Loss: 0.6766 | Acc: 81.52%\n",
      "Train Epoch [68/100] Batch [58/782] Loss: 0.4440 | Acc: 81.55%\n",
      "Train Epoch [68/100] Batch [59/782] Loss: 0.4724 | Acc: 81.62%\n",
      "Train Epoch [68/100] Batch [60/782] Loss: 0.4288 | Acc: 81.64%\n",
      "Train Epoch [68/100] Batch [61/782] Loss: 0.5698 | Acc: 81.53%\n",
      "Train Epoch [68/100] Batch [62/782] Loss: 0.5110 | Acc: 81.58%\n",
      "Train Epoch [68/100] Batch [63/782] Loss: 0.4989 | Acc: 81.55%\n",
      "Train Epoch [68/100] Batch [64/782] Loss: 0.7420 | Acc: 81.40%\n",
      "Train Epoch [68/100] Batch [65/782] Loss: 0.6635 | Acc: 81.37%\n",
      "Train Epoch [68/100] Batch [66/782] Loss: 0.5129 | Acc: 81.37%\n",
      "Train Epoch [68/100] Batch [67/782] Loss: 0.4578 | Acc: 81.37%\n",
      "Train Epoch [68/100] Batch [68/782] Loss: 0.5665 | Acc: 81.30%\n",
      "Train Epoch [68/100] Batch [69/782] Loss: 0.4819 | Acc: 81.34%\n",
      "Train Epoch [68/100] Batch [70/782] Loss: 0.5484 | Acc: 81.32%\n",
      "Train Epoch [68/100] Batch [71/782] Loss: 0.3656 | Acc: 81.36%\n",
      "Train Epoch [68/100] Batch [72/782] Loss: 0.6354 | Acc: 81.29%\n",
      "Train Epoch [68/100] Batch [73/782] Loss: 0.7536 | Acc: 81.23%\n",
      "Train Epoch [68/100] Batch [74/782] Loss: 0.6508 | Acc: 81.10%\n",
      "Train Epoch [68/100] Batch [75/782] Loss: 0.7265 | Acc: 81.02%\n",
      "Train Epoch [68/100] Batch [76/782] Loss: 0.4208 | Acc: 81.09%\n",
      "Train Epoch [68/100] Batch [77/782] Loss: 0.5362 | Acc: 81.13%\n",
      "Train Epoch [68/100] Batch [78/782] Loss: 0.4731 | Acc: 81.23%\n",
      "Train Epoch [68/100] Batch [79/782] Loss: 0.7664 | Acc: 81.09%\n",
      "Train Epoch [68/100] Batch [80/782] Loss: 0.6086 | Acc: 81.05%\n",
      "Train Epoch [68/100] Batch [81/782] Loss: 0.6066 | Acc: 81.02%\n",
      "Train Epoch [68/100] Batch [82/782] Loss: 0.4711 | Acc: 81.08%\n",
      "Train Epoch [68/100] Batch [83/782] Loss: 0.5722 | Acc: 81.02%\n",
      "Train Epoch [68/100] Batch [84/782] Loss: 0.3598 | Acc: 81.12%\n",
      "Train Epoch [68/100] Batch [85/782] Loss: 0.6269 | Acc: 81.07%\n",
      "Train Epoch [68/100] Batch [86/782] Loss: 0.4785 | Acc: 81.10%\n",
      "Train Epoch [68/100] Batch [87/782] Loss: 0.6700 | Acc: 81.05%\n",
      "Train Epoch [68/100] Batch [88/782] Loss: 0.4707 | Acc: 81.07%\n",
      "Train Epoch [68/100] Batch [89/782] Loss: 0.6726 | Acc: 81.04%\n",
      "Train Epoch [68/100] Batch [90/782] Loss: 0.5035 | Acc: 81.02%\n",
      "Train Epoch [68/100] Batch [91/782] Loss: 0.6906 | Acc: 80.99%\n",
      "Train Epoch [68/100] Batch [92/782] Loss: 0.6092 | Acc: 80.96%\n",
      "Train Epoch [68/100] Batch [93/782] Loss: 0.5118 | Acc: 80.98%\n",
      "Train Epoch [68/100] Batch [94/782] Loss: 0.5821 | Acc: 80.93%\n",
      "Train Epoch [68/100] Batch [95/782] Loss: 0.4819 | Acc: 81.02%\n",
      "Train Epoch [68/100] Batch [96/782] Loss: 0.5114 | Acc: 81.05%\n",
      "Train Epoch [68/100] Batch [97/782] Loss: 0.4399 | Acc: 81.14%\n",
      "Train Epoch [68/100] Batch [98/782] Loss: 0.7211 | Acc: 81.04%\n",
      "Train Epoch [68/100] Batch [99/782] Loss: 0.4954 | Acc: 81.00%\n",
      "Train Epoch [68/100] Batch [100/782] Loss: 0.6798 | Acc: 80.91%\n",
      "Train Epoch [68/100] Batch [101/782] Loss: 0.4717 | Acc: 80.94%\n",
      "Train Epoch [68/100] Batch [102/782] Loss: 0.4346 | Acc: 80.96%\n",
      "Train Epoch [68/100] Batch [103/782] Loss: 0.4277 | Acc: 80.98%\n",
      "Train Epoch [68/100] Batch [104/782] Loss: 0.5724 | Acc: 80.93%\n",
      "Train Epoch [68/100] Batch [105/782] Loss: 0.5336 | Acc: 80.95%\n",
      "Train Epoch [68/100] Batch [106/782] Loss: 0.6772 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [107/782] Loss: 0.5347 | Acc: 80.78%\n",
      "Train Epoch [68/100] Batch [108/782] Loss: 0.4106 | Acc: 80.83%\n",
      "Train Epoch [68/100] Batch [109/782] Loss: 0.4902 | Acc: 80.82%\n",
      "Train Epoch [68/100] Batch [110/782] Loss: 0.5426 | Acc: 80.81%\n",
      "Train Epoch [68/100] Batch [111/782] Loss: 0.4697 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [112/782] Loss: 0.5579 | Acc: 80.83%\n",
      "Train Epoch [68/100] Batch [113/782] Loss: 0.3903 | Acc: 80.90%\n",
      "Train Epoch [68/100] Batch [114/782] Loss: 0.7051 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [115/782] Loss: 0.3949 | Acc: 80.87%\n",
      "Train Epoch [68/100] Batch [116/782] Loss: 0.5695 | Acc: 80.85%\n",
      "Train Epoch [68/100] Batch [117/782] Loss: 0.4327 | Acc: 80.85%\n",
      "Train Epoch [68/100] Batch [118/782] Loss: 0.5171 | Acc: 80.91%\n",
      "Train Epoch [68/100] Batch [119/782] Loss: 0.4294 | Acc: 80.88%\n",
      "Train Epoch [68/100] Batch [120/782] Loss: 0.4957 | Acc: 80.87%\n",
      "Train Epoch [68/100] Batch [121/782] Loss: 0.5523 | Acc: 80.90%\n",
      "Train Epoch [68/100] Batch [122/782] Loss: 0.3458 | Acc: 80.97%\n",
      "Train Epoch [68/100] Batch [123/782] Loss: 0.4952 | Acc: 80.97%\n",
      "Train Epoch [68/100] Batch [124/782] Loss: 0.6108 | Acc: 80.97%\n",
      "Train Epoch [68/100] Batch [125/782] Loss: 0.5531 | Acc: 80.89%\n",
      "Train Epoch [68/100] Batch [126/782] Loss: 0.5749 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [127/782] Loss: 0.5567 | Acc: 80.88%\n",
      "Train Epoch [68/100] Batch [128/782] Loss: 0.5290 | Acc: 80.88%\n",
      "Train Epoch [68/100] Batch [129/782] Loss: 0.6254 | Acc: 80.89%\n",
      "Train Epoch [68/100] Batch [130/782] Loss: 0.5943 | Acc: 80.88%\n",
      "Train Epoch [68/100] Batch [131/782] Loss: 0.3743 | Acc: 80.90%\n",
      "Train Epoch [68/100] Batch [132/782] Loss: 0.6730 | Acc: 80.88%\n",
      "Train Epoch [68/100] Batch [133/782] Loss: 0.6274 | Acc: 80.85%\n",
      "Train Epoch [68/100] Batch [134/782] Loss: 0.7582 | Acc: 80.81%\n",
      "Train Epoch [68/100] Batch [135/782] Loss: 0.5472 | Acc: 80.80%\n",
      "Train Epoch [68/100] Batch [136/782] Loss: 0.4458 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [137/782] Loss: 0.5793 | Acc: 80.81%\n",
      "Train Epoch [68/100] Batch [138/782] Loss: 0.5829 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [139/782] Loss: 0.6989 | Acc: 80.78%\n",
      "Train Epoch [68/100] Batch [140/782] Loss: 0.3683 | Acc: 80.83%\n",
      "Train Epoch [68/100] Batch [141/782] Loss: 0.6157 | Acc: 80.83%\n",
      "Train Epoch [68/100] Batch [142/782] Loss: 0.6809 | Acc: 80.80%\n",
      "Train Epoch [68/100] Batch [143/782] Loss: 0.4987 | Acc: 80.82%\n",
      "Train Epoch [68/100] Batch [144/782] Loss: 0.4393 | Acc: 80.85%\n",
      "Train Epoch [68/100] Batch [145/782] Loss: 0.4550 | Acc: 80.84%\n",
      "Train Epoch [68/100] Batch [146/782] Loss: 0.7454 | Acc: 80.78%\n",
      "Train Epoch [68/100] Batch [147/782] Loss: 0.7231 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [148/782] Loss: 0.5130 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [149/782] Loss: 0.5515 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [150/782] Loss: 0.4313 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [151/782] Loss: 0.5087 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [152/782] Loss: 0.4567 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [153/782] Loss: 0.3808 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [154/782] Loss: 0.4865 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [155/782] Loss: 0.4320 | Acc: 80.79%\n",
      "Train Epoch [68/100] Batch [156/782] Loss: 0.5334 | Acc: 80.79%\n",
      "Train Epoch [68/100] Batch [157/782] Loss: 0.4380 | Acc: 80.80%\n",
      "Train Epoch [68/100] Batch [158/782] Loss: 0.6126 | Acc: 80.78%\n",
      "Train Epoch [68/100] Batch [159/782] Loss: 0.5159 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [160/782] Loss: 0.5228 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [161/782] Loss: 0.4786 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [162/782] Loss: 0.4539 | Acc: 80.79%\n",
      "Train Epoch [68/100] Batch [163/782] Loss: 0.6081 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [164/782] Loss: 0.6330 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [165/782] Loss: 0.5936 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [166/782] Loss: 0.5133 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [167/782] Loss: 0.3990 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [168/782] Loss: 0.7878 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [169/782] Loss: 0.5699 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [170/782] Loss: 0.5548 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [171/782] Loss: 0.4540 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [172/782] Loss: 0.4447 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [173/782] Loss: 0.6128 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [174/782] Loss: 0.6379 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [175/782] Loss: 0.3011 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [176/782] Loss: 0.6233 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [177/782] Loss: 0.7029 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [178/782] Loss: 0.5211 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [179/782] Loss: 0.6239 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [180/782] Loss: 0.5568 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [181/782] Loss: 0.4817 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [182/782] Loss: 0.8416 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [183/782] Loss: 0.5272 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [184/782] Loss: 0.2307 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [185/782] Loss: 0.6257 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [186/782] Loss: 0.3734 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [187/782] Loss: 0.3701 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [188/782] Loss: 0.5206 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [189/782] Loss: 0.7398 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [190/782] Loss: 0.5445 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [191/782] Loss: 0.5385 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [192/782] Loss: 0.4903 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [193/782] Loss: 0.4265 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [194/782] Loss: 0.6411 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [195/782] Loss: 0.4980 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [196/782] Loss: 0.6603 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [197/782] Loss: 0.7706 | Acc: 80.46%\n",
      "Train Epoch [68/100] Batch [198/782] Loss: 0.4546 | Acc: 80.48%\n",
      "Train Epoch [68/100] Batch [199/782] Loss: 0.5311 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [200/782] Loss: 0.6150 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [201/782] Loss: 0.5236 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [202/782] Loss: 0.4383 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [203/782] Loss: 0.5807 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [204/782] Loss: 0.4484 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [205/782] Loss: 0.4057 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [206/782] Loss: 0.5492 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [207/782] Loss: 0.5523 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [208/782] Loss: 0.7037 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [209/782] Loss: 0.4353 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [210/782] Loss: 0.3526 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [211/782] Loss: 0.5449 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [212/782] Loss: 0.5311 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [213/782] Loss: 0.5295 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [214/782] Loss: 0.7437 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [215/782] Loss: 0.4371 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [216/782] Loss: 0.5061 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [217/782] Loss: 0.4612 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [218/782] Loss: 0.3954 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [219/782] Loss: 0.6173 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [220/782] Loss: 0.6196 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [221/782] Loss: 0.5407 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [222/782] Loss: 0.6472 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [223/782] Loss: 0.4584 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [224/782] Loss: 0.3097 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [225/782] Loss: 0.5655 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [226/782] Loss: 0.5032 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [227/782] Loss: 0.4278 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [228/782] Loss: 0.5184 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [229/782] Loss: 0.6267 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [230/782] Loss: 0.5665 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [231/782] Loss: 0.5530 | Acc: 80.49%\n",
      "Train Epoch [68/100] Batch [232/782] Loss: 0.4837 | Acc: 80.49%\n",
      "Train Epoch [68/100] Batch [233/782] Loss: 0.5534 | Acc: 80.47%\n",
      "Train Epoch [68/100] Batch [234/782] Loss: 0.5185 | Acc: 80.47%\n",
      "Train Epoch [68/100] Batch [235/782] Loss: 0.6999 | Acc: 80.44%\n",
      "Train Epoch [68/100] Batch [236/782] Loss: 0.6907 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [237/782] Loss: 0.6830 | Acc: 80.39%\n",
      "Train Epoch [68/100] Batch [238/782] Loss: 0.4319 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [239/782] Loss: 0.4830 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [240/782] Loss: 0.5976 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [241/782] Loss: 0.4241 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [242/782] Loss: 0.4607 | Acc: 80.43%\n",
      "Train Epoch [68/100] Batch [243/782] Loss: 0.5980 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [244/782] Loss: 0.6489 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [245/782] Loss: 0.5259 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [246/782] Loss: 0.4043 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [247/782] Loss: 0.6697 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [248/782] Loss: 0.4967 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [249/782] Loss: 0.7561 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [250/782] Loss: 0.4916 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [251/782] Loss: 0.5863 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [252/782] Loss: 0.3412 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [253/782] Loss: 0.3384 | Acc: 80.43%\n",
      "Train Epoch [68/100] Batch [254/782] Loss: 0.6569 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [255/782] Loss: 0.6645 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [256/782] Loss: 0.7048 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [257/782] Loss: 0.5470 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [258/782] Loss: 0.3914 | Acc: 80.43%\n",
      "Train Epoch [68/100] Batch [259/782] Loss: 0.4413 | Acc: 80.43%\n",
      "Train Epoch [68/100] Batch [260/782] Loss: 0.6594 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [261/782] Loss: 0.7358 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [262/782] Loss: 0.4870 | Acc: 80.39%\n",
      "Train Epoch [68/100] Batch [263/782] Loss: 0.5801 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [264/782] Loss: 0.4890 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [265/782] Loss: 0.6792 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [266/782] Loss: 0.4387 | Acc: 80.36%\n",
      "Train Epoch [68/100] Batch [267/782] Loss: 0.6413 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [268/782] Loss: 0.4023 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [269/782] Loss: 0.5268 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [270/782] Loss: 0.4160 | Acc: 80.37%\n",
      "Train Epoch [68/100] Batch [271/782] Loss: 0.5681 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [272/782] Loss: 0.4639 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [273/782] Loss: 0.4943 | Acc: 80.35%\n",
      "Train Epoch [68/100] Batch [274/782] Loss: 0.3088 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [275/782] Loss: 0.4271 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [276/782] Loss: 0.4202 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [277/782] Loss: 0.8352 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [278/782] Loss: 0.6557 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [279/782] Loss: 0.5577 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [280/782] Loss: 0.4394 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [281/782] Loss: 0.6071 | Acc: 80.38%\n",
      "Train Epoch [68/100] Batch [282/782] Loss: 0.4731 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [283/782] Loss: 0.5218 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [284/782] Loss: 0.6747 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [285/782] Loss: 0.5870 | Acc: 80.39%\n",
      "Train Epoch [68/100] Batch [286/782] Loss: 0.6493 | Acc: 80.37%\n",
      "Train Epoch [68/100] Batch [287/782] Loss: 0.3634 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [288/782] Loss: 0.5199 | Acc: 80.39%\n",
      "Train Epoch [68/100] Batch [289/782] Loss: 0.4390 | Acc: 80.40%\n",
      "Train Epoch [68/100] Batch [290/782] Loss: 0.4723 | Acc: 80.41%\n",
      "Train Epoch [68/100] Batch [291/782] Loss: 0.4468 | Acc: 80.42%\n",
      "Train Epoch [68/100] Batch [292/782] Loss: 0.5475 | Acc: 80.43%\n",
      "Train Epoch [68/100] Batch [293/782] Loss: 0.3130 | Acc: 80.47%\n",
      "Train Epoch [68/100] Batch [294/782] Loss: 0.4717 | Acc: 80.47%\n",
      "Train Epoch [68/100] Batch [295/782] Loss: 0.4246 | Acc: 80.48%\n",
      "Train Epoch [68/100] Batch [296/782] Loss: 0.5597 | Acc: 80.49%\n",
      "Train Epoch [68/100] Batch [297/782] Loss: 0.5177 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [298/782] Loss: 0.4466 | Acc: 80.49%\n",
      "Train Epoch [68/100] Batch [299/782] Loss: 0.5796 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [300/782] Loss: 0.6257 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [301/782] Loss: 0.4321 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [302/782] Loss: 0.5356 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [303/782] Loss: 0.5152 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [304/782] Loss: 0.3819 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [305/782] Loss: 0.5515 | Acc: 80.50%\n",
      "Train Epoch [68/100] Batch [306/782] Loss: 0.5345 | Acc: 80.51%\n",
      "Train Epoch [68/100] Batch [307/782] Loss: 0.5373 | Acc: 80.52%\n",
      "Train Epoch [68/100] Batch [308/782] Loss: 0.5279 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [309/782] Loss: 0.5709 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [310/782] Loss: 0.4852 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [311/782] Loss: 0.4617 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [312/782] Loss: 0.6603 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [313/782] Loss: 0.6467 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [314/782] Loss: 0.3589 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [315/782] Loss: 0.5775 | Acc: 80.53%\n",
      "Train Epoch [68/100] Batch [316/782] Loss: 0.3367 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [317/782] Loss: 0.5185 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [318/782] Loss: 0.3915 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [319/782] Loss: 0.5328 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [320/782] Loss: 0.5545 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [321/782] Loss: 0.4783 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [322/782] Loss: 0.4201 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [323/782] Loss: 0.4496 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [324/782] Loss: 0.5294 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [325/782] Loss: 0.3883 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [326/782] Loss: 0.6568 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [327/782] Loss: 0.5885 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [328/782] Loss: 0.4177 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [329/782] Loss: 0.3977 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [330/782] Loss: 0.4370 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [331/782] Loss: 0.5506 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [332/782] Loss: 0.4498 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [333/782] Loss: 0.6586 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [334/782] Loss: 0.4893 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [335/782] Loss: 0.4385 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [336/782] Loss: 0.5050 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [337/782] Loss: 0.5193 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [338/782] Loss: 0.5379 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [339/782] Loss: 0.7034 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [340/782] Loss: 0.3068 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [341/782] Loss: 0.4343 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [342/782] Loss: 0.5786 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [343/782] Loss: 0.4211 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [344/782] Loss: 0.6110 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [345/782] Loss: 0.5740 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [346/782] Loss: 0.5415 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [347/782] Loss: 0.5374 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [348/782] Loss: 0.4464 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [349/782] Loss: 0.4731 | Acc: 80.77%\n",
      "Train Epoch [68/100] Batch [350/782] Loss: 0.5908 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [351/782] Loss: 0.6117 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [352/782] Loss: 0.6149 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [353/782] Loss: 0.7529 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [354/782] Loss: 0.7315 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [355/782] Loss: 0.6326 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [356/782] Loss: 0.5724 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [357/782] Loss: 0.5830 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [358/782] Loss: 0.5086 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [359/782] Loss: 0.5654 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [360/782] Loss: 0.4586 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [361/782] Loss: 0.6522 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [362/782] Loss: 0.5063 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [363/782] Loss: 0.4917 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [364/782] Loss: 0.6675 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [365/782] Loss: 0.7696 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [366/782] Loss: 0.3891 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [367/782] Loss: 0.5617 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [368/782] Loss: 0.4727 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [369/782] Loss: 0.3023 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [370/782] Loss: 0.5986 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [371/782] Loss: 0.6121 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [372/782] Loss: 0.4701 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [373/782] Loss: 0.6659 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [374/782] Loss: 0.7253 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [375/782] Loss: 0.5558 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [376/782] Loss: 0.4852 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [377/782] Loss: 0.7421 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [378/782] Loss: 0.4821 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [379/782] Loss: 0.5120 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [380/782] Loss: 0.5206 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [381/782] Loss: 0.4118 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [382/782] Loss: 0.4124 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [383/782] Loss: 0.6262 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [384/782] Loss: 0.5532 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [385/782] Loss: 0.6080 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [386/782] Loss: 0.6230 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [387/782] Loss: 0.5220 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [388/782] Loss: 0.6588 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [389/782] Loss: 0.4580 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [390/782] Loss: 0.5574 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [391/782] Loss: 0.6322 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [392/782] Loss: 0.7001 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [393/782] Loss: 0.8273 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [394/782] Loss: 0.6729 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [395/782] Loss: 0.4509 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [396/782] Loss: 0.5863 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [397/782] Loss: 0.5718 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [398/782] Loss: 0.6604 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [399/782] Loss: 0.4258 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [400/782] Loss: 0.5812 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [401/782] Loss: 0.4063 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [402/782] Loss: 0.7634 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [403/782] Loss: 0.6025 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [404/782] Loss: 0.4567 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [405/782] Loss: 0.3607 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [406/782] Loss: 0.6089 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [407/782] Loss: 0.8925 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [408/782] Loss: 0.4578 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [409/782] Loss: 0.6435 | Acc: 80.54%\n",
      "Train Epoch [68/100] Batch [410/782] Loss: 0.4172 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [411/782] Loss: 0.3487 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [412/782] Loss: 0.5543 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [413/782] Loss: 0.4729 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [414/782] Loss: 0.4946 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [415/782] Loss: 0.4672 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [416/782] Loss: 0.6527 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [417/782] Loss: 0.4603 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [418/782] Loss: 0.8732 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [419/782] Loss: 0.5136 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [420/782] Loss: 0.7023 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [421/782] Loss: 0.4946 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [422/782] Loss: 0.5271 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [423/782] Loss: 0.3350 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [424/782] Loss: 0.5459 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [425/782] Loss: 0.6112 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [426/782] Loss: 0.6175 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [427/782] Loss: 0.5015 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [428/782] Loss: 0.6326 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [429/782] Loss: 0.5795 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [430/782] Loss: 0.4282 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [431/782] Loss: 0.5184 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [432/782] Loss: 0.5622 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [433/782] Loss: 0.5138 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [434/782] Loss: 0.5397 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [435/782] Loss: 0.5989 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [436/782] Loss: 0.4982 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [437/782] Loss: 0.6279 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [438/782] Loss: 0.5955 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [439/782] Loss: 0.5872 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [440/782] Loss: 0.6573 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [441/782] Loss: 0.4814 | Acc: 80.55%\n",
      "Train Epoch [68/100] Batch [442/782] Loss: 0.4729 | Acc: 80.56%\n",
      "Train Epoch [68/100] Batch [443/782] Loss: 0.5244 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [444/782] Loss: 0.4896 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [445/782] Loss: 0.7393 | Acc: 80.57%\n",
      "Train Epoch [68/100] Batch [446/782] Loss: 0.4648 | Acc: 80.58%\n",
      "Train Epoch [68/100] Batch [447/782] Loss: 0.4354 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [448/782] Loss: 0.5250 | Acc: 80.59%\n",
      "Train Epoch [68/100] Batch [449/782] Loss: 0.5474 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [450/782] Loss: 0.6788 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [451/782] Loss: 0.3327 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [452/782] Loss: 0.4895 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [453/782] Loss: 0.3841 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [454/782] Loss: 0.5747 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [455/782] Loss: 0.4754 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [456/782] Loss: 0.5236 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [457/782] Loss: 0.5117 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [458/782] Loss: 0.5234 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [459/782] Loss: 0.5573 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [460/782] Loss: 0.8422 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [461/782] Loss: 0.6449 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [462/782] Loss: 0.4944 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [463/782] Loss: 0.7782 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [464/782] Loss: 0.4651 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [465/782] Loss: 0.5051 | Acc: 80.64%\n",
      "Train Epoch [68/100] Batch [466/782] Loss: 0.4669 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [467/782] Loss: 0.3782 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [468/782] Loss: 0.5334 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [469/782] Loss: 0.6282 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [470/782] Loss: 0.5756 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [471/782] Loss: 0.5385 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [472/782] Loss: 0.6348 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [473/782] Loss: 0.6159 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [474/782] Loss: 0.5451 | Acc: 80.60%\n",
      "Train Epoch [68/100] Batch [475/782] Loss: 0.4630 | Acc: 80.61%\n",
      "Train Epoch [68/100] Batch [476/782] Loss: 0.3101 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [477/782] Loss: 0.5236 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [478/782] Loss: 0.6716 | Acc: 80.62%\n",
      "Train Epoch [68/100] Batch [479/782] Loss: 0.4863 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [480/782] Loss: 0.3964 | Acc: 80.63%\n",
      "Train Epoch [68/100] Batch [481/782] Loss: 0.4696 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [482/782] Loss: 0.7262 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [483/782] Loss: 0.3521 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [484/782] Loss: 0.5183 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [485/782] Loss: 0.5131 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [486/782] Loss: 0.4406 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [487/782] Loss: 0.6234 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [488/782] Loss: 0.3724 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [489/782] Loss: 0.3583 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [490/782] Loss: 0.5319 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [491/782] Loss: 0.6322 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [492/782] Loss: 0.4404 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [493/782] Loss: 0.6987 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [494/782] Loss: 0.4788 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [495/782] Loss: 0.5905 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [496/782] Loss: 0.3660 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [497/782] Loss: 0.3390 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [498/782] Loss: 0.3756 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [499/782] Loss: 0.6674 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [500/782] Loss: 0.5986 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [501/782] Loss: 0.4166 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [502/782] Loss: 0.4622 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [503/782] Loss: 0.6708 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [504/782] Loss: 0.4918 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [505/782] Loss: 0.5792 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [506/782] Loss: 0.4903 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [507/782] Loss: 0.4968 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [508/782] Loss: 0.3881 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [509/782] Loss: 0.6333 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [510/782] Loss: 0.5840 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [511/782] Loss: 0.6584 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [512/782] Loss: 0.5210 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [513/782] Loss: 0.5218 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [514/782] Loss: 0.3694 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [515/782] Loss: 0.4549 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [516/782] Loss: 0.4417 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [517/782] Loss: 0.5393 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [518/782] Loss: 0.3748 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [519/782] Loss: 0.4192 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [520/782] Loss: 0.5489 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [521/782] Loss: 0.6309 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [522/782] Loss: 0.4649 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [523/782] Loss: 0.7072 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [524/782] Loss: 0.5474 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [525/782] Loss: 0.6183 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [526/782] Loss: 0.5034 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [527/782] Loss: 0.5383 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [528/782] Loss: 0.5297 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [529/782] Loss: 0.3473 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [530/782] Loss: 0.7634 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [531/782] Loss: 0.7315 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [532/782] Loss: 0.4058 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [533/782] Loss: 0.4250 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [534/782] Loss: 0.3605 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [535/782] Loss: 0.6097 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [536/782] Loss: 0.3567 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [537/782] Loss: 0.5248 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [538/782] Loss: 0.4859 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [539/782] Loss: 0.5453 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [540/782] Loss: 0.3768 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [541/782] Loss: 0.5988 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [542/782] Loss: 0.5258 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [543/782] Loss: 0.5203 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [544/782] Loss: 0.5779 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [545/782] Loss: 0.4571 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [546/782] Loss: 0.4933 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [547/782] Loss: 0.5173 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [548/782] Loss: 0.6283 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [549/782] Loss: 0.4011 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [550/782] Loss: 0.6758 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [551/782] Loss: 0.5068 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [552/782] Loss: 0.6144 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [553/782] Loss: 0.4885 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [554/782] Loss: 0.4137 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [555/782] Loss: 0.3529 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [556/782] Loss: 0.6306 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [557/782] Loss: 0.6400 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [558/782] Loss: 0.4948 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [559/782] Loss: 0.4765 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [560/782] Loss: 0.5543 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [561/782] Loss: 0.5519 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [562/782] Loss: 0.5468 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [563/782] Loss: 0.5898 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [564/782] Loss: 0.6757 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [565/782] Loss: 0.4593 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [566/782] Loss: 0.4021 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [567/782] Loss: 0.3169 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [568/782] Loss: 0.5501 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [569/782] Loss: 0.5301 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [570/782] Loss: 0.4025 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [571/782] Loss: 0.5616 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [572/782] Loss: 0.4900 | Acc: 80.77%\n",
      "Train Epoch [68/100] Batch [573/782] Loss: 0.4123 | Acc: 80.77%\n",
      "Train Epoch [68/100] Batch [574/782] Loss: 0.5743 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [575/782] Loss: 0.5888 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [576/782] Loss: 0.7297 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [577/782] Loss: 0.4429 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [578/782] Loss: 0.6259 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [579/782] Loss: 0.6287 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [580/782] Loss: 0.5617 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [581/782] Loss: 0.6243 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [582/782] Loss: 0.4555 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [583/782] Loss: 0.3309 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [584/782] Loss: 0.3612 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [585/782] Loss: 0.4761 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [586/782] Loss: 0.7719 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [587/782] Loss: 0.5403 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [588/782] Loss: 0.8138 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [589/782] Loss: 0.4080 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [590/782] Loss: 0.5054 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [591/782] Loss: 0.5481 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [592/782] Loss: 0.4076 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [593/782] Loss: 0.5486 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [594/782] Loss: 0.6163 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [595/782] Loss: 0.4982 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [596/782] Loss: 0.4887 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [597/782] Loss: 0.4198 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [598/782] Loss: 0.4642 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [599/782] Loss: 0.6574 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [600/782] Loss: 0.4907 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [601/782] Loss: 0.5497 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [602/782] Loss: 0.5527 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [603/782] Loss: 0.7183 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [604/782] Loss: 0.6376 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [605/782] Loss: 0.3271 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [606/782] Loss: 0.6133 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [607/782] Loss: 0.6070 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [608/782] Loss: 0.5909 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [609/782] Loss: 0.3985 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [610/782] Loss: 0.5014 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [611/782] Loss: 0.5271 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [612/782] Loss: 0.5039 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [613/782] Loss: 0.5842 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [614/782] Loss: 0.5373 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [615/782] Loss: 0.3749 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [616/782] Loss: 0.3861 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [617/782] Loss: 0.4689 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [618/782] Loss: 0.5127 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [619/782] Loss: 0.8809 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [620/782] Loss: 0.5424 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [621/782] Loss: 0.6448 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [622/782] Loss: 0.8654 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [623/782] Loss: 0.7154 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [624/782] Loss: 0.5214 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [625/782] Loss: 0.7286 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [626/782] Loss: 0.4369 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [627/782] Loss: 0.5628 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [628/782] Loss: 0.5150 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [629/782] Loss: 0.4428 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [630/782] Loss: 0.6072 | Acc: 80.76%\n",
      "Train Epoch [68/100] Batch [631/782] Loss: 0.6183 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [632/782] Loss: 0.6160 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [633/782] Loss: 0.5573 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [634/782] Loss: 0.4743 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [635/782] Loss: 0.4453 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [636/782] Loss: 0.5618 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [637/782] Loss: 0.4629 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [638/782] Loss: 0.5235 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [639/782] Loss: 0.4407 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [640/782] Loss: 0.5834 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [641/782] Loss: 0.5733 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [642/782] Loss: 0.6324 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [643/782] Loss: 0.6665 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [644/782] Loss: 0.8560 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [645/782] Loss: 0.5007 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [646/782] Loss: 0.5599 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [647/782] Loss: 0.5459 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [648/782] Loss: 0.5783 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [649/782] Loss: 0.5274 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [650/782] Loss: 0.5415 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [651/782] Loss: 0.3803 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [652/782] Loss: 0.6003 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [653/782] Loss: 0.7516 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [654/782] Loss: 0.4892 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [655/782] Loss: 0.4278 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [656/782] Loss: 0.4342 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [657/782] Loss: 0.6300 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [658/782] Loss: 0.6177 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [659/782] Loss: 0.4421 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [660/782] Loss: 0.5000 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [661/782] Loss: 0.5892 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [662/782] Loss: 0.6503 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [663/782] Loss: 0.3724 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [664/782] Loss: 0.5238 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [665/782] Loss: 0.5329 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [666/782] Loss: 0.4267 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [667/782] Loss: 0.5125 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [668/782] Loss: 0.5780 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [669/782] Loss: 0.5911 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [670/782] Loss: 0.4014 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [671/782] Loss: 0.6135 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [672/782] Loss: 0.7231 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [673/782] Loss: 0.4837 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [674/782] Loss: 0.3793 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [675/782] Loss: 0.5206 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [676/782] Loss: 0.5911 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [677/782] Loss: 0.5823 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [678/782] Loss: 0.3652 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [679/782] Loss: 0.7897 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [680/782] Loss: 0.5519 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [681/782] Loss: 0.3369 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [682/782] Loss: 0.3688 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [683/782] Loss: 0.5699 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [684/782] Loss: 0.7684 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [685/782] Loss: 0.5394 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [686/782] Loss: 0.7486 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [687/782] Loss: 0.5994 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [688/782] Loss: 0.6182 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [689/782] Loss: 0.7339 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [690/782] Loss: 0.6286 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [691/782] Loss: 0.6750 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [692/782] Loss: 0.4755 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [693/782] Loss: 0.4429 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [694/782] Loss: 0.4336 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [695/782] Loss: 0.7887 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [696/782] Loss: 0.5597 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [697/782] Loss: 0.5823 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [698/782] Loss: 0.6483 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [699/782] Loss: 0.4942 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [700/782] Loss: 0.5335 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [701/782] Loss: 0.5031 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [702/782] Loss: 0.5574 | Acc: 80.65%\n",
      "Train Epoch [68/100] Batch [703/782] Loss: 0.4557 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [704/782] Loss: 0.6071 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [705/782] Loss: 0.3904 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [706/782] Loss: 0.5693 | Acc: 80.66%\n",
      "Train Epoch [68/100] Batch [707/782] Loss: 0.4557 | Acc: 80.67%\n",
      "Train Epoch [68/100] Batch [708/782] Loss: 0.5289 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [709/782] Loss: 0.4612 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [710/782] Loss: 0.3136 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [711/782] Loss: 0.5630 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [712/782] Loss: 0.4841 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [713/782] Loss: 0.6270 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [714/782] Loss: 0.4059 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [715/782] Loss: 0.4898 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [716/782] Loss: 0.4819 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [717/782] Loss: 0.7333 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [718/782] Loss: 0.5901 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [719/782] Loss: 0.5371 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [720/782] Loss: 0.3939 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [721/782] Loss: 0.4937 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [722/782] Loss: 0.5522 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [723/782] Loss: 0.4687 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [724/782] Loss: 0.4440 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [725/782] Loss: 0.4571 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [726/782] Loss: 0.7448 | Acc: 80.68%\n",
      "Train Epoch [68/100] Batch [727/782] Loss: 0.4961 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [728/782] Loss: 0.5105 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [729/782] Loss: 0.6418 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [730/782] Loss: 0.4661 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [731/782] Loss: 0.4856 | Acc: 80.69%\n",
      "Train Epoch [68/100] Batch [732/782] Loss: 0.3467 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [733/782] Loss: 0.3310 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [734/782] Loss: 0.3737 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [735/782] Loss: 0.7392 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [736/782] Loss: 0.6102 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [737/782] Loss: 0.7060 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [738/782] Loss: 0.4716 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [739/782] Loss: 0.5593 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [740/782] Loss: 0.4303 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [741/782] Loss: 0.6360 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [742/782] Loss: 0.6192 | Acc: 80.70%\n",
      "Train Epoch [68/100] Batch [743/782] Loss: 0.4797 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [744/782] Loss: 0.3969 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [745/782] Loss: 0.4420 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [746/782] Loss: 0.6692 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [747/782] Loss: 0.3282 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [748/782] Loss: 0.4574 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [749/782] Loss: 0.6656 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [750/782] Loss: 0.4428 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [751/782] Loss: 0.6011 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [752/782] Loss: 0.4001 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [753/782] Loss: 0.3770 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [754/782] Loss: 0.5609 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [755/782] Loss: 0.4760 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [756/782] Loss: 0.4539 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [757/782] Loss: 0.5041 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [758/782] Loss: 0.7628 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [759/782] Loss: 0.4006 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [760/782] Loss: 0.7078 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [761/782] Loss: 1.0341 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [762/782] Loss: 0.6913 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [763/782] Loss: 0.4777 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [764/782] Loss: 0.4799 | Acc: 80.71%\n",
      "Train Epoch [68/100] Batch [765/782] Loss: 0.4810 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [766/782] Loss: 0.5982 | Acc: 80.72%\n",
      "Train Epoch [68/100] Batch [767/782] Loss: 0.3361 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [768/782] Loss: 0.4027 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [769/782] Loss: 0.3740 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [770/782] Loss: 0.6609 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [771/782] Loss: 0.5180 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [772/782] Loss: 0.6397 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [773/782] Loss: 0.4127 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [774/782] Loss: 0.5807 | Acc: 80.73%\n",
      "Train Epoch [68/100] Batch [775/782] Loss: 0.4867 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [776/782] Loss: 0.5233 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [777/782] Loss: 0.5275 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [778/782] Loss: 0.6788 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [779/782] Loss: 0.6044 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [780/782] Loss: 0.4984 | Acc: 80.74%\n",
      "Train Epoch [68/100] Batch [781/782] Loss: 0.4883 | Acc: 80.75%\n",
      "Train Epoch [68/100] Batch [782/782] Loss: 0.1954 | Acc: 80.75%\n",
      "Epoch 68 completed in 30.14s.\n",
      "Test Epoch [68/100] Loss: 0.9246 | Acc: 72.23% | Inference Time: 8.18s\n",
      "Epoch 68 results saved to CSV.\n",
      "Epoch 69/100\n",
      "Train Epoch [69/100] Batch [1/782] Loss: 0.4887 | Acc: 84.38%\n",
      "Train Epoch [69/100] Batch [2/782] Loss: 0.5825 | Acc: 79.69%\n",
      "Train Epoch [69/100] Batch [3/782] Loss: 0.4776 | Acc: 80.73%\n",
      "Train Epoch [69/100] Batch [4/782] Loss: 0.3316 | Acc: 82.81%\n",
      "Train Epoch [69/100] Batch [5/782] Loss: 0.6646 | Acc: 82.50%\n",
      "Train Epoch [69/100] Batch [6/782] Loss: 0.6422 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [7/782] Loss: 0.6660 | Acc: 80.13%\n",
      "Train Epoch [69/100] Batch [8/782] Loss: 0.6889 | Acc: 79.30%\n",
      "Train Epoch [69/100] Batch [9/782] Loss: 0.5891 | Acc: 79.17%\n",
      "Train Epoch [69/100] Batch [10/782] Loss: 0.6507 | Acc: 78.75%\n",
      "Train Epoch [69/100] Batch [11/782] Loss: 0.8340 | Acc: 78.12%\n",
      "Train Epoch [69/100] Batch [12/782] Loss: 0.4372 | Acc: 78.65%\n",
      "Train Epoch [69/100] Batch [13/782] Loss: 0.5564 | Acc: 78.73%\n",
      "Train Epoch [69/100] Batch [14/782] Loss: 0.6499 | Acc: 78.79%\n",
      "Train Epoch [69/100] Batch [15/782] Loss: 0.5377 | Acc: 78.75%\n",
      "Train Epoch [69/100] Batch [16/782] Loss: 0.4637 | Acc: 78.81%\n",
      "Train Epoch [69/100] Batch [17/782] Loss: 0.4308 | Acc: 79.14%\n",
      "Train Epoch [69/100] Batch [18/782] Loss: 0.4356 | Acc: 79.43%\n",
      "Train Epoch [69/100] Batch [19/782] Loss: 0.4861 | Acc: 79.52%\n",
      "Train Epoch [69/100] Batch [20/782] Loss: 0.4961 | Acc: 79.61%\n",
      "Train Epoch [69/100] Batch [21/782] Loss: 0.4029 | Acc: 79.91%\n",
      "Train Epoch [69/100] Batch [22/782] Loss: 0.6251 | Acc: 79.62%\n",
      "Train Epoch [69/100] Batch [23/782] Loss: 0.5616 | Acc: 79.62%\n",
      "Train Epoch [69/100] Batch [24/782] Loss: 0.6701 | Acc: 79.49%\n",
      "Train Epoch [69/100] Batch [25/782] Loss: 0.4880 | Acc: 79.75%\n",
      "Train Epoch [69/100] Batch [26/782] Loss: 0.6263 | Acc: 79.75%\n",
      "Train Epoch [69/100] Batch [27/782] Loss: 0.8060 | Acc: 79.46%\n",
      "Train Epoch [69/100] Batch [28/782] Loss: 0.6477 | Acc: 79.58%\n",
      "Train Epoch [69/100] Batch [29/782] Loss: 0.5216 | Acc: 79.53%\n",
      "Train Epoch [69/100] Batch [30/782] Loss: 0.7202 | Acc: 79.48%\n",
      "Train Epoch [69/100] Batch [31/782] Loss: 0.6129 | Acc: 79.44%\n",
      "Train Epoch [69/100] Batch [32/782] Loss: 0.6503 | Acc: 79.44%\n",
      "Train Epoch [69/100] Batch [33/782] Loss: 0.8642 | Acc: 79.21%\n",
      "Train Epoch [69/100] Batch [34/782] Loss: 0.5417 | Acc: 79.23%\n",
      "Train Epoch [69/100] Batch [35/782] Loss: 0.5095 | Acc: 79.29%\n",
      "Train Epoch [69/100] Batch [36/782] Loss: 0.5723 | Acc: 79.30%\n",
      "Train Epoch [69/100] Batch [37/782] Loss: 0.5637 | Acc: 79.43%\n",
      "Train Epoch [69/100] Batch [38/782] Loss: 0.5549 | Acc: 79.40%\n",
      "Train Epoch [69/100] Batch [39/782] Loss: 0.4811 | Acc: 79.29%\n",
      "Train Epoch [69/100] Batch [40/782] Loss: 0.4401 | Acc: 79.34%\n",
      "Train Epoch [69/100] Batch [41/782] Loss: 0.3233 | Acc: 79.65%\n",
      "Train Epoch [69/100] Batch [42/782] Loss: 0.4623 | Acc: 79.72%\n",
      "Train Epoch [69/100] Batch [43/782] Loss: 0.4869 | Acc: 79.83%\n",
      "Train Epoch [69/100] Batch [44/782] Loss: 0.6182 | Acc: 79.83%\n",
      "Train Epoch [69/100] Batch [45/782] Loss: 0.5641 | Acc: 79.83%\n",
      "Train Epoch [69/100] Batch [46/782] Loss: 0.5988 | Acc: 79.79%\n",
      "Train Epoch [69/100] Batch [47/782] Loss: 0.6306 | Acc: 79.85%\n",
      "Train Epoch [69/100] Batch [48/782] Loss: 0.3864 | Acc: 80.05%\n",
      "Train Epoch [69/100] Batch [49/782] Loss: 0.5056 | Acc: 80.04%\n",
      "Train Epoch [69/100] Batch [50/782] Loss: 0.6175 | Acc: 80.00%\n",
      "Train Epoch [69/100] Batch [51/782] Loss: 0.5137 | Acc: 79.96%\n",
      "Train Epoch [69/100] Batch [52/782] Loss: 0.3551 | Acc: 80.02%\n",
      "Train Epoch [69/100] Batch [53/782] Loss: 0.4379 | Acc: 80.10%\n",
      "Train Epoch [69/100] Batch [54/782] Loss: 0.3276 | Acc: 80.30%\n",
      "Train Epoch [69/100] Batch [55/782] Loss: 0.6622 | Acc: 80.17%\n",
      "Train Epoch [69/100] Batch [56/782] Loss: 0.4526 | Acc: 80.22%\n",
      "Train Epoch [69/100] Batch [57/782] Loss: 0.3790 | Acc: 80.26%\n",
      "Train Epoch [69/100] Batch [58/782] Loss: 0.4081 | Acc: 80.36%\n",
      "Train Epoch [69/100] Batch [59/782] Loss: 0.5031 | Acc: 80.40%\n",
      "Train Epoch [69/100] Batch [60/782] Loss: 0.4387 | Acc: 80.42%\n",
      "Train Epoch [69/100] Batch [61/782] Loss: 0.5233 | Acc: 80.38%\n",
      "Train Epoch [69/100] Batch [62/782] Loss: 0.4711 | Acc: 80.42%\n",
      "Train Epoch [69/100] Batch [63/782] Loss: 0.5394 | Acc: 80.46%\n",
      "Train Epoch [69/100] Batch [64/782] Loss: 0.6484 | Acc: 80.40%\n",
      "Train Epoch [69/100] Batch [65/782] Loss: 0.4344 | Acc: 80.36%\n",
      "Train Epoch [69/100] Batch [66/782] Loss: 0.5067 | Acc: 80.35%\n",
      "Train Epoch [69/100] Batch [67/782] Loss: 0.6467 | Acc: 80.36%\n",
      "Train Epoch [69/100] Batch [68/782] Loss: 0.4135 | Acc: 80.40%\n",
      "Train Epoch [69/100] Batch [69/782] Loss: 0.3924 | Acc: 80.46%\n",
      "Train Epoch [69/100] Batch [70/782] Loss: 0.4962 | Acc: 80.49%\n",
      "Train Epoch [69/100] Batch [71/782] Loss: 0.7695 | Acc: 80.35%\n",
      "Train Epoch [69/100] Batch [72/782] Loss: 0.3444 | Acc: 80.47%\n",
      "Train Epoch [69/100] Batch [73/782] Loss: 0.5708 | Acc: 80.46%\n",
      "Train Epoch [69/100] Batch [74/782] Loss: 0.5533 | Acc: 80.47%\n",
      "Train Epoch [69/100] Batch [75/782] Loss: 0.5543 | Acc: 80.48%\n",
      "Train Epoch [69/100] Batch [76/782] Loss: 0.5091 | Acc: 80.53%\n",
      "Train Epoch [69/100] Batch [77/782] Loss: 0.3047 | Acc: 80.64%\n",
      "Train Epoch [69/100] Batch [78/782] Loss: 0.4438 | Acc: 80.59%\n",
      "Train Epoch [69/100] Batch [79/782] Loss: 0.3629 | Acc: 80.66%\n",
      "Train Epoch [69/100] Batch [80/782] Loss: 0.3845 | Acc: 80.72%\n",
      "Train Epoch [69/100] Batch [81/782] Loss: 0.4857 | Acc: 80.71%\n",
      "Train Epoch [69/100] Batch [82/782] Loss: 0.6319 | Acc: 80.70%\n",
      "Train Epoch [69/100] Batch [83/782] Loss: 0.6247 | Acc: 80.67%\n",
      "Train Epoch [69/100] Batch [84/782] Loss: 0.6535 | Acc: 80.62%\n",
      "Train Epoch [69/100] Batch [85/782] Loss: 0.6936 | Acc: 80.61%\n",
      "Train Epoch [69/100] Batch [86/782] Loss: 0.5006 | Acc: 80.67%\n",
      "Train Epoch [69/100] Batch [87/782] Loss: 0.3641 | Acc: 80.77%\n",
      "Train Epoch [69/100] Batch [88/782] Loss: 0.5324 | Acc: 80.75%\n",
      "Train Epoch [69/100] Batch [89/782] Loss: 0.5281 | Acc: 80.76%\n",
      "Train Epoch [69/100] Batch [90/782] Loss: 0.6787 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [91/782] Loss: 0.4263 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [92/782] Loss: 0.6374 | Acc: 80.77%\n",
      "Train Epoch [69/100] Batch [93/782] Loss: 0.4972 | Acc: 80.76%\n",
      "Train Epoch [69/100] Batch [94/782] Loss: 0.5509 | Acc: 80.75%\n",
      "Train Epoch [69/100] Batch [95/782] Loss: 0.3182 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [96/782] Loss: 0.6099 | Acc: 80.78%\n",
      "Train Epoch [69/100] Batch [97/782] Loss: 0.4682 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [98/782] Loss: 0.5018 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [99/782] Loss: 0.2595 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [100/782] Loss: 0.6561 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [101/782] Loss: 0.6287 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [102/782] Loss: 0.4428 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [103/782] Loss: 0.4139 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [104/782] Loss: 0.3789 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [105/782] Loss: 0.4185 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [106/782] Loss: 0.6622 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [107/782] Loss: 0.6395 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [108/782] Loss: 0.5639 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [109/782] Loss: 0.5533 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [110/782] Loss: 0.6056 | Acc: 80.78%\n",
      "Train Epoch [69/100] Batch [111/782] Loss: 0.5633 | Acc: 80.81%\n",
      "Train Epoch [69/100] Batch [112/782] Loss: 0.5768 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [113/782] Loss: 0.6711 | Acc: 80.77%\n",
      "Train Epoch [69/100] Batch [114/782] Loss: 0.5186 | Acc: 80.78%\n",
      "Train Epoch [69/100] Batch [115/782] Loss: 0.5224 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [116/782] Loss: 0.4324 | Acc: 80.81%\n",
      "Train Epoch [69/100] Batch [117/782] Loss: 0.3421 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [118/782] Loss: 0.5147 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [119/782] Loss: 0.5010 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [120/782] Loss: 0.5129 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [121/782] Loss: 0.4230 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [122/782] Loss: 0.6664 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [123/782] Loss: 0.5115 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [124/782] Loss: 0.5892 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [125/782] Loss: 0.4116 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [126/782] Loss: 0.6196 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [127/782] Loss: 0.4389 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [128/782] Loss: 0.5159 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [129/782] Loss: 0.6140 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [130/782] Loss: 0.5363 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [131/782] Loss: 0.3826 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [132/782] Loss: 0.4753 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [133/782] Loss: 0.3690 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [134/782] Loss: 0.5814 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [135/782] Loss: 0.6040 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [136/782] Loss: 0.5443 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [137/782] Loss: 0.2637 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [138/782] Loss: 0.7214 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [139/782] Loss: 0.5391 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [140/782] Loss: 0.2884 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [141/782] Loss: 0.5821 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [142/782] Loss: 0.3872 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [143/782] Loss: 0.7129 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [144/782] Loss: 0.8509 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [145/782] Loss: 0.4834 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [146/782] Loss: 0.4271 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [147/782] Loss: 0.4867 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [148/782] Loss: 0.7310 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [149/782] Loss: 0.4748 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [150/782] Loss: 0.5134 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [151/782] Loss: 0.3668 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [152/782] Loss: 0.5242 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [153/782] Loss: 0.4756 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [154/782] Loss: 0.4018 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [155/782] Loss: 0.3983 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [156/782] Loss: 0.6126 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [157/782] Loss: 0.4885 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [158/782] Loss: 0.5089 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [159/782] Loss: 0.5821 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [160/782] Loss: 0.5045 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [161/782] Loss: 0.4711 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [162/782] Loss: 0.6196 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [163/782] Loss: 0.6809 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [164/782] Loss: 0.5830 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [165/782] Loss: 0.3191 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [166/782] Loss: 0.4535 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [167/782] Loss: 0.5592 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [168/782] Loss: 0.4353 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [169/782] Loss: 0.5084 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [170/782] Loss: 0.4717 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [171/782] Loss: 0.7171 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [172/782] Loss: 0.6399 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [173/782] Loss: 0.5007 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [174/782] Loss: 0.4654 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [175/782] Loss: 0.4808 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [176/782] Loss: 0.5494 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [177/782] Loss: 0.6082 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [178/782] Loss: 0.4104 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [179/782] Loss: 0.4652 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [180/782] Loss: 0.5289 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [181/782] Loss: 0.6074 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [182/782] Loss: 0.4257 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [183/782] Loss: 0.4617 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [184/782] Loss: 0.6189 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [185/782] Loss: 0.4612 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [186/782] Loss: 0.4714 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [187/782] Loss: 0.5560 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [188/782] Loss: 0.6110 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [189/782] Loss: 0.2544 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [190/782] Loss: 0.6437 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [191/782] Loss: 0.5657 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [192/782] Loss: 0.5116 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [193/782] Loss: 0.3555 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [194/782] Loss: 0.3998 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [195/782] Loss: 0.7050 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [196/782] Loss: 0.7328 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [197/782] Loss: 0.4399 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [198/782] Loss: 0.4435 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [199/782] Loss: 0.7297 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [200/782] Loss: 0.6583 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [201/782] Loss: 0.4758 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [202/782] Loss: 0.5035 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [203/782] Loss: 0.4509 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [204/782] Loss: 0.4928 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [205/782] Loss: 0.6280 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [206/782] Loss: 0.4998 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [207/782] Loss: 0.6712 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [208/782] Loss: 0.5480 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [209/782] Loss: 0.5356 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [210/782] Loss: 0.4732 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [211/782] Loss: 0.2678 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [212/782] Loss: 0.6029 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [213/782] Loss: 0.5497 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [214/782] Loss: 0.5469 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [215/782] Loss: 0.6425 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [216/782] Loss: 0.6277 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [217/782] Loss: 0.5534 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [218/782] Loss: 0.4914 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [219/782] Loss: 0.4201 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [220/782] Loss: 0.5281 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [221/782] Loss: 0.4165 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [222/782] Loss: 1.0330 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [223/782] Loss: 0.3521 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [224/782] Loss: 0.6645 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [225/782] Loss: 0.5410 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [226/782] Loss: 0.6846 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [227/782] Loss: 0.5037 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [228/782] Loss: 0.4914 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [229/782] Loss: 0.5761 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [230/782] Loss: 0.6406 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [231/782] Loss: 0.5673 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [232/782] Loss: 0.6131 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [233/782] Loss: 0.5563 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [234/782] Loss: 0.5838 | Acc: 80.83%\n",
      "Train Epoch [69/100] Batch [235/782] Loss: 0.5017 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [236/782] Loss: 0.4077 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [237/782] Loss: 0.4105 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [238/782] Loss: 0.5586 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [239/782] Loss: 0.5336 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [240/782] Loss: 0.4856 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [241/782] Loss: 0.4945 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [242/782] Loss: 0.4739 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [243/782] Loss: 0.5844 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [244/782] Loss: 0.5149 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [245/782] Loss: 0.5623 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [246/782] Loss: 0.5177 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [247/782] Loss: 0.5070 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [248/782] Loss: 0.6516 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [249/782] Loss: 0.3764 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [250/782] Loss: 0.5251 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [251/782] Loss: 0.3703 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [252/782] Loss: 0.5778 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [253/782] Loss: 0.6314 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [254/782] Loss: 0.2625 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [255/782] Loss: 0.5045 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [256/782] Loss: 0.5768 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [257/782] Loss: 0.6367 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [258/782] Loss: 0.5693 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [259/782] Loss: 0.6990 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [260/782] Loss: 0.4601 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [261/782] Loss: 0.3256 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [262/782] Loss: 0.4156 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [263/782] Loss: 0.4348 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [264/782] Loss: 0.4269 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [265/782] Loss: 0.4317 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [266/782] Loss: 0.3983 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [267/782] Loss: 0.4970 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [268/782] Loss: 0.5573 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [269/782] Loss: 0.6016 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [270/782] Loss: 0.5436 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [271/782] Loss: 0.5984 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [272/782] Loss: 0.6723 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [273/782] Loss: 0.6989 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [274/782] Loss: 0.5223 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [275/782] Loss: 0.4228 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [276/782] Loss: 0.5291 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [277/782] Loss: 0.5326 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [278/782] Loss: 0.6992 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [279/782] Loss: 0.4830 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [280/782] Loss: 0.5659 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [281/782] Loss: 0.5511 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [282/782] Loss: 0.5794 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [283/782] Loss: 0.6580 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [284/782] Loss: 0.6658 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [285/782] Loss: 0.3231 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [286/782] Loss: 0.6049 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [287/782] Loss: 0.6876 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [288/782] Loss: 0.6555 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [289/782] Loss: 0.7943 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [290/782] Loss: 0.3635 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [291/782] Loss: 0.6758 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [292/782] Loss: 0.4788 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [293/782] Loss: 0.4486 | Acc: 80.82%\n",
      "Train Epoch [69/100] Batch [294/782] Loss: 0.4154 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [295/782] Loss: 0.7597 | Acc: 80.83%\n",
      "Train Epoch [69/100] Batch [296/782] Loss: 0.6954 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [297/782] Loss: 0.4202 | Acc: 80.81%\n",
      "Train Epoch [69/100] Batch [298/782] Loss: 0.5283 | Acc: 80.80%\n",
      "Train Epoch [69/100] Batch [299/782] Loss: 0.5215 | Acc: 80.81%\n",
      "Train Epoch [69/100] Batch [300/782] Loss: 0.4747 | Acc: 80.83%\n",
      "Train Epoch [69/100] Batch [301/782] Loss: 0.5395 | Acc: 80.83%\n",
      "Train Epoch [69/100] Batch [302/782] Loss: 0.3544 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [303/782] Loss: 0.4598 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [304/782] Loss: 0.5837 | Acc: 80.86%\n",
      "Train Epoch [69/100] Batch [305/782] Loss: 0.8370 | Acc: 80.84%\n",
      "Train Epoch [69/100] Batch [306/782] Loss: 0.3218 | Acc: 80.85%\n",
      "Train Epoch [69/100] Batch [307/782] Loss: 0.5079 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [308/782] Loss: 0.5796 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [309/782] Loss: 0.2721 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [310/782] Loss: 0.5156 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [311/782] Loss: 0.5106 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [312/782] Loss: 0.4784 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [313/782] Loss: 0.3504 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [314/782] Loss: 0.3239 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [315/782] Loss: 0.5172 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [316/782] Loss: 0.5778 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [317/782] Loss: 0.6645 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [318/782] Loss: 0.3312 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [319/782] Loss: 0.4315 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [320/782] Loss: 0.5778 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [321/782] Loss: 0.4243 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [322/782] Loss: 0.4496 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [323/782] Loss: 0.6412 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [324/782] Loss: 0.4540 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [325/782] Loss: 0.5318 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [326/782] Loss: 0.4641 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [327/782] Loss: 0.3575 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [328/782] Loss: 0.5173 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [329/782] Loss: 0.5999 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [330/782] Loss: 0.7594 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [331/782] Loss: 0.7190 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [332/782] Loss: 0.5692 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [333/782] Loss: 0.4857 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [334/782] Loss: 0.6151 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [335/782] Loss: 0.3676 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [336/782] Loss: 0.4628 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [337/782] Loss: 0.4448 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [338/782] Loss: 0.5080 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [339/782] Loss: 0.7478 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [340/782] Loss: 0.5806 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [341/782] Loss: 0.4615 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [342/782] Loss: 0.6249 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [343/782] Loss: 0.4676 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [344/782] Loss: 0.6025 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [345/782] Loss: 0.2967 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [346/782] Loss: 0.4355 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [347/782] Loss: 0.4882 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [348/782] Loss: 0.3919 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [349/782] Loss: 0.3740 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [350/782] Loss: 0.5947 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [351/782] Loss: 0.5249 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [352/782] Loss: 0.6932 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [353/782] Loss: 0.3861 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [354/782] Loss: 0.4706 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [355/782] Loss: 0.3246 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [356/782] Loss: 0.6160 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [357/782] Loss: 0.4602 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [358/782] Loss: 0.5432 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [359/782] Loss: 0.4591 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [360/782] Loss: 0.4656 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [361/782] Loss: 0.8239 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [362/782] Loss: 0.5894 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [363/782] Loss: 0.6727 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [364/782] Loss: 0.4985 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [365/782] Loss: 0.3698 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [366/782] Loss: 0.4409 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [367/782] Loss: 0.4231 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [368/782] Loss: 0.8761 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [369/782] Loss: 0.6590 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [370/782] Loss: 0.4591 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [371/782] Loss: 0.3921 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [372/782] Loss: 0.4176 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [373/782] Loss: 0.7568 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [374/782] Loss: 0.4687 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [375/782] Loss: 0.4541 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [376/782] Loss: 0.6501 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [377/782] Loss: 0.5922 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [378/782] Loss: 0.4797 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [379/782] Loss: 0.3842 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [380/782] Loss: 0.4528 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [381/782] Loss: 0.5488 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [382/782] Loss: 0.3357 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [383/782] Loss: 0.5990 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [384/782] Loss: 0.4167 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [385/782] Loss: 0.5636 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [386/782] Loss: 0.6713 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [387/782] Loss: 0.5763 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [388/782] Loss: 0.4959 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [389/782] Loss: 0.6007 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [390/782] Loss: 0.6406 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [391/782] Loss: 0.4399 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [392/782] Loss: 0.4929 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [393/782] Loss: 0.5955 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [394/782] Loss: 0.6153 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [395/782] Loss: 0.7040 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [396/782] Loss: 0.4654 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [397/782] Loss: 0.3681 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [398/782] Loss: 0.7456 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [399/782] Loss: 0.6411 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [400/782] Loss: 0.3646 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [401/782] Loss: 0.3433 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [402/782] Loss: 0.6518 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [403/782] Loss: 0.3886 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [404/782] Loss: 0.5401 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [405/782] Loss: 0.4624 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [406/782] Loss: 0.5221 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [407/782] Loss: 0.4956 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [408/782] Loss: 0.5719 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [409/782] Loss: 0.4299 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [410/782] Loss: 0.4159 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [411/782] Loss: 0.5088 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [412/782] Loss: 0.8785 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [413/782] Loss: 0.6294 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [414/782] Loss: 0.3965 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [415/782] Loss: 0.5734 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [416/782] Loss: 0.4331 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [417/782] Loss: 0.4194 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [418/782] Loss: 0.4188 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [419/782] Loss: 0.6168 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [420/782] Loss: 0.5965 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [421/782] Loss: 0.3265 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [422/782] Loss: 0.5508 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [423/782] Loss: 0.4783 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [424/782] Loss: 0.4949 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [425/782] Loss: 0.4159 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [426/782] Loss: 0.3589 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [427/782] Loss: 0.6349 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [428/782] Loss: 0.4037 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [429/782] Loss: 0.5825 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [430/782] Loss: 0.5291 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [431/782] Loss: 0.4738 | Acc: 81.15%\n",
      "Train Epoch [69/100] Batch [432/782] Loss: 0.8548 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [433/782] Loss: 0.8093 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [434/782] Loss: 0.4433 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [435/782] Loss: 0.4730 | Acc: 81.10%\n",
      "Train Epoch [69/100] Batch [436/782] Loss: 0.5021 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [437/782] Loss: 0.4795 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [438/782] Loss: 0.5572 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [439/782] Loss: 0.4977 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [440/782] Loss: 0.5926 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [441/782] Loss: 0.4192 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [442/782] Loss: 0.6227 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [443/782] Loss: 0.5324 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [444/782] Loss: 0.4133 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [445/782] Loss: 0.5378 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [446/782] Loss: 0.4419 | Acc: 81.15%\n",
      "Train Epoch [69/100] Batch [447/782] Loss: 0.3966 | Acc: 81.16%\n",
      "Train Epoch [69/100] Batch [448/782] Loss: 0.5773 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [449/782] Loss: 0.6215 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [450/782] Loss: 0.6087 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [451/782] Loss: 0.7704 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [452/782] Loss: 0.3596 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [453/782] Loss: 0.5907 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [454/782] Loss: 0.4567 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [455/782] Loss: 0.6350 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [456/782] Loss: 0.5587 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [457/782] Loss: 0.3746 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [458/782] Loss: 0.5818 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [459/782] Loss: 0.6417 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [460/782] Loss: 0.5151 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [461/782] Loss: 0.6586 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [462/782] Loss: 0.4363 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [463/782] Loss: 0.3113 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [464/782] Loss: 0.3932 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [465/782] Loss: 0.4066 | Acc: 81.12%\n",
      "Train Epoch [69/100] Batch [466/782] Loss: 0.4071 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [467/782] Loss: 0.7029 | Acc: 81.14%\n",
      "Train Epoch [69/100] Batch [468/782] Loss: 0.5284 | Acc: 81.13%\n",
      "Train Epoch [69/100] Batch [469/782] Loss: 0.7273 | Acc: 81.11%\n",
      "Train Epoch [69/100] Batch [470/782] Loss: 0.6596 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [471/782] Loss: 0.6006 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [472/782] Loss: 0.5126 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [473/782] Loss: 0.6067 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [474/782] Loss: 0.4491 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [475/782] Loss: 0.4191 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [476/782] Loss: 0.5504 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [477/782] Loss: 0.4279 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [478/782] Loss: 0.4815 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [479/782] Loss: 0.5180 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [480/782] Loss: 0.5627 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [481/782] Loss: 0.6537 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [482/782] Loss: 0.5117 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [483/782] Loss: 0.5016 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [484/782] Loss: 0.7547 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [485/782] Loss: 0.5602 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [486/782] Loss: 0.4168 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [487/782] Loss: 0.5265 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [488/782] Loss: 0.4477 | Acc: 81.09%\n",
      "Train Epoch [69/100] Batch [489/782] Loss: 0.6432 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [490/782] Loss: 0.3912 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [491/782] Loss: 0.4707 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [492/782] Loss: 0.6038 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [493/782] Loss: 0.6739 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [494/782] Loss: 0.6448 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [495/782] Loss: 0.7379 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [496/782] Loss: 0.4564 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [497/782] Loss: 0.4983 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [498/782] Loss: 0.5077 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [499/782] Loss: 0.5946 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [500/782] Loss: 0.6501 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [501/782] Loss: 0.5986 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [502/782] Loss: 0.6567 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [503/782] Loss: 0.4446 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [504/782] Loss: 0.3827 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [505/782] Loss: 0.3817 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [506/782] Loss: 0.5719 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [507/782] Loss: 0.4619 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [508/782] Loss: 0.5368 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [509/782] Loss: 0.6090 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [510/782] Loss: 0.5245 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [511/782] Loss: 0.5883 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [512/782] Loss: 0.5226 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [513/782] Loss: 0.5839 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [514/782] Loss: 0.5452 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [515/782] Loss: 0.4742 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [516/782] Loss: 0.4116 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [517/782] Loss: 0.3413 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [518/782] Loss: 0.4512 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [519/782] Loss: 0.6256 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [520/782] Loss: 0.4651 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [521/782] Loss: 0.5590 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [522/782] Loss: 0.4049 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [523/782] Loss: 0.3963 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [524/782] Loss: 0.4709 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [525/782] Loss: 0.5687 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [526/782] Loss: 0.5233 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [527/782] Loss: 0.4389 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [528/782] Loss: 0.4922 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [529/782] Loss: 0.4759 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [530/782] Loss: 0.4007 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [531/782] Loss: 0.4870 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [532/782] Loss: 0.4441 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [533/782] Loss: 0.5932 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [534/782] Loss: 0.6376 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [535/782] Loss: 0.6091 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [536/782] Loss: 0.4983 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [537/782] Loss: 0.5876 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [538/782] Loss: 0.4986 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [539/782] Loss: 0.4934 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [540/782] Loss: 0.4210 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [541/782] Loss: 0.6241 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [542/782] Loss: 0.6892 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [543/782] Loss: 0.5578 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [544/782] Loss: 0.4232 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [545/782] Loss: 0.5439 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [546/782] Loss: 0.5406 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [547/782] Loss: 0.5168 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [548/782] Loss: 0.5490 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [549/782] Loss: 0.5785 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [550/782] Loss: 0.4113 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [551/782] Loss: 0.6077 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [552/782] Loss: 0.5522 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [553/782] Loss: 0.6022 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [554/782] Loss: 0.5858 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [555/782] Loss: 0.4949 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [556/782] Loss: 0.5073 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [557/782] Loss: 0.4647 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [558/782] Loss: 0.5057 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [559/782] Loss: 0.4568 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [560/782] Loss: 0.6413 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [561/782] Loss: 0.5444 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [562/782] Loss: 0.5058 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [563/782] Loss: 0.6429 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [564/782] Loss: 0.5760 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [565/782] Loss: 0.5938 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [566/782] Loss: 0.4770 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [567/782] Loss: 0.6501 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [568/782] Loss: 0.6214 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [569/782] Loss: 0.5070 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [570/782] Loss: 0.5006 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [571/782] Loss: 0.5614 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [572/782] Loss: 0.4710 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [573/782] Loss: 0.6525 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [574/782] Loss: 0.6298 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [575/782] Loss: 0.6387 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [576/782] Loss: 0.5831 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [577/782] Loss: 0.3986 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [578/782] Loss: 0.4459 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [579/782] Loss: 0.5056 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [580/782] Loss: 0.3937 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [581/782] Loss: 0.5729 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [582/782] Loss: 0.5945 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [583/782] Loss: 0.4361 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [584/782] Loss: 0.5576 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [585/782] Loss: 0.3810 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [586/782] Loss: 0.5060 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [587/782] Loss: 0.5107 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [588/782] Loss: 0.6499 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [589/782] Loss: 0.5626 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [590/782] Loss: 0.6148 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [591/782] Loss: 0.5062 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [592/782] Loss: 0.7523 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [593/782] Loss: 0.4593 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [594/782] Loss: 0.5604 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [595/782] Loss: 0.5348 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [596/782] Loss: 0.4007 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [597/782] Loss: 0.5550 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [598/782] Loss: 0.5154 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [599/782] Loss: 0.5346 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [600/782] Loss: 0.3595 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [601/782] Loss: 0.5517 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [602/782] Loss: 0.3541 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [603/782] Loss: 0.5456 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [604/782] Loss: 0.5079 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [605/782] Loss: 0.7321 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [606/782] Loss: 0.4850 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [607/782] Loss: 0.4315 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [608/782] Loss: 0.4671 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [609/782] Loss: 0.4896 | Acc: 81.08%\n",
      "Train Epoch [69/100] Batch [610/782] Loss: 0.5899 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [611/782] Loss: 0.4964 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [612/782] Loss: 0.6575 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [613/782] Loss: 0.6515 | Acc: 81.06%\n",
      "Train Epoch [69/100] Batch [614/782] Loss: 0.5460 | Acc: 81.07%\n",
      "Train Epoch [69/100] Batch [615/782] Loss: 0.6394 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [616/782] Loss: 0.4740 | Acc: 81.05%\n",
      "Train Epoch [69/100] Batch [617/782] Loss: 0.7024 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [618/782] Loss: 0.5322 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [619/782] Loss: 0.5560 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [620/782] Loss: 0.7436 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [621/782] Loss: 0.5446 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [622/782] Loss: 0.4593 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [623/782] Loss: 0.5363 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [624/782] Loss: 0.7768 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [625/782] Loss: 0.3735 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [626/782] Loss: 0.5653 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [627/782] Loss: 0.5003 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [628/782] Loss: 0.5564 | Acc: 81.04%\n",
      "Train Epoch [69/100] Batch [629/782] Loss: 0.5731 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [630/782] Loss: 0.5642 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [631/782] Loss: 0.6423 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [632/782] Loss: 0.5487 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [633/782] Loss: 0.4245 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [634/782] Loss: 0.5636 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [635/782] Loss: 0.6151 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [636/782] Loss: 0.4026 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [637/782] Loss: 0.5210 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [638/782] Loss: 0.4641 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [639/782] Loss: 0.5690 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [640/782] Loss: 0.5805 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [641/782] Loss: 0.5578 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [642/782] Loss: 0.5049 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [643/782] Loss: 0.4275 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [644/782] Loss: 0.5891 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [645/782] Loss: 0.4447 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [646/782] Loss: 0.5118 | Acc: 81.03%\n",
      "Train Epoch [69/100] Batch [647/782] Loss: 0.7691 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [648/782] Loss: 0.6009 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [649/782] Loss: 0.5886 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [650/782] Loss: 0.4826 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [651/782] Loss: 0.4383 | Acc: 81.02%\n",
      "Train Epoch [69/100] Batch [652/782] Loss: 0.6687 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [653/782] Loss: 0.4508 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [654/782] Loss: 0.5662 | Acc: 81.01%\n",
      "Train Epoch [69/100] Batch [655/782] Loss: 0.6315 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [656/782] Loss: 0.6617 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [657/782] Loss: 0.3859 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [658/782] Loss: 0.3746 | Acc: 81.00%\n",
      "Train Epoch [69/100] Batch [659/782] Loss: 0.6057 | Acc: 80.99%\n",
      "Train Epoch [69/100] Batch [660/782] Loss: 0.5445 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [661/782] Loss: 0.4777 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [662/782] Loss: 0.3809 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [663/782] Loss: 0.6109 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [664/782] Loss: 0.5686 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [665/782] Loss: 0.3791 | Acc: 80.98%\n",
      "Train Epoch [69/100] Batch [666/782] Loss: 0.6301 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [667/782] Loss: 0.4266 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [668/782] Loss: 0.6067 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [669/782] Loss: 0.5527 | Acc: 80.97%\n",
      "Train Epoch [69/100] Batch [670/782] Loss: 0.5594 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [671/782] Loss: 0.4671 | Acc: 80.96%\n",
      "Train Epoch [69/100] Batch [672/782] Loss: 0.6892 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [673/782] Loss: 0.6659 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [674/782] Loss: 0.6372 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [675/782] Loss: 0.6261 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [676/782] Loss: 0.5469 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [677/782] Loss: 0.5867 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [678/782] Loss: 0.5706 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [679/782] Loss: 0.3272 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [680/782] Loss: 0.6429 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [681/782] Loss: 0.6684 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [682/782] Loss: 0.5171 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [683/782] Loss: 0.5005 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [684/782] Loss: 0.5231 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [685/782] Loss: 0.4731 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [686/782] Loss: 0.3868 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [687/782] Loss: 0.6536 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [688/782] Loss: 0.5337 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [689/782] Loss: 0.5666 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [690/782] Loss: 0.5246 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [691/782] Loss: 0.5739 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [692/782] Loss: 0.5755 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [693/782] Loss: 0.4816 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [694/782] Loss: 0.8770 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [695/782] Loss: 0.6583 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [696/782] Loss: 0.6518 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [697/782] Loss: 0.4904 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [698/782] Loss: 0.5362 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [699/782] Loss: 0.7283 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [700/782] Loss: 0.4147 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [701/782] Loss: 0.7045 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [702/782] Loss: 0.5446 | Acc: 80.87%\n",
      "Train Epoch [69/100] Batch [703/782] Loss: 0.4322 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [704/782] Loss: 0.6447 | Acc: 80.88%\n",
      "Train Epoch [69/100] Batch [705/782] Loss: 0.4669 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [706/782] Loss: 0.4164 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [707/782] Loss: 0.4363 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [708/782] Loss: 0.7367 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [709/782] Loss: 0.5826 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [710/782] Loss: 0.4975 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [711/782] Loss: 0.4266 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [712/782] Loss: 0.5298 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [713/782] Loss: 0.4994 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [714/782] Loss: 0.5482 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [715/782] Loss: 0.5673 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [716/782] Loss: 0.4187 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [717/782] Loss: 0.4289 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [718/782] Loss: 0.5066 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [719/782] Loss: 0.4893 | Acc: 80.89%\n",
      "Train Epoch [69/100] Batch [720/782] Loss: 0.3573 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [721/782] Loss: 0.3383 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [722/782] Loss: 0.3907 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [723/782] Loss: 0.4789 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [724/782] Loss: 0.4548 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [725/782] Loss: 0.4829 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [726/782] Loss: 0.6933 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [727/782] Loss: 0.6160 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [728/782] Loss: 0.4261 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [729/782] Loss: 0.5704 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [730/782] Loss: 0.4026 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [731/782] Loss: 0.5483 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [732/782] Loss: 0.4694 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [733/782] Loss: 0.7249 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [734/782] Loss: 0.5540 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [735/782] Loss: 0.5616 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [736/782] Loss: 0.5216 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [737/782] Loss: 0.2929 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [738/782] Loss: 0.5000 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [739/782] Loss: 0.4442 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [740/782] Loss: 0.5827 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [741/782] Loss: 0.3043 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [742/782] Loss: 0.6358 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [743/782] Loss: 0.5670 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [744/782] Loss: 0.4755 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [745/782] Loss: 0.6183 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [746/782] Loss: 0.5358 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [747/782] Loss: 0.6570 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [748/782] Loss: 0.4658 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [749/782] Loss: 0.5847 | Acc: 80.90%\n",
      "Train Epoch [69/100] Batch [750/782] Loss: 0.3857 | Acc: 80.91%\n",
      "Train Epoch [69/100] Batch [751/782] Loss: 0.3712 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [752/782] Loss: 0.3263 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [753/782] Loss: 0.4386 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [754/782] Loss: 0.5058 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [755/782] Loss: 0.4227 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [756/782] Loss: 0.5999 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [757/782] Loss: 0.5135 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [758/782] Loss: 0.3691 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [759/782] Loss: 0.7374 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [760/782] Loss: 0.3938 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [761/782] Loss: 0.3177 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [762/782] Loss: 0.6872 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [763/782] Loss: 0.4443 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [764/782] Loss: 0.4766 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [765/782] Loss: 0.4372 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [766/782] Loss: 0.4691 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [767/782] Loss: 0.6377 | Acc: 80.95%\n",
      "Train Epoch [69/100] Batch [768/782] Loss: 0.7013 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [769/782] Loss: 0.5882 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [770/782] Loss: 0.3623 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [771/782] Loss: 0.4563 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [772/782] Loss: 0.5499 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [773/782] Loss: 0.4976 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [774/782] Loss: 0.5794 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [775/782] Loss: 0.7069 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [776/782] Loss: 0.5043 | Acc: 80.92%\n",
      "Train Epoch [69/100] Batch [777/782] Loss: 0.4886 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [778/782] Loss: 0.6422 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [779/782] Loss: 0.4565 | Acc: 80.94%\n",
      "Train Epoch [69/100] Batch [780/782] Loss: 0.6610 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [781/782] Loss: 0.5002 | Acc: 80.93%\n",
      "Train Epoch [69/100] Batch [782/782] Loss: 0.5333 | Acc: 80.93%\n",
      "Epoch 69 completed in 29.14s.\n",
      "Test Epoch [69/100] Loss: 0.9256 | Acc: 72.10% | Inference Time: 8.32s\n",
      "Epoch 69 results saved to CSV.\n",
      "Epoch 70/100\n",
      "Train Epoch [70/100] Batch [1/782] Loss: 0.6627 | Acc: 78.12%\n",
      "Train Epoch [70/100] Batch [2/782] Loss: 0.3305 | Acc: 82.03%\n",
      "Train Epoch [70/100] Batch [3/782] Loss: 0.6395 | Acc: 82.81%\n",
      "Train Epoch [70/100] Batch [4/782] Loss: 0.4132 | Acc: 83.59%\n",
      "Train Epoch [70/100] Batch [5/782] Loss: 0.6814 | Acc: 81.88%\n",
      "Train Epoch [70/100] Batch [6/782] Loss: 0.5416 | Acc: 81.51%\n",
      "Train Epoch [70/100] Batch [7/782] Loss: 0.3395 | Acc: 82.14%\n",
      "Train Epoch [70/100] Batch [8/782] Loss: 0.7077 | Acc: 80.86%\n",
      "Train Epoch [70/100] Batch [9/782] Loss: 0.6073 | Acc: 80.21%\n",
      "Train Epoch [70/100] Batch [10/782] Loss: 0.4470 | Acc: 80.94%\n",
      "Train Epoch [70/100] Batch [11/782] Loss: 0.4729 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [12/782] Loss: 0.6799 | Acc: 80.99%\n",
      "Train Epoch [70/100] Batch [13/782] Loss: 0.4738 | Acc: 80.89%\n",
      "Train Epoch [70/100] Batch [14/782] Loss: 0.4797 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [15/782] Loss: 0.3991 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [16/782] Loss: 0.3004 | Acc: 81.74%\n",
      "Train Epoch [70/100] Batch [17/782] Loss: 0.4090 | Acc: 82.17%\n",
      "Train Epoch [70/100] Batch [18/782] Loss: 0.6645 | Acc: 82.03%\n",
      "Train Epoch [70/100] Batch [19/782] Loss: 0.4670 | Acc: 82.24%\n",
      "Train Epoch [70/100] Batch [20/782] Loss: 0.5463 | Acc: 82.19%\n",
      "Train Epoch [70/100] Batch [21/782] Loss: 0.4658 | Acc: 82.22%\n",
      "Train Epoch [70/100] Batch [22/782] Loss: 0.5690 | Acc: 82.03%\n",
      "Train Epoch [70/100] Batch [23/782] Loss: 0.6230 | Acc: 81.93%\n",
      "Train Epoch [70/100] Batch [24/782] Loss: 0.6494 | Acc: 81.58%\n",
      "Train Epoch [70/100] Batch [25/782] Loss: 0.6348 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [26/782] Loss: 0.5520 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [27/782] Loss: 0.4858 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [28/782] Loss: 0.5459 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [29/782] Loss: 0.7694 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [30/782] Loss: 0.4599 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [31/782] Loss: 0.3763 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [32/782] Loss: 0.6789 | Acc: 81.01%\n",
      "Train Epoch [70/100] Batch [33/782] Loss: 0.5367 | Acc: 80.82%\n",
      "Train Epoch [70/100] Batch [34/782] Loss: 0.5835 | Acc: 80.84%\n",
      "Train Epoch [70/100] Batch [35/782] Loss: 0.3756 | Acc: 80.98%\n",
      "Train Epoch [70/100] Batch [36/782] Loss: 0.5312 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [37/782] Loss: 0.4154 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [38/782] Loss: 0.4118 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [39/782] Loss: 0.6223 | Acc: 80.97%\n",
      "Train Epoch [70/100] Batch [40/782] Loss: 0.5684 | Acc: 80.78%\n",
      "Train Epoch [70/100] Batch [41/782] Loss: 0.6275 | Acc: 80.75%\n",
      "Train Epoch [70/100] Batch [42/782] Loss: 0.5425 | Acc: 80.65%\n",
      "Train Epoch [70/100] Batch [43/782] Loss: 0.6088 | Acc: 80.67%\n",
      "Train Epoch [70/100] Batch [44/782] Loss: 0.5294 | Acc: 80.68%\n",
      "Train Epoch [70/100] Batch [45/782] Loss: 0.4569 | Acc: 80.66%\n",
      "Train Epoch [70/100] Batch [46/782] Loss: 0.6392 | Acc: 80.57%\n",
      "Train Epoch [70/100] Batch [47/782] Loss: 0.4748 | Acc: 80.59%\n",
      "Train Epoch [70/100] Batch [48/782] Loss: 0.3504 | Acc: 80.79%\n",
      "Train Epoch [70/100] Batch [49/782] Loss: 0.5431 | Acc: 80.74%\n",
      "Train Epoch [70/100] Batch [50/782] Loss: 0.6199 | Acc: 80.75%\n",
      "Train Epoch [70/100] Batch [51/782] Loss: 0.5333 | Acc: 80.70%\n",
      "Train Epoch [70/100] Batch [52/782] Loss: 0.4896 | Acc: 80.77%\n",
      "Train Epoch [70/100] Batch [53/782] Loss: 0.3784 | Acc: 80.87%\n",
      "Train Epoch [70/100] Batch [54/782] Loss: 0.3874 | Acc: 80.96%\n",
      "Train Epoch [70/100] Batch [55/782] Loss: 0.3945 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [56/782] Loss: 0.4122 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [57/782] Loss: 0.4765 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [58/782] Loss: 0.5637 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [59/782] Loss: 0.5955 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [60/782] Loss: 0.4020 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [61/782] Loss: 0.4440 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [62/782] Loss: 0.5442 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [63/782] Loss: 0.7135 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [64/782] Loss: 0.5028 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [65/782] Loss: 0.4413 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [66/782] Loss: 0.3730 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [67/782] Loss: 0.3515 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [68/782] Loss: 0.4343 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [69/782] Loss: 0.5326 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [70/782] Loss: 0.4192 | Acc: 81.50%\n",
      "Train Epoch [70/100] Batch [71/782] Loss: 0.4689 | Acc: 81.49%\n",
      "Train Epoch [70/100] Batch [72/782] Loss: 0.5940 | Acc: 81.45%\n",
      "Train Epoch [70/100] Batch [73/782] Loss: 0.3451 | Acc: 81.53%\n",
      "Train Epoch [70/100] Batch [74/782] Loss: 0.5041 | Acc: 81.55%\n",
      "Train Epoch [70/100] Batch [75/782] Loss: 0.6267 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [76/782] Loss: 0.7021 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [77/782] Loss: 0.4285 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [78/782] Loss: 0.5786 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [79/782] Loss: 0.7308 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [80/782] Loss: 0.5702 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [81/782] Loss: 0.5952 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [82/782] Loss: 0.5617 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [83/782] Loss: 0.5121 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [84/782] Loss: 0.3989 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [85/782] Loss: 0.4849 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [86/782] Loss: 0.5042 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [87/782] Loss: 0.5936 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [88/782] Loss: 0.5580 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [89/782] Loss: 0.3835 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [90/782] Loss: 0.3749 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [91/782] Loss: 0.5158 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [92/782] Loss: 0.4500 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [93/782] Loss: 0.5383 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [94/782] Loss: 0.5032 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [95/782] Loss: 0.5699 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [96/782] Loss: 0.5778 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [97/782] Loss: 0.5589 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [98/782] Loss: 0.3905 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [99/782] Loss: 0.5193 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [100/782] Loss: 0.3763 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [101/782] Loss: 0.6593 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [102/782] Loss: 0.3255 | Acc: 81.46%\n",
      "Train Epoch [70/100] Batch [103/782] Loss: 0.5490 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [104/782] Loss: 0.5495 | Acc: 81.46%\n",
      "Train Epoch [70/100] Batch [105/782] Loss: 0.3872 | Acc: 81.49%\n",
      "Train Epoch [70/100] Batch [106/782] Loss: 0.5376 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [107/782] Loss: 0.5487 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [108/782] Loss: 0.5309 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [109/782] Loss: 0.4615 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [110/782] Loss: 0.7485 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [111/782] Loss: 0.5343 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [112/782] Loss: 0.5891 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [113/782] Loss: 0.3436 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [114/782] Loss: 0.3833 | Acc: 81.46%\n",
      "Train Epoch [70/100] Batch [115/782] Loss: 0.5126 | Acc: 81.45%\n",
      "Train Epoch [70/100] Batch [116/782] Loss: 0.6788 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [117/782] Loss: 0.5896 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [118/782] Loss: 0.5593 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [119/782] Loss: 0.2989 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [120/782] Loss: 0.6953 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [121/782] Loss: 0.3460 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [122/782] Loss: 0.4394 | Acc: 81.47%\n",
      "Train Epoch [70/100] Batch [123/782] Loss: 0.5385 | Acc: 81.47%\n",
      "Train Epoch [70/100] Batch [124/782] Loss: 0.7053 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [125/782] Loss: 0.5265 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [126/782] Loss: 0.5438 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [127/782] Loss: 0.6502 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [128/782] Loss: 0.4036 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [129/782] Loss: 0.5320 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [130/782] Loss: 0.5052 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [131/782] Loss: 0.6494 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [132/782] Loss: 0.5184 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [133/782] Loss: 0.6783 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [134/782] Loss: 0.5285 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [135/782] Loss: 0.5118 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [136/782] Loss: 0.6682 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [137/782] Loss: 0.5233 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [138/782] Loss: 0.5419 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [139/782] Loss: 0.5732 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [140/782] Loss: 0.3712 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [141/782] Loss: 0.8059 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [142/782] Loss: 0.5215 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [143/782] Loss: 0.5417 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [144/782] Loss: 0.4430 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [145/782] Loss: 0.4698 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [146/782] Loss: 0.5180 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [147/782] Loss: 0.7942 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [148/782] Loss: 0.5049 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [149/782] Loss: 0.4839 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [150/782] Loss: 0.4656 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [151/782] Loss: 0.5330 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [152/782] Loss: 0.4531 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [153/782] Loss: 0.4932 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [154/782] Loss: 0.6235 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [155/782] Loss: 0.5068 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [156/782] Loss: 0.4581 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [157/782] Loss: 0.4809 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [158/782] Loss: 0.5378 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [159/782] Loss: 0.4817 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [160/782] Loss: 0.6359 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [161/782] Loss: 0.3475 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [162/782] Loss: 0.6838 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [163/782] Loss: 0.3775 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [164/782] Loss: 0.3707 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [165/782] Loss: 0.4179 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [166/782] Loss: 0.5211 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [167/782] Loss: 0.5522 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [168/782] Loss: 0.4918 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [169/782] Loss: 0.5265 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [170/782] Loss: 0.5143 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [171/782] Loss: 0.4852 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [172/782] Loss: 0.5142 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [173/782] Loss: 0.3836 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [174/782] Loss: 0.4413 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [175/782] Loss: 0.6535 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [176/782] Loss: 0.5379 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [177/782] Loss: 0.3756 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [178/782] Loss: 0.5424 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [179/782] Loss: 0.4766 | Acc: 81.46%\n",
      "Train Epoch [70/100] Batch [180/782] Loss: 0.5986 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [181/782] Loss: 0.5866 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [182/782] Loss: 0.4885 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [183/782] Loss: 0.5489 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [184/782] Loss: 0.5518 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [185/782] Loss: 0.5984 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [186/782] Loss: 0.5141 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [187/782] Loss: 0.4654 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [188/782] Loss: 0.5719 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [189/782] Loss: 0.5128 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [190/782] Loss: 0.5955 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [191/782] Loss: 0.4461 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [192/782] Loss: 0.6649 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [193/782] Loss: 0.3002 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [194/782] Loss: 0.4868 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [195/782] Loss: 0.7051 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [196/782] Loss: 0.6015 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [197/782] Loss: 0.6118 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [198/782] Loss: 0.4253 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [199/782] Loss: 0.3737 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [200/782] Loss: 0.3176 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [201/782] Loss: 0.2802 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [202/782] Loss: 0.5017 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [203/782] Loss: 0.4140 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [204/782] Loss: 0.3718 | Acc: 81.45%\n",
      "Train Epoch [70/100] Batch [205/782] Loss: 0.5681 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [206/782] Loss: 0.6108 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [207/782] Loss: 0.5067 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [208/782] Loss: 0.6506 | Acc: 81.42%\n",
      "Train Epoch [70/100] Batch [209/782] Loss: 0.5214 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [210/782] Loss: 0.3415 | Acc: 81.44%\n",
      "Train Epoch [70/100] Batch [211/782] Loss: 0.4597 | Acc: 81.45%\n",
      "Train Epoch [70/100] Batch [212/782] Loss: 0.4563 | Acc: 81.43%\n",
      "Train Epoch [70/100] Batch [213/782] Loss: 0.5661 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [214/782] Loss: 0.4359 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [215/782] Loss: 0.4962 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [216/782] Loss: 0.5735 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [217/782] Loss: 0.5448 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [218/782] Loss: 0.4394 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [219/782] Loss: 0.5813 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [220/782] Loss: 0.7691 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [221/782] Loss: 0.7266 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [222/782] Loss: 0.5447 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [223/782] Loss: 0.3429 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [224/782] Loss: 0.5383 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [225/782] Loss: 0.5360 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [226/782] Loss: 0.5528 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [227/782] Loss: 0.6357 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [228/782] Loss: 0.4482 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [229/782] Loss: 0.5983 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [230/782] Loss: 0.4621 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [231/782] Loss: 0.3934 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [232/782] Loss: 0.5773 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [233/782] Loss: 0.4598 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [234/782] Loss: 0.7082 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [235/782] Loss: 0.5939 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [236/782] Loss: 0.6584 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [237/782] Loss: 0.7055 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [238/782] Loss: 0.5550 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [239/782] Loss: 0.5069 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [240/782] Loss: 0.3966 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [241/782] Loss: 0.3722 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [242/782] Loss: 0.5005 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [243/782] Loss: 0.6377 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [244/782] Loss: 0.4779 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [245/782] Loss: 0.5382 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [246/782] Loss: 0.3117 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [247/782] Loss: 0.3981 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [248/782] Loss: 0.5707 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [249/782] Loss: 0.5672 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [250/782] Loss: 0.4493 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [251/782] Loss: 0.3688 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [252/782] Loss: 0.5303 | Acc: 81.41%\n",
      "Train Epoch [70/100] Batch [253/782] Loss: 0.6269 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [254/782] Loss: 0.4662 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [255/782] Loss: 0.5861 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [256/782] Loss: 0.4692 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [257/782] Loss: 0.3531 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [258/782] Loss: 0.4057 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [259/782] Loss: 0.4612 | Acc: 81.40%\n",
      "Train Epoch [70/100] Batch [260/782] Loss: 0.5067 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [261/782] Loss: 0.7828 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [262/782] Loss: 0.7460 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [263/782] Loss: 0.3824 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [264/782] Loss: 0.5030 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [265/782] Loss: 0.5425 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [266/782] Loss: 0.5919 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [267/782] Loss: 0.4885 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [268/782] Loss: 0.6069 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [269/782] Loss: 0.6140 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [270/782] Loss: 0.5301 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [271/782] Loss: 0.4381 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [272/782] Loss: 0.6196 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [273/782] Loss: 0.5088 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [274/782] Loss: 0.7625 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [275/782] Loss: 0.5448 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [276/782] Loss: 0.5421 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [277/782] Loss: 0.4553 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [278/782] Loss: 0.3516 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [279/782] Loss: 0.6421 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [280/782] Loss: 0.5402 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [281/782] Loss: 0.3348 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [282/782] Loss: 0.7433 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [283/782] Loss: 0.5817 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [284/782] Loss: 0.6226 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [285/782] Loss: 0.7399 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [286/782] Loss: 0.4915 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [287/782] Loss: 0.4976 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [288/782] Loss: 0.4630 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [289/782] Loss: 0.5837 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [290/782] Loss: 0.5603 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [291/782] Loss: 0.2996 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [292/782] Loss: 0.5650 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [293/782] Loss: 0.6498 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [294/782] Loss: 0.5278 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [295/782] Loss: 0.4387 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [296/782] Loss: 0.6346 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [297/782] Loss: 0.6025 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [298/782] Loss: 0.3422 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [299/782] Loss: 0.5663 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [300/782] Loss: 0.4655 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [301/782] Loss: 0.5835 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [302/782] Loss: 0.4327 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [303/782] Loss: 0.3392 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [304/782] Loss: 0.7834 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [305/782] Loss: 0.4064 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [306/782] Loss: 0.5573 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [307/782] Loss: 0.5530 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [308/782] Loss: 0.5948 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [309/782] Loss: 0.6522 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [310/782] Loss: 0.7743 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [311/782] Loss: 0.2619 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [312/782] Loss: 0.5688 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [313/782] Loss: 0.4549 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [314/782] Loss: 0.4652 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [315/782] Loss: 0.6393 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [316/782] Loss: 0.5305 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [317/782] Loss: 0.5724 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [318/782] Loss: 0.5383 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [319/782] Loss: 0.4618 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [320/782] Loss: 0.4431 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [321/782] Loss: 0.4829 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [322/782] Loss: 0.6528 | Acc: 81.11%\n",
      "Train Epoch [70/100] Batch [323/782] Loss: 0.6195 | Acc: 81.11%\n",
      "Train Epoch [70/100] Batch [324/782] Loss: 0.4667 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [325/782] Loss: 0.6042 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [326/782] Loss: 0.5639 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [327/782] Loss: 0.4410 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [328/782] Loss: 0.5684 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [329/782] Loss: 0.5531 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [330/782] Loss: 0.6288 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [331/782] Loss: 0.5041 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [332/782] Loss: 0.4186 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [333/782] Loss: 0.4556 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [334/782] Loss: 0.6693 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [335/782] Loss: 0.3690 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [336/782] Loss: 0.5523 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [337/782] Loss: 0.4035 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [338/782] Loss: 0.7129 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [339/782] Loss: 0.2669 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [340/782] Loss: 0.6242 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [341/782] Loss: 0.5881 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [342/782] Loss: 0.4815 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [343/782] Loss: 0.5360 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [344/782] Loss: 0.2696 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [345/782] Loss: 0.4172 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [346/782] Loss: 0.6153 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [347/782] Loss: 0.5522 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [348/782] Loss: 0.5250 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [349/782] Loss: 0.4397 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [350/782] Loss: 0.4620 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [351/782] Loss: 0.3946 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [352/782] Loss: 0.3892 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [353/782] Loss: 0.6197 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [354/782] Loss: 0.5236 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [355/782] Loss: 0.6267 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [356/782] Loss: 0.5492 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [357/782] Loss: 0.7736 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [358/782] Loss: 0.4151 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [359/782] Loss: 0.4947 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [360/782] Loss: 0.8365 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [361/782] Loss: 0.6270 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [362/782] Loss: 0.5263 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [363/782] Loss: 0.4012 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [364/782] Loss: 0.4920 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [365/782] Loss: 0.6057 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [366/782] Loss: 0.3840 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [367/782] Loss: 0.6356 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [368/782] Loss: 0.4313 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [369/782] Loss: 0.5307 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [370/782] Loss: 0.4398 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [371/782] Loss: 0.6564 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [372/782] Loss: 0.4240 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [373/782] Loss: 0.4270 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [374/782] Loss: 0.5245 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [375/782] Loss: 0.5723 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [376/782] Loss: 0.5510 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [377/782] Loss: 0.6027 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [378/782] Loss: 0.5749 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [379/782] Loss: 0.4190 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [380/782] Loss: 0.5681 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [381/782] Loss: 0.4766 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [382/782] Loss: 0.4038 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [383/782] Loss: 0.5607 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [384/782] Loss: 0.5987 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [385/782] Loss: 0.5488 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [386/782] Loss: 0.4710 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [387/782] Loss: 0.5007 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [388/782] Loss: 0.4647 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [389/782] Loss: 0.4468 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [390/782] Loss: 0.4942 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [391/782] Loss: 0.4517 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [392/782] Loss: 0.3134 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [393/782] Loss: 0.3896 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [394/782] Loss: 0.5082 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [395/782] Loss: 0.6488 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [396/782] Loss: 0.5406 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [397/782] Loss: 0.3240 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [398/782] Loss: 0.5804 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [399/782] Loss: 0.7534 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [400/782] Loss: 0.4816 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [401/782] Loss: 0.5128 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [402/782] Loss: 0.6152 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [403/782] Loss: 0.4543 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [404/782] Loss: 0.3303 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [405/782] Loss: 0.7393 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [406/782] Loss: 0.4746 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [407/782] Loss: 0.3900 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [408/782] Loss: 0.3411 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [409/782] Loss: 0.5922 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [410/782] Loss: 0.6951 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [411/782] Loss: 0.5158 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [412/782] Loss: 0.5422 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [413/782] Loss: 0.4212 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [414/782] Loss: 0.3523 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [415/782] Loss: 0.4591 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [416/782] Loss: 0.4375 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [417/782] Loss: 0.4782 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [418/782] Loss: 0.3991 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [419/782] Loss: 0.4159 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [420/782] Loss: 0.6316 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [421/782] Loss: 0.7703 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [422/782] Loss: 0.4004 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [423/782] Loss: 0.3628 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [424/782] Loss: 0.4701 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [425/782] Loss: 0.6587 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [426/782] Loss: 0.3582 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [427/782] Loss: 0.5526 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [428/782] Loss: 0.5685 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [429/782] Loss: 0.4147 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [430/782] Loss: 0.6031 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [431/782] Loss: 0.5892 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [432/782] Loss: 0.5888 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [433/782] Loss: 0.5910 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [434/782] Loss: 0.6130 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [435/782] Loss: 0.5558 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [436/782] Loss: 0.4455 | Acc: 81.26%\n",
      "Train Epoch [70/100] Batch [437/782] Loss: 0.4012 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [438/782] Loss: 0.6480 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [439/782] Loss: 0.4752 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [440/782] Loss: 0.2684 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [441/782] Loss: 0.4698 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [442/782] Loss: 0.5608 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [443/782] Loss: 0.4276 | Acc: 81.32%\n",
      "Train Epoch [70/100] Batch [444/782] Loss: 0.3822 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [445/782] Loss: 0.5168 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [446/782] Loss: 0.6611 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [447/782] Loss: 0.5034 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [448/782] Loss: 0.5557 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [449/782] Loss: 0.2992 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [450/782] Loss: 0.5657 | Acc: 81.33%\n",
      "Train Epoch [70/100] Batch [451/782] Loss: 0.5023 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [452/782] Loss: 0.3725 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [453/782] Loss: 0.6618 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [454/782] Loss: 0.5582 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [455/782] Loss: 0.4550 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [456/782] Loss: 0.4160 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [457/782] Loss: 0.3179 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [458/782] Loss: 0.5082 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [459/782] Loss: 0.5097 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [460/782] Loss: 0.5164 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [461/782] Loss: 0.4566 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [462/782] Loss: 0.4889 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [463/782] Loss: 0.4782 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [464/782] Loss: 0.4785 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [465/782] Loss: 0.6918 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [466/782] Loss: 0.4014 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [467/782] Loss: 0.5972 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [468/782] Loss: 0.7805 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [469/782] Loss: 0.5710 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [470/782] Loss: 0.5565 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [471/782] Loss: 0.3732 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [472/782] Loss: 0.3984 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [473/782] Loss: 0.5550 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [474/782] Loss: 0.4869 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [475/782] Loss: 0.6850 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [476/782] Loss: 0.3125 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [477/782] Loss: 0.6594 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [478/782] Loss: 0.4736 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [479/782] Loss: 0.4245 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [480/782] Loss: 0.3508 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [481/782] Loss: 0.6314 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [482/782] Loss: 0.4691 | Acc: 81.38%\n",
      "Train Epoch [70/100] Batch [483/782] Loss: 0.3843 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [484/782] Loss: 0.4739 | Acc: 81.39%\n",
      "Train Epoch [70/100] Batch [485/782] Loss: 0.5918 | Acc: 81.37%\n",
      "Train Epoch [70/100] Batch [486/782] Loss: 0.8110 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [487/782] Loss: 0.6330 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [488/782] Loss: 0.5870 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [489/782] Loss: 0.6647 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [490/782] Loss: 0.4832 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [491/782] Loss: 0.6037 | Acc: 81.36%\n",
      "Train Epoch [70/100] Batch [492/782] Loss: 0.5099 | Acc: 81.35%\n",
      "Train Epoch [70/100] Batch [493/782] Loss: 0.7421 | Acc: 81.34%\n",
      "Train Epoch [70/100] Batch [494/782] Loss: 0.8493 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [495/782] Loss: 0.4376 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [496/782] Loss: 0.4954 | Acc: 81.31%\n",
      "Train Epoch [70/100] Batch [497/782] Loss: 0.4383 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [498/782] Loss: 0.4973 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [499/782] Loss: 0.5446 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [500/782] Loss: 0.7835 | Acc: 81.28%\n",
      "Train Epoch [70/100] Batch [501/782] Loss: 0.4657 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [502/782] Loss: 0.5571 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [503/782] Loss: 0.5205 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [504/782] Loss: 0.4801 | Acc: 81.30%\n",
      "Train Epoch [70/100] Batch [505/782] Loss: 0.4490 | Acc: 81.29%\n",
      "Train Epoch [70/100] Batch [506/782] Loss: 0.8276 | Acc: 81.27%\n",
      "Train Epoch [70/100] Batch [507/782] Loss: 0.6542 | Acc: 81.25%\n",
      "Train Epoch [70/100] Batch [508/782] Loss: 0.6844 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [509/782] Loss: 0.5574 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [510/782] Loss: 0.6518 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [511/782] Loss: 0.5312 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [512/782] Loss: 0.6538 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [513/782] Loss: 0.5952 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [514/782] Loss: 0.4976 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [515/782] Loss: 0.5299 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [516/782] Loss: 0.6016 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [517/782] Loss: 0.5391 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [518/782] Loss: 0.4352 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [519/782] Loss: 0.4909 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [520/782] Loss: 0.4045 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [521/782] Loss: 0.6033 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [522/782] Loss: 0.5849 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [523/782] Loss: 0.4321 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [524/782] Loss: 0.3472 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [525/782] Loss: 0.5446 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [526/782] Loss: 0.4013 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [527/782] Loss: 0.6108 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [528/782] Loss: 0.4964 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [529/782] Loss: 0.7378 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [530/782] Loss: 0.6165 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [531/782] Loss: 0.4738 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [532/782] Loss: 0.3584 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [533/782] Loss: 0.7847 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [534/782] Loss: 0.3804 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [535/782] Loss: 0.8417 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [536/782] Loss: 0.4204 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [537/782] Loss: 0.3223 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [538/782] Loss: 0.6070 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [539/782] Loss: 0.6266 | Acc: 81.17%\n",
      "Train Epoch [70/100] Batch [540/782] Loss: 0.4016 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [541/782] Loss: 0.2325 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [542/782] Loss: 0.3758 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [543/782] Loss: 0.4249 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [544/782] Loss: 0.4907 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [545/782] Loss: 0.4969 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [546/782] Loss: 0.5604 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [547/782] Loss: 0.3971 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [548/782] Loss: 0.7355 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [549/782] Loss: 0.3501 | Acc: 81.23%\n",
      "Train Epoch [70/100] Batch [550/782] Loss: 0.6382 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [551/782] Loss: 0.3601 | Acc: 81.24%\n",
      "Train Epoch [70/100] Batch [552/782] Loss: 0.5814 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [553/782] Loss: 0.5504 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [554/782] Loss: 0.5208 | Acc: 81.22%\n",
      "Train Epoch [70/100] Batch [555/782] Loss: 0.5350 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [556/782] Loss: 0.7017 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [557/782] Loss: 0.3130 | Acc: 81.21%\n",
      "Train Epoch [70/100] Batch [558/782] Loss: 0.4447 | Acc: 81.20%\n",
      "Train Epoch [70/100] Batch [559/782] Loss: 0.5177 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [560/782] Loss: 0.4976 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [561/782] Loss: 0.5494 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [562/782] Loss: 0.4859 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [563/782] Loss: 0.4905 | Acc: 81.19%\n",
      "Train Epoch [70/100] Batch [564/782] Loss: 0.5102 | Acc: 81.18%\n",
      "Train Epoch [70/100] Batch [565/782] Loss: 0.7125 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [566/782] Loss: 0.5045 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [567/782] Loss: 0.5200 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [568/782] Loss: 0.7154 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [569/782] Loss: 0.5432 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [570/782] Loss: 0.4926 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [571/782] Loss: 0.5939 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [572/782] Loss: 0.4544 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [573/782] Loss: 0.5242 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [574/782] Loss: 0.6250 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [575/782] Loss: 0.3331 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [576/782] Loss: 0.7352 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [577/782] Loss: 0.4422 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [578/782] Loss: 0.4731 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [579/782] Loss: 0.5399 | Acc: 81.16%\n",
      "Train Epoch [70/100] Batch [580/782] Loss: 0.6283 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [581/782] Loss: 0.4776 | Acc: 81.15%\n",
      "Train Epoch [70/100] Batch [582/782] Loss: 0.7714 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [583/782] Loss: 0.4744 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [584/782] Loss: 0.4837 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [585/782] Loss: 0.5322 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [586/782] Loss: 0.5702 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [587/782] Loss: 0.5753 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [588/782] Loss: 0.5323 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [589/782] Loss: 0.6031 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [590/782] Loss: 0.3463 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [591/782] Loss: 0.6629 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [592/782] Loss: 0.5071 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [593/782] Loss: 0.5451 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [594/782] Loss: 0.4167 | Acc: 81.14%\n",
      "Train Epoch [70/100] Batch [595/782] Loss: 0.6120 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [596/782] Loss: 0.5333 | Acc: 81.13%\n",
      "Train Epoch [70/100] Batch [597/782] Loss: 0.5558 | Acc: 81.12%\n",
      "Train Epoch [70/100] Batch [598/782] Loss: 0.7418 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [599/782] Loss: 0.5161 | Acc: 81.11%\n",
      "Train Epoch [70/100] Batch [600/782] Loss: 0.6742 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [601/782] Loss: 0.6544 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [602/782] Loss: 0.5850 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [603/782] Loss: 0.5081 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [604/782] Loss: 0.3827 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [605/782] Loss: 0.3104 | Acc: 81.11%\n",
      "Train Epoch [70/100] Batch [606/782] Loss: 0.6877 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [607/782] Loss: 0.3259 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [608/782] Loss: 0.4508 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [609/782] Loss: 0.5579 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [610/782] Loss: 0.4928 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [611/782] Loss: 0.5986 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [612/782] Loss: 0.6370 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [613/782] Loss: 0.7849 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [614/782] Loss: 0.6127 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [615/782] Loss: 0.3790 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [616/782] Loss: 0.4852 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [617/782] Loss: 0.5100 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [618/782] Loss: 0.5925 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [619/782] Loss: 0.5809 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [620/782] Loss: 0.5290 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [621/782] Loss: 0.5539 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [622/782] Loss: 0.5580 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [623/782] Loss: 0.5570 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [624/782] Loss: 0.6564 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [625/782] Loss: 0.4753 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [626/782] Loss: 0.5627 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [627/782] Loss: 0.3873 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [628/782] Loss: 0.6300 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [629/782] Loss: 0.5277 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [630/782] Loss: 0.5113 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [631/782] Loss: 0.5525 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [632/782] Loss: 0.6276 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [633/782] Loss: 0.4523 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [634/782] Loss: 0.4694 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [635/782] Loss: 0.5563 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [636/782] Loss: 0.4014 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [637/782] Loss: 0.7496 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [638/782] Loss: 0.5041 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [639/782] Loss: 0.3452 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [640/782] Loss: 0.6210 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [641/782] Loss: 0.6684 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [642/782] Loss: 0.6023 | Acc: 81.02%\n",
      "Train Epoch [70/100] Batch [643/782] Loss: 0.3036 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [644/782] Loss: 0.7209 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [645/782] Loss: 0.5319 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [646/782] Loss: 0.5630 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [647/782] Loss: 0.5132 | Acc: 81.02%\n",
      "Train Epoch [70/100] Batch [648/782] Loss: 0.4202 | Acc: 81.02%\n",
      "Train Epoch [70/100] Batch [649/782] Loss: 0.4186 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [650/782] Loss: 0.4463 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [651/782] Loss: 0.5366 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [652/782] Loss: 0.4480 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [653/782] Loss: 0.5027 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [654/782] Loss: 0.5000 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [655/782] Loss: 0.5876 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [656/782] Loss: 0.4896 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [657/782] Loss: 0.3660 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [658/782] Loss: 0.4428 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [659/782] Loss: 0.4809 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [660/782] Loss: 0.5241 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [661/782] Loss: 0.6752 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [662/782] Loss: 0.4994 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [663/782] Loss: 0.4109 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [664/782] Loss: 0.4610 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [665/782] Loss: 0.4236 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [666/782] Loss: 0.5704 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [667/782] Loss: 0.3753 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [668/782] Loss: 0.4515 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [669/782] Loss: 0.5401 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [670/782] Loss: 0.5325 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [671/782] Loss: 0.5088 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [672/782] Loss: 0.5433 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [673/782] Loss: 0.7434 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [674/782] Loss: 0.6172 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [675/782] Loss: 0.6282 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [676/782] Loss: 0.6171 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [677/782] Loss: 0.5984 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [678/782] Loss: 0.3337 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [679/782] Loss: 0.6487 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [680/782] Loss: 0.7461 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [681/782] Loss: 0.4479 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [682/782] Loss: 0.4886 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [683/782] Loss: 0.5038 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [684/782] Loss: 0.5184 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [685/782] Loss: 0.4385 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [686/782] Loss: 0.6209 | Acc: 81.10%\n",
      "Train Epoch [70/100] Batch [687/782] Loss: 0.5579 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [688/782] Loss: 0.5087 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [689/782] Loss: 0.7122 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [690/782] Loss: 0.5692 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [691/782] Loss: 0.5221 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [692/782] Loss: 0.6659 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [693/782] Loss: 0.6073 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [694/782] Loss: 0.5146 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [695/782] Loss: 0.5888 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [696/782] Loss: 0.5703 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [697/782] Loss: 0.3888 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [698/782] Loss: 0.6826 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [699/782] Loss: 0.5180 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [700/782] Loss: 0.4462 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [701/782] Loss: 0.7525 | Acc: 81.03%\n",
      "Train Epoch [70/100] Batch [702/782] Loss: 0.4189 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [703/782] Loss: 0.4014 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [704/782] Loss: 0.5527 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [705/782] Loss: 0.3938 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [706/782] Loss: 0.5584 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [707/782] Loss: 0.3917 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [708/782] Loss: 0.5341 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [709/782] Loss: 0.6142 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [710/782] Loss: 0.5043 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [711/782] Loss: 0.3917 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [712/782] Loss: 0.6009 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [713/782] Loss: 0.4100 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [714/782] Loss: 0.5198 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [715/782] Loss: 0.4881 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [716/782] Loss: 0.5172 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [717/782] Loss: 0.5927 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [718/782] Loss: 0.7258 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [719/782] Loss: 0.6065 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [720/782] Loss: 0.5487 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [721/782] Loss: 0.5177 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [722/782] Loss: 0.5329 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [723/782] Loss: 0.5936 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [724/782] Loss: 0.3915 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [725/782] Loss: 0.5379 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [726/782] Loss: 0.5085 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [727/782] Loss: 0.5849 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [728/782] Loss: 0.6223 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [729/782] Loss: 0.8000 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [730/782] Loss: 0.4871 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [731/782] Loss: 0.4823 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [732/782] Loss: 0.4198 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [733/782] Loss: 0.7477 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [734/782] Loss: 0.5044 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [735/782] Loss: 0.5117 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [736/782] Loss: 0.5251 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [737/782] Loss: 0.4623 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [738/782] Loss: 0.6063 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [739/782] Loss: 0.4249 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [740/782] Loss: 0.6863 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [741/782] Loss: 0.6140 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [742/782] Loss: 0.4696 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [743/782] Loss: 0.4967 | Acc: 81.04%\n",
      "Train Epoch [70/100] Batch [744/782] Loss: 0.3224 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [745/782] Loss: 0.4112 | Acc: 81.05%\n",
      "Train Epoch [70/100] Batch [746/782] Loss: 0.5379 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [747/782] Loss: 0.6552 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [748/782] Loss: 0.5068 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [749/782] Loss: 0.4659 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [750/782] Loss: 0.4190 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [751/782] Loss: 0.5755 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [752/782] Loss: 0.5950 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [753/782] Loss: 0.4561 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [754/782] Loss: 0.4348 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [755/782] Loss: 0.6561 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [756/782] Loss: 0.4718 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [757/782] Loss: 0.6783 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [758/782] Loss: 0.3682 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [759/782] Loss: 0.5531 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [760/782] Loss: 0.5668 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [761/782] Loss: 0.5731 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [762/782] Loss: 0.6132 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [763/782] Loss: 0.4887 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [764/782] Loss: 0.5405 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [765/782] Loss: 0.4486 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [766/782] Loss: 0.5710 | Acc: 81.06%\n",
      "Train Epoch [70/100] Batch [767/782] Loss: 0.4571 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [768/782] Loss: 0.5302 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [769/782] Loss: 0.4094 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [770/782] Loss: 0.6832 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [771/782] Loss: 0.3607 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [772/782] Loss: 0.4768 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [773/782] Loss: 0.4217 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [774/782] Loss: 0.5956 | Acc: 81.09%\n",
      "Train Epoch [70/100] Batch [775/782] Loss: 0.5803 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [776/782] Loss: 0.5848 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [777/782] Loss: 0.6470 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [778/782] Loss: 0.5811 | Acc: 81.08%\n",
      "Train Epoch [70/100] Batch [779/782] Loss: 0.6533 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [780/782] Loss: 0.4848 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [781/782] Loss: 0.6292 | Acc: 81.07%\n",
      "Train Epoch [70/100] Batch [782/782] Loss: 0.3962 | Acc: 81.07%\n",
      "Epoch 70 completed in 30.09s.\n",
      "Test Epoch [70/100] Loss: 0.9208 | Acc: 72.57% | Inference Time: 8.30s\n",
      "Epoch 70 results saved to CSV.\n",
      "Epoch 71/100\n",
      "Train Epoch [71/100] Batch [1/782] Loss: 0.5598 | Acc: 84.38%\n",
      "Train Epoch [71/100] Batch [2/782] Loss: 0.6479 | Acc: 83.59%\n",
      "Train Epoch [71/100] Batch [3/782] Loss: 0.3749 | Acc: 83.33%\n",
      "Train Epoch [71/100] Batch [4/782] Loss: 0.3865 | Acc: 83.98%\n",
      "Train Epoch [71/100] Batch [5/782] Loss: 0.4336 | Acc: 83.75%\n",
      "Train Epoch [71/100] Batch [6/782] Loss: 0.4095 | Acc: 84.11%\n",
      "Train Epoch [71/100] Batch [7/782] Loss: 0.5834 | Acc: 83.04%\n",
      "Train Epoch [71/100] Batch [8/782] Loss: 0.3634 | Acc: 83.59%\n",
      "Train Epoch [71/100] Batch [9/782] Loss: 0.3685 | Acc: 84.20%\n",
      "Train Epoch [71/100] Batch [10/782] Loss: 0.7216 | Acc: 83.59%\n",
      "Train Epoch [71/100] Batch [11/782] Loss: 0.4803 | Acc: 82.95%\n",
      "Train Epoch [71/100] Batch [12/782] Loss: 0.6086 | Acc: 82.68%\n",
      "Train Epoch [71/100] Batch [13/782] Loss: 0.5010 | Acc: 82.33%\n",
      "Train Epoch [71/100] Batch [14/782] Loss: 0.4891 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [15/782] Loss: 0.4610 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [16/782] Loss: 0.3972 | Acc: 82.52%\n",
      "Train Epoch [71/100] Batch [17/782] Loss: 0.5246 | Acc: 82.54%\n",
      "Train Epoch [71/100] Batch [18/782] Loss: 0.5039 | Acc: 82.73%\n",
      "Train Epoch [71/100] Batch [19/782] Loss: 0.4378 | Acc: 82.65%\n",
      "Train Epoch [71/100] Batch [20/782] Loss: 0.5118 | Acc: 82.58%\n",
      "Train Epoch [71/100] Batch [21/782] Loss: 0.5780 | Acc: 82.51%\n",
      "Train Epoch [71/100] Batch [22/782] Loss: 0.6487 | Acc: 82.24%\n",
      "Train Epoch [71/100] Batch [23/782] Loss: 0.4846 | Acc: 82.07%\n",
      "Train Epoch [71/100] Batch [24/782] Loss: 0.4679 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [25/782] Loss: 0.4550 | Acc: 82.38%\n",
      "Train Epoch [71/100] Batch [26/782] Loss: 0.4484 | Acc: 82.33%\n",
      "Train Epoch [71/100] Batch [27/782] Loss: 0.6740 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [28/782] Loss: 0.3744 | Acc: 82.09%\n",
      "Train Epoch [71/100] Batch [29/782] Loss: 0.3314 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [30/782] Loss: 0.5517 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [31/782] Loss: 0.4003 | Acc: 82.41%\n",
      "Train Epoch [71/100] Batch [32/782] Loss: 0.4438 | Acc: 82.37%\n",
      "Train Epoch [71/100] Batch [33/782] Loss: 0.6439 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [34/782] Loss: 0.4301 | Acc: 82.26%\n",
      "Train Epoch [71/100] Batch [35/782] Loss: 0.4320 | Acc: 82.28%\n",
      "Train Epoch [71/100] Batch [36/782] Loss: 0.6031 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [37/782] Loss: 0.4238 | Acc: 82.31%\n",
      "Train Epoch [71/100] Batch [38/782] Loss: 0.7564 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [39/782] Loss: 0.4629 | Acc: 82.13%\n",
      "Train Epoch [71/100] Batch [40/782] Loss: 0.4780 | Acc: 82.07%\n",
      "Train Epoch [71/100] Batch [41/782] Loss: 0.4608 | Acc: 82.24%\n",
      "Train Epoch [71/100] Batch [42/782] Loss: 0.2768 | Acc: 82.44%\n",
      "Train Epoch [71/100] Batch [43/782] Loss: 0.5312 | Acc: 82.30%\n",
      "Train Epoch [71/100] Batch [44/782] Loss: 0.5298 | Acc: 82.32%\n",
      "Train Epoch [71/100] Batch [45/782] Loss: 0.5567 | Acc: 82.33%\n",
      "Train Epoch [71/100] Batch [46/782] Loss: 0.4588 | Acc: 82.24%\n",
      "Train Epoch [71/100] Batch [47/782] Loss: 0.3695 | Acc: 82.35%\n",
      "Train Epoch [71/100] Batch [48/782] Loss: 0.4993 | Acc: 82.42%\n",
      "Train Epoch [71/100] Batch [49/782] Loss: 0.4338 | Acc: 82.43%\n",
      "Train Epoch [71/100] Batch [50/782] Loss: 0.3520 | Acc: 82.56%\n",
      "Train Epoch [71/100] Batch [51/782] Loss: 0.4040 | Acc: 82.63%\n",
      "Train Epoch [71/100] Batch [52/782] Loss: 0.4119 | Acc: 82.72%\n",
      "Train Epoch [71/100] Batch [53/782] Loss: 0.4019 | Acc: 82.81%\n",
      "Train Epoch [71/100] Batch [54/782] Loss: 0.4955 | Acc: 82.84%\n",
      "Train Epoch [71/100] Batch [55/782] Loss: 0.6227 | Acc: 82.76%\n",
      "Train Epoch [71/100] Batch [56/782] Loss: 0.4839 | Acc: 82.67%\n",
      "Train Epoch [71/100] Batch [57/782] Loss: 0.5171 | Acc: 82.68%\n",
      "Train Epoch [71/100] Batch [58/782] Loss: 0.6510 | Acc: 82.49%\n",
      "Train Epoch [71/100] Batch [59/782] Loss: 0.6539 | Acc: 82.44%\n",
      "Train Epoch [71/100] Batch [60/782] Loss: 0.3455 | Acc: 82.45%\n",
      "Train Epoch [71/100] Batch [61/782] Loss: 0.4730 | Acc: 82.48%\n",
      "Train Epoch [71/100] Batch [62/782] Loss: 0.5157 | Acc: 82.51%\n",
      "Train Epoch [71/100] Batch [63/782] Loss: 0.3955 | Acc: 82.59%\n",
      "Train Epoch [71/100] Batch [64/782] Loss: 0.5338 | Acc: 82.52%\n",
      "Train Epoch [71/100] Batch [65/782] Loss: 0.5806 | Acc: 82.40%\n",
      "Train Epoch [71/100] Batch [66/782] Loss: 0.5679 | Acc: 82.34%\n",
      "Train Epoch [71/100] Batch [67/782] Loss: 0.3803 | Acc: 82.42%\n",
      "Train Epoch [71/100] Batch [68/782] Loss: 0.2900 | Acc: 82.56%\n",
      "Train Epoch [71/100] Batch [69/782] Loss: 0.5353 | Acc: 82.59%\n",
      "Train Epoch [71/100] Batch [70/782] Loss: 0.6181 | Acc: 82.50%\n",
      "Train Epoch [71/100] Batch [71/782] Loss: 0.4937 | Acc: 82.39%\n",
      "Train Epoch [71/100] Batch [72/782] Loss: 0.3868 | Acc: 82.44%\n",
      "Train Epoch [71/100] Batch [73/782] Loss: 0.5455 | Acc: 82.45%\n",
      "Train Epoch [71/100] Batch [74/782] Loss: 0.5047 | Acc: 82.45%\n",
      "Train Epoch [71/100] Batch [75/782] Loss: 0.5044 | Acc: 82.54%\n",
      "Train Epoch [71/100] Batch [76/782] Loss: 0.5301 | Acc: 82.55%\n",
      "Train Epoch [71/100] Batch [77/782] Loss: 0.5414 | Acc: 82.43%\n",
      "Train Epoch [71/100] Batch [78/782] Loss: 0.4738 | Acc: 82.43%\n",
      "Train Epoch [71/100] Batch [79/782] Loss: 0.5699 | Acc: 82.36%\n",
      "Train Epoch [71/100] Batch [80/782] Loss: 0.7178 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [81/782] Loss: 0.2803 | Acc: 82.31%\n",
      "Train Epoch [71/100] Batch [82/782] Loss: 0.4471 | Acc: 82.32%\n",
      "Train Epoch [71/100] Batch [83/782] Loss: 0.5431 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [84/782] Loss: 0.4548 | Acc: 82.20%\n",
      "Train Epoch [71/100] Batch [85/782] Loss: 0.4514 | Acc: 82.17%\n",
      "Train Epoch [71/100] Batch [86/782] Loss: 0.6312 | Acc: 82.12%\n",
      "Train Epoch [71/100] Batch [87/782] Loss: 0.5877 | Acc: 82.09%\n",
      "Train Epoch [71/100] Batch [88/782] Loss: 0.3833 | Acc: 82.17%\n",
      "Train Epoch [71/100] Batch [89/782] Loss: 0.6478 | Acc: 82.13%\n",
      "Train Epoch [71/100] Batch [90/782] Loss: 0.6200 | Acc: 82.05%\n",
      "Train Epoch [71/100] Batch [91/782] Loss: 0.4849 | Acc: 82.07%\n",
      "Train Epoch [71/100] Batch [92/782] Loss: 0.7971 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [93/782] Loss: 0.5175 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [94/782] Loss: 0.4688 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [95/782] Loss: 0.2253 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [96/782] Loss: 0.4262 | Acc: 82.19%\n",
      "Train Epoch [71/100] Batch [97/782] Loss: 0.5558 | Acc: 82.17%\n",
      "Train Epoch [71/100] Batch [98/782] Loss: 0.7636 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [99/782] Loss: 0.3714 | Acc: 82.23%\n",
      "Train Epoch [71/100] Batch [100/782] Loss: 0.2991 | Acc: 82.31%\n",
      "Train Epoch [71/100] Batch [101/782] Loss: 0.4827 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [102/782] Loss: 0.5161 | Acc: 82.26%\n",
      "Train Epoch [71/100] Batch [103/782] Loss: 0.4733 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [104/782] Loss: 0.4774 | Acc: 82.26%\n",
      "Train Epoch [71/100] Batch [105/782] Loss: 0.3794 | Acc: 82.34%\n",
      "Train Epoch [71/100] Batch [106/782] Loss: 0.4406 | Acc: 82.33%\n",
      "Train Epoch [71/100] Batch [107/782] Loss: 0.3695 | Acc: 82.36%\n",
      "Train Epoch [71/100] Batch [108/782] Loss: 0.5384 | Acc: 82.35%\n",
      "Train Epoch [71/100] Batch [109/782] Loss: 0.6043 | Acc: 82.35%\n",
      "Train Epoch [71/100] Batch [110/782] Loss: 0.4706 | Acc: 82.37%\n",
      "Train Epoch [71/100] Batch [111/782] Loss: 0.6743 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [112/782] Loss: 0.4701 | Acc: 82.34%\n",
      "Train Epoch [71/100] Batch [113/782] Loss: 0.5804 | Acc: 82.30%\n",
      "Train Epoch [71/100] Batch [114/782] Loss: 0.5335 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [115/782] Loss: 0.5869 | Acc: 82.31%\n",
      "Train Epoch [71/100] Batch [116/782] Loss: 0.4448 | Acc: 82.30%\n",
      "Train Epoch [71/100] Batch [117/782] Loss: 0.5693 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [118/782] Loss: 0.5276 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [119/782] Loss: 0.4351 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [120/782] Loss: 0.5465 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [121/782] Loss: 0.4874 | Acc: 82.26%\n",
      "Train Epoch [71/100] Batch [122/782] Loss: 0.4693 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [123/782] Loss: 0.4132 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [124/782] Loss: 0.4670 | Acc: 82.28%\n",
      "Train Epoch [71/100] Batch [125/782] Loss: 0.5171 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [126/782] Loss: 0.5310 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [127/782] Loss: 0.5248 | Acc: 82.25%\n",
      "Train Epoch [71/100] Batch [128/782] Loss: 0.5848 | Acc: 82.24%\n",
      "Train Epoch [71/100] Batch [129/782] Loss: 0.5087 | Acc: 82.23%\n",
      "Train Epoch [71/100] Batch [130/782] Loss: 0.6890 | Acc: 82.16%\n",
      "Train Epoch [71/100] Batch [131/782] Loss: 0.4097 | Acc: 82.20%\n",
      "Train Epoch [71/100] Batch [132/782] Loss: 0.3149 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [133/782] Loss: 0.4015 | Acc: 82.28%\n",
      "Train Epoch [71/100] Batch [134/782] Loss: 0.4114 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [135/782] Loss: 0.4655 | Acc: 82.29%\n",
      "Train Epoch [71/100] Batch [136/782] Loss: 0.4664 | Acc: 82.27%\n",
      "Train Epoch [71/100] Batch [137/782] Loss: 0.4268 | Acc: 82.30%\n",
      "Train Epoch [71/100] Batch [138/782] Loss: 0.6737 | Acc: 82.21%\n",
      "Train Epoch [71/100] Batch [139/782] Loss: 0.6764 | Acc: 82.15%\n",
      "Train Epoch [71/100] Batch [140/782] Loss: 0.5254 | Acc: 82.12%\n",
      "Train Epoch [71/100] Batch [141/782] Loss: 0.3739 | Acc: 82.16%\n",
      "Train Epoch [71/100] Batch [142/782] Loss: 0.5079 | Acc: 82.15%\n",
      "Train Epoch [71/100] Batch [143/782] Loss: 0.3957 | Acc: 82.17%\n",
      "Train Epoch [71/100] Batch [144/782] Loss: 0.5155 | Acc: 82.13%\n",
      "Train Epoch [71/100] Batch [145/782] Loss: 0.6830 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [146/782] Loss: 0.4983 | Acc: 82.10%\n",
      "Train Epoch [71/100] Batch [147/782] Loss: 0.3921 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [148/782] Loss: 0.5518 | Acc: 82.15%\n",
      "Train Epoch [71/100] Batch [149/782] Loss: 0.5882 | Acc: 82.09%\n",
      "Train Epoch [71/100] Batch [150/782] Loss: 0.5673 | Acc: 82.06%\n",
      "Train Epoch [71/100] Batch [151/782] Loss: 0.4642 | Acc: 82.05%\n",
      "Train Epoch [71/100] Batch [152/782] Loss: 0.3520 | Acc: 82.08%\n",
      "Train Epoch [71/100] Batch [153/782] Loss: 0.4705 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [154/782] Loss: 0.4694 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [155/782] Loss: 0.5446 | Acc: 82.09%\n",
      "Train Epoch [71/100] Batch [156/782] Loss: 0.7509 | Acc: 82.03%\n",
      "Train Epoch [71/100] Batch [157/782] Loss: 0.3804 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [158/782] Loss: 0.6541 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [159/782] Loss: 0.7196 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [160/782] Loss: 0.4180 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [161/782] Loss: 0.4626 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [162/782] Loss: 0.5371 | Acc: 81.98%\n",
      "Train Epoch [71/100] Batch [163/782] Loss: 0.4338 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [164/782] Loss: 0.4411 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [165/782] Loss: 0.3137 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [166/782] Loss: 0.4503 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [167/782] Loss: 0.5182 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [168/782] Loss: 0.4671 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [169/782] Loss: 0.4617 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [170/782] Loss: 0.6018 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [171/782] Loss: 0.5089 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [172/782] Loss: 0.4798 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [173/782] Loss: 0.4218 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [174/782] Loss: 0.3779 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [175/782] Loss: 0.3747 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [176/782] Loss: 0.6111 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [177/782] Loss: 0.6076 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [178/782] Loss: 0.3726 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [179/782] Loss: 0.7402 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [180/782] Loss: 0.6002 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [181/782] Loss: 0.4765 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [182/782] Loss: 0.5839 | Acc: 81.90%\n",
      "Train Epoch [71/100] Batch [183/782] Loss: 0.6969 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [184/782] Loss: 0.4994 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [185/782] Loss: 0.4307 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [186/782] Loss: 0.5296 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [187/782] Loss: 0.4801 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [188/782] Loss: 0.3749 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [189/782] Loss: 0.6450 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [190/782] Loss: 0.6895 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [191/782] Loss: 0.4917 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [192/782] Loss: 0.4191 | Acc: 81.90%\n",
      "Train Epoch [71/100] Batch [193/782] Loss: 0.4056 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [194/782] Loss: 0.2983 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [195/782] Loss: 0.3676 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [196/782] Loss: 0.5952 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [197/782] Loss: 0.6720 | Acc: 81.98%\n",
      "Train Epoch [71/100] Batch [198/782] Loss: 0.4125 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [199/782] Loss: 0.4008 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [200/782] Loss: 0.5474 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [201/782] Loss: 0.5476 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [202/782] Loss: 0.1762 | Acc: 82.06%\n",
      "Train Epoch [71/100] Batch [203/782] Loss: 0.7004 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [204/782] Loss: 0.3748 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [205/782] Loss: 0.6281 | Acc: 81.98%\n",
      "Train Epoch [71/100] Batch [206/782] Loss: 0.4675 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [207/782] Loss: 0.4940 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [208/782] Loss: 0.5657 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [209/782] Loss: 0.4521 | Acc: 81.98%\n",
      "Train Epoch [71/100] Batch [210/782] Loss: 0.7950 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [211/782] Loss: 0.3508 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [212/782] Loss: 0.5404 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [213/782] Loss: 0.4558 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [214/782] Loss: 0.3965 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [215/782] Loss: 0.4551 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [216/782] Loss: 0.5483 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [217/782] Loss: 0.5588 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [218/782] Loss: 0.4973 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [219/782] Loss: 0.3238 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [220/782] Loss: 0.4465 | Acc: 82.03%\n",
      "Train Epoch [71/100] Batch [221/782] Loss: 0.5098 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [222/782] Loss: 0.4981 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [223/782] Loss: 0.4123 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [224/782] Loss: 0.5900 | Acc: 82.03%\n",
      "Train Epoch [71/100] Batch [225/782] Loss: 0.4600 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [226/782] Loss: 0.4176 | Acc: 82.06%\n",
      "Train Epoch [71/100] Batch [227/782] Loss: 0.4293 | Acc: 82.06%\n",
      "Train Epoch [71/100] Batch [228/782] Loss: 0.5549 | Acc: 82.07%\n",
      "Train Epoch [71/100] Batch [229/782] Loss: 0.4738 | Acc: 82.08%\n",
      "Train Epoch [71/100] Batch [230/782] Loss: 0.3370 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [231/782] Loss: 0.3171 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [232/782] Loss: 0.5798 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [233/782] Loss: 0.6213 | Acc: 82.14%\n",
      "Train Epoch [71/100] Batch [234/782] Loss: 0.5101 | Acc: 82.11%\n",
      "Train Epoch [71/100] Batch [235/782] Loss: 0.5775 | Acc: 82.09%\n",
      "Train Epoch [71/100] Batch [236/782] Loss: 0.3303 | Acc: 82.10%\n",
      "Train Epoch [71/100] Batch [237/782] Loss: 0.7193 | Acc: 82.08%\n",
      "Train Epoch [71/100] Batch [238/782] Loss: 0.5322 | Acc: 82.08%\n",
      "Train Epoch [71/100] Batch [239/782] Loss: 0.4809 | Acc: 82.07%\n",
      "Train Epoch [71/100] Batch [240/782] Loss: 0.6764 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [241/782] Loss: 0.4278 | Acc: 82.03%\n",
      "Train Epoch [71/100] Batch [242/782] Loss: 0.3996 | Acc: 82.06%\n",
      "Train Epoch [71/100] Batch [243/782] Loss: 0.7029 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [244/782] Loss: 0.6952 | Acc: 82.04%\n",
      "Train Epoch [71/100] Batch [245/782] Loss: 0.5913 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [246/782] Loss: 0.4801 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [247/782] Loss: 0.5486 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [248/782] Loss: 0.3490 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [249/782] Loss: 0.3184 | Acc: 82.03%\n",
      "Train Epoch [71/100] Batch [250/782] Loss: 0.6234 | Acc: 82.02%\n",
      "Train Epoch [71/100] Batch [251/782] Loss: 0.6269 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [252/782] Loss: 0.6197 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [253/782] Loss: 0.3945 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [254/782] Loss: 0.5346 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [255/782] Loss: 0.6445 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [256/782] Loss: 0.5610 | Acc: 81.98%\n",
      "Train Epoch [71/100] Batch [257/782] Loss: 0.4037 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [258/782] Loss: 0.5280 | Acc: 81.99%\n",
      "Train Epoch [71/100] Batch [259/782] Loss: 0.4199 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [260/782] Loss: 0.4834 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [261/782] Loss: 0.4478 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [262/782] Loss: 0.4578 | Acc: 82.01%\n",
      "Train Epoch [71/100] Batch [263/782] Loss: 0.5275 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [264/782] Loss: 0.5188 | Acc: 82.00%\n",
      "Train Epoch [71/100] Batch [265/782] Loss: 0.7877 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [266/782] Loss: 0.4973 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [267/782] Loss: 0.5347 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [268/782] Loss: 0.3849 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [269/782] Loss: 0.5225 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [270/782] Loss: 0.6311 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [271/782] Loss: 0.5062 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [272/782] Loss: 0.6659 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [273/782] Loss: 0.5468 | Acc: 81.96%\n",
      "Train Epoch [71/100] Batch [274/782] Loss: 0.4783 | Acc: 81.97%\n",
      "Train Epoch [71/100] Batch [275/782] Loss: 0.7076 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [276/782] Loss: 0.4112 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [277/782] Loss: 0.4868 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [278/782] Loss: 0.5346 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [279/782] Loss: 0.5724 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [280/782] Loss: 0.5260 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [281/782] Loss: 0.4477 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [282/782] Loss: 0.4150 | Acc: 81.94%\n",
      "Train Epoch [71/100] Batch [283/782] Loss: 0.4234 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [284/782] Loss: 0.4351 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [285/782] Loss: 0.6187 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [286/782] Loss: 0.5406 | Acc: 81.92%\n",
      "Train Epoch [71/100] Batch [287/782] Loss: 0.4226 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [288/782] Loss: 0.3594 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [289/782] Loss: 0.5407 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [290/782] Loss: 0.5134 | Acc: 81.95%\n",
      "Train Epoch [71/100] Batch [291/782] Loss: 0.7421 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [292/782] Loss: 0.4749 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [293/782] Loss: 0.3994 | Acc: 81.92%\n",
      "Train Epoch [71/100] Batch [294/782] Loss: 0.4468 | Acc: 81.93%\n",
      "Train Epoch [71/100] Batch [295/782] Loss: 0.6175 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [296/782] Loss: 0.5541 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [297/782] Loss: 0.4181 | Acc: 81.90%\n",
      "Train Epoch [71/100] Batch [298/782] Loss: 0.7758 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [299/782] Loss: 0.5678 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [300/782] Loss: 0.5728 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [301/782] Loss: 0.4951 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [302/782] Loss: 0.4584 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [303/782] Loss: 0.5744 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [304/782] Loss: 0.4433 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [305/782] Loss: 0.4293 | Acc: 81.90%\n",
      "Train Epoch [71/100] Batch [306/782] Loss: 0.5414 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [307/782] Loss: 0.4688 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [308/782] Loss: 0.5609 | Acc: 81.91%\n",
      "Train Epoch [71/100] Batch [309/782] Loss: 0.7480 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [310/782] Loss: 0.5934 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [311/782] Loss: 0.4793 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [312/782] Loss: 0.4601 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [313/782] Loss: 0.4461 | Acc: 81.88%\n",
      "Train Epoch [71/100] Batch [314/782] Loss: 0.6624 | Acc: 81.89%\n",
      "Train Epoch [71/100] Batch [315/782] Loss: 0.6781 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [316/782] Loss: 0.5509 | Acc: 81.85%\n",
      "Train Epoch [71/100] Batch [317/782] Loss: 0.5120 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [318/782] Loss: 0.6204 | Acc: 81.85%\n",
      "Train Epoch [71/100] Batch [319/782] Loss: 0.4943 | Acc: 81.84%\n",
      "Train Epoch [71/100] Batch [320/782] Loss: 0.2926 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [321/782] Loss: 0.7225 | Acc: 81.84%\n",
      "Train Epoch [71/100] Batch [322/782] Loss: 0.3609 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [323/782] Loss: 0.5306 | Acc: 81.86%\n",
      "Train Epoch [71/100] Batch [324/782] Loss: 0.4575 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [325/782] Loss: 0.4041 | Acc: 81.87%\n",
      "Train Epoch [71/100] Batch [326/782] Loss: 0.6402 | Acc: 81.84%\n",
      "Train Epoch [71/100] Batch [327/782] Loss: 0.5308 | Acc: 81.83%\n",
      "Train Epoch [71/100] Batch [328/782] Loss: 0.5317 | Acc: 81.82%\n",
      "Train Epoch [71/100] Batch [329/782] Loss: 0.4763 | Acc: 81.83%\n",
      "Train Epoch [71/100] Batch [330/782] Loss: 0.4510 | Acc: 81.83%\n",
      "Train Epoch [71/100] Batch [331/782] Loss: 0.5919 | Acc: 81.82%\n",
      "Train Epoch [71/100] Batch [332/782] Loss: 0.5965 | Acc: 81.80%\n",
      "Train Epoch [71/100] Batch [333/782] Loss: 0.5633 | Acc: 81.78%\n",
      "Train Epoch [71/100] Batch [334/782] Loss: 0.4300 | Acc: 81.80%\n",
      "Train Epoch [71/100] Batch [335/782] Loss: 0.5058 | Acc: 81.81%\n",
      "Train Epoch [71/100] Batch [336/782] Loss: 0.7133 | Acc: 81.78%\n",
      "Train Epoch [71/100] Batch [337/782] Loss: 0.3929 | Acc: 81.81%\n",
      "Train Epoch [71/100] Batch [338/782] Loss: 0.5476 | Acc: 81.79%\n",
      "Train Epoch [71/100] Batch [339/782] Loss: 0.4495 | Acc: 81.79%\n",
      "Train Epoch [71/100] Batch [340/782] Loss: 0.5706 | Acc: 81.79%\n",
      "Train Epoch [71/100] Batch [341/782] Loss: 0.6589 | Acc: 81.79%\n",
      "Train Epoch [71/100] Batch [342/782] Loss: 0.4196 | Acc: 81.78%\n",
      "Train Epoch [71/100] Batch [343/782] Loss: 0.6319 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [344/782] Loss: 0.5519 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [345/782] Loss: 0.4165 | Acc: 81.77%\n",
      "Train Epoch [71/100] Batch [346/782] Loss: 0.4761 | Acc: 81.77%\n",
      "Train Epoch [71/100] Batch [347/782] Loss: 0.6452 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [348/782] Loss: 0.5180 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [349/782] Loss: 0.4277 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [350/782] Loss: 0.4892 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [351/782] Loss: 0.5028 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [352/782] Loss: 0.5552 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [353/782] Loss: 0.4047 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [354/782] Loss: 0.6646 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [355/782] Loss: 0.6380 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [356/782] Loss: 0.5510 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [357/782] Loss: 0.4990 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [358/782] Loss: 0.5733 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [359/782] Loss: 0.5610 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [360/782] Loss: 0.4096 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [361/782] Loss: 0.3687 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [362/782] Loss: 0.3797 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [363/782] Loss: 0.5316 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [364/782] Loss: 0.3354 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [365/782] Loss: 0.4968 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [366/782] Loss: 0.4826 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [367/782] Loss: 0.6253 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [368/782] Loss: 0.5028 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [369/782] Loss: 0.4895 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [370/782] Loss: 0.6181 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [371/782] Loss: 0.4087 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [372/782] Loss: 0.4575 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [373/782] Loss: 0.6466 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [374/782] Loss: 0.4462 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [375/782] Loss: 0.5226 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [376/782] Loss: 0.5958 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [377/782] Loss: 0.5895 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [378/782] Loss: 0.4225 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [379/782] Loss: 0.5102 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [380/782] Loss: 0.3024 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [381/782] Loss: 0.6789 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [382/782] Loss: 0.6695 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [383/782] Loss: 0.4389 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [384/782] Loss: 0.5875 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [385/782] Loss: 0.4104 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [386/782] Loss: 0.4529 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [387/782] Loss: 0.5129 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [388/782] Loss: 0.7727 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [389/782] Loss: 0.5755 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [390/782] Loss: 0.5316 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [391/782] Loss: 0.5813 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [392/782] Loss: 0.5658 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [393/782] Loss: 0.9215 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [394/782] Loss: 0.4773 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [395/782] Loss: 0.4863 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [396/782] Loss: 0.6959 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [397/782] Loss: 0.4505 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [398/782] Loss: 0.4401 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [399/782] Loss: 0.6491 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [400/782] Loss: 0.6638 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [401/782] Loss: 0.6568 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [402/782] Loss: 0.4690 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [403/782] Loss: 0.4516 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [404/782] Loss: 0.3904 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [405/782] Loss: 0.4216 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [406/782] Loss: 0.6182 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [407/782] Loss: 0.4107 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [408/782] Loss: 0.3329 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [409/782] Loss: 0.4247 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [410/782] Loss: 0.4810 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [411/782] Loss: 0.5923 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [412/782] Loss: 0.5449 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [413/782] Loss: 0.3582 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [414/782] Loss: 0.3921 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [415/782] Loss: 0.5494 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [416/782] Loss: 0.5183 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [417/782] Loss: 0.4689 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [418/782] Loss: 0.5970 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [419/782] Loss: 0.4803 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [420/782] Loss: 0.4493 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [421/782] Loss: 0.4912 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [422/782] Loss: 0.4869 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [423/782] Loss: 0.4662 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [424/782] Loss: 0.4813 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [425/782] Loss: 0.4746 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [426/782] Loss: 0.3874 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [427/782] Loss: 0.4121 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [428/782] Loss: 0.6097 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [429/782] Loss: 0.6015 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [430/782] Loss: 0.5552 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [431/782] Loss: 0.5358 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [432/782] Loss: 0.5493 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [433/782] Loss: 0.3819 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [434/782] Loss: 0.3329 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [435/782] Loss: 0.6721 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [436/782] Loss: 0.5196 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [437/782] Loss: 0.5667 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [438/782] Loss: 0.4624 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [439/782] Loss: 0.5596 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [440/782] Loss: 0.5542 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [441/782] Loss: 0.4011 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [442/782] Loss: 0.6667 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [443/782] Loss: 0.7835 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [444/782] Loss: 0.4531 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [445/782] Loss: 0.5576 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [446/782] Loss: 0.3484 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [447/782] Loss: 0.5244 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [448/782] Loss: 0.7513 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [449/782] Loss: 0.5328 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [450/782] Loss: 0.5273 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [451/782] Loss: 0.5059 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [452/782] Loss: 0.6366 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [453/782] Loss: 0.4154 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [454/782] Loss: 0.4366 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [455/782] Loss: 0.5562 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [456/782] Loss: 0.5250 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [457/782] Loss: 0.5175 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [458/782] Loss: 0.5301 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [459/782] Loss: 0.3877 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [460/782] Loss: 0.4416 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [461/782] Loss: 0.4612 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [462/782] Loss: 0.5078 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [463/782] Loss: 0.6114 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [464/782] Loss: 0.4541 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [465/782] Loss: 0.5276 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [466/782] Loss: 0.4498 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [467/782] Loss: 0.4549 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [468/782] Loss: 0.6751 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [469/782] Loss: 0.6828 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [470/782] Loss: 0.3902 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [471/782] Loss: 0.6629 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [472/782] Loss: 0.7424 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [473/782] Loss: 0.5658 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [474/782] Loss: 0.5915 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [475/782] Loss: 0.4526 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [476/782] Loss: 0.5384 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [477/782] Loss: 0.3481 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [478/782] Loss: 0.3601 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [479/782] Loss: 0.4240 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [480/782] Loss: 0.6038 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [481/782] Loss: 0.5266 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [482/782] Loss: 0.5380 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [483/782] Loss: 0.5705 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [484/782] Loss: 0.5154 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [485/782] Loss: 0.5294 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [486/782] Loss: 0.5851 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [487/782] Loss: 0.4041 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [488/782] Loss: 0.6520 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [489/782] Loss: 0.8754 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [490/782] Loss: 0.4938 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [491/782] Loss: 0.5645 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [492/782] Loss: 0.3656 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [493/782] Loss: 0.4889 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [494/782] Loss: 0.5653 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [495/782] Loss: 0.3478 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [496/782] Loss: 0.5116 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [497/782] Loss: 0.4998 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [498/782] Loss: 0.4093 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [499/782] Loss: 0.5704 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [500/782] Loss: 0.7582 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [501/782] Loss: 0.3959 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [502/782] Loss: 0.5520 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [503/782] Loss: 0.4920 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [504/782] Loss: 0.3505 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [505/782] Loss: 0.5302 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [506/782] Loss: 0.6116 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [507/782] Loss: 0.4210 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [508/782] Loss: 0.4424 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [509/782] Loss: 0.5645 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [510/782] Loss: 0.5486 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [511/782] Loss: 0.4129 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [512/782] Loss: 0.5113 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [513/782] Loss: 0.3770 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [514/782] Loss: 0.5468 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [515/782] Loss: 0.5450 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [516/782] Loss: 0.3803 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [517/782] Loss: 0.5001 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [518/782] Loss: 0.6686 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [519/782] Loss: 0.4478 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [520/782] Loss: 0.6881 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [521/782] Loss: 0.5823 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [522/782] Loss: 0.4167 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [523/782] Loss: 0.3757 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [524/782] Loss: 0.4229 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [525/782] Loss: 0.4984 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [526/782] Loss: 0.5580 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [527/782] Loss: 0.4440 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [528/782] Loss: 0.3027 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [529/782] Loss: 0.7331 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [530/782] Loss: 0.5242 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [531/782] Loss: 0.7472 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [532/782] Loss: 0.4208 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [533/782] Loss: 0.3565 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [534/782] Loss: 0.6763 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [535/782] Loss: 0.6482 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [536/782] Loss: 0.3928 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [537/782] Loss: 0.3102 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [538/782] Loss: 0.3634 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [539/782] Loss: 0.7039 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [540/782] Loss: 0.4885 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [541/782] Loss: 0.5322 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [542/782] Loss: 0.4651 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [543/782] Loss: 0.5133 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [544/782] Loss: 0.5306 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [545/782] Loss: 0.3868 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [546/782] Loss: 0.4734 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [547/782] Loss: 0.6859 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [548/782] Loss: 0.4894 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [549/782] Loss: 0.5873 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [550/782] Loss: 0.4693 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [551/782] Loss: 0.4792 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [552/782] Loss: 0.3984 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [553/782] Loss: 0.5144 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [554/782] Loss: 0.4146 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [555/782] Loss: 0.4449 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [556/782] Loss: 0.5019 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [557/782] Loss: 0.6803 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [558/782] Loss: 0.4894 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [559/782] Loss: 0.4838 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [560/782] Loss: 0.5069 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [561/782] Loss: 0.6947 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [562/782] Loss: 0.3441 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [563/782] Loss: 0.6344 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [564/782] Loss: 0.3602 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [565/782] Loss: 0.4020 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [566/782] Loss: 0.4077 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [567/782] Loss: 0.5366 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [568/782] Loss: 0.7348 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [569/782] Loss: 0.6166 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [570/782] Loss: 0.4771 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [571/782] Loss: 0.3913 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [572/782] Loss: 0.5322 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [573/782] Loss: 0.4857 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [574/782] Loss: 0.3376 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [575/782] Loss: 0.6198 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [576/782] Loss: 0.4877 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [577/782] Loss: 0.3730 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [578/782] Loss: 0.5010 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [579/782] Loss: 0.3931 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [580/782] Loss: 0.4444 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [581/782] Loss: 0.5936 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [582/782] Loss: 0.3749 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [583/782] Loss: 0.5935 | Acc: 81.75%\n",
      "Train Epoch [71/100] Batch [584/782] Loss: 0.5292 | Acc: 81.74%\n",
      "Train Epoch [71/100] Batch [585/782] Loss: 0.6071 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [586/782] Loss: 0.5819 | Acc: 81.72%\n",
      "Train Epoch [71/100] Batch [587/782] Loss: 0.5104 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [588/782] Loss: 0.5412 | Acc: 81.73%\n",
      "Train Epoch [71/100] Batch [589/782] Loss: 0.6568 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [590/782] Loss: 0.5491 | Acc: 81.71%\n",
      "Train Epoch [71/100] Batch [591/782] Loss: 0.6716 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [592/782] Loss: 0.5177 | Acc: 81.70%\n",
      "Train Epoch [71/100] Batch [593/782] Loss: 0.5293 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [594/782] Loss: 0.5675 | Acc: 81.69%\n",
      "Train Epoch [71/100] Batch [595/782] Loss: 0.6445 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [596/782] Loss: 0.3730 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [597/782] Loss: 0.5766 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [598/782] Loss: 0.6142 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [599/782] Loss: 0.4762 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [600/782] Loss: 0.5427 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [601/782] Loss: 0.5720 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [602/782] Loss: 0.4002 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [603/782] Loss: 0.3952 | Acc: 81.67%\n",
      "Train Epoch [71/100] Batch [604/782] Loss: 0.4013 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [605/782] Loss: 0.4384 | Acc: 81.68%\n",
      "Train Epoch [71/100] Batch [606/782] Loss: 0.5850 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [607/782] Loss: 0.5106 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [608/782] Loss: 0.4147 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [609/782] Loss: 0.5712 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [610/782] Loss: 0.4894 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [611/782] Loss: 0.4984 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [612/782] Loss: 0.4612 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [613/782] Loss: 0.6139 | Acc: 81.66%\n",
      "Train Epoch [71/100] Batch [614/782] Loss: 0.4021 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [615/782] Loss: 0.6706 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [616/782] Loss: 0.5951 | Acc: 81.65%\n",
      "Train Epoch [71/100] Batch [617/782] Loss: 0.6667 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [618/782] Loss: 0.7394 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [619/782] Loss: 0.4502 | Acc: 81.64%\n",
      "Train Epoch [71/100] Batch [620/782] Loss: 0.6259 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [621/782] Loss: 0.5018 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [622/782] Loss: 0.7218 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [623/782] Loss: 0.5852 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [624/782] Loss: 0.5490 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [625/782] Loss: 0.5003 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [626/782] Loss: 0.4599 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [627/782] Loss: 0.4926 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [628/782] Loss: 0.3989 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [629/782] Loss: 0.4060 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [630/782] Loss: 0.5869 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [631/782] Loss: 0.5373 | Acc: 81.63%\n",
      "Train Epoch [71/100] Batch [632/782] Loss: 0.5999 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [633/782] Loss: 0.6125 | Acc: 81.61%\n",
      "Train Epoch [71/100] Batch [634/782] Loss: 0.5000 | Acc: 81.62%\n",
      "Train Epoch [71/100] Batch [635/782] Loss: 0.7400 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [636/782] Loss: 0.7427 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [637/782] Loss: 0.4807 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [638/782] Loss: 0.6211 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [639/782] Loss: 0.6011 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [640/782] Loss: 0.5047 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [641/782] Loss: 0.6365 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [642/782] Loss: 0.5087 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [643/782] Loss: 0.6444 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [644/782] Loss: 0.4802 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [645/782] Loss: 0.3991 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [646/782] Loss: 0.5319 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [647/782] Loss: 0.3999 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [648/782] Loss: 0.5249 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [649/782] Loss: 0.3912 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [650/782] Loss: 0.5225 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [651/782] Loss: 0.4985 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [652/782] Loss: 0.5204 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [653/782] Loss: 0.4361 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [654/782] Loss: 0.5744 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [655/782] Loss: 0.4272 | Acc: 81.60%\n",
      "Train Epoch [71/100] Batch [656/782] Loss: 0.7027 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [657/782] Loss: 0.4968 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [658/782] Loss: 0.4841 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [659/782] Loss: 0.6148 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [660/782] Loss: 0.7379 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [661/782] Loss: 0.4782 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [662/782] Loss: 0.2918 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [663/782] Loss: 0.3423 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [664/782] Loss: 0.7026 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [665/782] Loss: 0.5425 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [666/782] Loss: 0.4933 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [667/782] Loss: 0.4261 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [668/782] Loss: 0.7310 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [669/782] Loss: 0.5501 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [670/782] Loss: 0.6739 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [671/782] Loss: 0.5885 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [672/782] Loss: 0.4858 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [673/782] Loss: 0.6691 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [674/782] Loss: 0.2980 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [675/782] Loss: 0.3604 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [676/782] Loss: 0.3919 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [677/782] Loss: 0.6675 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [678/782] Loss: 0.4286 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [679/782] Loss: 0.3480 | Acc: 81.59%\n",
      "Train Epoch [71/100] Batch [680/782] Loss: 0.6318 | Acc: 81.58%\n",
      "Train Epoch [71/100] Batch [681/782] Loss: 0.7766 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [682/782] Loss: 0.4591 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [683/782] Loss: 0.4895 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [684/782] Loss: 0.6782 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [685/782] Loss: 0.6531 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [686/782] Loss: 0.4865 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [687/782] Loss: 0.4315 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [688/782] Loss: 0.6631 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [689/782] Loss: 0.5814 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [690/782] Loss: 0.4761 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [691/782] Loss: 0.5251 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [692/782] Loss: 0.7780 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [693/782] Loss: 0.4897 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [694/782] Loss: 0.4606 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [695/782] Loss: 0.5092 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [696/782] Loss: 0.5043 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [697/782] Loss: 0.4394 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [698/782] Loss: 0.4997 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [699/782] Loss: 0.6211 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [700/782] Loss: 0.3786 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [701/782] Loss: 0.2596 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [702/782] Loss: 0.5975 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [703/782] Loss: 0.5655 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [704/782] Loss: 0.4668 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [705/782] Loss: 0.4126 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [706/782] Loss: 0.4852 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [707/782] Loss: 0.5414 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [708/782] Loss: 0.7081 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [709/782] Loss: 0.3278 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [710/782] Loss: 0.5794 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [711/782] Loss: 0.3294 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [712/782] Loss: 0.5382 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [713/782] Loss: 0.4752 | Acc: 81.55%\n",
      "Train Epoch [71/100] Batch [714/782] Loss: 0.4943 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [715/782] Loss: 0.4046 | Acc: 81.57%\n",
      "Train Epoch [71/100] Batch [716/782] Loss: 0.6882 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [717/782] Loss: 0.5665 | Acc: 81.56%\n",
      "Train Epoch [71/100] Batch [718/782] Loss: 0.6398 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [719/782] Loss: 0.6323 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [720/782] Loss: 0.6041 | Acc: 81.54%\n",
      "Train Epoch [71/100] Batch [721/782] Loss: 0.5736 | Acc: 81.53%\n",
      "Train Epoch [71/100] Batch [722/782] Loss: 0.5773 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [723/782] Loss: 0.5699 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [724/782] Loss: 0.5827 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [725/782] Loss: 0.4713 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [726/782] Loss: 0.5231 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [727/782] Loss: 0.4442 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [728/782] Loss: 0.7073 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [729/782] Loss: 0.5535 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [730/782] Loss: 0.4589 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [731/782] Loss: 0.4496 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [732/782] Loss: 0.5920 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [733/782] Loss: 0.5923 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [734/782] Loss: 0.4531 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [735/782] Loss: 0.5217 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [736/782] Loss: 0.3739 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [737/782] Loss: 0.4411 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [738/782] Loss: 0.4624 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [739/782] Loss: 0.4689 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [740/782] Loss: 0.3516 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [741/782] Loss: 0.7456 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [742/782] Loss: 0.5203 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [743/782] Loss: 0.4849 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [744/782] Loss: 0.3249 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [745/782] Loss: 0.6442 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [746/782] Loss: 0.5082 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [747/782] Loss: 0.3867 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [748/782] Loss: 0.5593 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [749/782] Loss: 0.5447 | Acc: 81.52%\n",
      "Train Epoch [71/100] Batch [750/782] Loss: 0.6185 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [751/782] Loss: 0.5376 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [752/782] Loss: 0.4454 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [753/782] Loss: 0.5429 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [754/782] Loss: 0.5793 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [755/782] Loss: 0.5299 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [756/782] Loss: 0.4293 | Acc: 81.51%\n",
      "Train Epoch [71/100] Batch [757/782] Loss: 0.5664 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [758/782] Loss: 0.6615 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [759/782] Loss: 0.5347 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [760/782] Loss: 0.4610 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [761/782] Loss: 0.5679 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [762/782] Loss: 0.5832 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [763/782] Loss: 0.5985 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [764/782] Loss: 0.3670 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [765/782] Loss: 0.5701 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [766/782] Loss: 0.4803 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [767/782] Loss: 0.4789 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [768/782] Loss: 0.5999 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [769/782] Loss: 0.7505 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [770/782] Loss: 0.5137 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [771/782] Loss: 0.3228 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [772/782] Loss: 0.4556 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [773/782] Loss: 0.6950 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [774/782] Loss: 0.3727 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [775/782] Loss: 0.4446 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [776/782] Loss: 0.6435 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [777/782] Loss: 0.6997 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [778/782] Loss: 0.3364 | Acc: 81.48%\n",
      "Train Epoch [71/100] Batch [779/782] Loss: 0.3584 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [780/782] Loss: 0.4195 | Acc: 81.50%\n",
      "Train Epoch [71/100] Batch [781/782] Loss: 0.5371 | Acc: 81.49%\n",
      "Train Epoch [71/100] Batch [782/782] Loss: 0.8952 | Acc: 81.48%\n",
      "Epoch 71 completed in 30.68s.\n",
      "Test Epoch [71/100] Loss: 0.9491 | Acc: 71.62% | Inference Time: 8.47s\n",
      "Epoch 71 results saved to CSV.\n",
      "Epoch 72/100\n",
      "Train Epoch [72/100] Batch [1/782] Loss: 0.3142 | Acc: 89.06%\n",
      "Train Epoch [72/100] Batch [2/782] Loss: 0.3976 | Acc: 86.72%\n",
      "Train Epoch [72/100] Batch [3/782] Loss: 0.4167 | Acc: 85.94%\n",
      "Train Epoch [72/100] Batch [4/782] Loss: 0.4983 | Acc: 85.94%\n",
      "Train Epoch [72/100] Batch [5/782] Loss: 0.4397 | Acc: 85.62%\n",
      "Train Epoch [72/100] Batch [6/782] Loss: 0.6129 | Acc: 84.90%\n",
      "Train Epoch [72/100] Batch [7/782] Loss: 0.5132 | Acc: 84.60%\n",
      "Train Epoch [72/100] Batch [8/782] Loss: 0.3888 | Acc: 84.77%\n",
      "Train Epoch [72/100] Batch [9/782] Loss: 0.4848 | Acc: 84.03%\n",
      "Train Epoch [72/100] Batch [10/782] Loss: 0.6030 | Acc: 83.75%\n",
      "Train Epoch [72/100] Batch [11/782] Loss: 0.4695 | Acc: 83.52%\n",
      "Train Epoch [72/100] Batch [12/782] Loss: 0.3725 | Acc: 83.85%\n",
      "Train Epoch [72/100] Batch [13/782] Loss: 0.4879 | Acc: 83.53%\n",
      "Train Epoch [72/100] Batch [14/782] Loss: 0.4896 | Acc: 83.26%\n",
      "Train Epoch [72/100] Batch [15/782] Loss: 0.5980 | Acc: 83.02%\n",
      "Train Epoch [72/100] Batch [16/782] Loss: 0.3399 | Acc: 83.50%\n",
      "Train Epoch [72/100] Batch [17/782] Loss: 0.4450 | Acc: 83.55%\n",
      "Train Epoch [72/100] Batch [18/782] Loss: 0.5393 | Acc: 83.33%\n",
      "Train Epoch [72/100] Batch [19/782] Loss: 0.5522 | Acc: 83.14%\n",
      "Train Epoch [72/100] Batch [20/782] Loss: 0.2656 | Acc: 83.44%\n",
      "Train Epoch [72/100] Batch [21/782] Loss: 0.5059 | Acc: 83.26%\n",
      "Train Epoch [72/100] Batch [22/782] Loss: 0.5005 | Acc: 83.24%\n",
      "Train Epoch [72/100] Batch [23/782] Loss: 0.4202 | Acc: 83.22%\n",
      "Train Epoch [72/100] Batch [24/782] Loss: 0.4288 | Acc: 83.20%\n",
      "Train Epoch [72/100] Batch [25/782] Loss: 0.3240 | Acc: 83.38%\n",
      "Train Epoch [72/100] Batch [26/782] Loss: 0.4022 | Acc: 83.47%\n",
      "Train Epoch [72/100] Batch [27/782] Loss: 0.4330 | Acc: 83.33%\n",
      "Train Epoch [72/100] Batch [28/782] Loss: 0.4039 | Acc: 83.37%\n",
      "Train Epoch [72/100] Batch [29/782] Loss: 0.3494 | Acc: 83.62%\n",
      "Train Epoch [72/100] Batch [30/782] Loss: 0.6027 | Acc: 83.49%\n",
      "Train Epoch [72/100] Batch [31/782] Loss: 0.5509 | Acc: 83.37%\n",
      "Train Epoch [72/100] Batch [32/782] Loss: 0.5614 | Acc: 83.25%\n",
      "Train Epoch [72/100] Batch [33/782] Loss: 0.5290 | Acc: 83.24%\n",
      "Train Epoch [72/100] Batch [34/782] Loss: 0.5058 | Acc: 83.32%\n",
      "Train Epoch [72/100] Batch [35/782] Loss: 0.6260 | Acc: 83.30%\n",
      "Train Epoch [72/100] Batch [36/782] Loss: 0.5368 | Acc: 83.12%\n",
      "Train Epoch [72/100] Batch [37/782] Loss: 0.6697 | Acc: 82.81%\n",
      "Train Epoch [72/100] Batch [38/782] Loss: 0.6304 | Acc: 82.61%\n",
      "Train Epoch [72/100] Batch [39/782] Loss: 0.5917 | Acc: 82.45%\n",
      "Train Epoch [72/100] Batch [40/782] Loss: 0.5947 | Acc: 82.30%\n",
      "Train Epoch [72/100] Batch [41/782] Loss: 0.5600 | Acc: 82.24%\n",
      "Train Epoch [72/100] Batch [42/782] Loss: 0.5653 | Acc: 82.03%\n",
      "Train Epoch [72/100] Batch [43/782] Loss: 0.4394 | Acc: 82.12%\n",
      "Train Epoch [72/100] Batch [44/782] Loss: 0.8001 | Acc: 82.00%\n",
      "Train Epoch [72/100] Batch [45/782] Loss: 0.5307 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [46/782] Loss: 0.5026 | Acc: 82.07%\n",
      "Train Epoch [72/100] Batch [47/782] Loss: 0.5319 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [48/782] Loss: 0.5136 | Acc: 81.97%\n",
      "Train Epoch [72/100] Batch [49/782] Loss: 0.5431 | Acc: 81.92%\n",
      "Train Epoch [72/100] Batch [50/782] Loss: 0.5485 | Acc: 81.91%\n",
      "Train Epoch [72/100] Batch [51/782] Loss: 0.4412 | Acc: 81.92%\n",
      "Train Epoch [72/100] Batch [52/782] Loss: 0.3381 | Acc: 82.00%\n",
      "Train Epoch [72/100] Batch [53/782] Loss: 0.4535 | Acc: 82.05%\n",
      "Train Epoch [72/100] Batch [54/782] Loss: 0.3880 | Acc: 82.12%\n",
      "Train Epoch [72/100] Batch [55/782] Loss: 0.4744 | Acc: 82.13%\n",
      "Train Epoch [72/100] Batch [56/782] Loss: 0.7519 | Acc: 81.95%\n",
      "Train Epoch [72/100] Batch [57/782] Loss: 0.3158 | Acc: 82.07%\n",
      "Train Epoch [72/100] Batch [58/782] Loss: 0.4854 | Acc: 82.09%\n",
      "Train Epoch [72/100] Batch [59/782] Loss: 0.5715 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [60/782] Loss: 0.4835 | Acc: 82.03%\n",
      "Train Epoch [72/100] Batch [61/782] Loss: 0.7001 | Acc: 81.94%\n",
      "Train Epoch [72/100] Batch [62/782] Loss: 0.7182 | Acc: 81.80%\n",
      "Train Epoch [72/100] Batch [63/782] Loss: 0.5473 | Acc: 81.80%\n",
      "Train Epoch [72/100] Batch [64/782] Loss: 0.4963 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [65/782] Loss: 0.4636 | Acc: 81.78%\n",
      "Train Epoch [72/100] Batch [66/782] Loss: 0.4425 | Acc: 81.84%\n",
      "Train Epoch [72/100] Batch [67/782] Loss: 0.6669 | Acc: 81.74%\n",
      "Train Epoch [72/100] Batch [68/782] Loss: 0.4269 | Acc: 81.80%\n",
      "Train Epoch [72/100] Batch [69/782] Loss: 0.2887 | Acc: 81.91%\n",
      "Train Epoch [72/100] Batch [70/782] Loss: 0.5795 | Acc: 81.88%\n",
      "Train Epoch [72/100] Batch [71/782] Loss: 0.4499 | Acc: 81.89%\n",
      "Train Epoch [72/100] Batch [72/782] Loss: 0.7136 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [73/782] Loss: 0.5151 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [74/782] Loss: 0.6216 | Acc: 81.74%\n",
      "Train Epoch [72/100] Batch [75/782] Loss: 0.7461 | Acc: 81.69%\n",
      "Train Epoch [72/100] Batch [76/782] Loss: 0.4638 | Acc: 81.70%\n",
      "Train Epoch [72/100] Batch [77/782] Loss: 0.7121 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [78/782] Loss: 0.4046 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [79/782] Loss: 0.3610 | Acc: 81.84%\n",
      "Train Epoch [72/100] Batch [80/782] Loss: 0.4468 | Acc: 81.93%\n",
      "Train Epoch [72/100] Batch [81/782] Loss: 0.4090 | Acc: 81.93%\n",
      "Train Epoch [72/100] Batch [82/782] Loss: 0.4334 | Acc: 81.96%\n",
      "Train Epoch [72/100] Batch [83/782] Loss: 0.4172 | Acc: 81.93%\n",
      "Train Epoch [72/100] Batch [84/782] Loss: 0.5115 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [85/782] Loss: 0.6162 | Acc: 81.88%\n",
      "Train Epoch [72/100] Batch [86/782] Loss: 0.4404 | Acc: 81.90%\n",
      "Train Epoch [72/100] Batch [87/782] Loss: 0.4333 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [88/782] Loss: 0.3137 | Acc: 82.05%\n",
      "Train Epoch [72/100] Batch [89/782] Loss: 0.3743 | Acc: 82.11%\n",
      "Train Epoch [72/100] Batch [90/782] Loss: 0.5871 | Acc: 82.08%\n",
      "Train Epoch [72/100] Batch [91/782] Loss: 0.4697 | Acc: 82.09%\n",
      "Train Epoch [72/100] Batch [92/782] Loss: 0.4640 | Acc: 82.12%\n",
      "Train Epoch [72/100] Batch [93/782] Loss: 0.4553 | Acc: 82.11%\n",
      "Train Epoch [72/100] Batch [94/782] Loss: 0.5900 | Acc: 82.11%\n",
      "Train Epoch [72/100] Batch [95/782] Loss: 0.4822 | Acc: 82.15%\n",
      "Train Epoch [72/100] Batch [96/782] Loss: 0.4638 | Acc: 82.15%\n",
      "Train Epoch [72/100] Batch [97/782] Loss: 0.5043 | Acc: 82.12%\n",
      "Train Epoch [72/100] Batch [98/782] Loss: 0.3694 | Acc: 82.16%\n",
      "Train Epoch [72/100] Batch [99/782] Loss: 0.6515 | Acc: 82.10%\n",
      "Train Epoch [72/100] Batch [100/782] Loss: 0.4714 | Acc: 82.09%\n",
      "Train Epoch [72/100] Batch [101/782] Loss: 0.7040 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [102/782] Loss: 0.4345 | Acc: 82.08%\n",
      "Train Epoch [72/100] Batch [103/782] Loss: 0.3910 | Acc: 82.11%\n",
      "Train Epoch [72/100] Batch [104/782] Loss: 0.3974 | Acc: 82.18%\n",
      "Train Epoch [72/100] Batch [105/782] Loss: 0.3614 | Acc: 82.29%\n",
      "Train Epoch [72/100] Batch [106/782] Loss: 0.4537 | Acc: 82.28%\n",
      "Train Epoch [72/100] Batch [107/782] Loss: 0.4469 | Acc: 82.26%\n",
      "Train Epoch [72/100] Batch [108/782] Loss: 0.4370 | Acc: 82.28%\n",
      "Train Epoch [72/100] Batch [109/782] Loss: 0.4583 | Acc: 82.33%\n",
      "Train Epoch [72/100] Batch [110/782] Loss: 0.5071 | Acc: 82.33%\n",
      "Train Epoch [72/100] Batch [111/782] Loss: 0.2930 | Acc: 82.42%\n",
      "Train Epoch [72/100] Batch [112/782] Loss: 0.3981 | Acc: 82.44%\n",
      "Train Epoch [72/100] Batch [113/782] Loss: 0.4821 | Acc: 82.44%\n",
      "Train Epoch [72/100] Batch [114/782] Loss: 0.5895 | Acc: 82.37%\n",
      "Train Epoch [72/100] Batch [115/782] Loss: 0.3672 | Acc: 82.40%\n",
      "Train Epoch [72/100] Batch [116/782] Loss: 0.3637 | Acc: 82.46%\n",
      "Train Epoch [72/100] Batch [117/782] Loss: 0.4964 | Acc: 82.44%\n",
      "Train Epoch [72/100] Batch [118/782] Loss: 0.6837 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [119/782] Loss: 0.4592 | Acc: 82.39%\n",
      "Train Epoch [72/100] Batch [120/782] Loss: 0.4480 | Acc: 82.41%\n",
      "Train Epoch [72/100] Batch [121/782] Loss: 0.5709 | Acc: 82.40%\n",
      "Train Epoch [72/100] Batch [122/782] Loss: 0.5936 | Acc: 82.40%\n",
      "Train Epoch [72/100] Batch [123/782] Loss: 0.4513 | Acc: 82.39%\n",
      "Train Epoch [72/100] Batch [124/782] Loss: 0.5347 | Acc: 82.41%\n",
      "Train Epoch [72/100] Batch [125/782] Loss: 0.5723 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [126/782] Loss: 0.8235 | Acc: 82.29%\n",
      "Train Epoch [72/100] Batch [127/782] Loss: 0.4072 | Acc: 82.28%\n",
      "Train Epoch [72/100] Batch [128/782] Loss: 0.3938 | Acc: 82.34%\n",
      "Train Epoch [72/100] Batch [129/782] Loss: 0.4409 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [130/782] Loss: 0.4308 | Acc: 82.42%\n",
      "Train Epoch [72/100] Batch [131/782] Loss: 0.4963 | Acc: 82.43%\n",
      "Train Epoch [72/100] Batch [132/782] Loss: 0.4625 | Acc: 82.42%\n",
      "Train Epoch [72/100] Batch [133/782] Loss: 0.3779 | Acc: 82.45%\n",
      "Train Epoch [72/100] Batch [134/782] Loss: 0.6289 | Acc: 82.44%\n",
      "Train Epoch [72/100] Batch [135/782] Loss: 0.7398 | Acc: 82.35%\n",
      "Train Epoch [72/100] Batch [136/782] Loss: 0.3460 | Acc: 82.35%\n",
      "Train Epoch [72/100] Batch [137/782] Loss: 0.5642 | Acc: 82.29%\n",
      "Train Epoch [72/100] Batch [138/782] Loss: 0.2217 | Acc: 82.37%\n",
      "Train Epoch [72/100] Batch [139/782] Loss: 0.5159 | Acc: 82.37%\n",
      "Train Epoch [72/100] Batch [140/782] Loss: 0.3818 | Acc: 82.41%\n",
      "Train Epoch [72/100] Batch [141/782] Loss: 0.4699 | Acc: 82.40%\n",
      "Train Epoch [72/100] Batch [142/782] Loss: 0.5459 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [143/782] Loss: 0.5253 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [144/782] Loss: 0.3999 | Acc: 82.39%\n",
      "Train Epoch [72/100] Batch [145/782] Loss: 0.4970 | Acc: 82.38%\n",
      "Train Epoch [72/100] Batch [146/782] Loss: 0.7111 | Acc: 82.35%\n",
      "Train Epoch [72/100] Batch [147/782] Loss: 0.5192 | Acc: 82.32%\n",
      "Train Epoch [72/100] Batch [148/782] Loss: 0.4204 | Acc: 82.36%\n",
      "Train Epoch [72/100] Batch [149/782] Loss: 0.5896 | Acc: 82.34%\n",
      "Train Epoch [72/100] Batch [150/782] Loss: 0.6199 | Acc: 82.31%\n",
      "Train Epoch [72/100] Batch [151/782] Loss: 0.5490 | Acc: 82.32%\n",
      "Train Epoch [72/100] Batch [152/782] Loss: 0.5973 | Acc: 82.29%\n",
      "Train Epoch [72/100] Batch [153/782] Loss: 0.6900 | Acc: 82.24%\n",
      "Train Epoch [72/100] Batch [154/782] Loss: 0.4087 | Acc: 82.26%\n",
      "Train Epoch [72/100] Batch [155/782] Loss: 0.7689 | Acc: 82.25%\n",
      "Train Epoch [72/100] Batch [156/782] Loss: 0.5654 | Acc: 82.25%\n",
      "Train Epoch [72/100] Batch [157/782] Loss: 0.5475 | Acc: 82.25%\n",
      "Train Epoch [72/100] Batch [158/782] Loss: 0.4838 | Acc: 82.26%\n",
      "Train Epoch [72/100] Batch [159/782] Loss: 0.6334 | Acc: 82.18%\n",
      "Train Epoch [72/100] Batch [160/782] Loss: 0.5752 | Acc: 82.16%\n",
      "Train Epoch [72/100] Batch [161/782] Loss: 0.5217 | Acc: 82.12%\n",
      "Train Epoch [72/100] Batch [162/782] Loss: 0.6374 | Acc: 82.08%\n",
      "Train Epoch [72/100] Batch [163/782] Loss: 0.5595 | Acc: 82.03%\n",
      "Train Epoch [72/100] Batch [164/782] Loss: 0.5012 | Acc: 82.05%\n",
      "Train Epoch [72/100] Batch [165/782] Loss: 0.5912 | Acc: 82.03%\n",
      "Train Epoch [72/100] Batch [166/782] Loss: 0.5077 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [167/782] Loss: 0.5160 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [168/782] Loss: 0.6057 | Acc: 82.03%\n",
      "Train Epoch [72/100] Batch [169/782] Loss: 0.4357 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [170/782] Loss: 0.6018 | Acc: 82.02%\n",
      "Train Epoch [72/100] Batch [171/782] Loss: 0.5885 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [172/782] Loss: 0.4715 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [173/782] Loss: 0.4663 | Acc: 82.00%\n",
      "Train Epoch [72/100] Batch [174/782] Loss: 0.4893 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [175/782] Loss: 0.3883 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [176/782] Loss: 0.4268 | Acc: 82.00%\n",
      "Train Epoch [72/100] Batch [177/782] Loss: 0.5770 | Acc: 82.01%\n",
      "Train Epoch [72/100] Batch [178/782] Loss: 0.5527 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [179/782] Loss: 0.5536 | Acc: 82.02%\n",
      "Train Epoch [72/100] Batch [180/782] Loss: 0.4137 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [181/782] Loss: 0.7714 | Acc: 81.96%\n",
      "Train Epoch [72/100] Batch [182/782] Loss: 0.6960 | Acc: 81.95%\n",
      "Train Epoch [72/100] Batch [183/782] Loss: 0.4957 | Acc: 81.97%\n",
      "Train Epoch [72/100] Batch [184/782] Loss: 0.3500 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [185/782] Loss: 0.5677 | Acc: 81.98%\n",
      "Train Epoch [72/100] Batch [186/782] Loss: 0.4703 | Acc: 81.99%\n",
      "Train Epoch [72/100] Batch [187/782] Loss: 0.2638 | Acc: 82.04%\n",
      "Train Epoch [72/100] Batch [188/782] Loss: 0.7575 | Acc: 82.01%\n",
      "Train Epoch [72/100] Batch [189/782] Loss: 0.8197 | Acc: 81.97%\n",
      "Train Epoch [72/100] Batch [190/782] Loss: 0.6571 | Acc: 81.95%\n",
      "Train Epoch [72/100] Batch [191/782] Loss: 0.7983 | Acc: 81.92%\n",
      "Train Epoch [72/100] Batch [192/782] Loss: 0.4544 | Acc: 81.92%\n",
      "Train Epoch [72/100] Batch [193/782] Loss: 0.5896 | Acc: 81.89%\n",
      "Train Epoch [72/100] Batch [194/782] Loss: 0.6519 | Acc: 81.84%\n",
      "Train Epoch [72/100] Batch [195/782] Loss: 0.5286 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [196/782] Loss: 0.5399 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [197/782] Loss: 0.4802 | Acc: 81.77%\n",
      "Train Epoch [72/100] Batch [198/782] Loss: 0.7754 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [199/782] Loss: 0.5967 | Acc: 81.71%\n",
      "Train Epoch [72/100] Batch [200/782] Loss: 0.3593 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [201/782] Loss: 0.2915 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [202/782] Loss: 0.4240 | Acc: 81.81%\n",
      "Train Epoch [72/100] Batch [203/782] Loss: 0.6080 | Acc: 81.77%\n",
      "Train Epoch [72/100] Batch [204/782] Loss: 0.4583 | Acc: 81.79%\n",
      "Train Epoch [72/100] Batch [205/782] Loss: 0.5240 | Acc: 81.78%\n",
      "Train Epoch [72/100] Batch [206/782] Loss: 0.6281 | Acc: 81.74%\n",
      "Train Epoch [72/100] Batch [207/782] Loss: 0.6162 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [208/782] Loss: 0.4401 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [209/782] Loss: 0.8292 | Acc: 81.69%\n",
      "Train Epoch [72/100] Batch [210/782] Loss: 0.4236 | Acc: 81.69%\n",
      "Train Epoch [72/100] Batch [211/782] Loss: 0.4040 | Acc: 81.71%\n",
      "Train Epoch [72/100] Batch [212/782] Loss: 0.3810 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [213/782] Loss: 0.5668 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [214/782] Loss: 0.2561 | Acc: 81.77%\n",
      "Train Epoch [72/100] Batch [215/782] Loss: 0.5521 | Acc: 81.74%\n",
      "Train Epoch [72/100] Batch [216/782] Loss: 0.6839 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [217/782] Loss: 0.4778 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [218/782] Loss: 0.5433 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [219/782] Loss: 0.5723 | Acc: 81.70%\n",
      "Train Epoch [72/100] Batch [220/782] Loss: 0.4530 | Acc: 81.70%\n",
      "Train Epoch [72/100] Batch [221/782] Loss: 0.6848 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [222/782] Loss: 0.4754 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [223/782] Loss: 0.6065 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [224/782] Loss: 0.5724 | Acc: 81.69%\n",
      "Train Epoch [72/100] Batch [225/782] Loss: 0.5828 | Acc: 81.69%\n",
      "Train Epoch [72/100] Batch [226/782] Loss: 0.4143 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [227/782] Loss: 0.4810 | Acc: 81.72%\n",
      "Train Epoch [72/100] Batch [228/782] Loss: 0.3459 | Acc: 81.76%\n",
      "Train Epoch [72/100] Batch [229/782] Loss: 0.6023 | Acc: 81.75%\n",
      "Train Epoch [72/100] Batch [230/782] Loss: 0.5346 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [231/782] Loss: 0.5449 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [232/782] Loss: 0.5098 | Acc: 81.71%\n",
      "Train Epoch [72/100] Batch [233/782] Loss: 0.4007 | Acc: 81.73%\n",
      "Train Epoch [72/100] Batch [234/782] Loss: 0.5265 | Acc: 81.70%\n",
      "Train Epoch [72/100] Batch [235/782] Loss: 0.6103 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [236/782] Loss: 0.6716 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [237/782] Loss: 0.2546 | Acc: 81.70%\n",
      "Train Epoch [72/100] Batch [238/782] Loss: 0.6522 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [239/782] Loss: 0.6347 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [240/782] Loss: 0.4586 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [241/782] Loss: 0.6321 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [242/782] Loss: 0.4267 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [243/782] Loss: 0.5406 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [244/782] Loss: 0.5569 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [245/782] Loss: 0.3766 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [246/782] Loss: 0.5572 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [247/782] Loss: 0.4565 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [248/782] Loss: 0.4464 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [249/782] Loss: 0.6436 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [250/782] Loss: 0.3591 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [251/782] Loss: 0.4357 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [252/782] Loss: 0.7770 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [253/782] Loss: 0.6037 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [254/782] Loss: 0.4658 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [255/782] Loss: 0.4748 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [256/782] Loss: 0.3095 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [257/782] Loss: 0.4575 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [258/782] Loss: 0.5483 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [259/782] Loss: 0.6091 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [260/782] Loss: 0.3569 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [261/782] Loss: 0.4875 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [262/782] Loss: 0.4800 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [263/782] Loss: 0.7278 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [264/782] Loss: 0.4636 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [265/782] Loss: 0.5754 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [266/782] Loss: 0.4390 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [267/782] Loss: 0.3172 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [268/782] Loss: 0.6278 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [269/782] Loss: 0.5740 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [270/782] Loss: 0.4357 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [271/782] Loss: 0.4860 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [272/782] Loss: 0.6281 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [273/782] Loss: 0.3247 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [274/782] Loss: 0.5353 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [275/782] Loss: 0.3852 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [276/782] Loss: 0.5172 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [277/782] Loss: 0.6479 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [278/782] Loss: 0.3513 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [279/782] Loss: 0.5626 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [280/782] Loss: 0.5959 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [281/782] Loss: 0.3906 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [282/782] Loss: 0.5174 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [283/782] Loss: 0.4691 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [284/782] Loss: 0.6029 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [285/782] Loss: 0.4840 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [286/782] Loss: 0.6033 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [287/782] Loss: 0.6181 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [288/782] Loss: 0.5595 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [289/782] Loss: 0.5469 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [290/782] Loss: 0.3544 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [291/782] Loss: 0.7838 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [292/782] Loss: 0.3451 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [293/782] Loss: 0.5585 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [294/782] Loss: 0.4884 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [295/782] Loss: 0.4344 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [296/782] Loss: 0.5677 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [297/782] Loss: 0.2652 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [298/782] Loss: 0.4970 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [299/782] Loss: 0.6559 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [300/782] Loss: 0.4097 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [301/782] Loss: 0.4281 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [302/782] Loss: 0.4945 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [303/782] Loss: 0.6279 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [304/782] Loss: 0.4014 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [305/782] Loss: 0.6246 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [306/782] Loss: 0.5051 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [307/782] Loss: 0.4242 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [308/782] Loss: 0.4496 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [309/782] Loss: 0.4470 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [310/782] Loss: 0.3544 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [311/782] Loss: 0.4121 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [312/782] Loss: 0.4619 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [313/782] Loss: 0.6523 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [314/782] Loss: 0.4435 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [315/782] Loss: 0.4325 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [316/782] Loss: 0.4395 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [317/782] Loss: 0.5207 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [318/782] Loss: 0.5452 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [319/782] Loss: 0.4932 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [320/782] Loss: 0.4786 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [321/782] Loss: 0.5758 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [322/782] Loss: 0.6987 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [323/782] Loss: 0.4005 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [324/782] Loss: 0.7547 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [325/782] Loss: 0.5925 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [326/782] Loss: 0.5866 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [327/782] Loss: 0.4761 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [328/782] Loss: 0.3536 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [329/782] Loss: 0.4228 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [330/782] Loss: 0.6267 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [331/782] Loss: 0.4672 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [332/782] Loss: 0.6417 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [333/782] Loss: 0.6511 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [334/782] Loss: 0.4613 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [335/782] Loss: 0.3349 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [336/782] Loss: 0.3529 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [337/782] Loss: 0.5604 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [338/782] Loss: 0.4652 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [339/782] Loss: 0.3833 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [340/782] Loss: 0.3324 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [341/782] Loss: 0.4506 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [342/782] Loss: 0.5255 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [343/782] Loss: 0.5976 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [344/782] Loss: 0.5082 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [345/782] Loss: 0.5281 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [346/782] Loss: 0.5281 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [347/782] Loss: 0.5594 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [348/782] Loss: 0.4884 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [349/782] Loss: 0.4340 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [350/782] Loss: 0.5196 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [351/782] Loss: 0.6490 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [352/782] Loss: 0.4524 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [353/782] Loss: 0.4950 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [354/782] Loss: 0.6079 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [355/782] Loss: 0.5152 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [356/782] Loss: 0.3334 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [357/782] Loss: 0.4618 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [358/782] Loss: 0.5042 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [359/782] Loss: 0.5416 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [360/782] Loss: 0.5577 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [361/782] Loss: 0.3647 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [362/782] Loss: 0.5304 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [363/782] Loss: 0.5369 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [364/782] Loss: 0.5235 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [365/782] Loss: 0.4656 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [366/782] Loss: 0.4608 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [367/782] Loss: 0.4333 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [368/782] Loss: 0.5566 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [369/782] Loss: 0.4025 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [370/782] Loss: 0.6447 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [371/782] Loss: 0.4952 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [372/782] Loss: 0.4949 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [373/782] Loss: 0.4760 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [374/782] Loss: 0.5348 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [375/782] Loss: 0.4766 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [376/782] Loss: 0.4309 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [377/782] Loss: 0.3631 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [378/782] Loss: 0.5394 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [379/782] Loss: 0.3908 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [380/782] Loss: 0.5783 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [381/782] Loss: 0.6702 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [382/782] Loss: 0.3776 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [383/782] Loss: 0.4189 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [384/782] Loss: 0.6691 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [385/782] Loss: 0.5581 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [386/782] Loss: 0.5717 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [387/782] Loss: 0.3969 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [388/782] Loss: 0.4709 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [389/782] Loss: 0.7043 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [390/782] Loss: 0.3487 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [391/782] Loss: 0.4810 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [392/782] Loss: 0.5280 | Acc: 81.68%\n",
      "Train Epoch [72/100] Batch [393/782] Loss: 0.4851 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [394/782] Loss: 0.6104 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [395/782] Loss: 0.5064 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [396/782] Loss: 0.5467 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [397/782] Loss: 0.4410 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [398/782] Loss: 0.4631 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [399/782] Loss: 0.6658 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [400/782] Loss: 0.3499 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [401/782] Loss: 0.3978 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [402/782] Loss: 0.6593 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [403/782] Loss: 0.5261 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [404/782] Loss: 0.6166 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [405/782] Loss: 0.5028 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [406/782] Loss: 0.3259 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [407/782] Loss: 0.5323 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [408/782] Loss: 0.5579 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [409/782] Loss: 0.3100 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [410/782] Loss: 0.2874 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [411/782] Loss: 0.6782 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [412/782] Loss: 0.6174 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [413/782] Loss: 0.5086 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [414/782] Loss: 0.4480 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [415/782] Loss: 0.5239 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [416/782] Loss: 0.5461 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [417/782] Loss: 0.7516 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [418/782] Loss: 0.3654 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [419/782] Loss: 0.6319 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [420/782] Loss: 0.4735 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [421/782] Loss: 0.4926 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [422/782] Loss: 0.6473 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [423/782] Loss: 0.4036 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [424/782] Loss: 0.5316 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [425/782] Loss: 0.6092 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [426/782] Loss: 0.4512 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [427/782] Loss: 0.5231 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [428/782] Loss: 0.4435 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [429/782] Loss: 0.5741 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [430/782] Loss: 0.3537 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [431/782] Loss: 0.5350 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [432/782] Loss: 0.4372 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [433/782] Loss: 0.4703 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [434/782] Loss: 0.4849 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [435/782] Loss: 0.5476 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [436/782] Loss: 0.6654 | Acc: 81.65%\n",
      "Train Epoch [72/100] Batch [437/782] Loss: 0.4922 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [438/782] Loss: 0.4823 | Acc: 81.67%\n",
      "Train Epoch [72/100] Batch [439/782] Loss: 0.6007 | Acc: 81.66%\n",
      "Train Epoch [72/100] Batch [440/782] Loss: 0.8805 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [441/782] Loss: 0.4806 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [442/782] Loss: 0.6942 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [443/782] Loss: 0.6906 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [444/782] Loss: 0.3125 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [445/782] Loss: 0.4012 | Acc: 81.64%\n",
      "Train Epoch [72/100] Batch [446/782] Loss: 0.6618 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [447/782] Loss: 0.4631 | Acc: 81.63%\n",
      "Train Epoch [72/100] Batch [448/782] Loss: 0.6803 | Acc: 81.61%\n",
      "Train Epoch [72/100] Batch [449/782] Loss: 0.4450 | Acc: 81.62%\n",
      "Train Epoch [72/100] Batch [450/782] Loss: 0.6665 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [451/782] Loss: 0.5270 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [452/782] Loss: 0.4307 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [453/782] Loss: 0.6309 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [454/782] Loss: 0.6210 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [455/782] Loss: 0.4051 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [456/782] Loss: 0.5555 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [457/782] Loss: 0.5911 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [458/782] Loss: 0.7378 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [459/782] Loss: 0.5980 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [460/782] Loss: 0.5264 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [461/782] Loss: 0.4727 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [462/782] Loss: 0.3336 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [463/782] Loss: 0.4252 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [464/782] Loss: 0.3430 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [465/782] Loss: 0.7706 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [466/782] Loss: 0.6188 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [467/782] Loss: 0.6533 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [468/782] Loss: 0.5716 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [469/782] Loss: 0.4339 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [470/782] Loss: 0.4033 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [471/782] Loss: 0.5486 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [472/782] Loss: 0.4483 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [473/782] Loss: 0.2465 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [474/782] Loss: 0.5325 | Acc: 81.59%\n",
      "Train Epoch [72/100] Batch [475/782] Loss: 0.4079 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [476/782] Loss: 0.4841 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [477/782] Loss: 0.4764 | Acc: 81.60%\n",
      "Train Epoch [72/100] Batch [478/782] Loss: 0.6723 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [479/782] Loss: 0.6292 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [480/782] Loss: 0.5528 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [481/782] Loss: 0.5556 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [482/782] Loss: 0.4554 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [483/782] Loss: 0.5160 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [484/782] Loss: 0.5879 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [485/782] Loss: 0.4782 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [486/782] Loss: 0.2836 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [487/782] Loss: 0.4262 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [488/782] Loss: 0.5179 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [489/782] Loss: 0.5686 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [490/782] Loss: 0.3547 | Acc: 81.58%\n",
      "Train Epoch [72/100] Batch [491/782] Loss: 0.7168 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [492/782] Loss: 0.3678 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [493/782] Loss: 0.3201 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [494/782] Loss: 0.5499 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [495/782] Loss: 0.7191 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [496/782] Loss: 0.2706 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [497/782] Loss: 0.7281 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [498/782] Loss: 0.3850 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [499/782] Loss: 0.5466 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [500/782] Loss: 0.8602 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [501/782] Loss: 0.4565 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [502/782] Loss: 0.5203 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [503/782] Loss: 0.4073 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [504/782] Loss: 0.5245 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [505/782] Loss: 0.3332 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [506/782] Loss: 0.5473 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [507/782] Loss: 0.5382 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [508/782] Loss: 0.3573 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [509/782] Loss: 0.6232 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [510/782] Loss: 0.4433 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [511/782] Loss: 0.4779 | Acc: 81.57%\n",
      "Train Epoch [72/100] Batch [512/782] Loss: 0.5025 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [513/782] Loss: 0.5937 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [514/782] Loss: 0.5740 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [515/782] Loss: 0.3361 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [516/782] Loss: 0.6878 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [517/782] Loss: 0.5269 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [518/782] Loss: 0.5511 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [519/782] Loss: 0.4950 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [520/782] Loss: 0.5687 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [521/782] Loss: 0.5295 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [522/782] Loss: 0.5702 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [523/782] Loss: 0.4251 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [524/782] Loss: 0.5547 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [525/782] Loss: 0.3922 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [526/782] Loss: 0.5210 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [527/782] Loss: 0.4669 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [528/782] Loss: 0.5420 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [529/782] Loss: 0.4139 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [530/782] Loss: 0.4314 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [531/782] Loss: 0.6036 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [532/782] Loss: 0.4303 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [533/782] Loss: 0.4392 | Acc: 81.53%\n",
      "Train Epoch [72/100] Batch [534/782] Loss: 0.4283 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [535/782] Loss: 0.3918 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [536/782] Loss: 0.5227 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [537/782] Loss: 0.4818 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [538/782] Loss: 0.4924 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [539/782] Loss: 0.3397 | Acc: 81.56%\n",
      "Train Epoch [72/100] Batch [540/782] Loss: 0.5530 | Acc: 81.55%\n",
      "Train Epoch [72/100] Batch [541/782] Loss: 0.6261 | Acc: 81.54%\n",
      "Train Epoch [72/100] Batch [542/782] Loss: 0.7264 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [543/782] Loss: 0.5210 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [544/782] Loss: 0.5252 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [545/782] Loss: 0.5470 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [546/782] Loss: 0.5076 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [547/782] Loss: 0.4685 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [548/782] Loss: 0.6506 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [549/782] Loss: 0.4562 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [550/782] Loss: 0.4155 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [551/782] Loss: 0.4137 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [552/782] Loss: 0.6039 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [553/782] Loss: 0.4737 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [554/782] Loss: 0.6604 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [555/782] Loss: 0.4422 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [556/782] Loss: 0.4578 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [557/782] Loss: 0.4018 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [558/782] Loss: 0.3718 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [559/782] Loss: 0.5045 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [560/782] Loss: 0.6044 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [561/782] Loss: 0.6186 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [562/782] Loss: 0.7242 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [563/782] Loss: 0.5093 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [564/782] Loss: 0.4389 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [565/782] Loss: 0.5029 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [566/782] Loss: 0.5003 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [567/782] Loss: 0.6653 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [568/782] Loss: 0.4093 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [569/782] Loss: 0.4863 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [570/782] Loss: 0.5558 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [571/782] Loss: 0.3673 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [572/782] Loss: 0.4129 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [573/782] Loss: 0.5368 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [574/782] Loss: 0.5896 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [575/782] Loss: 0.5668 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [576/782] Loss: 0.5835 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [577/782] Loss: 0.3153 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [578/782] Loss: 0.5057 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [579/782] Loss: 0.4618 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [580/782] Loss: 0.5174 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [581/782] Loss: 0.5018 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [582/782] Loss: 0.4599 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [583/782] Loss: 0.7479 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [584/782] Loss: 0.3923 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [585/782] Loss: 0.6525 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [586/782] Loss: 0.3980 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [587/782] Loss: 0.5044 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [588/782] Loss: 0.5821 | Acc: 81.52%\n",
      "Train Epoch [72/100] Batch [589/782] Loss: 0.5557 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [590/782] Loss: 0.4655 | Acc: 81.51%\n",
      "Train Epoch [72/100] Batch [591/782] Loss: 0.6475 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [592/782] Loss: 0.6793 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [593/782] Loss: 0.4204 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [594/782] Loss: 0.5323 | Acc: 81.50%\n",
      "Train Epoch [72/100] Batch [595/782] Loss: 0.6917 | Acc: 81.49%\n",
      "Train Epoch [72/100] Batch [596/782] Loss: 0.7802 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [597/782] Loss: 0.5840 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [598/782] Loss: 0.7037 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [599/782] Loss: 0.7467 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [600/782] Loss: 0.7358 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [601/782] Loss: 0.4325 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [602/782] Loss: 0.3675 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [603/782] Loss: 0.6157 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [604/782] Loss: 0.5175 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [605/782] Loss: 0.5874 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [606/782] Loss: 0.6989 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [607/782] Loss: 0.4268 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [608/782] Loss: 0.5972 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [609/782] Loss: 0.4559 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [610/782] Loss: 0.5080 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [611/782] Loss: 0.5006 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [612/782] Loss: 0.5246 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [613/782] Loss: 0.4262 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [614/782] Loss: 0.5294 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [615/782] Loss: 0.4286 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [616/782] Loss: 0.5590 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [617/782] Loss: 0.7174 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [618/782] Loss: 0.4368 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [619/782] Loss: 0.6422 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [620/782] Loss: 0.4832 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [621/782] Loss: 0.5918 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [622/782] Loss: 0.6455 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [623/782] Loss: 0.3336 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [624/782] Loss: 0.5232 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [625/782] Loss: 0.4629 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [626/782] Loss: 0.5830 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [627/782] Loss: 0.4541 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [628/782] Loss: 0.7474 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [629/782] Loss: 0.7055 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [630/782] Loss: 0.6145 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [631/782] Loss: 0.6815 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [632/782] Loss: 0.4661 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [633/782] Loss: 0.4547 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [634/782] Loss: 0.4737 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [635/782] Loss: 0.4582 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [636/782] Loss: 0.5092 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [637/782] Loss: 0.3606 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [638/782] Loss: 0.2991 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [639/782] Loss: 0.4315 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [640/782] Loss: 0.3196 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [641/782] Loss: 0.4033 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [642/782] Loss: 0.5734 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [643/782] Loss: 0.4745 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [644/782] Loss: 0.5781 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [645/782] Loss: 0.7393 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [646/782] Loss: 0.5843 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [647/782] Loss: 0.2931 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [648/782] Loss: 0.4774 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [649/782] Loss: 0.3703 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [650/782] Loss: 0.4921 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [651/782] Loss: 0.4616 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [652/782] Loss: 0.4210 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [653/782] Loss: 0.3470 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [654/782] Loss: 0.5821 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [655/782] Loss: 0.5986 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [656/782] Loss: 0.5497 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [657/782] Loss: 0.4695 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [658/782] Loss: 0.6264 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [659/782] Loss: 0.4909 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [660/782] Loss: 0.7391 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [661/782] Loss: 0.3895 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [662/782] Loss: 0.5152 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [663/782] Loss: 0.7950 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [664/782] Loss: 0.5749 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [665/782] Loss: 0.3598 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [666/782] Loss: 0.5380 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [667/782] Loss: 0.5655 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [668/782] Loss: 0.8096 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [669/782] Loss: 0.6400 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [670/782] Loss: 0.5774 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [671/782] Loss: 0.4764 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [672/782] Loss: 0.5979 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [673/782] Loss: 0.6224 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [674/782] Loss: 0.5579 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [675/782] Loss: 0.5267 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [676/782] Loss: 0.6450 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [677/782] Loss: 0.3615 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [678/782] Loss: 0.6077 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [679/782] Loss: 0.5515 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [680/782] Loss: 0.5261 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [681/782] Loss: 0.4575 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [682/782] Loss: 0.5033 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [683/782] Loss: 0.4243 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [684/782] Loss: 0.5793 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [685/782] Loss: 0.3559 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [686/782] Loss: 0.5891 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [687/782] Loss: 0.4675 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [688/782] Loss: 0.4457 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [689/782] Loss: 0.5664 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [690/782] Loss: 0.3775 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [691/782] Loss: 0.4113 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [692/782] Loss: 0.4824 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [693/782] Loss: 0.5192 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [694/782] Loss: 0.4598 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [695/782] Loss: 0.5212 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [696/782] Loss: 0.7382 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [697/782] Loss: 0.5119 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [698/782] Loss: 0.6327 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [699/782] Loss: 0.5397 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [700/782] Loss: 0.5561 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [701/782] Loss: 0.5144 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [702/782] Loss: 0.4954 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [703/782] Loss: 0.5491 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [704/782] Loss: 0.4458 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [705/782] Loss: 0.4825 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [706/782] Loss: 0.2915 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [707/782] Loss: 0.6279 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [708/782] Loss: 0.6959 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [709/782] Loss: 0.6510 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [710/782] Loss: 0.6600 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [711/782] Loss: 0.4126 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [712/782] Loss: 0.7285 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [713/782] Loss: 0.6903 | Acc: 81.41%\n",
      "Train Epoch [72/100] Batch [714/782] Loss: 0.6382 | Acc: 81.40%\n",
      "Train Epoch [72/100] Batch [715/782] Loss: 0.5504 | Acc: 81.41%\n",
      "Train Epoch [72/100] Batch [716/782] Loss: 0.4119 | Acc: 81.41%\n",
      "Train Epoch [72/100] Batch [717/782] Loss: 0.4625 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [718/782] Loss: 0.4286 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [719/782] Loss: 0.4949 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [720/782] Loss: 0.4841 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [721/782] Loss: 0.3366 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [722/782] Loss: 0.3806 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [723/782] Loss: 0.6259 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [724/782] Loss: 0.4794 | Acc: 81.42%\n",
      "Train Epoch [72/100] Batch [725/782] Loss: 0.5563 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [726/782] Loss: 0.3983 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [727/782] Loss: 0.6532 | Acc: 81.41%\n",
      "Train Epoch [72/100] Batch [728/782] Loss: 0.5143 | Acc: 81.41%\n",
      "Train Epoch [72/100] Batch [729/782] Loss: 0.3953 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [730/782] Loss: 0.4499 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [731/782] Loss: 0.5043 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [732/782] Loss: 0.5530 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [733/782] Loss: 0.3563 | Acc: 81.43%\n",
      "Train Epoch [72/100] Batch [734/782] Loss: 0.3929 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [735/782] Loss: 0.3538 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [736/782] Loss: 0.2283 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [737/782] Loss: 0.4375 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [738/782] Loss: 0.4726 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [739/782] Loss: 0.4456 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [740/782] Loss: 0.3558 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [741/782] Loss: 0.4207 | Acc: 81.48%\n",
      "Train Epoch [72/100] Batch [742/782] Loss: 0.5989 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [743/782] Loss: 0.5394 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [744/782] Loss: 0.4470 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [745/782] Loss: 0.7080 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [746/782] Loss: 0.6849 | Acc: 81.45%\n",
      "Train Epoch [72/100] Batch [747/782] Loss: 0.4793 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [748/782] Loss: 0.4300 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [749/782] Loss: 0.6289 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [750/782] Loss: 0.5066 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [751/782] Loss: 0.5993 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [752/782] Loss: 0.5135 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [753/782] Loss: 0.5450 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [754/782] Loss: 0.3909 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [755/782] Loss: 0.5547 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [756/782] Loss: 0.4718 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [757/782] Loss: 0.7974 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [758/782] Loss: 0.5709 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [759/782] Loss: 0.3827 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [760/782] Loss: 0.6570 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [761/782] Loss: 0.4553 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [762/782] Loss: 0.4940 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [763/782] Loss: 0.5757 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [764/782] Loss: 0.3221 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [765/782] Loss: 0.5471 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [766/782] Loss: 0.3908 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [767/782] Loss: 0.4398 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [768/782] Loss: 0.4146 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [769/782] Loss: 0.6068 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [770/782] Loss: 0.7020 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [771/782] Loss: 0.4231 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [772/782] Loss: 0.4802 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [773/782] Loss: 0.6478 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [774/782] Loss: 0.5480 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [775/782] Loss: 0.4772 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [776/782] Loss: 0.4731 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [777/782] Loss: 0.5084 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [778/782] Loss: 0.5285 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [779/782] Loss: 0.6695 | Acc: 81.44%\n",
      "Train Epoch [72/100] Batch [780/782] Loss: 0.4039 | Acc: 81.46%\n",
      "Train Epoch [72/100] Batch [781/782] Loss: 0.3435 | Acc: 81.47%\n",
      "Train Epoch [72/100] Batch [782/782] Loss: 0.4245 | Acc: 81.47%\n",
      "Epoch 72 completed in 30.79s.\n",
      "Test Epoch [72/100] Loss: 0.9492 | Acc: 71.90% | Inference Time: 8.44s\n",
      "Epoch 72 results saved to CSV.\n",
      "Epoch 73/100\n",
      "Train Epoch [73/100] Batch [1/782] Loss: 0.3915 | Acc: 85.94%\n",
      "Train Epoch [73/100] Batch [2/782] Loss: 0.6272 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [3/782] Loss: 0.4881 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [4/782] Loss: 0.5527 | Acc: 80.86%\n",
      "Train Epoch [73/100] Batch [5/782] Loss: 0.4157 | Acc: 81.88%\n",
      "Train Epoch [73/100] Batch [6/782] Loss: 0.6776 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [7/782] Loss: 0.6724 | Acc: 80.58%\n",
      "Train Epoch [73/100] Batch [8/782] Loss: 0.5282 | Acc: 80.08%\n",
      "Train Epoch [73/100] Batch [9/782] Loss: 0.5084 | Acc: 80.03%\n",
      "Train Epoch [73/100] Batch [10/782] Loss: 0.5861 | Acc: 79.53%\n",
      "Train Epoch [73/100] Batch [11/782] Loss: 0.6544 | Acc: 79.26%\n",
      "Train Epoch [73/100] Batch [12/782] Loss: 0.4730 | Acc: 79.69%\n",
      "Train Epoch [73/100] Batch [13/782] Loss: 0.5494 | Acc: 79.93%\n",
      "Train Epoch [73/100] Batch [14/782] Loss: 0.3952 | Acc: 80.36%\n",
      "Train Epoch [73/100] Batch [15/782] Loss: 0.5788 | Acc: 80.00%\n",
      "Train Epoch [73/100] Batch [16/782] Loss: 0.5381 | Acc: 80.18%\n",
      "Train Epoch [73/100] Batch [17/782] Loss: 0.3587 | Acc: 80.61%\n",
      "Train Epoch [73/100] Batch [18/782] Loss: 0.5329 | Acc: 80.82%\n",
      "Train Epoch [73/100] Batch [19/782] Loss: 0.5281 | Acc: 80.51%\n",
      "Train Epoch [73/100] Batch [20/782] Loss: 0.4747 | Acc: 80.55%\n",
      "Train Epoch [73/100] Batch [21/782] Loss: 0.5877 | Acc: 80.51%\n",
      "Train Epoch [73/100] Batch [22/782] Loss: 0.3493 | Acc: 80.89%\n",
      "Train Epoch [73/100] Batch [23/782] Loss: 0.2874 | Acc: 81.32%\n",
      "Train Epoch [73/100] Batch [24/782] Loss: 0.4997 | Acc: 81.58%\n",
      "Train Epoch [73/100] Batch [25/782] Loss: 0.4832 | Acc: 81.62%\n",
      "Train Epoch [73/100] Batch [26/782] Loss: 0.3884 | Acc: 81.91%\n",
      "Train Epoch [73/100] Batch [27/782] Loss: 0.4068 | Acc: 81.89%\n",
      "Train Epoch [73/100] Batch [28/782] Loss: 0.6781 | Acc: 81.53%\n",
      "Train Epoch [73/100] Batch [29/782] Loss: 0.6536 | Acc: 81.30%\n",
      "Train Epoch [73/100] Batch [30/782] Loss: 0.6046 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [31/782] Loss: 0.5708 | Acc: 81.20%\n",
      "Train Epoch [73/100] Batch [32/782] Loss: 0.4813 | Acc: 81.20%\n",
      "Train Epoch [73/100] Batch [33/782] Loss: 0.4219 | Acc: 81.20%\n",
      "Train Epoch [73/100] Batch [34/782] Loss: 0.7985 | Acc: 80.97%\n",
      "Train Epoch [73/100] Batch [35/782] Loss: 0.5161 | Acc: 80.85%\n",
      "Train Epoch [73/100] Batch [36/782] Loss: 0.4183 | Acc: 80.86%\n",
      "Train Epoch [73/100] Batch [37/782] Loss: 0.6339 | Acc: 80.83%\n",
      "Train Epoch [73/100] Batch [38/782] Loss: 0.4132 | Acc: 80.96%\n",
      "Train Epoch [73/100] Batch [39/782] Loss: 0.5013 | Acc: 80.85%\n",
      "Train Epoch [73/100] Batch [40/782] Loss: 0.4427 | Acc: 80.94%\n",
      "Train Epoch [73/100] Batch [41/782] Loss: 0.4833 | Acc: 80.87%\n",
      "Train Epoch [73/100] Batch [42/782] Loss: 0.3305 | Acc: 81.06%\n",
      "Train Epoch [73/100] Batch [43/782] Loss: 0.5000 | Acc: 81.03%\n",
      "Train Epoch [73/100] Batch [44/782] Loss: 0.4139 | Acc: 81.11%\n",
      "Train Epoch [73/100] Batch [45/782] Loss: 0.4432 | Acc: 81.22%\n",
      "Train Epoch [73/100] Batch [46/782] Loss: 0.5199 | Acc: 81.18%\n",
      "Train Epoch [73/100] Batch [47/782] Loss: 0.7983 | Acc: 80.88%\n",
      "Train Epoch [73/100] Batch [48/782] Loss: 0.6860 | Acc: 80.76%\n",
      "Train Epoch [73/100] Batch [49/782] Loss: 0.6470 | Acc: 80.64%\n",
      "Train Epoch [73/100] Batch [50/782] Loss: 0.5532 | Acc: 80.69%\n",
      "Train Epoch [73/100] Batch [51/782] Loss: 0.6503 | Acc: 80.58%\n",
      "Train Epoch [73/100] Batch [52/782] Loss: 0.6787 | Acc: 80.47%\n",
      "Train Epoch [73/100] Batch [53/782] Loss: 0.3749 | Acc: 80.63%\n",
      "Train Epoch [73/100] Batch [54/782] Loss: 0.4651 | Acc: 80.58%\n",
      "Train Epoch [73/100] Batch [55/782] Loss: 0.3948 | Acc: 80.65%\n",
      "Train Epoch [73/100] Batch [56/782] Loss: 0.3657 | Acc: 80.83%\n",
      "Train Epoch [73/100] Batch [57/782] Loss: 0.3897 | Acc: 80.98%\n",
      "Train Epoch [73/100] Batch [58/782] Loss: 0.4882 | Acc: 81.01%\n",
      "Train Epoch [73/100] Batch [59/782] Loss: 0.4663 | Acc: 81.01%\n",
      "Train Epoch [73/100] Batch [60/782] Loss: 0.2683 | Acc: 81.15%\n",
      "Train Epoch [73/100] Batch [61/782] Loss: 0.4615 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [62/782] Loss: 0.4937 | Acc: 81.25%\n",
      "Train Epoch [73/100] Batch [63/782] Loss: 0.4382 | Acc: 81.32%\n",
      "Train Epoch [73/100] Batch [64/782] Loss: 0.4051 | Acc: 81.35%\n",
      "Train Epoch [73/100] Batch [65/782] Loss: 0.4654 | Acc: 81.44%\n",
      "Train Epoch [73/100] Batch [66/782] Loss: 0.4531 | Acc: 81.53%\n",
      "Train Epoch [73/100] Batch [67/782] Loss: 0.5688 | Acc: 81.46%\n",
      "Train Epoch [73/100] Batch [68/782] Loss: 0.4076 | Acc: 81.48%\n",
      "Train Epoch [73/100] Batch [69/782] Loss: 0.6503 | Acc: 81.45%\n",
      "Train Epoch [73/100] Batch [70/782] Loss: 0.5014 | Acc: 81.45%\n",
      "Train Epoch [73/100] Batch [71/782] Loss: 0.3483 | Acc: 81.56%\n",
      "Train Epoch [73/100] Batch [72/782] Loss: 0.5302 | Acc: 81.55%\n",
      "Train Epoch [73/100] Batch [73/782] Loss: 0.5406 | Acc: 81.53%\n",
      "Train Epoch [73/100] Batch [74/782] Loss: 0.4259 | Acc: 81.55%\n",
      "Train Epoch [73/100] Batch [75/782] Loss: 0.3324 | Acc: 81.67%\n",
      "Train Epoch [73/100] Batch [76/782] Loss: 0.4991 | Acc: 81.72%\n",
      "Train Epoch [73/100] Batch [77/782] Loss: 0.3866 | Acc: 81.78%\n",
      "Train Epoch [73/100] Batch [78/782] Loss: 0.5543 | Acc: 81.75%\n",
      "Train Epoch [73/100] Batch [79/782] Loss: 0.5145 | Acc: 81.74%\n",
      "Train Epoch [73/100] Batch [80/782] Loss: 0.3885 | Acc: 81.78%\n",
      "Train Epoch [73/100] Batch [81/782] Loss: 0.3759 | Acc: 81.83%\n",
      "Train Epoch [73/100] Batch [82/782] Loss: 0.4255 | Acc: 81.88%\n",
      "Train Epoch [73/100] Batch [83/782] Loss: 0.5017 | Acc: 81.85%\n",
      "Train Epoch [73/100] Batch [84/782] Loss: 0.5283 | Acc: 81.90%\n",
      "Train Epoch [73/100] Batch [85/782] Loss: 0.5179 | Acc: 81.89%\n",
      "Train Epoch [73/100] Batch [86/782] Loss: 0.3970 | Acc: 81.98%\n",
      "Train Epoch [73/100] Batch [87/782] Loss: 0.5932 | Acc: 82.00%\n",
      "Train Epoch [73/100] Batch [88/782] Loss: 0.4895 | Acc: 81.98%\n",
      "Train Epoch [73/100] Batch [89/782] Loss: 0.3962 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [90/782] Loss: 0.3694 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [91/782] Loss: 0.5001 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [92/782] Loss: 0.4764 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [93/782] Loss: 0.5292 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [94/782] Loss: 0.3775 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [95/782] Loss: 0.5992 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [96/782] Loss: 0.3243 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [97/782] Loss: 0.6099 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [98/782] Loss: 0.5955 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [99/782] Loss: 0.4145 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [100/782] Loss: 0.5556 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [101/782] Loss: 0.4213 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [102/782] Loss: 0.4532 | Acc: 82.23%\n",
      "Train Epoch [73/100] Batch [103/782] Loss: 0.5089 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [104/782] Loss: 0.4742 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [105/782] Loss: 0.3321 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [106/782] Loss: 0.4859 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [107/782] Loss: 0.2920 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [108/782] Loss: 0.4093 | Acc: 82.39%\n",
      "Train Epoch [73/100] Batch [109/782] Loss: 0.5427 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [110/782] Loss: 0.5222 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [111/782] Loss: 0.5752 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [112/782] Loss: 0.2863 | Acc: 82.41%\n",
      "Train Epoch [73/100] Batch [113/782] Loss: 0.5994 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [114/782] Loss: 0.5389 | Acc: 82.37%\n",
      "Train Epoch [73/100] Batch [115/782] Loss: 0.3481 | Acc: 82.43%\n",
      "Train Epoch [73/100] Batch [116/782] Loss: 0.4756 | Acc: 82.44%\n",
      "Train Epoch [73/100] Batch [117/782] Loss: 0.5840 | Acc: 82.39%\n",
      "Train Epoch [73/100] Batch [118/782] Loss: 0.5434 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [119/782] Loss: 0.4628 | Acc: 82.43%\n",
      "Train Epoch [73/100] Batch [120/782] Loss: 0.5884 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [121/782] Loss: 0.3667 | Acc: 82.43%\n",
      "Train Epoch [73/100] Batch [122/782] Loss: 0.4543 | Acc: 82.47%\n",
      "Train Epoch [73/100] Batch [123/782] Loss: 0.6622 | Acc: 82.41%\n",
      "Train Epoch [73/100] Batch [124/782] Loss: 0.4484 | Acc: 82.41%\n",
      "Train Epoch [73/100] Batch [125/782] Loss: 0.4932 | Acc: 82.44%\n",
      "Train Epoch [73/100] Batch [126/782] Loss: 0.5445 | Acc: 82.40%\n",
      "Train Epoch [73/100] Batch [127/782] Loss: 0.5834 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [128/782] Loss: 0.6582 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [129/782] Loss: 0.4333 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [130/782] Loss: 0.4112 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [131/782] Loss: 0.6032 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [132/782] Loss: 0.4990 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [133/782] Loss: 0.5523 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [134/782] Loss: 0.5569 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [135/782] Loss: 0.4945 | Acc: 82.27%\n",
      "Train Epoch [73/100] Batch [136/782] Loss: 0.3404 | Acc: 82.31%\n",
      "Train Epoch [73/100] Batch [137/782] Loss: 0.4572 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [138/782] Loss: 0.5737 | Acc: 82.27%\n",
      "Train Epoch [73/100] Batch [139/782] Loss: 0.4194 | Acc: 82.31%\n",
      "Train Epoch [73/100] Batch [140/782] Loss: 0.3776 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [141/782] Loss: 0.5091 | Acc: 82.29%\n",
      "Train Epoch [73/100] Batch [142/782] Loss: 0.4595 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [143/782] Loss: 0.5540 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [144/782] Loss: 0.4924 | Acc: 82.26%\n",
      "Train Epoch [73/100] Batch [145/782] Loss: 0.5644 | Acc: 82.25%\n",
      "Train Epoch [73/100] Batch [146/782] Loss: 0.7173 | Acc: 82.22%\n",
      "Train Epoch [73/100] Batch [147/782] Loss: 0.5169 | Acc: 82.23%\n",
      "Train Epoch [73/100] Batch [148/782] Loss: 0.3048 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [149/782] Loss: 0.4699 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [150/782] Loss: 0.4832 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [151/782] Loss: 0.5151 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [152/782] Loss: 0.4743 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [153/782] Loss: 0.6048 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [154/782] Loss: 0.4951 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [155/782] Loss: 0.4089 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [156/782] Loss: 0.6231 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [157/782] Loss: 0.3652 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [158/782] Loss: 0.4248 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [159/782] Loss: 0.6105 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [160/782] Loss: 0.5048 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [161/782] Loss: 0.4779 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [162/782] Loss: 0.3309 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [163/782] Loss: 0.5734 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [164/782] Loss: 0.3792 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [165/782] Loss: 0.6859 | Acc: 82.30%\n",
      "Train Epoch [73/100] Batch [166/782] Loss: 0.3594 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [167/782] Loss: 0.5240 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [168/782] Loss: 0.4701 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [169/782] Loss: 0.5176 | Acc: 82.40%\n",
      "Train Epoch [73/100] Batch [170/782] Loss: 0.5056 | Acc: 82.40%\n",
      "Train Epoch [73/100] Batch [171/782] Loss: 0.4287 | Acc: 82.42%\n",
      "Train Epoch [73/100] Batch [172/782] Loss: 0.5322 | Acc: 82.39%\n",
      "Train Epoch [73/100] Batch [173/782] Loss: 0.4671 | Acc: 82.42%\n",
      "Train Epoch [73/100] Batch [174/782] Loss: 0.3138 | Acc: 82.46%\n",
      "Train Epoch [73/100] Batch [175/782] Loss: 0.3813 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [176/782] Loss: 0.4424 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [177/782] Loss: 0.3942 | Acc: 82.53%\n",
      "Train Epoch [73/100] Batch [178/782] Loss: 0.3458 | Acc: 82.54%\n",
      "Train Epoch [73/100] Batch [179/782] Loss: 0.3238 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [180/782] Loss: 0.5028 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [181/782] Loss: 0.4463 | Acc: 82.58%\n",
      "Train Epoch [73/100] Batch [182/782] Loss: 0.4238 | Acc: 82.59%\n",
      "Train Epoch [73/100] Batch [183/782] Loss: 0.4035 | Acc: 82.61%\n",
      "Train Epoch [73/100] Batch [184/782] Loss: 0.6393 | Acc: 82.59%\n",
      "Train Epoch [73/100] Batch [185/782] Loss: 0.4143 | Acc: 82.60%\n",
      "Train Epoch [73/100] Batch [186/782] Loss: 0.6079 | Acc: 82.58%\n",
      "Train Epoch [73/100] Batch [187/782] Loss: 0.4674 | Acc: 82.56%\n",
      "Train Epoch [73/100] Batch [188/782] Loss: 0.6458 | Acc: 82.52%\n",
      "Train Epoch [73/100] Batch [189/782] Loss: 0.3776 | Acc: 82.54%\n",
      "Train Epoch [73/100] Batch [190/782] Loss: 0.6626 | Acc: 82.48%\n",
      "Train Epoch [73/100] Batch [191/782] Loss: 0.3564 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [192/782] Loss: 0.3022 | Acc: 82.54%\n",
      "Train Epoch [73/100] Batch [193/782] Loss: 0.5858 | Acc: 82.52%\n",
      "Train Epoch [73/100] Batch [194/782] Loss: 0.4577 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [195/782] Loss: 0.4957 | Acc: 82.52%\n",
      "Train Epoch [73/100] Batch [196/782] Loss: 0.6306 | Acc: 82.53%\n",
      "Train Epoch [73/100] Batch [197/782] Loss: 0.5613 | Acc: 82.48%\n",
      "Train Epoch [73/100] Batch [198/782] Loss: 0.5414 | Acc: 82.45%\n",
      "Train Epoch [73/100] Batch [199/782] Loss: 0.4090 | Acc: 82.46%\n",
      "Train Epoch [73/100] Batch [200/782] Loss: 0.7209 | Acc: 82.42%\n",
      "Train Epoch [73/100] Batch [201/782] Loss: 0.3109 | Acc: 82.45%\n",
      "Train Epoch [73/100] Batch [202/782] Loss: 0.3966 | Acc: 82.48%\n",
      "Train Epoch [73/100] Batch [203/782] Loss: 0.3393 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [204/782] Loss: 0.7492 | Acc: 82.47%\n",
      "Train Epoch [73/100] Batch [205/782] Loss: 0.5355 | Acc: 82.47%\n",
      "Train Epoch [73/100] Batch [206/782] Loss: 0.5057 | Acc: 82.49%\n",
      "Train Epoch [73/100] Batch [207/782] Loss: 0.5810 | Acc: 82.49%\n",
      "Train Epoch [73/100] Batch [208/782] Loss: 0.4111 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [209/782] Loss: 0.5362 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [210/782] Loss: 0.5978 | Acc: 82.51%\n",
      "Train Epoch [73/100] Batch [211/782] Loss: 0.2500 | Acc: 82.55%\n",
      "Train Epoch [73/100] Batch [212/782] Loss: 0.4740 | Acc: 82.55%\n",
      "Train Epoch [73/100] Batch [213/782] Loss: 0.4580 | Acc: 82.55%\n",
      "Train Epoch [73/100] Batch [214/782] Loss: 0.8261 | Acc: 82.53%\n",
      "Train Epoch [73/100] Batch [215/782] Loss: 0.3546 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [216/782] Loss: 0.4554 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [217/782] Loss: 0.4781 | Acc: 82.60%\n",
      "Train Epoch [73/100] Batch [218/782] Loss: 0.3903 | Acc: 82.60%\n",
      "Train Epoch [73/100] Batch [219/782] Loss: 0.5709 | Acc: 82.61%\n",
      "Train Epoch [73/100] Batch [220/782] Loss: 0.7753 | Acc: 82.58%\n",
      "Train Epoch [73/100] Batch [221/782] Loss: 0.4307 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [222/782] Loss: 0.3926 | Acc: 82.56%\n",
      "Train Epoch [73/100] Batch [223/782] Loss: 0.5414 | Acc: 82.57%\n",
      "Train Epoch [73/100] Batch [224/782] Loss: 0.5864 | Acc: 82.53%\n",
      "Train Epoch [73/100] Batch [225/782] Loss: 0.5230 | Acc: 82.53%\n",
      "Train Epoch [73/100] Batch [226/782] Loss: 0.6249 | Acc: 82.50%\n",
      "Train Epoch [73/100] Batch [227/782] Loss: 0.5858 | Acc: 82.50%\n",
      "Train Epoch [73/100] Batch [228/782] Loss: 0.5691 | Acc: 82.46%\n",
      "Train Epoch [73/100] Batch [229/782] Loss: 0.9465 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [230/782] Loss: 0.4298 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [231/782] Loss: 0.6037 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [232/782] Loss: 0.5110 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [233/782] Loss: 0.4920 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [234/782] Loss: 0.3742 | Acc: 82.37%\n",
      "Train Epoch [73/100] Batch [235/782] Loss: 0.5174 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [236/782] Loss: 0.5437 | Acc: 82.37%\n",
      "Train Epoch [73/100] Batch [237/782] Loss: 0.4694 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [238/782] Loss: 0.5224 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [239/782] Loss: 0.3316 | Acc: 82.39%\n",
      "Train Epoch [73/100] Batch [240/782] Loss: 0.5614 | Acc: 82.38%\n",
      "Train Epoch [73/100] Batch [241/782] Loss: 0.4353 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [242/782] Loss: 0.6088 | Acc: 82.35%\n",
      "Train Epoch [73/100] Batch [243/782] Loss: 0.4329 | Acc: 82.36%\n",
      "Train Epoch [73/100] Batch [244/782] Loss: 0.6016 | Acc: 82.34%\n",
      "Train Epoch [73/100] Batch [245/782] Loss: 0.6863 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [246/782] Loss: 0.7528 | Acc: 82.30%\n",
      "Train Epoch [73/100] Batch [247/782] Loss: 0.3512 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [248/782] Loss: 0.5248 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [249/782] Loss: 0.6067 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [250/782] Loss: 0.5054 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [251/782] Loss: 0.4549 | Acc: 82.32%\n",
      "Train Epoch [73/100] Batch [252/782] Loss: 0.5034 | Acc: 82.33%\n",
      "Train Epoch [73/100] Batch [253/782] Loss: 0.7305 | Acc: 82.29%\n",
      "Train Epoch [73/100] Batch [254/782] Loss: 0.5327 | Acc: 82.28%\n",
      "Train Epoch [73/100] Batch [255/782] Loss: 0.5867 | Acc: 82.26%\n",
      "Train Epoch [73/100] Batch [256/782] Loss: 0.5672 | Acc: 82.26%\n",
      "Train Epoch [73/100] Batch [257/782] Loss: 0.5931 | Acc: 82.25%\n",
      "Train Epoch [73/100] Batch [258/782] Loss: 0.4489 | Acc: 82.26%\n",
      "Train Epoch [73/100] Batch [259/782] Loss: 0.3640 | Acc: 82.27%\n",
      "Train Epoch [73/100] Batch [260/782] Loss: 0.4286 | Acc: 82.30%\n",
      "Train Epoch [73/100] Batch [261/782] Loss: 0.7503 | Acc: 82.27%\n",
      "Train Epoch [73/100] Batch [262/782] Loss: 0.5763 | Acc: 82.25%\n",
      "Train Epoch [73/100] Batch [263/782] Loss: 0.6457 | Acc: 82.24%\n",
      "Train Epoch [73/100] Batch [264/782] Loss: 0.5598 | Acc: 82.23%\n",
      "Train Epoch [73/100] Batch [265/782] Loss: 0.5021 | Acc: 82.23%\n",
      "Train Epoch [73/100] Batch [266/782] Loss: 0.4169 | Acc: 82.25%\n",
      "Train Epoch [73/100] Batch [267/782] Loss: 0.5106 | Acc: 82.25%\n",
      "Train Epoch [73/100] Batch [268/782] Loss: 0.5128 | Acc: 82.24%\n",
      "Train Epoch [73/100] Batch [269/782] Loss: 0.5480 | Acc: 82.22%\n",
      "Train Epoch [73/100] Batch [270/782] Loss: 0.3938 | Acc: 82.22%\n",
      "Train Epoch [73/100] Batch [271/782] Loss: 0.4733 | Acc: 82.22%\n",
      "Train Epoch [73/100] Batch [272/782] Loss: 0.6230 | Acc: 82.22%\n",
      "Train Epoch [73/100] Batch [273/782] Loss: 0.5262 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [274/782] Loss: 0.4874 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [275/782] Loss: 0.5624 | Acc: 82.19%\n",
      "Train Epoch [73/100] Batch [276/782] Loss: 0.4196 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [277/782] Loss: 0.7223 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [278/782] Loss: 0.5259 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [279/782] Loss: 0.6316 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [280/782] Loss: 0.3812 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [281/782] Loss: 0.4109 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [282/782] Loss: 0.6100 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [283/782] Loss: 0.3151 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [284/782] Loss: 0.6080 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [285/782] Loss: 0.4430 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [286/782] Loss: 0.4008 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [287/782] Loss: 0.7093 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [288/782] Loss: 0.3940 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [289/782] Loss: 0.4969 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [290/782] Loss: 0.4209 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [291/782] Loss: 0.4162 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [292/782] Loss: 0.4244 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [293/782] Loss: 0.5591 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [294/782] Loss: 0.4591 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [295/782] Loss: 0.6261 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [296/782] Loss: 0.5180 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [297/782] Loss: 0.6378 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [298/782] Loss: 0.5511 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [299/782] Loss: 0.4838 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [300/782] Loss: 0.4337 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [301/782] Loss: 0.8044 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [302/782] Loss: 0.5225 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [303/782] Loss: 0.4733 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [304/782] Loss: 0.4794 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [305/782] Loss: 0.6145 | Acc: 81.99%\n",
      "Train Epoch [73/100] Batch [306/782] Loss: 0.4623 | Acc: 82.01%\n",
      "Train Epoch [73/100] Batch [307/782] Loss: 0.3707 | Acc: 82.01%\n",
      "Train Epoch [73/100] Batch [308/782] Loss: 0.4578 | Acc: 82.01%\n",
      "Train Epoch [73/100] Batch [309/782] Loss: 0.4494 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [310/782] Loss: 0.3791 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [311/782] Loss: 0.4025 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [312/782] Loss: 0.4249 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [313/782] Loss: 0.4296 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [314/782] Loss: 0.4673 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [315/782] Loss: 0.6190 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [316/782] Loss: 0.6381 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [317/782] Loss: 0.6026 | Acc: 82.02%\n",
      "Train Epoch [73/100] Batch [318/782] Loss: 0.4188 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [319/782] Loss: 0.5368 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [320/782] Loss: 0.3674 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [321/782] Loss: 0.7698 | Acc: 82.00%\n",
      "Train Epoch [73/100] Batch [322/782] Loss: 0.6826 | Acc: 81.98%\n",
      "Train Epoch [73/100] Batch [323/782] Loss: 0.2714 | Acc: 82.01%\n",
      "Train Epoch [73/100] Batch [324/782] Loss: 0.6106 | Acc: 82.01%\n",
      "Train Epoch [73/100] Batch [325/782] Loss: 0.4753 | Acc: 82.03%\n",
      "Train Epoch [73/100] Batch [326/782] Loss: 0.5483 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [327/782] Loss: 0.5409 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [328/782] Loss: 0.4954 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [329/782] Loss: 0.3463 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [330/782] Loss: 0.5583 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [331/782] Loss: 0.4901 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [332/782] Loss: 0.4757 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [333/782] Loss: 0.5021 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [334/782] Loss: 0.5005 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [335/782] Loss: 0.3435 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [336/782] Loss: 0.3463 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [337/782] Loss: 0.4406 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [338/782] Loss: 0.4652 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [339/782] Loss: 0.4456 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [340/782] Loss: 0.3978 | Acc: 82.19%\n",
      "Train Epoch [73/100] Batch [341/782] Loss: 0.4983 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [342/782] Loss: 0.4224 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [343/782] Loss: 0.4907 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [344/782] Loss: 0.5221 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [345/782] Loss: 0.7001 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [346/782] Loss: 0.3739 | Acc: 82.19%\n",
      "Train Epoch [73/100] Batch [347/782] Loss: 0.3394 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [348/782] Loss: 0.4420 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [349/782] Loss: 0.5110 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [350/782] Loss: 0.4403 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [351/782] Loss: 0.5274 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [352/782] Loss: 0.2482 | Acc: 82.23%\n",
      "Train Epoch [73/100] Batch [353/782] Loss: 0.7261 | Acc: 82.21%\n",
      "Train Epoch [73/100] Batch [354/782] Loss: 0.5007 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [355/782] Loss: 0.5943 | Acc: 82.19%\n",
      "Train Epoch [73/100] Batch [356/782] Loss: 0.5246 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [357/782] Loss: 0.3469 | Acc: 82.20%\n",
      "Train Epoch [73/100] Batch [358/782] Loss: 0.6657 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [359/782] Loss: 0.4713 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [360/782] Loss: 0.4391 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [361/782] Loss: 0.7795 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [362/782] Loss: 0.4993 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [363/782] Loss: 0.5165 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [364/782] Loss: 0.7115 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [365/782] Loss: 0.5724 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [366/782] Loss: 0.6134 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [367/782] Loss: 0.4270 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [368/782] Loss: 0.5371 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [369/782] Loss: 0.6607 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [370/782] Loss: 0.6207 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [371/782] Loss: 0.3672 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [372/782] Loss: 0.4330 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [373/782] Loss: 0.4979 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [374/782] Loss: 0.4856 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [375/782] Loss: 0.3872 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [376/782] Loss: 0.6891 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [377/782] Loss: 0.6607 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [378/782] Loss: 0.6553 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [379/782] Loss: 0.3691 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [380/782] Loss: 0.4589 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [381/782] Loss: 0.5233 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [382/782] Loss: 0.4268 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [383/782] Loss: 0.5252 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [384/782] Loss: 0.5028 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [385/782] Loss: 0.7189 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [386/782] Loss: 0.5635 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [387/782] Loss: 0.3523 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [388/782] Loss: 0.4473 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [389/782] Loss: 0.4856 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [390/782] Loss: 0.3782 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [391/782] Loss: 0.3977 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [392/782] Loss: 0.5043 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [393/782] Loss: 0.3894 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [394/782] Loss: 0.3769 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [395/782] Loss: 0.5344 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [396/782] Loss: 0.4420 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [397/782] Loss: 0.6312 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [398/782] Loss: 0.4546 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [399/782] Loss: 0.6370 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [400/782] Loss: 0.7356 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [401/782] Loss: 0.6137 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [402/782] Loss: 0.3964 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [403/782] Loss: 0.5557 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [404/782] Loss: 0.4352 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [405/782] Loss: 0.3684 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [406/782] Loss: 0.3331 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [407/782] Loss: 0.4294 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [408/782] Loss: 0.7333 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [409/782] Loss: 0.4263 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [410/782] Loss: 0.3947 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [411/782] Loss: 0.6075 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [412/782] Loss: 0.4027 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [413/782] Loss: 0.5017 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [414/782] Loss: 0.5374 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [415/782] Loss: 0.6051 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [416/782] Loss: 0.4542 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [417/782] Loss: 0.5482 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [418/782] Loss: 0.6538 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [419/782] Loss: 0.3135 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [420/782] Loss: 0.5661 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [421/782] Loss: 0.3985 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [422/782] Loss: 0.5303 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [423/782] Loss: 0.4967 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [424/782] Loss: 0.5504 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [425/782] Loss: 0.6969 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [426/782] Loss: 0.4490 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [427/782] Loss: 0.4279 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [428/782] Loss: 0.5040 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [429/782] Loss: 0.5095 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [430/782] Loss: 0.3498 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [431/782] Loss: 0.3619 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [432/782] Loss: 0.3893 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [433/782] Loss: 0.4356 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [434/782] Loss: 0.5684 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [435/782] Loss: 0.4570 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [436/782] Loss: 0.4526 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [437/782] Loss: 0.6459 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [438/782] Loss: 0.6115 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [439/782] Loss: 0.4203 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [440/782] Loss: 0.5209 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [441/782] Loss: 0.5265 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [442/782] Loss: 0.6116 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [443/782] Loss: 0.6784 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [444/782] Loss: 0.6130 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [445/782] Loss: 0.4089 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [446/782] Loss: 0.4779 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [447/782] Loss: 0.3815 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [448/782] Loss: 0.5515 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [449/782] Loss: 0.5042 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [450/782] Loss: 0.3846 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [451/782] Loss: 0.3485 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [452/782] Loss: 0.4286 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [453/782] Loss: 0.8587 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [454/782] Loss: 0.5287 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [455/782] Loss: 0.4276 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [456/782] Loss: 0.5220 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [457/782] Loss: 0.4451 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [458/782] Loss: 0.4654 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [459/782] Loss: 0.6277 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [460/782] Loss: 0.4635 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [461/782] Loss: 0.4338 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [462/782] Loss: 0.4064 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [463/782] Loss: 0.3918 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [464/782] Loss: 0.5658 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [465/782] Loss: 0.6308 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [466/782] Loss: 0.4647 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [467/782] Loss: 0.6160 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [468/782] Loss: 0.6127 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [469/782] Loss: 0.4571 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [470/782] Loss: 0.5481 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [471/782] Loss: 0.5357 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [472/782] Loss: 0.6978 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [473/782] Loss: 0.5039 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [474/782] Loss: 0.6801 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [475/782] Loss: 0.4100 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [476/782] Loss: 0.4114 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [477/782] Loss: 0.4354 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [478/782] Loss: 0.4259 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [479/782] Loss: 0.6632 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [480/782] Loss: 0.4568 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [481/782] Loss: 0.4354 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [482/782] Loss: 0.5817 | Acc: 82.04%\n",
      "Train Epoch [73/100] Batch [483/782] Loss: 0.3215 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [484/782] Loss: 0.5557 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [485/782] Loss: 0.5284 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [486/782] Loss: 0.5263 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [487/782] Loss: 0.3840 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [488/782] Loss: 0.5193 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [489/782] Loss: 0.3680 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [490/782] Loss: 0.3714 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [491/782] Loss: 0.4694 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [492/782] Loss: 0.5520 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [493/782] Loss: 0.4407 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [494/782] Loss: 0.6369 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [495/782] Loss: 0.5003 | Acc: 82.05%\n",
      "Train Epoch [73/100] Batch [496/782] Loss: 0.4289 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [497/782] Loss: 0.5303 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [498/782] Loss: 0.6077 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [499/782] Loss: 0.4376 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [500/782] Loss: 0.5932 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [501/782] Loss: 0.5000 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [502/782] Loss: 0.4994 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [503/782] Loss: 0.7768 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [504/782] Loss: 0.4595 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [505/782] Loss: 0.4268 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [506/782] Loss: 0.6410 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [507/782] Loss: 0.5009 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [508/782] Loss: 0.5334 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [509/782] Loss: 0.5356 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [510/782] Loss: 0.4665 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [511/782] Loss: 0.3047 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [512/782] Loss: 0.6044 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [513/782] Loss: 0.4225 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [514/782] Loss: 0.3976 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [515/782] Loss: 0.6211 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [516/782] Loss: 0.3269 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [517/782] Loss: 0.5274 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [518/782] Loss: 0.4256 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [519/782] Loss: 0.3763 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [520/782] Loss: 0.3989 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [521/782] Loss: 0.7306 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [522/782] Loss: 0.4466 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [523/782] Loss: 0.4062 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [524/782] Loss: 0.3677 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [525/782] Loss: 0.6504 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [526/782] Loss: 0.3622 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [527/782] Loss: 0.4587 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [528/782] Loss: 0.5424 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [529/782] Loss: 0.6951 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [530/782] Loss: 0.4555 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [531/782] Loss: 0.7906 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [532/782] Loss: 0.3841 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [533/782] Loss: 0.5020 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [534/782] Loss: 0.4955 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [535/782] Loss: 0.5935 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [536/782] Loss: 0.4135 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [537/782] Loss: 0.3604 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [538/782] Loss: 0.3649 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [539/782] Loss: 0.6382 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [540/782] Loss: 0.4892 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [541/782] Loss: 0.4130 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [542/782] Loss: 0.5090 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [543/782] Loss: 0.5213 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [544/782] Loss: 0.4688 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [545/782] Loss: 0.6842 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [546/782] Loss: 0.5713 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [547/782] Loss: 0.6247 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [548/782] Loss: 0.5249 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [549/782] Loss: 0.4448 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [550/782] Loss: 0.5470 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [551/782] Loss: 0.3372 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [552/782] Loss: 0.3654 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [553/782] Loss: 0.3533 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [554/782] Loss: 0.7058 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [555/782] Loss: 0.5727 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [556/782] Loss: 0.5630 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [557/782] Loss: 0.4392 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [558/782] Loss: 0.5185 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [559/782] Loss: 0.3362 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [560/782] Loss: 0.4106 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [561/782] Loss: 0.4350 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [562/782] Loss: 0.3451 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [563/782] Loss: 0.6190 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [564/782] Loss: 0.5327 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [565/782] Loss: 0.3046 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [566/782] Loss: 0.4116 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [567/782] Loss: 0.4008 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [568/782] Loss: 0.4428 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [569/782] Loss: 0.5534 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [570/782] Loss: 0.5731 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [571/782] Loss: 0.6439 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [572/782] Loss: 0.4632 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [573/782] Loss: 0.3688 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [574/782] Loss: 0.6119 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [575/782] Loss: 0.6830 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [576/782] Loss: 0.5213 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [577/782] Loss: 0.5478 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [578/782] Loss: 0.3753 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [579/782] Loss: 0.4651 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [580/782] Loss: 0.4330 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [581/782] Loss: 0.3107 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [582/782] Loss: 0.4779 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [583/782] Loss: 0.4078 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [584/782] Loss: 0.3886 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [585/782] Loss: 0.4824 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [586/782] Loss: 0.5608 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [587/782] Loss: 0.4897 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [588/782] Loss: 0.5674 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [589/782] Loss: 0.6185 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [590/782] Loss: 0.6381 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [591/782] Loss: 0.6839 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [592/782] Loss: 0.6185 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [593/782] Loss: 0.5140 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [594/782] Loss: 0.3730 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [595/782] Loss: 0.4653 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [596/782] Loss: 0.4258 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [597/782] Loss: 0.4678 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [598/782] Loss: 0.4699 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [599/782] Loss: 0.5037 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [600/782] Loss: 0.5052 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [601/782] Loss: 0.4307 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [602/782] Loss: 0.4106 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [603/782] Loss: 0.5724 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [604/782] Loss: 0.6908 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [605/782] Loss: 0.5596 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [606/782] Loss: 0.5432 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [607/782] Loss: 0.4756 | Acc: 82.07%\n",
      "Train Epoch [73/100] Batch [608/782] Loss: 0.6543 | Acc: 82.06%\n",
      "Train Epoch [73/100] Batch [609/782] Loss: 0.2691 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [610/782] Loss: 0.3951 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [611/782] Loss: 0.3780 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [612/782] Loss: 0.6217 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [613/782] Loss: 0.4439 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [614/782] Loss: 0.2858 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [615/782] Loss: 0.4465 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [616/782] Loss: 0.6387 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [617/782] Loss: 0.3075 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [618/782] Loss: 0.4825 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [619/782] Loss: 0.5070 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [620/782] Loss: 0.3784 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [621/782] Loss: 0.4361 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [622/782] Loss: 0.4075 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [623/782] Loss: 0.4496 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [624/782] Loss: 0.6637 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [625/782] Loss: 0.5720 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [626/782] Loss: 0.5841 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [627/782] Loss: 0.5389 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [628/782] Loss: 0.6396 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [629/782] Loss: 0.3690 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [630/782] Loss: 0.6449 | Acc: 82.08%\n",
      "Train Epoch [73/100] Batch [631/782] Loss: 0.4422 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [632/782] Loss: 0.4423 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [633/782] Loss: 0.3780 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [634/782] Loss: 0.4348 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [635/782] Loss: 0.3449 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [636/782] Loss: 0.5736 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [637/782] Loss: 0.4123 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [638/782] Loss: 0.6284 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [639/782] Loss: 0.3880 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [640/782] Loss: 0.6187 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [641/782] Loss: 0.5510 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [642/782] Loss: 0.5110 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [643/782] Loss: 0.5095 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [644/782] Loss: 0.3288 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [645/782] Loss: 0.4301 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [646/782] Loss: 0.5540 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [647/782] Loss: 0.3039 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [648/782] Loss: 0.5572 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [649/782] Loss: 0.6611 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [650/782] Loss: 0.6217 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [651/782] Loss: 0.6267 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [652/782] Loss: 0.5600 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [653/782] Loss: 0.5728 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [654/782] Loss: 0.8209 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [655/782] Loss: 0.3411 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [656/782] Loss: 0.7030 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [657/782] Loss: 0.5733 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [658/782] Loss: 0.5440 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [659/782] Loss: 0.6799 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [660/782] Loss: 0.3010 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [661/782] Loss: 0.4586 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [662/782] Loss: 0.5982 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [663/782] Loss: 0.4285 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [664/782] Loss: 0.5723 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [665/782] Loss: 0.3169 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [666/782] Loss: 0.5056 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [667/782] Loss: 0.4174 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [668/782] Loss: 0.5153 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [669/782] Loss: 0.5463 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [670/782] Loss: 0.7724 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [671/782] Loss: 0.6739 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [672/782] Loss: 0.5325 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [673/782] Loss: 0.4262 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [674/782] Loss: 0.3811 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [675/782] Loss: 0.5596 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [676/782] Loss: 0.5305 | Acc: 82.09%\n",
      "Train Epoch [73/100] Batch [677/782] Loss: 0.2435 | Acc: 82.10%\n",
      "Train Epoch [73/100] Batch [678/782] Loss: 0.3994 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [679/782] Loss: 0.4095 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [680/782] Loss: 0.4152 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [681/782] Loss: 0.3026 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [682/782] Loss: 0.4385 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [683/782] Loss: 0.6012 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [684/782] Loss: 0.5071 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [685/782] Loss: 0.6113 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [686/782] Loss: 0.3206 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [687/782] Loss: 0.4687 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [688/782] Loss: 0.6381 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [689/782] Loss: 0.4128 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [690/782] Loss: 0.5524 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [691/782] Loss: 0.5592 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [692/782] Loss: 0.4803 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [693/782] Loss: 0.2481 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [694/782] Loss: 0.3597 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [695/782] Loss: 0.4881 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [696/782] Loss: 0.4730 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [697/782] Loss: 0.4659 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [698/782] Loss: 0.4499 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [699/782] Loss: 0.5081 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [700/782] Loss: 0.3550 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [701/782] Loss: 0.4685 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [702/782] Loss: 0.4961 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [703/782] Loss: 0.3553 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [704/782] Loss: 0.4894 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [705/782] Loss: 0.6488 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [706/782] Loss: 0.6505 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [707/782] Loss: 0.4825 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [708/782] Loss: 0.4641 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [709/782] Loss: 0.5077 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [710/782] Loss: 0.5683 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [711/782] Loss: 0.4700 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [712/782] Loss: 0.4352 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [713/782] Loss: 0.6325 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [714/782] Loss: 0.6380 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [715/782] Loss: 0.5582 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [716/782] Loss: 0.4599 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [717/782] Loss: 0.5807 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [718/782] Loss: 0.6473 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [719/782] Loss: 0.4764 | Acc: 82.11%\n",
      "Train Epoch [73/100] Batch [720/782] Loss: 0.4157 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [721/782] Loss: 0.4022 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [722/782] Loss: 0.4331 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [723/782] Loss: 0.4373 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [724/782] Loss: 0.4062 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [725/782] Loss: 0.5131 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [726/782] Loss: 0.4956 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [727/782] Loss: 0.6188 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [728/782] Loss: 0.5819 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [729/782] Loss: 0.7077 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [730/782] Loss: 0.4925 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [731/782] Loss: 0.6301 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [732/782] Loss: 0.3419 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [733/782] Loss: 0.5428 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [734/782] Loss: 0.4276 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [735/782] Loss: 0.5641 | Acc: 82.12%\n",
      "Train Epoch [73/100] Batch [736/782] Loss: 0.3346 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [737/782] Loss: 0.5214 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [738/782] Loss: 0.5028 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [739/782] Loss: 0.3935 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [740/782] Loss: 0.6703 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [741/782] Loss: 0.6274 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [742/782] Loss: 0.5564 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [743/782] Loss: 0.5806 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [744/782] Loss: 0.3915 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [745/782] Loss: 0.5219 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [746/782] Loss: 0.5314 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [747/782] Loss: 0.3988 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [748/782] Loss: 0.3769 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [749/782] Loss: 0.5729 | Acc: 82.13%\n",
      "Train Epoch [73/100] Batch [750/782] Loss: 0.4474 | Acc: 82.14%\n",
      "Train Epoch [73/100] Batch [751/782] Loss: 0.2805 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [752/782] Loss: 0.6687 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [753/782] Loss: 0.5189 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [754/782] Loss: 0.6108 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [755/782] Loss: 0.5640 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [756/782] Loss: 0.4331 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [757/782] Loss: 0.5413 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [758/782] Loss: 0.4265 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [759/782] Loss: 0.5351 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [760/782] Loss: 0.5784 | Acc: 82.15%\n",
      "Train Epoch [73/100] Batch [761/782] Loss: 0.4860 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [762/782] Loss: 0.3845 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [763/782] Loss: 0.5905 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [764/782] Loss: 0.5107 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [765/782] Loss: 0.6420 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [766/782] Loss: 0.4248 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [767/782] Loss: 0.3855 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [768/782] Loss: 0.5664 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [769/782] Loss: 0.4704 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [770/782] Loss: 0.4923 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [771/782] Loss: 0.4190 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [772/782] Loss: 0.6157 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [773/782] Loss: 0.4543 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [774/782] Loss: 0.4115 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [775/782] Loss: 0.6130 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [776/782] Loss: 0.5882 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [777/782] Loss: 0.3604 | Acc: 82.18%\n",
      "Train Epoch [73/100] Batch [778/782] Loss: 0.6014 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [779/782] Loss: 0.5445 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [780/782] Loss: 0.3632 | Acc: 82.17%\n",
      "Train Epoch [73/100] Batch [781/782] Loss: 0.5952 | Acc: 82.16%\n",
      "Train Epoch [73/100] Batch [782/782] Loss: 0.5645 | Acc: 82.16%\n",
      "Epoch 73 completed in 30.52s.\n",
      "Test Epoch [73/100] Loss: 0.9461 | Acc: 72.34% | Inference Time: 8.59s\n",
      "Epoch 73 results saved to CSV.\n",
      "Epoch 74/100\n",
      "Train Epoch [74/100] Batch [1/782] Loss: 0.5070 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [2/782] Loss: 0.4502 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [3/782] Loss: 0.6328 | Acc: 81.25%\n",
      "Train Epoch [74/100] Batch [4/782] Loss: 0.6033 | Acc: 80.47%\n",
      "Train Epoch [74/100] Batch [5/782] Loss: 0.4997 | Acc: 81.25%\n",
      "Train Epoch [74/100] Batch [6/782] Loss: 0.4346 | Acc: 82.29%\n",
      "Train Epoch [74/100] Batch [7/782] Loss: 0.3432 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [8/782] Loss: 0.3113 | Acc: 83.01%\n",
      "Train Epoch [74/100] Batch [9/782] Loss: 0.3886 | Acc: 83.16%\n",
      "Train Epoch [74/100] Batch [10/782] Loss: 0.5481 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [11/782] Loss: 0.5167 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [12/782] Loss: 0.3891 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [13/782] Loss: 0.5562 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [14/782] Loss: 0.4694 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [15/782] Loss: 0.4700 | Acc: 82.92%\n",
      "Train Epoch [74/100] Batch [16/782] Loss: 0.3423 | Acc: 83.40%\n",
      "Train Epoch [74/100] Batch [17/782] Loss: 0.4847 | Acc: 83.00%\n",
      "Train Epoch [74/100] Batch [18/782] Loss: 0.5232 | Acc: 82.90%\n",
      "Train Epoch [74/100] Batch [19/782] Loss: 0.6310 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [20/782] Loss: 0.4421 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [21/782] Loss: 0.4624 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [22/782] Loss: 0.5494 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [23/782] Loss: 0.4906 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [24/782] Loss: 0.5157 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [25/782] Loss: 0.3315 | Acc: 82.88%\n",
      "Train Epoch [74/100] Batch [26/782] Loss: 0.4002 | Acc: 83.05%\n",
      "Train Epoch [74/100] Batch [27/782] Loss: 0.5180 | Acc: 82.99%\n",
      "Train Epoch [74/100] Batch [28/782] Loss: 0.4231 | Acc: 83.09%\n",
      "Train Epoch [74/100] Batch [29/782] Loss: 0.6104 | Acc: 82.87%\n",
      "Train Epoch [74/100] Batch [30/782] Loss: 0.4935 | Acc: 82.86%\n",
      "Train Epoch [74/100] Batch [31/782] Loss: 0.5399 | Acc: 82.86%\n",
      "Train Epoch [74/100] Batch [32/782] Loss: 0.4205 | Acc: 83.01%\n",
      "Train Epoch [74/100] Batch [33/782] Loss: 0.4933 | Acc: 82.95%\n",
      "Train Epoch [74/100] Batch [34/782] Loss: 0.3032 | Acc: 83.13%\n",
      "Train Epoch [74/100] Batch [35/782] Loss: 0.5482 | Acc: 83.08%\n",
      "Train Epoch [74/100] Batch [36/782] Loss: 0.6809 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [37/782] Loss: 0.4606 | Acc: 82.98%\n",
      "Train Epoch [74/100] Batch [38/782] Loss: 0.4644 | Acc: 83.10%\n",
      "Train Epoch [74/100] Batch [39/782] Loss: 0.4567 | Acc: 83.09%\n",
      "Train Epoch [74/100] Batch [40/782] Loss: 0.4154 | Acc: 83.09%\n",
      "Train Epoch [74/100] Batch [41/782] Loss: 0.5276 | Acc: 83.00%\n",
      "Train Epoch [74/100] Batch [42/782] Loss: 0.4923 | Acc: 83.04%\n",
      "Train Epoch [74/100] Batch [43/782] Loss: 0.4404 | Acc: 83.14%\n",
      "Train Epoch [74/100] Batch [44/782] Loss: 0.5245 | Acc: 82.95%\n",
      "Train Epoch [74/100] Batch [45/782] Loss: 0.4095 | Acc: 82.92%\n",
      "Train Epoch [74/100] Batch [46/782] Loss: 0.5247 | Acc: 82.91%\n",
      "Train Epoch [74/100] Batch [47/782] Loss: 0.3725 | Acc: 82.95%\n",
      "Train Epoch [74/100] Batch [48/782] Loss: 0.4811 | Acc: 82.88%\n",
      "Train Epoch [74/100] Batch [49/782] Loss: 0.4834 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [50/782] Loss: 0.3965 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [51/782] Loss: 0.4916 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [52/782] Loss: 0.4800 | Acc: 82.75%\n",
      "Train Epoch [74/100] Batch [53/782] Loss: 0.7004 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [54/782] Loss: 0.3998 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [55/782] Loss: 0.3814 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [56/782] Loss: 0.4071 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [57/782] Loss: 0.5088 | Acc: 82.79%\n",
      "Train Epoch [74/100] Batch [58/782] Loss: 0.5595 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [59/782] Loss: 0.5544 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [60/782] Loss: 0.4287 | Acc: 82.79%\n",
      "Train Epoch [74/100] Batch [61/782] Loss: 0.5598 | Acc: 82.74%\n",
      "Train Epoch [74/100] Batch [62/782] Loss: 0.2938 | Acc: 82.91%\n",
      "Train Epoch [74/100] Batch [63/782] Loss: 0.3319 | Acc: 83.01%\n",
      "Train Epoch [74/100] Batch [64/782] Loss: 0.5091 | Acc: 83.01%\n",
      "Train Epoch [74/100] Batch [65/782] Loss: 0.5839 | Acc: 82.93%\n",
      "Train Epoch [74/100] Batch [66/782] Loss: 0.3012 | Acc: 83.00%\n",
      "Train Epoch [74/100] Batch [67/782] Loss: 0.5284 | Acc: 83.00%\n",
      "Train Epoch [74/100] Batch [68/782] Loss: 0.5010 | Acc: 83.07%\n",
      "Train Epoch [74/100] Batch [69/782] Loss: 0.3625 | Acc: 83.15%\n",
      "Train Epoch [74/100] Batch [70/782] Loss: 0.4211 | Acc: 83.21%\n",
      "Train Epoch [74/100] Batch [71/782] Loss: 0.5244 | Acc: 83.19%\n",
      "Train Epoch [74/100] Batch [72/782] Loss: 0.4618 | Acc: 83.14%\n",
      "Train Epoch [74/100] Batch [73/782] Loss: 0.3463 | Acc: 83.22%\n",
      "Train Epoch [74/100] Batch [74/782] Loss: 0.5840 | Acc: 83.11%\n",
      "Train Epoch [74/100] Batch [75/782] Loss: 0.5395 | Acc: 83.08%\n",
      "Train Epoch [74/100] Batch [76/782] Loss: 0.3738 | Acc: 83.14%\n",
      "Train Epoch [74/100] Batch [77/782] Loss: 0.5411 | Acc: 83.02%\n",
      "Train Epoch [74/100] Batch [78/782] Loss: 0.3366 | Acc: 83.05%\n",
      "Train Epoch [74/100] Batch [79/782] Loss: 0.6730 | Acc: 82.95%\n",
      "Train Epoch [74/100] Batch [80/782] Loss: 0.6385 | Acc: 82.87%\n",
      "Train Epoch [74/100] Batch [81/782] Loss: 0.6385 | Acc: 82.79%\n",
      "Train Epoch [74/100] Batch [82/782] Loss: 0.6048 | Acc: 82.76%\n",
      "Train Epoch [74/100] Batch [83/782] Loss: 0.5051 | Acc: 82.74%\n",
      "Train Epoch [74/100] Batch [84/782] Loss: 0.5177 | Acc: 82.81%\n",
      "Train Epoch [74/100] Batch [85/782] Loss: 0.3596 | Acc: 82.85%\n",
      "Train Epoch [74/100] Batch [86/782] Loss: 0.5833 | Acc: 82.79%\n",
      "Train Epoch [74/100] Batch [87/782] Loss: 0.5353 | Acc: 82.79%\n",
      "Train Epoch [74/100] Batch [88/782] Loss: 0.3528 | Acc: 82.87%\n",
      "Train Epoch [74/100] Batch [89/782] Loss: 0.4738 | Acc: 82.83%\n",
      "Train Epoch [74/100] Batch [90/782] Loss: 0.5348 | Acc: 82.83%\n",
      "Train Epoch [74/100] Batch [91/782] Loss: 0.6058 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [92/782] Loss: 0.4749 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [93/782] Loss: 0.5099 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [94/782] Loss: 0.3534 | Acc: 82.75%\n",
      "Train Epoch [74/100] Batch [95/782] Loss: 0.5455 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [96/782] Loss: 0.6184 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [97/782] Loss: 0.6124 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [98/782] Loss: 0.6459 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [99/782] Loss: 0.6208 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [100/782] Loss: 0.5949 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [101/782] Loss: 0.6148 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [102/782] Loss: 0.4518 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [103/782] Loss: 0.3153 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [104/782] Loss: 0.5547 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [105/782] Loss: 0.4510 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [106/782] Loss: 0.4789 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [107/782] Loss: 0.5777 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [108/782] Loss: 0.5493 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [109/782] Loss: 0.6087 | Acc: 82.37%\n",
      "Train Epoch [74/100] Batch [110/782] Loss: 0.4548 | Acc: 82.34%\n",
      "Train Epoch [74/100] Batch [111/782] Loss: 0.3728 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [112/782] Loss: 0.5261 | Acc: 82.37%\n",
      "Train Epoch [74/100] Batch [113/782] Loss: 0.4942 | Acc: 82.38%\n",
      "Train Epoch [74/100] Batch [114/782] Loss: 0.3670 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [115/782] Loss: 0.3088 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [116/782] Loss: 0.5978 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [117/782] Loss: 0.3664 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [118/782] Loss: 0.3634 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [119/782] Loss: 0.5428 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [120/782] Loss: 0.5322 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [121/782] Loss: 0.5341 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [122/782] Loss: 0.3487 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [123/782] Loss: 0.4939 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [124/782] Loss: 0.6188 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [125/782] Loss: 0.3060 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [126/782] Loss: 0.4464 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [127/782] Loss: 0.5179 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [128/782] Loss: 0.5306 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [129/782] Loss: 0.7956 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [130/782] Loss: 0.4218 | Acc: 82.45%\n",
      "Train Epoch [74/100] Batch [131/782] Loss: 0.5027 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [132/782] Loss: 0.5545 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [133/782] Loss: 0.6049 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [134/782] Loss: 0.5538 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [135/782] Loss: 0.4008 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [136/782] Loss: 0.4805 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [137/782] Loss: 0.4736 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [138/782] Loss: 0.3606 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [139/782] Loss: 0.4235 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [140/782] Loss: 0.3836 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [141/782] Loss: 0.3864 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [142/782] Loss: 0.3788 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [143/782] Loss: 0.6571 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [144/782] Loss: 0.4712 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [145/782] Loss: 0.5660 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [146/782] Loss: 0.8069 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [147/782] Loss: 0.5293 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [148/782] Loss: 0.5630 | Acc: 82.36%\n",
      "Train Epoch [74/100] Batch [149/782] Loss: 0.4137 | Acc: 82.37%\n",
      "Train Epoch [74/100] Batch [150/782] Loss: 0.3478 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [151/782] Loss: 0.4807 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [152/782] Loss: 0.5662 | Acc: 82.38%\n",
      "Train Epoch [74/100] Batch [153/782] Loss: 0.7059 | Acc: 82.32%\n",
      "Train Epoch [74/100] Batch [154/782] Loss: 0.4290 | Acc: 82.33%\n",
      "Train Epoch [74/100] Batch [155/782] Loss: 0.6299 | Acc: 82.29%\n",
      "Train Epoch [74/100] Batch [156/782] Loss: 0.4870 | Acc: 82.29%\n",
      "Train Epoch [74/100] Batch [157/782] Loss: 0.6540 | Acc: 82.25%\n",
      "Train Epoch [74/100] Batch [158/782] Loss: 0.5506 | Acc: 82.24%\n",
      "Train Epoch [74/100] Batch [159/782] Loss: 0.4149 | Acc: 82.26%\n",
      "Train Epoch [74/100] Batch [160/782] Loss: 0.4048 | Acc: 82.29%\n",
      "Train Epoch [74/100] Batch [161/782] Loss: 0.4336 | Acc: 82.29%\n",
      "Train Epoch [74/100] Batch [162/782] Loss: 0.3270 | Acc: 82.34%\n",
      "Train Epoch [74/100] Batch [163/782] Loss: 0.4817 | Acc: 82.35%\n",
      "Train Epoch [74/100] Batch [164/782] Loss: 0.6190 | Acc: 82.32%\n",
      "Train Epoch [74/100] Batch [165/782] Loss: 0.3620 | Acc: 82.34%\n",
      "Train Epoch [74/100] Batch [166/782] Loss: 0.4674 | Acc: 82.33%\n",
      "Train Epoch [74/100] Batch [167/782] Loss: 0.4553 | Acc: 82.34%\n",
      "Train Epoch [74/100] Batch [168/782] Loss: 0.3308 | Acc: 82.37%\n",
      "Train Epoch [74/100] Batch [169/782] Loss: 0.3320 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [170/782] Loss: 0.4483 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [171/782] Loss: 0.6995 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [172/782] Loss: 0.3220 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [173/782] Loss: 0.3876 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [174/782] Loss: 0.4817 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [175/782] Loss: 0.3816 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [176/782] Loss: 0.4653 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [177/782] Loss: 0.5326 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [178/782] Loss: 0.4759 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [179/782] Loss: 0.6176 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [180/782] Loss: 0.4221 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [181/782] Loss: 0.6284 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [182/782] Loss: 0.3754 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [183/782] Loss: 0.3929 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [184/782] Loss: 0.4765 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [185/782] Loss: 0.5943 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [186/782] Loss: 0.5101 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [187/782] Loss: 0.5629 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [188/782] Loss: 0.4667 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [189/782] Loss: 0.4827 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [190/782] Loss: 0.4465 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [191/782] Loss: 0.5144 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [192/782] Loss: 0.5622 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [193/782] Loss: 0.5650 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [194/782] Loss: 0.3904 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [195/782] Loss: 0.5055 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [196/782] Loss: 0.3900 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [197/782] Loss: 0.5441 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [198/782] Loss: 0.4115 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [199/782] Loss: 0.4144 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [200/782] Loss: 0.5902 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [201/782] Loss: 0.5449 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [202/782] Loss: 0.6010 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [203/782] Loss: 0.6371 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [204/782] Loss: 0.5631 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [205/782] Loss: 0.5191 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [206/782] Loss: 0.2015 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [207/782] Loss: 0.4727 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [208/782] Loss: 0.3910 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [209/782] Loss: 0.5460 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [210/782] Loss: 0.4108 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [211/782] Loss: 0.4920 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [212/782] Loss: 0.7053 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [213/782] Loss: 0.5892 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [214/782] Loss: 0.2635 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [215/782] Loss: 0.5442 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [216/782] Loss: 0.3842 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [217/782] Loss: 0.6200 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [218/782] Loss: 0.3373 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [219/782] Loss: 0.3651 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [220/782] Loss: 0.5304 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [221/782] Loss: 0.4539 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [222/782] Loss: 0.6342 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [223/782] Loss: 0.2963 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [224/782] Loss: 0.4922 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [225/782] Loss: 0.5131 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [226/782] Loss: 0.3268 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [227/782] Loss: 0.4629 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [228/782] Loss: 0.4794 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [229/782] Loss: 0.3674 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [230/782] Loss: 0.6557 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [231/782] Loss: 0.5038 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [232/782] Loss: 0.6681 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [233/782] Loss: 0.5429 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [234/782] Loss: 0.5135 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [235/782] Loss: 0.5640 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [236/782] Loss: 0.5877 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [237/782] Loss: 0.5027 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [238/782] Loss: 0.4642 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [239/782] Loss: 0.4077 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [240/782] Loss: 0.6532 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [241/782] Loss: 0.3842 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [242/782] Loss: 0.4843 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [243/782] Loss: 0.5640 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [244/782] Loss: 0.3519 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [245/782] Loss: 0.4538 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [246/782] Loss: 0.6217 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [247/782] Loss: 0.5004 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [248/782] Loss: 0.3241 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [249/782] Loss: 0.3949 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [250/782] Loss: 0.6465 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [251/782] Loss: 0.6054 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [252/782] Loss: 0.6021 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [253/782] Loss: 0.6016 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [254/782] Loss: 0.4352 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [255/782] Loss: 0.5317 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [256/782] Loss: 0.5943 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [257/782] Loss: 0.4508 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [258/782] Loss: 0.6276 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [259/782] Loss: 0.3361 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [260/782] Loss: 0.5319 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [261/782] Loss: 0.5136 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [262/782] Loss: 0.5279 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [263/782] Loss: 0.3938 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [264/782] Loss: 0.5755 | Acc: 82.45%\n",
      "Train Epoch [74/100] Batch [265/782] Loss: 0.5227 | Acc: 82.44%\n",
      "Train Epoch [74/100] Batch [266/782] Loss: 0.6872 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [267/782] Loss: 0.2645 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [268/782] Loss: 0.3106 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [269/782] Loss: 0.5268 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [270/782] Loss: 0.7011 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [271/782] Loss: 0.4854 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [272/782] Loss: 0.4743 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [273/782] Loss: 0.4817 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [274/782] Loss: 0.3728 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [275/782] Loss: 0.5335 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [276/782] Loss: 0.4126 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [277/782] Loss: 0.5203 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [278/782] Loss: 0.7074 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [279/782] Loss: 0.3392 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [280/782] Loss: 0.6526 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [281/782] Loss: 0.2006 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [282/782] Loss: 0.2921 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [283/782] Loss: 0.5902 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [284/782] Loss: 0.5448 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [285/782] Loss: 0.4966 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [286/782] Loss: 0.3329 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [287/782] Loss: 0.4561 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [288/782] Loss: 0.4679 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [289/782] Loss: 0.5632 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [290/782] Loss: 0.5639 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [291/782] Loss: 0.5520 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [292/782] Loss: 0.6066 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [293/782] Loss: 0.5923 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [294/782] Loss: 0.4323 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [295/782] Loss: 0.5849 | Acc: 82.39%\n",
      "Train Epoch [74/100] Batch [296/782] Loss: 0.5036 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [297/782] Loss: 0.3944 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [298/782] Loss: 0.5237 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [299/782] Loss: 0.4120 | Acc: 82.42%\n",
      "Train Epoch [74/100] Batch [300/782] Loss: 0.4487 | Acc: 82.41%\n",
      "Train Epoch [74/100] Batch [301/782] Loss: 0.6537 | Acc: 82.39%\n",
      "Train Epoch [74/100] Batch [302/782] Loss: 0.4483 | Acc: 82.39%\n",
      "Train Epoch [74/100] Batch [303/782] Loss: 0.5314 | Acc: 82.39%\n",
      "Train Epoch [74/100] Batch [304/782] Loss: 0.4041 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [305/782] Loss: 0.4970 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [306/782] Loss: 0.4399 | Acc: 82.40%\n",
      "Train Epoch [74/100] Batch [307/782] Loss: 0.3033 | Acc: 82.43%\n",
      "Train Epoch [74/100] Batch [308/782] Loss: 0.2647 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [309/782] Loss: 0.3805 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [310/782] Loss: 0.3832 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [311/782] Loss: 0.4384 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [312/782] Loss: 0.3161 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [313/782] Loss: 0.4188 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [314/782] Loss: 0.5887 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [315/782] Loss: 0.5402 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [316/782] Loss: 0.6018 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [317/782] Loss: 0.5846 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [318/782] Loss: 0.4842 | Acc: 82.45%\n",
      "Train Epoch [74/100] Batch [319/782] Loss: 0.4195 | Acc: 82.45%\n",
      "Train Epoch [74/100] Batch [320/782] Loss: 0.4505 | Acc: 82.45%\n",
      "Train Epoch [74/100] Batch [321/782] Loss: 0.3117 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [322/782] Loss: 0.5635 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [323/782] Loss: 0.2438 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [324/782] Loss: 0.4613 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [325/782] Loss: 0.4699 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [326/782] Loss: 0.4445 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [327/782] Loss: 0.4523 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [328/782] Loss: 0.5861 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [329/782] Loss: 0.3905 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [330/782] Loss: 0.4011 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [331/782] Loss: 0.6717 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [332/782] Loss: 0.4175 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [333/782] Loss: 0.3768 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [334/782] Loss: 0.2517 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [335/782] Loss: 0.5022 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [336/782] Loss: 0.3306 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [337/782] Loss: 0.5085 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [338/782] Loss: 0.6403 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [339/782] Loss: 0.3881 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [340/782] Loss: 0.4511 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [341/782] Loss: 0.5357 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [342/782] Loss: 0.5281 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [343/782] Loss: 0.4469 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [344/782] Loss: 0.5012 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [345/782] Loss: 0.4790 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [346/782] Loss: 0.6089 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [347/782] Loss: 0.4112 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [348/782] Loss: 0.4971 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [349/782] Loss: 0.3081 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [350/782] Loss: 0.6644 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [351/782] Loss: 0.3136 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [352/782] Loss: 0.6681 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [353/782] Loss: 0.4737 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [354/782] Loss: 0.3723 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [355/782] Loss: 0.7641 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [356/782] Loss: 0.5340 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [357/782] Loss: 0.4340 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [358/782] Loss: 0.6524 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [359/782] Loss: 0.3967 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [360/782] Loss: 0.4960 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [361/782] Loss: 0.4908 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [362/782] Loss: 0.6844 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [363/782] Loss: 0.5380 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [364/782] Loss: 0.4398 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [365/782] Loss: 0.4849 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [366/782] Loss: 0.5549 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [367/782] Loss: 0.4730 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [368/782] Loss: 0.3744 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [369/782] Loss: 0.5903 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [370/782] Loss: 0.4080 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [371/782] Loss: 0.4978 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [372/782] Loss: 0.4260 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [373/782] Loss: 0.5926 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [374/782] Loss: 0.4905 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [375/782] Loss: 0.7314 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [376/782] Loss: 0.5059 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [377/782] Loss: 0.4758 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [378/782] Loss: 0.4837 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [379/782] Loss: 0.4219 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [380/782] Loss: 0.4185 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [381/782] Loss: 0.4687 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [382/782] Loss: 0.4623 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [383/782] Loss: 0.3915 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [384/782] Loss: 0.4750 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [385/782] Loss: 0.4428 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [386/782] Loss: 0.6611 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [387/782] Loss: 0.5591 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [388/782] Loss: 0.5054 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [389/782] Loss: 0.4106 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [390/782] Loss: 0.3752 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [391/782] Loss: 0.6341 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [392/782] Loss: 0.4308 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [393/782] Loss: 0.5194 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [394/782] Loss: 0.5328 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [395/782] Loss: 0.4146 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [396/782] Loss: 0.3101 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [397/782] Loss: 0.4882 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [398/782] Loss: 0.5964 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [399/782] Loss: 0.4524 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [400/782] Loss: 0.5709 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [401/782] Loss: 0.6321 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [402/782] Loss: 0.4190 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [403/782] Loss: 0.4871 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [404/782] Loss: 0.4431 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [405/782] Loss: 0.3782 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [406/782] Loss: 0.4409 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [407/782] Loss: 0.5526 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [408/782] Loss: 0.5619 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [409/782] Loss: 0.5058 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [410/782] Loss: 0.5032 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [411/782] Loss: 0.3653 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [412/782] Loss: 0.6018 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [413/782] Loss: 0.6241 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [414/782] Loss: 0.5790 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [415/782] Loss: 0.4368 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [416/782] Loss: 0.4261 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [417/782] Loss: 0.5182 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [418/782] Loss: 0.3174 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [419/782] Loss: 0.4399 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [420/782] Loss: 0.7382 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [421/782] Loss: 0.3796 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [422/782] Loss: 0.4368 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [423/782] Loss: 0.5635 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [424/782] Loss: 0.3359 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [425/782] Loss: 0.3385 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [426/782] Loss: 0.4762 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [427/782] Loss: 0.2547 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [428/782] Loss: 0.3309 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [429/782] Loss: 0.5361 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [430/782] Loss: 0.6352 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [431/782] Loss: 0.3700 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [432/782] Loss: 0.4736 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [433/782] Loss: 0.3961 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [434/782] Loss: 0.6310 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [435/782] Loss: 0.4680 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [436/782] Loss: 0.4594 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [437/782] Loss: 0.3951 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [438/782] Loss: 0.4371 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [439/782] Loss: 0.5069 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [440/782] Loss: 0.4355 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [441/782] Loss: 0.3487 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [442/782] Loss: 0.5431 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [443/782] Loss: 0.5190 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [444/782] Loss: 0.4224 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [445/782] Loss: 0.5678 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [446/782] Loss: 0.3629 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [447/782] Loss: 0.4978 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [448/782] Loss: 0.4005 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [449/782] Loss: 0.4214 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [450/782] Loss: 0.4689 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [451/782] Loss: 0.4463 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [452/782] Loss: 0.4380 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [453/782] Loss: 0.4661 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [454/782] Loss: 0.5727 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [455/782] Loss: 0.4016 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [456/782] Loss: 0.3170 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [457/782] Loss: 0.4069 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [458/782] Loss: 0.4666 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [459/782] Loss: 0.4497 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [460/782] Loss: 0.4260 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [461/782] Loss: 0.3479 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [462/782] Loss: 0.6969 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [463/782] Loss: 0.6599 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [464/782] Loss: 0.4023 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [465/782] Loss: 0.4745 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [466/782] Loss: 0.3943 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [467/782] Loss: 0.5081 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [468/782] Loss: 0.5597 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [469/782] Loss: 0.6976 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [470/782] Loss: 0.3088 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [471/782] Loss: 0.6218 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [472/782] Loss: 0.4441 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [473/782] Loss: 0.4237 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [474/782] Loss: 0.5317 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [475/782] Loss: 0.4471 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [476/782] Loss: 0.5401 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [477/782] Loss: 0.5150 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [478/782] Loss: 0.4434 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [479/782] Loss: 0.4490 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [480/782] Loss: 0.4214 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [481/782] Loss: 0.4098 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [482/782] Loss: 0.4312 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [483/782] Loss: 0.3249 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [484/782] Loss: 0.6025 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [485/782] Loss: 0.5657 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [486/782] Loss: 0.7635 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [487/782] Loss: 0.4573 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [488/782] Loss: 0.4468 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [489/782] Loss: 0.4476 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [490/782] Loss: 0.3631 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [491/782] Loss: 0.4818 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [492/782] Loss: 0.4937 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [493/782] Loss: 0.5547 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [494/782] Loss: 0.4303 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [495/782] Loss: 0.3929 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [496/782] Loss: 0.6290 | Acc: 82.71%\n",
      "Train Epoch [74/100] Batch [497/782] Loss: 0.2414 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [498/782] Loss: 0.3705 | Acc: 82.74%\n",
      "Train Epoch [74/100] Batch [499/782] Loss: 0.4203 | Acc: 82.74%\n",
      "Train Epoch [74/100] Batch [500/782] Loss: 0.4415 | Acc: 82.74%\n",
      "Train Epoch [74/100] Batch [501/782] Loss: 0.6971 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [502/782] Loss: 0.5463 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [503/782] Loss: 0.3551 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [504/782] Loss: 0.6649 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [505/782] Loss: 0.6181 | Acc: 82.73%\n",
      "Train Epoch [74/100] Batch [506/782] Loss: 0.5067 | Acc: 82.72%\n",
      "Train Epoch [74/100] Batch [507/782] Loss: 0.6916 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [508/782] Loss: 0.5383 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [509/782] Loss: 0.4830 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [510/782] Loss: 0.4094 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [511/782] Loss: 0.4295 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [512/782] Loss: 0.4978 | Acc: 82.69%\n",
      "Train Epoch [74/100] Batch [513/782] Loss: 0.7090 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [514/782] Loss: 0.4833 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [515/782] Loss: 0.6509 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [516/782] Loss: 0.3124 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [517/782] Loss: 0.5562 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [518/782] Loss: 0.5795 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [519/782] Loss: 0.6786 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [520/782] Loss: 0.3545 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [521/782] Loss: 0.6290 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [522/782] Loss: 0.3881 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [523/782] Loss: 0.4853 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [524/782] Loss: 0.4558 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [525/782] Loss: 0.5415 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [526/782] Loss: 0.5222 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [527/782] Loss: 0.3617 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [528/782] Loss: 0.6449 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [529/782] Loss: 0.4441 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [530/782] Loss: 0.4500 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [531/782] Loss: 0.5094 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [532/782] Loss: 0.4639 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [533/782] Loss: 0.6584 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [534/782] Loss: 0.5757 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [535/782] Loss: 0.4197 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [536/782] Loss: 0.4393 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [537/782] Loss: 0.6096 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [538/782] Loss: 0.5915 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [539/782] Loss: 0.3203 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [540/782] Loss: 0.5118 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [541/782] Loss: 0.4235 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [542/782] Loss: 0.4326 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [543/782] Loss: 0.6100 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [544/782] Loss: 0.3335 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [545/782] Loss: 0.3036 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [546/782] Loss: 0.3405 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [547/782] Loss: 0.4354 | Acc: 82.70%\n",
      "Train Epoch [74/100] Batch [548/782] Loss: 0.5683 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [549/782] Loss: 0.5300 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [550/782] Loss: 0.3623 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [551/782] Loss: 0.4927 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [552/782] Loss: 0.6020 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [553/782] Loss: 0.5536 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [554/782] Loss: 0.4358 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [555/782] Loss: 0.5311 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [556/782] Loss: 0.5046 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [557/782] Loss: 0.5229 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [558/782] Loss: 0.5892 | Acc: 82.68%\n",
      "Train Epoch [74/100] Batch [559/782] Loss: 0.6193 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [560/782] Loss: 0.5410 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [561/782] Loss: 0.5752 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [562/782] Loss: 0.4870 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [563/782] Loss: 0.5248 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [564/782] Loss: 0.2749 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [565/782] Loss: 0.3533 | Acc: 82.67%\n",
      "Train Epoch [74/100] Batch [566/782] Loss: 0.4690 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [567/782] Loss: 0.5220 | Acc: 82.66%\n",
      "Train Epoch [74/100] Batch [568/782] Loss: 0.7139 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [569/782] Loss: 0.3815 | Acc: 82.65%\n",
      "Train Epoch [74/100] Batch [570/782] Loss: 0.6021 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [571/782] Loss: 0.5603 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [572/782] Loss: 0.6137 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [573/782] Loss: 0.5187 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [574/782] Loss: 0.5105 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [575/782] Loss: 0.5898 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [576/782] Loss: 0.4324 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [577/782] Loss: 0.5706 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [578/782] Loss: 0.4798 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [579/782] Loss: 0.4873 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [580/782] Loss: 0.4713 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [581/782] Loss: 0.3971 | Acc: 82.64%\n",
      "Train Epoch [74/100] Batch [582/782] Loss: 0.5234 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [583/782] Loss: 0.4173 | Acc: 82.63%\n",
      "Train Epoch [74/100] Batch [584/782] Loss: 0.7400 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [585/782] Loss: 0.6534 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [586/782] Loss: 0.4326 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [587/782] Loss: 0.4018 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [588/782] Loss: 0.6836 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [589/782] Loss: 0.4852 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [590/782] Loss: 0.4918 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [591/782] Loss: 0.3880 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [592/782] Loss: 0.3656 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [593/782] Loss: 0.6685 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [594/782] Loss: 0.4047 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [595/782] Loss: 0.5540 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [596/782] Loss: 0.4311 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [597/782] Loss: 0.5882 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [598/782] Loss: 0.4820 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [599/782] Loss: 0.5821 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [600/782] Loss: 0.4914 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [601/782] Loss: 0.4645 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [602/782] Loss: 0.5912 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [603/782] Loss: 0.3963 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [604/782] Loss: 0.6100 | Acc: 82.62%\n",
      "Train Epoch [74/100] Batch [605/782] Loss: 0.5267 | Acc: 82.61%\n",
      "Train Epoch [74/100] Batch [606/782] Loss: 0.7121 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [607/782] Loss: 0.3994 | Acc: 82.60%\n",
      "Train Epoch [74/100] Batch [608/782] Loss: 0.7754 | Acc: 82.58%\n",
      "Train Epoch [74/100] Batch [609/782] Loss: 0.4552 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [610/782] Loss: 0.5031 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [611/782] Loss: 0.6505 | Acc: 82.59%\n",
      "Train Epoch [74/100] Batch [612/782] Loss: 0.6499 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [613/782] Loss: 0.5923 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [614/782] Loss: 0.3640 | Acc: 82.57%\n",
      "Train Epoch [74/100] Batch [615/782] Loss: 0.5178 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [616/782] Loss: 0.4587 | Acc: 82.56%\n",
      "Train Epoch [74/100] Batch [617/782] Loss: 0.5599 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [618/782] Loss: 0.6125 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [619/782] Loss: 0.4265 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [620/782] Loss: 0.5666 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [621/782] Loss: 0.4927 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [622/782] Loss: 0.4317 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [623/782] Loss: 0.3731 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [624/782] Loss: 0.5517 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [625/782] Loss: 0.4417 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [626/782] Loss: 0.6642 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [627/782] Loss: 0.4873 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [628/782] Loss: 0.5498 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [629/782] Loss: 0.5385 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [630/782] Loss: 0.4436 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [631/782] Loss: 0.5166 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [632/782] Loss: 0.4796 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [633/782] Loss: 0.5680 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [634/782] Loss: 0.6140 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [635/782] Loss: 0.6412 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [636/782] Loss: 0.4682 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [637/782] Loss: 0.4597 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [638/782] Loss: 0.3990 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [639/782] Loss: 0.3783 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [640/782] Loss: 0.4546 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [641/782] Loss: 0.4783 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [642/782] Loss: 0.5550 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [643/782] Loss: 0.5016 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [644/782] Loss: 0.5831 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [645/782] Loss: 0.6984 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [646/782] Loss: 0.3930 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [647/782] Loss: 0.6275 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [648/782] Loss: 0.3590 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [649/782] Loss: 0.5363 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [650/782] Loss: 0.3099 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [651/782] Loss: 0.6629 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [652/782] Loss: 0.3587 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [653/782] Loss: 0.4430 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [654/782] Loss: 0.4806 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [655/782] Loss: 0.4954 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [656/782] Loss: 0.2662 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [657/782] Loss: 0.5692 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [658/782] Loss: 0.5486 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [659/782] Loss: 0.4260 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [660/782] Loss: 0.3728 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [661/782] Loss: 0.4088 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [662/782] Loss: 0.2951 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [663/782] Loss: 0.4399 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [664/782] Loss: 0.5476 | Acc: 82.55%\n",
      "Train Epoch [74/100] Batch [665/782] Loss: 0.5628 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [666/782] Loss: 0.4189 | Acc: 82.54%\n",
      "Train Epoch [74/100] Batch [667/782] Loss: 0.7247 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [668/782] Loss: 0.5817 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [669/782] Loss: 0.4009 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [670/782] Loss: 0.6152 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [671/782] Loss: 0.5590 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [672/782] Loss: 0.4985 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [673/782] Loss: 0.5554 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [674/782] Loss: 0.7916 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [675/782] Loss: 0.4732 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [676/782] Loss: 0.6054 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [677/782] Loss: 0.4032 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [678/782] Loss: 0.5335 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [679/782] Loss: 0.4635 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [680/782] Loss: 0.5739 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [681/782] Loss: 0.5453 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [682/782] Loss: 0.5390 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [683/782] Loss: 0.5263 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [684/782] Loss: 0.4362 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [685/782] Loss: 0.5679 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [686/782] Loss: 0.4135 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [687/782] Loss: 0.4774 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [688/782] Loss: 0.3190 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [689/782] Loss: 0.4523 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [690/782] Loss: 0.4593 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [691/782] Loss: 0.3007 | Acc: 82.53%\n",
      "Train Epoch [74/100] Batch [692/782] Loss: 0.6521 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [693/782] Loss: 0.5651 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [694/782] Loss: 0.5307 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [695/782] Loss: 0.4940 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [696/782] Loss: 0.4864 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [697/782] Loss: 0.4780 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [698/782] Loss: 0.4403 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [699/782] Loss: 0.8505 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [700/782] Loss: 0.6181 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [701/782] Loss: 0.4256 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [702/782] Loss: 0.4459 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [703/782] Loss: 0.4002 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [704/782] Loss: 0.3377 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [705/782] Loss: 0.4928 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [706/782] Loss: 0.4510 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [707/782] Loss: 0.4716 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [708/782] Loss: 0.5520 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [709/782] Loss: 0.7476 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [710/782] Loss: 0.5667 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [711/782] Loss: 0.3445 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [712/782] Loss: 0.3892 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [713/782] Loss: 0.5610 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [714/782] Loss: 0.4964 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [715/782] Loss: 0.6585 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [716/782] Loss: 0.4871 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [717/782] Loss: 0.4821 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [718/782] Loss: 0.2130 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [719/782] Loss: 0.4728 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [720/782] Loss: 0.5448 | Acc: 82.52%\n",
      "Train Epoch [74/100] Batch [721/782] Loss: 0.6497 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [722/782] Loss: 0.4037 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [723/782] Loss: 0.5254 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [724/782] Loss: 0.6947 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [725/782] Loss: 0.4850 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [726/782] Loss: 0.6625 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [727/782] Loss: 0.3945 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [728/782] Loss: 0.4039 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [729/782] Loss: 0.5814 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [730/782] Loss: 0.6975 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [731/782] Loss: 0.2406 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [732/782] Loss: 0.3301 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [733/782] Loss: 0.4758 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [734/782] Loss: 0.6204 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [735/782] Loss: 0.4298 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [736/782] Loss: 0.6526 | Acc: 82.51%\n",
      "Train Epoch [74/100] Batch [737/782] Loss: 0.6260 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [738/782] Loss: 0.5013 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [739/782] Loss: 0.5401 | Acc: 82.50%\n",
      "Train Epoch [74/100] Batch [740/782] Loss: 0.5897 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [741/782] Loss: 0.3227 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [742/782] Loss: 0.5649 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [743/782] Loss: 0.6600 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [744/782] Loss: 0.3589 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [745/782] Loss: 0.4839 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [746/782] Loss: 0.8212 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [747/782] Loss: 0.5610 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [748/782] Loss: 0.4808 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [749/782] Loss: 0.4612 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [750/782] Loss: 0.3749 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [751/782] Loss: 0.4167 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [752/782] Loss: 0.4909 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [753/782] Loss: 0.5023 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [754/782] Loss: 0.5000 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [755/782] Loss: 0.5906 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [756/782] Loss: 0.5299 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [757/782] Loss: 0.2861 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [758/782] Loss: 0.5462 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [759/782] Loss: 0.4941 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [760/782] Loss: 0.3888 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [761/782] Loss: 0.6032 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [762/782] Loss: 0.6041 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [763/782] Loss: 0.4945 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [764/782] Loss: 0.4587 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [765/782] Loss: 0.5386 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [766/782] Loss: 0.3399 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [767/782] Loss: 0.4606 | Acc: 82.46%\n",
      "Train Epoch [74/100] Batch [768/782] Loss: 0.3300 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [769/782] Loss: 0.4794 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [770/782] Loss: 0.4095 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [771/782] Loss: 0.4083 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [772/782] Loss: 0.6695 | Acc: 82.49%\n",
      "Train Epoch [74/100] Batch [773/782] Loss: 0.6656 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [774/782] Loss: 0.5559 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [775/782] Loss: 0.3549 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [776/782] Loss: 0.4913 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [777/782] Loss: 0.5531 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [778/782] Loss: 0.5562 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [779/782] Loss: 0.4251 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [780/782] Loss: 0.5100 | Acc: 82.48%\n",
      "Train Epoch [74/100] Batch [781/782] Loss: 0.4837 | Acc: 82.47%\n",
      "Train Epoch [74/100] Batch [782/782] Loss: 0.6800 | Acc: 82.47%\n",
      "Epoch 74 completed in 30.81s.\n",
      "Test Epoch [74/100] Loss: 0.9435 | Acc: 72.40% | Inference Time: 8.70s\n",
      "Epoch 74 results saved to CSV.\n",
      "Epoch 75/100\n",
      "Train Epoch [75/100] Batch [1/782] Loss: 0.3795 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [2/782] Loss: 0.4379 | Acc: 85.16%\n",
      "Train Epoch [75/100] Batch [3/782] Loss: 0.4427 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [4/782] Loss: 0.5341 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [5/782] Loss: 0.5278 | Acc: 82.50%\n",
      "Train Epoch [75/100] Batch [6/782] Loss: 0.3625 | Acc: 83.33%\n",
      "Train Epoch [75/100] Batch [7/782] Loss: 0.3573 | Acc: 83.93%\n",
      "Train Epoch [75/100] Batch [8/782] Loss: 0.6236 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [9/782] Loss: 0.5051 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [10/782] Loss: 0.4800 | Acc: 82.97%\n",
      "Train Epoch [75/100] Batch [11/782] Loss: 0.2916 | Acc: 83.38%\n",
      "Train Epoch [75/100] Batch [12/782] Loss: 0.4376 | Acc: 83.46%\n",
      "Train Epoch [75/100] Batch [13/782] Loss: 0.4559 | Acc: 83.41%\n",
      "Train Epoch [75/100] Batch [14/782] Loss: 0.4952 | Acc: 83.37%\n",
      "Train Epoch [75/100] Batch [15/782] Loss: 0.4895 | Acc: 83.33%\n",
      "Train Epoch [75/100] Batch [16/782] Loss: 0.3769 | Acc: 83.30%\n",
      "Train Epoch [75/100] Batch [17/782] Loss: 0.5023 | Acc: 83.27%\n",
      "Train Epoch [75/100] Batch [18/782] Loss: 0.4040 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [19/782] Loss: 0.4582 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [20/782] Loss: 0.4884 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [21/782] Loss: 0.5505 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [22/782] Loss: 0.3686 | Acc: 82.88%\n",
      "Train Epoch [75/100] Batch [23/782] Loss: 0.3711 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [24/782] Loss: 0.4623 | Acc: 83.40%\n",
      "Train Epoch [75/100] Batch [25/782] Loss: 0.3795 | Acc: 83.50%\n",
      "Train Epoch [75/100] Batch [26/782] Loss: 0.3725 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [27/782] Loss: 0.4330 | Acc: 83.68%\n",
      "Train Epoch [75/100] Batch [28/782] Loss: 0.4525 | Acc: 83.48%\n",
      "Train Epoch [75/100] Batch [29/782] Loss: 0.5759 | Acc: 83.30%\n",
      "Train Epoch [75/100] Batch [30/782] Loss: 0.4665 | Acc: 83.28%\n",
      "Train Epoch [75/100] Batch [31/782] Loss: 0.4634 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [32/782] Loss: 0.5141 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [33/782] Loss: 0.6656 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [34/782] Loss: 0.5055 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [35/782] Loss: 0.3306 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [36/782] Loss: 0.3158 | Acc: 83.51%\n",
      "Train Epoch [75/100] Batch [37/782] Loss: 0.4482 | Acc: 83.57%\n",
      "Train Epoch [75/100] Batch [38/782] Loss: 0.4954 | Acc: 83.51%\n",
      "Train Epoch [75/100] Batch [39/782] Loss: 0.3008 | Acc: 83.65%\n",
      "Train Epoch [75/100] Batch [40/782] Loss: 0.3758 | Acc: 83.83%\n",
      "Train Epoch [75/100] Batch [41/782] Loss: 0.4499 | Acc: 83.84%\n",
      "Train Epoch [75/100] Batch [42/782] Loss: 0.5196 | Acc: 83.82%\n",
      "Train Epoch [75/100] Batch [43/782] Loss: 0.4963 | Acc: 83.90%\n",
      "Train Epoch [75/100] Batch [44/782] Loss: 0.3198 | Acc: 84.02%\n",
      "Train Epoch [75/100] Batch [45/782] Loss: 0.4215 | Acc: 84.03%\n",
      "Train Epoch [75/100] Batch [46/782] Loss: 0.3594 | Acc: 84.07%\n",
      "Train Epoch [75/100] Batch [47/782] Loss: 0.3229 | Acc: 84.14%\n",
      "Train Epoch [75/100] Batch [48/782] Loss: 0.3754 | Acc: 84.24%\n",
      "Train Epoch [75/100] Batch [49/782] Loss: 0.4231 | Acc: 84.25%\n",
      "Train Epoch [75/100] Batch [50/782] Loss: 0.3448 | Acc: 84.34%\n",
      "Train Epoch [75/100] Batch [51/782] Loss: 0.4805 | Acc: 84.38%\n",
      "Train Epoch [75/100] Batch [52/782] Loss: 0.4758 | Acc: 84.41%\n",
      "Train Epoch [75/100] Batch [53/782] Loss: 0.5702 | Acc: 84.29%\n",
      "Train Epoch [75/100] Batch [54/782] Loss: 0.4462 | Acc: 84.32%\n",
      "Train Epoch [75/100] Batch [55/782] Loss: 0.5016 | Acc: 84.23%\n",
      "Train Epoch [75/100] Batch [56/782] Loss: 0.6122 | Acc: 84.07%\n",
      "Train Epoch [75/100] Batch [57/782] Loss: 0.4788 | Acc: 84.05%\n",
      "Train Epoch [75/100] Batch [58/782] Loss: 0.5125 | Acc: 84.00%\n",
      "Train Epoch [75/100] Batch [59/782] Loss: 0.4198 | Acc: 84.08%\n",
      "Train Epoch [75/100] Batch [60/782] Loss: 0.4110 | Acc: 84.14%\n",
      "Train Epoch [75/100] Batch [61/782] Loss: 0.8689 | Acc: 83.91%\n",
      "Train Epoch [75/100] Batch [62/782] Loss: 0.4102 | Acc: 83.97%\n",
      "Train Epoch [75/100] Batch [63/782] Loss: 0.5458 | Acc: 83.90%\n",
      "Train Epoch [75/100] Batch [64/782] Loss: 0.2739 | Acc: 83.98%\n",
      "Train Epoch [75/100] Batch [65/782] Loss: 0.4716 | Acc: 83.97%\n",
      "Train Epoch [75/100] Batch [66/782] Loss: 0.3100 | Acc: 84.04%\n",
      "Train Epoch [75/100] Batch [67/782] Loss: 0.6499 | Acc: 83.96%\n",
      "Train Epoch [75/100] Batch [68/782] Loss: 0.4191 | Acc: 83.98%\n",
      "Train Epoch [75/100] Batch [69/782] Loss: 0.4574 | Acc: 83.99%\n",
      "Train Epoch [75/100] Batch [70/782] Loss: 0.4923 | Acc: 83.97%\n",
      "Train Epoch [75/100] Batch [71/782] Loss: 0.4772 | Acc: 84.02%\n",
      "Train Epoch [75/100] Batch [72/782] Loss: 0.4478 | Acc: 84.01%\n",
      "Train Epoch [75/100] Batch [73/782] Loss: 0.3531 | Acc: 84.16%\n",
      "Train Epoch [75/100] Batch [74/782] Loss: 0.4959 | Acc: 84.10%\n",
      "Train Epoch [75/100] Batch [75/782] Loss: 0.3468 | Acc: 84.15%\n",
      "Train Epoch [75/100] Batch [76/782] Loss: 0.6977 | Acc: 84.05%\n",
      "Train Epoch [75/100] Batch [77/782] Loss: 0.4351 | Acc: 84.05%\n",
      "Train Epoch [75/100] Batch [78/782] Loss: 0.5688 | Acc: 83.97%\n",
      "Train Epoch [75/100] Batch [79/782] Loss: 0.5658 | Acc: 83.84%\n",
      "Train Epoch [75/100] Batch [80/782] Loss: 0.4468 | Acc: 83.85%\n",
      "Train Epoch [75/100] Batch [81/782] Loss: 0.4170 | Acc: 83.83%\n",
      "Train Epoch [75/100] Batch [82/782] Loss: 0.6323 | Acc: 83.69%\n",
      "Train Epoch [75/100] Batch [83/782] Loss: 0.5534 | Acc: 83.62%\n",
      "Train Epoch [75/100] Batch [84/782] Loss: 0.5562 | Acc: 83.58%\n",
      "Train Epoch [75/100] Batch [85/782] Loss: 0.3812 | Acc: 83.58%\n",
      "Train Epoch [75/100] Batch [86/782] Loss: 0.3662 | Acc: 83.63%\n",
      "Train Epoch [75/100] Batch [87/782] Loss: 0.5131 | Acc: 83.60%\n",
      "Train Epoch [75/100] Batch [88/782] Loss: 0.4596 | Acc: 83.65%\n",
      "Train Epoch [75/100] Batch [89/782] Loss: 0.4737 | Acc: 83.66%\n",
      "Train Epoch [75/100] Batch [90/782] Loss: 0.3539 | Acc: 83.66%\n",
      "Train Epoch [75/100] Batch [91/782] Loss: 0.5514 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [92/782] Loss: 0.3504 | Acc: 83.64%\n",
      "Train Epoch [75/100] Batch [93/782] Loss: 0.5005 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [94/782] Loss: 0.4098 | Acc: 83.63%\n",
      "Train Epoch [75/100] Batch [95/782] Loss: 0.6089 | Acc: 83.60%\n",
      "Train Epoch [75/100] Batch [96/782] Loss: 0.6333 | Acc: 83.56%\n",
      "Train Epoch [75/100] Batch [97/782] Loss: 0.3472 | Acc: 83.62%\n",
      "Train Epoch [75/100] Batch [98/782] Loss: 0.4458 | Acc: 83.61%\n",
      "Train Epoch [75/100] Batch [99/782] Loss: 0.4356 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [100/782] Loss: 0.4367 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [101/782] Loss: 0.5934 | Acc: 83.52%\n",
      "Train Epoch [75/100] Batch [102/782] Loss: 0.4523 | Acc: 83.53%\n",
      "Train Epoch [75/100] Batch [103/782] Loss: 0.5609 | Acc: 83.51%\n",
      "Train Epoch [75/100] Batch [104/782] Loss: 0.2990 | Acc: 83.58%\n",
      "Train Epoch [75/100] Batch [105/782] Loss: 0.4663 | Acc: 83.57%\n",
      "Train Epoch [75/100] Batch [106/782] Loss: 0.5740 | Acc: 83.52%\n",
      "Train Epoch [75/100] Batch [107/782] Loss: 0.4055 | Acc: 83.53%\n",
      "Train Epoch [75/100] Batch [108/782] Loss: 0.4995 | Acc: 83.52%\n",
      "Train Epoch [75/100] Batch [109/782] Loss: 0.2817 | Acc: 83.60%\n",
      "Train Epoch [75/100] Batch [110/782] Loss: 0.5211 | Acc: 83.59%\n",
      "Train Epoch [75/100] Batch [111/782] Loss: 0.3807 | Acc: 83.64%\n",
      "Train Epoch [75/100] Batch [112/782] Loss: 0.5566 | Acc: 83.64%\n",
      "Train Epoch [75/100] Batch [113/782] Loss: 0.5496 | Acc: 83.60%\n",
      "Train Epoch [75/100] Batch [114/782] Loss: 0.4878 | Acc: 83.61%\n",
      "Train Epoch [75/100] Batch [115/782] Loss: 0.2719 | Acc: 83.67%\n",
      "Train Epoch [75/100] Batch [116/782] Loss: 0.3616 | Acc: 83.74%\n",
      "Train Epoch [75/100] Batch [117/782] Loss: 0.3308 | Acc: 83.77%\n",
      "Train Epoch [75/100] Batch [118/782] Loss: 0.5372 | Acc: 83.77%\n",
      "Train Epoch [75/100] Batch [119/782] Loss: 0.4571 | Acc: 83.76%\n",
      "Train Epoch [75/100] Batch [120/782] Loss: 0.5884 | Acc: 83.74%\n",
      "Train Epoch [75/100] Batch [121/782] Loss: 0.5478 | Acc: 83.72%\n",
      "Train Epoch [75/100] Batch [122/782] Loss: 0.5427 | Acc: 83.66%\n",
      "Train Epoch [75/100] Batch [123/782] Loss: 0.4866 | Acc: 83.68%\n",
      "Train Epoch [75/100] Batch [124/782] Loss: 0.2858 | Acc: 83.73%\n",
      "Train Epoch [75/100] Batch [125/782] Loss: 0.4508 | Acc: 83.75%\n",
      "Train Epoch [75/100] Batch [126/782] Loss: 0.2898 | Acc: 83.80%\n",
      "Train Epoch [75/100] Batch [127/782] Loss: 0.5110 | Acc: 83.78%\n",
      "Train Epoch [75/100] Batch [128/782] Loss: 0.5280 | Acc: 83.79%\n",
      "Train Epoch [75/100] Batch [129/782] Loss: 0.6091 | Acc: 83.70%\n",
      "Train Epoch [75/100] Batch [130/782] Loss: 0.4179 | Acc: 83.71%\n",
      "Train Epoch [75/100] Batch [131/782] Loss: 0.7992 | Acc: 83.66%\n",
      "Train Epoch [75/100] Batch [132/782] Loss: 0.4293 | Acc: 83.66%\n",
      "Train Epoch [75/100] Batch [133/782] Loss: 0.5252 | Acc: 83.61%\n",
      "Train Epoch [75/100] Batch [134/782] Loss: 0.4978 | Acc: 83.63%\n",
      "Train Epoch [75/100] Batch [135/782] Loss: 0.6091 | Acc: 83.56%\n",
      "Train Epoch [75/100] Batch [136/782] Loss: 0.5150 | Acc: 83.55%\n",
      "Train Epoch [75/100] Batch [137/782] Loss: 0.4785 | Acc: 83.54%\n",
      "Train Epoch [75/100] Batch [138/782] Loss: 0.6409 | Acc: 83.47%\n",
      "Train Epoch [75/100] Batch [139/782] Loss: 0.6154 | Acc: 83.43%\n",
      "Train Epoch [75/100] Batch [140/782] Loss: 0.6201 | Acc: 83.36%\n",
      "Train Epoch [75/100] Batch [141/782] Loss: 0.5980 | Acc: 83.33%\n",
      "Train Epoch [75/100] Batch [142/782] Loss: 0.2899 | Acc: 83.36%\n",
      "Train Epoch [75/100] Batch [143/782] Loss: 0.4572 | Acc: 83.38%\n",
      "Train Epoch [75/100] Batch [144/782] Loss: 0.4001 | Acc: 83.40%\n",
      "Train Epoch [75/100] Batch [145/782] Loss: 0.6424 | Acc: 83.29%\n",
      "Train Epoch [75/100] Batch [146/782] Loss: 0.4489 | Acc: 83.29%\n",
      "Train Epoch [75/100] Batch [147/782] Loss: 0.4016 | Acc: 83.33%\n",
      "Train Epoch [75/100] Batch [148/782] Loss: 0.3624 | Acc: 83.35%\n",
      "Train Epoch [75/100] Batch [149/782] Loss: 0.5176 | Acc: 83.27%\n",
      "Train Epoch [75/100] Batch [150/782] Loss: 0.5099 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [151/782] Loss: 0.4608 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [152/782] Loss: 0.5672 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [153/782] Loss: 0.5014 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [154/782] Loss: 0.3647 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [155/782] Loss: 0.5519 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [156/782] Loss: 0.5091 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [157/782] Loss: 0.6871 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [158/782] Loss: 0.4729 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [159/782] Loss: 0.5663 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [160/782] Loss: 0.3253 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [161/782] Loss: 0.4186 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [162/782] Loss: 0.5333 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [163/782] Loss: 0.3958 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [164/782] Loss: 0.4633 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [165/782] Loss: 0.6329 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [166/782] Loss: 0.6185 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [167/782] Loss: 0.6429 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [168/782] Loss: 0.3804 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [169/782] Loss: 0.6183 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [170/782] Loss: 0.4329 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [171/782] Loss: 0.3406 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [172/782] Loss: 0.3204 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [173/782] Loss: 0.3695 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [174/782] Loss: 0.6051 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [175/782] Loss: 0.3789 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [176/782] Loss: 0.4686 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [177/782] Loss: 0.3613 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [178/782] Loss: 0.4388 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [179/782] Loss: 0.5722 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [180/782] Loss: 0.2863 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [181/782] Loss: 0.4646 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [182/782] Loss: 0.3554 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [183/782] Loss: 0.5889 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [184/782] Loss: 0.4382 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [185/782] Loss: 0.4205 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [186/782] Loss: 0.3537 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [187/782] Loss: 0.4319 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [188/782] Loss: 0.5904 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [189/782] Loss: 0.4893 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [190/782] Loss: 0.7659 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [191/782] Loss: 0.6252 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [192/782] Loss: 0.4477 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [193/782] Loss: 0.5593 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [194/782] Loss: 0.6602 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [195/782] Loss: 0.4382 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [196/782] Loss: 0.5660 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [197/782] Loss: 0.7059 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [198/782] Loss: 0.3035 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [199/782] Loss: 0.5155 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [200/782] Loss: 0.4153 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [201/782] Loss: 0.4730 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [202/782] Loss: 0.4249 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [203/782] Loss: 0.3585 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [204/782] Loss: 0.6208 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [205/782] Loss: 0.4343 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [206/782] Loss: 0.4826 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [207/782] Loss: 0.7056 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [208/782] Loss: 0.4630 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [209/782] Loss: 0.5525 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [210/782] Loss: 0.5053 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [211/782] Loss: 0.3754 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [212/782] Loss: 0.5810 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [213/782] Loss: 0.4676 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [214/782] Loss: 0.7155 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [215/782] Loss: 0.5180 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [216/782] Loss: 0.4474 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [217/782] Loss: 0.4841 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [218/782] Loss: 0.6556 | Acc: 82.99%\n",
      "Train Epoch [75/100] Batch [219/782] Loss: 0.3902 | Acc: 82.99%\n",
      "Train Epoch [75/100] Batch [220/782] Loss: 0.5472 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [221/782] Loss: 0.5088 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [222/782] Loss: 0.6992 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [223/782] Loss: 0.5377 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [224/782] Loss: 0.5493 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [225/782] Loss: 0.3535 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [226/782] Loss: 0.4061 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [227/782] Loss: 0.5905 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [228/782] Loss: 0.3729 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [229/782] Loss: 0.5354 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [230/782] Loss: 0.6003 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [231/782] Loss: 0.3483 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [232/782] Loss: 0.3454 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [233/782] Loss: 0.4616 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [234/782] Loss: 0.5465 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [235/782] Loss: 0.3707 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [236/782] Loss: 0.3567 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [237/782] Loss: 0.4567 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [238/782] Loss: 0.4513 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [239/782] Loss: 0.4955 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [240/782] Loss: 0.5301 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [241/782] Loss: 0.4709 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [242/782] Loss: 0.4180 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [243/782] Loss: 0.5907 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [244/782] Loss: 0.4552 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [245/782] Loss: 0.5615 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [246/782] Loss: 0.4592 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [247/782] Loss: 0.4225 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [248/782] Loss: 0.4159 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [249/782] Loss: 0.3919 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [250/782] Loss: 0.4780 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [251/782] Loss: 0.3742 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [252/782] Loss: 0.5160 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [253/782] Loss: 0.4593 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [254/782] Loss: 0.5452 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [255/782] Loss: 0.6609 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [256/782] Loss: 0.4838 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [257/782] Loss: 0.3449 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [258/782] Loss: 0.5098 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [259/782] Loss: 0.6140 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [260/782] Loss: 0.1734 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [261/782] Loss: 0.6334 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [262/782] Loss: 0.5482 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [263/782] Loss: 0.5918 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [264/782] Loss: 0.5609 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [265/782] Loss: 0.5792 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [266/782] Loss: 0.3308 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [267/782] Loss: 0.5235 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [268/782] Loss: 0.5693 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [269/782] Loss: 0.4534 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [270/782] Loss: 0.4950 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [271/782] Loss: 0.3373 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [272/782] Loss: 0.4487 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [273/782] Loss: 0.4785 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [274/782] Loss: 0.5551 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [275/782] Loss: 0.3926 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [276/782] Loss: 0.4962 | Acc: 83.04%\n",
      "Train Epoch [75/100] Batch [277/782] Loss: 0.3006 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [278/782] Loss: 0.4499 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [279/782] Loss: 0.5779 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [280/782] Loss: 0.4745 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [281/782] Loss: 0.5010 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [282/782] Loss: 0.4863 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [283/782] Loss: 0.4701 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [284/782] Loss: 0.3657 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [285/782] Loss: 0.4066 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [286/782] Loss: 0.4769 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [287/782] Loss: 0.4306 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [288/782] Loss: 0.3333 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [289/782] Loss: 0.4287 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [290/782] Loss: 0.3881 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [291/782] Loss: 0.4965 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [292/782] Loss: 0.5627 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [293/782] Loss: 0.4149 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [294/782] Loss: 0.5032 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [295/782] Loss: 0.5145 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [296/782] Loss: 0.5107 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [297/782] Loss: 0.3447 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [298/782] Loss: 0.6356 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [299/782] Loss: 0.3906 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [300/782] Loss: 0.4849 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [301/782] Loss: 0.3603 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [302/782] Loss: 0.6406 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [303/782] Loss: 0.3232 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [304/782] Loss: 0.5117 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [305/782] Loss: 0.5458 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [306/782] Loss: 0.4879 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [307/782] Loss: 0.5986 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [308/782] Loss: 0.4255 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [309/782] Loss: 0.4612 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [310/782] Loss: 0.3983 | Acc: 83.12%\n",
      "Train Epoch [75/100] Batch [311/782] Loss: 0.4007 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [312/782] Loss: 0.3444 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [313/782] Loss: 0.4653 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [314/782] Loss: 0.3582 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [315/782] Loss: 0.2940 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [316/782] Loss: 0.5962 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [317/782] Loss: 0.3901 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [318/782] Loss: 0.3867 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [319/782] Loss: 0.5691 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [320/782] Loss: 0.5381 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [321/782] Loss: 0.3517 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [322/782] Loss: 0.3748 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [323/782] Loss: 0.4499 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [324/782] Loss: 0.3788 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [325/782] Loss: 0.4422 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [326/782] Loss: 0.3161 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [327/782] Loss: 0.3869 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [328/782] Loss: 0.4014 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [329/782] Loss: 0.4292 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [330/782] Loss: 0.5721 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [331/782] Loss: 0.3712 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [332/782] Loss: 0.6396 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [333/782] Loss: 0.5533 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [334/782] Loss: 0.4229 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [335/782] Loss: 0.3819 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [336/782] Loss: 0.4397 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [337/782] Loss: 0.3555 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [338/782] Loss: 0.6465 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [339/782] Loss: 0.3986 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [340/782] Loss: 0.3644 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [341/782] Loss: 0.4381 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [342/782] Loss: 0.5354 | Acc: 83.22%\n",
      "Train Epoch [75/100] Batch [343/782] Loss: 0.2851 | Acc: 83.25%\n",
      "Train Epoch [75/100] Batch [344/782] Loss: 0.5481 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [345/782] Loss: 0.4134 | Acc: 83.23%\n",
      "Train Epoch [75/100] Batch [346/782] Loss: 0.3630 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [347/782] Loss: 0.4160 | Acc: 83.25%\n",
      "Train Epoch [75/100] Batch [348/782] Loss: 0.6347 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [349/782] Loss: 0.4752 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [350/782] Loss: 0.4959 | Acc: 83.24%\n",
      "Train Epoch [75/100] Batch [351/782] Loss: 0.5792 | Acc: 83.23%\n",
      "Train Epoch [75/100] Batch [352/782] Loss: 0.6794 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [353/782] Loss: 0.4616 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [354/782] Loss: 0.5685 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [355/782] Loss: 0.5560 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [356/782] Loss: 0.4221 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [357/782] Loss: 0.5165 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [358/782] Loss: 0.5514 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [359/782] Loss: 0.5341 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [360/782] Loss: 0.4688 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [361/782] Loss: 0.3693 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [362/782] Loss: 0.4482 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [363/782] Loss: 0.5433 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [364/782] Loss: 0.4346 | Acc: 83.17%\n",
      "Train Epoch [75/100] Batch [365/782] Loss: 0.3973 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [366/782] Loss: 0.4585 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [367/782] Loss: 0.3993 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [368/782] Loss: 0.5754 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [369/782] Loss: 0.3089 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [370/782] Loss: 0.6556 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [371/782] Loss: 0.5092 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [372/782] Loss: 0.2369 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [373/782] Loss: 0.5066 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [374/782] Loss: 0.5169 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [375/782] Loss: 0.3770 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [376/782] Loss: 0.3119 | Acc: 83.21%\n",
      "Train Epoch [75/100] Batch [377/782] Loss: 0.5539 | Acc: 83.20%\n",
      "Train Epoch [75/100] Batch [378/782] Loss: 0.5707 | Acc: 83.19%\n",
      "Train Epoch [75/100] Batch [379/782] Loss: 0.6062 | Acc: 83.18%\n",
      "Train Epoch [75/100] Batch [380/782] Loss: 0.5937 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [381/782] Loss: 0.5158 | Acc: 83.15%\n",
      "Train Epoch [75/100] Batch [382/782] Loss: 0.4593 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [383/782] Loss: 0.5741 | Acc: 83.13%\n",
      "Train Epoch [75/100] Batch [384/782] Loss: 0.4029 | Acc: 83.14%\n",
      "Train Epoch [75/100] Batch [385/782] Loss: 0.3433 | Acc: 83.16%\n",
      "Train Epoch [75/100] Batch [386/782] Loss: 0.7221 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [387/782] Loss: 0.5921 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [388/782] Loss: 0.4605 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [389/782] Loss: 0.7265 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [390/782] Loss: 0.6450 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [391/782] Loss: 0.4421 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [392/782] Loss: 0.4620 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [393/782] Loss: 0.4342 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [394/782] Loss: 0.2733 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [395/782] Loss: 0.2477 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [396/782] Loss: 0.5669 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [397/782] Loss: 0.5481 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [398/782] Loss: 0.5354 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [399/782] Loss: 0.3403 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [400/782] Loss: 0.5973 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [401/782] Loss: 0.5115 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [402/782] Loss: 0.5881 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [403/782] Loss: 0.4484 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [404/782] Loss: 0.3252 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [405/782] Loss: 0.5524 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [406/782] Loss: 0.6127 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [407/782] Loss: 0.5188 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [408/782] Loss: 0.4712 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [409/782] Loss: 0.4322 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [410/782] Loss: 0.5222 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [411/782] Loss: 0.3623 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [412/782] Loss: 0.4593 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [413/782] Loss: 0.3480 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [414/782] Loss: 0.4308 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [415/782] Loss: 0.5172 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [416/782] Loss: 0.5021 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [417/782] Loss: 0.4827 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [418/782] Loss: 0.6234 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [419/782] Loss: 0.3094 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [420/782] Loss: 0.3741 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [421/782] Loss: 0.5047 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [422/782] Loss: 0.4727 | Acc: 83.10%\n",
      "Train Epoch [75/100] Batch [423/782] Loss: 0.5382 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [424/782] Loss: 0.3936 | Acc: 83.11%\n",
      "Train Epoch [75/100] Batch [425/782] Loss: 0.7012 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [426/782] Loss: 0.5143 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [427/782] Loss: 0.4387 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [428/782] Loss: 0.5765 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [429/782] Loss: 0.4233 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [430/782] Loss: 0.4320 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [431/782] Loss: 0.4108 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [432/782] Loss: 0.3647 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [433/782] Loss: 0.5884 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [434/782] Loss: 0.4321 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [435/782] Loss: 0.3260 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [436/782] Loss: 0.4392 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [437/782] Loss: 0.5756 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [438/782] Loss: 0.4831 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [439/782] Loss: 0.3377 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [440/782] Loss: 0.4082 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [441/782] Loss: 0.5320 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [442/782] Loss: 0.4604 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [443/782] Loss: 0.4320 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [444/782] Loss: 0.6501 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [445/782] Loss: 0.4277 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [446/782] Loss: 0.5584 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [447/782] Loss: 0.5258 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [448/782] Loss: 0.5640 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [449/782] Loss: 0.5213 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [450/782] Loss: 0.5009 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [451/782] Loss: 0.5295 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [452/782] Loss: 0.3468 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [453/782] Loss: 0.3259 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [454/782] Loss: 0.5357 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [455/782] Loss: 0.3581 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [456/782] Loss: 0.4243 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [457/782] Loss: 0.5416 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [458/782] Loss: 0.5800 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [459/782] Loss: 0.5013 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [460/782] Loss: 0.5560 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [461/782] Loss: 0.3807 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [462/782] Loss: 0.4075 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [463/782] Loss: 0.5986 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [464/782] Loss: 0.4467 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [465/782] Loss: 0.6203 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [466/782] Loss: 0.4003 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [467/782] Loss: 0.4939 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [468/782] Loss: 0.4594 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [469/782] Loss: 0.6854 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [470/782] Loss: 0.6512 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [471/782] Loss: 0.5631 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [472/782] Loss: 0.4055 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [473/782] Loss: 0.3189 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [474/782] Loss: 0.5110 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [475/782] Loss: 0.5928 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [476/782] Loss: 0.3780 | Acc: 83.07%\n",
      "Train Epoch [75/100] Batch [477/782] Loss: 0.3182 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [478/782] Loss: 0.3888 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [479/782] Loss: 0.3790 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [480/782] Loss: 0.4319 | Acc: 83.09%\n",
      "Train Epoch [75/100] Batch [481/782] Loss: 0.4723 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [482/782] Loss: 0.3633 | Acc: 83.08%\n",
      "Train Epoch [75/100] Batch [483/782] Loss: 0.6687 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [484/782] Loss: 0.5654 | Acc: 83.06%\n",
      "Train Epoch [75/100] Batch [485/782] Loss: 0.6598 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [486/782] Loss: 0.5711 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [487/782] Loss: 0.5564 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [488/782] Loss: 0.5397 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [489/782] Loss: 0.4534 | Acc: 83.05%\n",
      "Train Epoch [75/100] Batch [490/782] Loss: 0.8485 | Acc: 83.03%\n",
      "Train Epoch [75/100] Batch [491/782] Loss: 0.4993 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [492/782] Loss: 0.6497 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [493/782] Loss: 0.3204 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [494/782] Loss: 0.4849 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [495/782] Loss: 0.4050 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [496/782] Loss: 0.6589 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [497/782] Loss: 0.4394 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [498/782] Loss: 0.4622 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [499/782] Loss: 0.5369 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [500/782] Loss: 0.3780 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [501/782] Loss: 0.5423 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [502/782] Loss: 0.5420 | Acc: 83.00%\n",
      "Train Epoch [75/100] Batch [503/782] Loss: 0.4613 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [504/782] Loss: 0.3796 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [505/782] Loss: 0.3663 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [506/782] Loss: 0.5815 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [507/782] Loss: 0.5527 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [508/782] Loss: 0.6696 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [509/782] Loss: 0.3080 | Acc: 83.02%\n",
      "Train Epoch [75/100] Batch [510/782] Loss: 0.6670 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [511/782] Loss: 0.4787 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [512/782] Loss: 0.5134 | Acc: 83.01%\n",
      "Train Epoch [75/100] Batch [513/782] Loss: 0.7084 | Acc: 82.98%\n",
      "Train Epoch [75/100] Batch [514/782] Loss: 0.5650 | Acc: 82.97%\n",
      "Train Epoch [75/100] Batch [515/782] Loss: 0.4990 | Acc: 82.97%\n",
      "Train Epoch [75/100] Batch [516/782] Loss: 0.6376 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [517/782] Loss: 0.6756 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [518/782] Loss: 0.5046 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [519/782] Loss: 0.6660 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [520/782] Loss: 0.4952 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [521/782] Loss: 0.4689 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [522/782] Loss: 0.3207 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [523/782] Loss: 0.4962 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [524/782] Loss: 0.5500 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [525/782] Loss: 0.4224 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [526/782] Loss: 0.3872 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [527/782] Loss: 0.6441 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [528/782] Loss: 0.5479 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [529/782] Loss: 0.5555 | Acc: 82.90%\n",
      "Train Epoch [75/100] Batch [530/782] Loss: 0.5091 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [531/782] Loss: 0.4169 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [532/782] Loss: 0.3940 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [533/782] Loss: 0.4903 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [534/782] Loss: 0.3437 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [535/782] Loss: 0.5297 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [536/782] Loss: 0.5315 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [537/782] Loss: 0.6347 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [538/782] Loss: 0.4018 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [539/782] Loss: 0.4649 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [540/782] Loss: 0.4843 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [541/782] Loss: 0.4957 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [542/782] Loss: 0.5759 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [543/782] Loss: 0.4468 | Acc: 82.90%\n",
      "Train Epoch [75/100] Batch [544/782] Loss: 0.4512 | Acc: 82.90%\n",
      "Train Epoch [75/100] Batch [545/782] Loss: 0.4152 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [546/782] Loss: 0.5236 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [547/782] Loss: 0.5153 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [548/782] Loss: 0.4122 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [549/782] Loss: 0.4479 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [550/782] Loss: 0.4214 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [551/782] Loss: 0.3951 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [552/782] Loss: 0.4368 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [553/782] Loss: 0.3869 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [554/782] Loss: 0.4182 | Acc: 82.95%\n",
      "Train Epoch [75/100] Batch [555/782] Loss: 0.3208 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [556/782] Loss: 0.4380 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [557/782] Loss: 0.4413 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [558/782] Loss: 0.5473 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [559/782] Loss: 0.3770 | Acc: 82.97%\n",
      "Train Epoch [75/100] Batch [560/782] Loss: 0.5884 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [561/782] Loss: 0.4495 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [562/782] Loss: 0.4548 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [563/782] Loss: 0.5763 | Acc: 82.96%\n",
      "Train Epoch [75/100] Batch [564/782] Loss: 0.4092 | Acc: 82.95%\n",
      "Train Epoch [75/100] Batch [565/782] Loss: 0.7174 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [566/782] Loss: 0.3557 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [567/782] Loss: 0.5727 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [568/782] Loss: 0.6893 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [569/782] Loss: 0.3390 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [570/782] Loss: 0.3648 | Acc: 82.94%\n",
      "Train Epoch [75/100] Batch [571/782] Loss: 0.7327 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [572/782] Loss: 0.5325 | Acc: 82.93%\n",
      "Train Epoch [75/100] Batch [573/782] Loss: 0.5777 | Acc: 82.92%\n",
      "Train Epoch [75/100] Batch [574/782] Loss: 0.5243 | Acc: 82.91%\n",
      "Train Epoch [75/100] Batch [575/782] Loss: 0.5258 | Acc: 82.90%\n",
      "Train Epoch [75/100] Batch [576/782] Loss: 0.4937 | Acc: 82.90%\n",
      "Train Epoch [75/100] Batch [577/782] Loss: 0.5885 | Acc: 82.89%\n",
      "Train Epoch [75/100] Batch [578/782] Loss: 0.5953 | Acc: 82.88%\n",
      "Train Epoch [75/100] Batch [579/782] Loss: 0.4082 | Acc: 82.89%\n",
      "Train Epoch [75/100] Batch [580/782] Loss: 0.6124 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [581/782] Loss: 0.4643 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [582/782] Loss: 0.4842 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [583/782] Loss: 0.4616 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [584/782] Loss: 0.4892 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [585/782] Loss: 0.4508 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [586/782] Loss: 0.6508 | Acc: 82.86%\n",
      "Train Epoch [75/100] Batch [587/782] Loss: 0.3933 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [588/782] Loss: 0.3883 | Acc: 82.88%\n",
      "Train Epoch [75/100] Batch [589/782] Loss: 0.4028 | Acc: 82.88%\n",
      "Train Epoch [75/100] Batch [590/782] Loss: 0.7253 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [591/782] Loss: 0.4475 | Acc: 82.87%\n",
      "Train Epoch [75/100] Batch [592/782] Loss: 0.6558 | Acc: 82.86%\n",
      "Train Epoch [75/100] Batch [593/782] Loss: 0.6360 | Acc: 82.85%\n",
      "Train Epoch [75/100] Batch [594/782] Loss: 0.6711 | Acc: 82.84%\n",
      "Train Epoch [75/100] Batch [595/782] Loss: 0.6402 | Acc: 82.83%\n",
      "Train Epoch [75/100] Batch [596/782] Loss: 0.4651 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [597/782] Loss: 0.5092 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [598/782] Loss: 0.5780 | Acc: 82.83%\n",
      "Train Epoch [75/100] Batch [599/782] Loss: 0.6009 | Acc: 82.83%\n",
      "Train Epoch [75/100] Batch [600/782] Loss: 0.6056 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [601/782] Loss: 0.4005 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [602/782] Loss: 0.5690 | Acc: 82.83%\n",
      "Train Epoch [75/100] Batch [603/782] Loss: 0.5924 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [604/782] Loss: 0.4812 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [605/782] Loss: 0.5664 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [606/782] Loss: 0.3511 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [607/782] Loss: 0.4799 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [608/782] Loss: 0.4295 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [609/782] Loss: 0.7002 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [610/782] Loss: 0.4608 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [611/782] Loss: 0.5031 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [612/782] Loss: 0.4796 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [613/782] Loss: 0.2952 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [614/782] Loss: 0.5257 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [615/782] Loss: 0.5098 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [616/782] Loss: 0.5701 | Acc: 82.81%\n",
      "Train Epoch [75/100] Batch [617/782] Loss: 0.5785 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [618/782] Loss: 0.3155 | Acc: 82.82%\n",
      "Train Epoch [75/100] Batch [619/782] Loss: 0.5096 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [620/782] Loss: 0.6487 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [621/782] Loss: 0.5435 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [622/782] Loss: 0.4652 | Acc: 82.80%\n",
      "Train Epoch [75/100] Batch [623/782] Loss: 0.5759 | Acc: 82.79%\n",
      "Train Epoch [75/100] Batch [624/782] Loss: 0.6799 | Acc: 82.78%\n",
      "Train Epoch [75/100] Batch [625/782] Loss: 0.6886 | Acc: 82.78%\n",
      "Train Epoch [75/100] Batch [626/782] Loss: 0.4707 | Acc: 82.79%\n",
      "Train Epoch [75/100] Batch [627/782] Loss: 0.4329 | Acc: 82.79%\n",
      "Train Epoch [75/100] Batch [628/782] Loss: 0.6043 | Acc: 82.78%\n",
      "Train Epoch [75/100] Batch [629/782] Loss: 0.5628 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [630/782] Loss: 0.5178 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [631/782] Loss: 0.5709 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [632/782] Loss: 0.5328 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [633/782] Loss: 0.5154 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [634/782] Loss: 0.3277 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [635/782] Loss: 0.5483 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [636/782] Loss: 0.4057 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [637/782] Loss: 0.5510 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [638/782] Loss: 0.4859 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [639/782] Loss: 0.6116 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [640/782] Loss: 0.3676 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [641/782] Loss: 0.4197 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [642/782] Loss: 0.3305 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [643/782] Loss: 0.3473 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [644/782] Loss: 0.5504 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [645/782] Loss: 0.3521 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [646/782] Loss: 0.4605 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [647/782] Loss: 0.4857 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [648/782] Loss: 0.4508 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [649/782] Loss: 0.5289 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [650/782] Loss: 0.5904 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [651/782] Loss: 0.3735 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [652/782] Loss: 0.4842 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [653/782] Loss: 0.5178 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [654/782] Loss: 0.6498 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [655/782] Loss: 0.5937 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [656/782] Loss: 0.4571 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [657/782] Loss: 0.5076 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [658/782] Loss: 0.5981 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [659/782] Loss: 0.4858 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [660/782] Loss: 0.4694 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [661/782] Loss: 0.6702 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [662/782] Loss: 0.7349 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [663/782] Loss: 0.3966 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [664/782] Loss: 0.5511 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [665/782] Loss: 0.4640 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [666/782] Loss: 0.2969 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [667/782] Loss: 0.4255 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [668/782] Loss: 0.5562 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [669/782] Loss: 0.5414 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [670/782] Loss: 0.4480 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [671/782] Loss: 0.5354 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [672/782] Loss: 0.5850 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [673/782] Loss: 0.5211 | Acc: 82.68%\n",
      "Train Epoch [75/100] Batch [674/782] Loss: 0.5149 | Acc: 82.68%\n",
      "Train Epoch [75/100] Batch [675/782] Loss: 0.4475 | Acc: 82.68%\n",
      "Train Epoch [75/100] Batch [676/782] Loss: 0.4013 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [677/782] Loss: 0.5299 | Acc: 82.68%\n",
      "Train Epoch [75/100] Batch [678/782] Loss: 0.3802 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [679/782] Loss: 0.5946 | Acc: 82.68%\n",
      "Train Epoch [75/100] Batch [680/782] Loss: 0.4443 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [681/782] Loss: 0.3759 | Acc: 82.69%\n",
      "Train Epoch [75/100] Batch [682/782] Loss: 0.3204 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [683/782] Loss: 0.2824 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [684/782] Loss: 0.3302 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [685/782] Loss: 0.3618 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [686/782] Loss: 0.5112 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [687/782] Loss: 0.5060 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [688/782] Loss: 0.5010 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [689/782] Loss: 0.4753 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [690/782] Loss: 0.4927 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [691/782] Loss: 0.4240 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [692/782] Loss: 0.3430 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [693/782] Loss: 0.4601 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [694/782] Loss: 0.4555 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [695/782] Loss: 0.4980 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [696/782] Loss: 0.6112 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [697/782] Loss: 0.6372 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [698/782] Loss: 0.4236 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [699/782] Loss: 0.3962 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [700/782] Loss: 0.5332 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [701/782] Loss: 0.3927 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [702/782] Loss: 0.3935 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [703/782] Loss: 0.4808 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [704/782] Loss: 0.4407 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [705/782] Loss: 0.4013 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [706/782] Loss: 0.3967 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [707/782] Loss: 0.5817 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [708/782] Loss: 0.4450 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [709/782] Loss: 0.5266 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [710/782] Loss: 0.4870 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [711/782] Loss: 0.6110 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [712/782] Loss: 0.4193 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [713/782] Loss: 0.4638 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [714/782] Loss: 0.4742 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [715/782] Loss: 0.4797 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [716/782] Loss: 0.4773 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [717/782] Loss: 0.4064 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [718/782] Loss: 0.3486 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [719/782] Loss: 0.3520 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [720/782] Loss: 0.5222 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [721/782] Loss: 0.5772 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [722/782] Loss: 0.3266 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [723/782] Loss: 0.3227 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [724/782] Loss: 0.5561 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [725/782] Loss: 0.4652 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [726/782] Loss: 0.4492 | Acc: 82.77%\n",
      "Train Epoch [75/100] Batch [727/782] Loss: 0.6977 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [728/782] Loss: 0.4195 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [729/782] Loss: 0.4237 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [730/782] Loss: 0.4153 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [731/782] Loss: 0.5246 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [732/782] Loss: 0.3601 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [733/782] Loss: 0.3842 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [734/782] Loss: 0.5709 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [735/782] Loss: 0.7018 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [736/782] Loss: 0.4753 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [737/782] Loss: 0.3880 | Acc: 82.76%\n",
      "Train Epoch [75/100] Batch [738/782] Loss: 0.5084 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [739/782] Loss: 0.7412 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [740/782] Loss: 0.5471 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [741/782] Loss: 0.4706 | Acc: 82.75%\n",
      "Train Epoch [75/100] Batch [742/782] Loss: 0.6954 | Acc: 82.74%\n",
      "Train Epoch [75/100] Batch [743/782] Loss: 0.6220 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [744/782] Loss: 0.4054 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [745/782] Loss: 0.5133 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [746/782] Loss: 0.3966 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [747/782] Loss: 0.5566 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [748/782] Loss: 0.5503 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [749/782] Loss: 0.6817 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [750/782] Loss: 0.4855 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [751/782] Loss: 0.3779 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [752/782] Loss: 0.4890 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [753/782] Loss: 0.5590 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [754/782] Loss: 0.4946 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [755/782] Loss: 0.5709 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [756/782] Loss: 0.3468 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [757/782] Loss: 0.4205 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [758/782] Loss: 0.3274 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [759/782] Loss: 0.6360 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [760/782] Loss: 0.4639 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [761/782] Loss: 0.4128 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [762/782] Loss: 0.5857 | Acc: 82.70%\n",
      "Train Epoch [75/100] Batch [763/782] Loss: 0.3333 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [764/782] Loss: 0.3539 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [765/782] Loss: 0.4119 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [766/782] Loss: 0.5269 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [767/782] Loss: 0.3584 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [768/782] Loss: 0.4278 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [769/782] Loss: 0.6724 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [770/782] Loss: 0.3805 | Acc: 82.73%\n",
      "Train Epoch [75/100] Batch [771/782] Loss: 0.5957 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [772/782] Loss: 0.6907 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [773/782] Loss: 0.3623 | Acc: 82.72%\n",
      "Train Epoch [75/100] Batch [774/782] Loss: 0.5972 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [775/782] Loss: 0.5218 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [776/782] Loss: 0.4926 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [777/782] Loss: 0.3685 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [778/782] Loss: 0.4874 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [779/782] Loss: 0.5892 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [780/782] Loss: 0.5061 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [781/782] Loss: 0.5201 | Acc: 82.71%\n",
      "Train Epoch [75/100] Batch [782/782] Loss: 0.4307 | Acc: 82.71%\n",
      "Epoch 75 completed in 30.78s.\n",
      "Test Epoch [75/100] Loss: 0.9304 | Acc: 73.04% | Inference Time: 8.56s\n",
      "Epoch 75 results saved to CSV.\n",
      "Epoch 76/100\n",
      "Train Epoch [76/100] Batch [1/782] Loss: 0.4171 | Acc: 85.94%\n",
      "Train Epoch [76/100] Batch [2/782] Loss: 0.6416 | Acc: 82.03%\n",
      "Train Epoch [76/100] Batch [3/782] Loss: 0.4830 | Acc: 82.29%\n",
      "Train Epoch [76/100] Batch [4/782] Loss: 0.6002 | Acc: 82.03%\n",
      "Train Epoch [76/100] Batch [5/782] Loss: 0.3051 | Acc: 83.44%\n",
      "Train Epoch [76/100] Batch [6/782] Loss: 0.3306 | Acc: 84.38%\n",
      "Train Epoch [76/100] Batch [7/782] Loss: 0.6308 | Acc: 82.59%\n",
      "Train Epoch [76/100] Batch [8/782] Loss: 0.7055 | Acc: 81.64%\n",
      "Train Epoch [76/100] Batch [9/782] Loss: 0.3198 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [10/782] Loss: 0.6484 | Acc: 82.50%\n",
      "Train Epoch [76/100] Batch [11/782] Loss: 0.6700 | Acc: 82.10%\n",
      "Train Epoch [76/100] Batch [12/782] Loss: 0.4867 | Acc: 82.16%\n",
      "Train Epoch [76/100] Batch [13/782] Loss: 0.5153 | Acc: 81.97%\n",
      "Train Epoch [76/100] Batch [14/782] Loss: 0.5641 | Acc: 82.03%\n",
      "Train Epoch [76/100] Batch [15/782] Loss: 0.3797 | Acc: 82.08%\n",
      "Train Epoch [76/100] Batch [16/782] Loss: 0.4391 | Acc: 81.93%\n",
      "Train Epoch [76/100] Batch [17/782] Loss: 0.5251 | Acc: 81.71%\n",
      "Train Epoch [76/100] Batch [18/782] Loss: 0.5476 | Acc: 81.60%\n",
      "Train Epoch [76/100] Batch [19/782] Loss: 0.4014 | Acc: 81.91%\n",
      "Train Epoch [76/100] Batch [20/782] Loss: 0.4659 | Acc: 82.11%\n",
      "Train Epoch [76/100] Batch [21/782] Loss: 0.4389 | Acc: 82.14%\n",
      "Train Epoch [76/100] Batch [22/782] Loss: 0.4458 | Acc: 82.17%\n",
      "Train Epoch [76/100] Batch [23/782] Loss: 0.7490 | Acc: 81.86%\n",
      "Train Epoch [76/100] Batch [24/782] Loss: 0.6324 | Acc: 81.77%\n",
      "Train Epoch [76/100] Batch [25/782] Loss: 0.3514 | Acc: 81.88%\n",
      "Train Epoch [76/100] Batch [26/782] Loss: 0.4915 | Acc: 82.03%\n",
      "Train Epoch [76/100] Batch [27/782] Loss: 0.3930 | Acc: 82.29%\n",
      "Train Epoch [76/100] Batch [28/782] Loss: 0.4185 | Acc: 82.31%\n",
      "Train Epoch [76/100] Batch [29/782] Loss: 0.6326 | Acc: 82.06%\n",
      "Train Epoch [76/100] Batch [30/782] Loss: 0.5688 | Acc: 81.98%\n",
      "Train Epoch [76/100] Batch [31/782] Loss: 0.4570 | Acc: 81.96%\n",
      "Train Epoch [76/100] Batch [32/782] Loss: 0.2619 | Acc: 82.28%\n",
      "Train Epoch [76/100] Batch [33/782] Loss: 0.4744 | Acc: 82.24%\n",
      "Train Epoch [76/100] Batch [34/782] Loss: 0.4073 | Acc: 82.31%\n",
      "Train Epoch [76/100] Batch [35/782] Loss: 0.5762 | Acc: 82.41%\n",
      "Train Epoch [76/100] Batch [36/782] Loss: 0.5179 | Acc: 82.34%\n",
      "Train Epoch [76/100] Batch [37/782] Loss: 0.5416 | Acc: 82.35%\n",
      "Train Epoch [76/100] Batch [38/782] Loss: 0.4678 | Acc: 82.32%\n",
      "Train Epoch [76/100] Batch [39/782] Loss: 0.3306 | Acc: 82.49%\n",
      "Train Epoch [76/100] Batch [40/782] Loss: 0.5069 | Acc: 82.58%\n",
      "Train Epoch [76/100] Batch [41/782] Loss: 0.4975 | Acc: 82.51%\n",
      "Train Epoch [76/100] Batch [42/782] Loss: 0.5764 | Acc: 82.51%\n",
      "Train Epoch [76/100] Batch [43/782] Loss: 0.4032 | Acc: 82.56%\n",
      "Train Epoch [76/100] Batch [44/782] Loss: 0.4860 | Acc: 82.60%\n",
      "Train Epoch [76/100] Batch [45/782] Loss: 0.5402 | Acc: 82.53%\n",
      "Train Epoch [76/100] Batch [46/782] Loss: 0.3032 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [47/782] Loss: 0.2894 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [48/782] Loss: 0.5708 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [49/782] Loss: 0.5838 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [50/782] Loss: 0.4288 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [51/782] Loss: 0.5302 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [52/782] Loss: 0.3501 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [53/782] Loss: 0.4470 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [54/782] Loss: 0.5251 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [55/782] Loss: 0.4738 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [56/782] Loss: 0.3274 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [57/782] Loss: 0.5978 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [58/782] Loss: 0.4707 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [59/782] Loss: 0.4208 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [60/782] Loss: 0.3877 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [61/782] Loss: 0.5139 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [62/782] Loss: 0.6181 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [63/782] Loss: 0.3122 | Acc: 83.06%\n",
      "Train Epoch [76/100] Batch [64/782] Loss: 0.3710 | Acc: 83.15%\n",
      "Train Epoch [76/100] Batch [65/782] Loss: 0.5475 | Acc: 83.08%\n",
      "Train Epoch [76/100] Batch [66/782] Loss: 0.4674 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [67/782] Loss: 0.3973 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [68/782] Loss: 0.4299 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [69/782] Loss: 0.5338 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [70/782] Loss: 0.3161 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [71/782] Loss: 0.4536 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [72/782] Loss: 0.3300 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [73/782] Loss: 0.4604 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [74/782] Loss: 0.4998 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [75/782] Loss: 0.4240 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [76/782] Loss: 0.5107 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [77/782] Loss: 0.3647 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [78/782] Loss: 0.5684 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [79/782] Loss: 0.5151 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [80/782] Loss: 0.4597 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [81/782] Loss: 0.4606 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [82/782] Loss: 0.5128 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [83/782] Loss: 0.5070 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [84/782] Loss: 0.3071 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [85/782] Loss: 0.3275 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [86/782] Loss: 0.3992 | Acc: 83.12%\n",
      "Train Epoch [76/100] Batch [87/782] Loss: 0.3154 | Acc: 83.21%\n",
      "Train Epoch [76/100] Batch [88/782] Loss: 0.5381 | Acc: 83.19%\n",
      "Train Epoch [76/100] Batch [89/782] Loss: 0.4013 | Acc: 83.18%\n",
      "Train Epoch [76/100] Batch [90/782] Loss: 0.6187 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [91/782] Loss: 0.5790 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [92/782] Loss: 0.5419 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [93/782] Loss: 0.6034 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [94/782] Loss: 0.4687 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [95/782] Loss: 0.4685 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [96/782] Loss: 0.3855 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [97/782] Loss: 0.6077 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [98/782] Loss: 0.5656 | Acc: 82.92%\n",
      "Train Epoch [76/100] Batch [99/782] Loss: 0.3281 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [100/782] Loss: 0.5206 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [101/782] Loss: 0.4318 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [102/782] Loss: 0.5154 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [103/782] Loss: 0.3233 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [104/782] Loss: 0.4665 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [105/782] Loss: 0.7707 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [106/782] Loss: 0.4426 | Acc: 82.92%\n",
      "Train Epoch [76/100] Batch [107/782] Loss: 0.4532 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [108/782] Loss: 0.4327 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [109/782] Loss: 0.4649 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [110/782] Loss: 0.5616 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [111/782] Loss: 0.5590 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [112/782] Loss: 0.6150 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [113/782] Loss: 0.4130 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [114/782] Loss: 0.5345 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [115/782] Loss: 0.3293 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [116/782] Loss: 0.6412 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [117/782] Loss: 0.4247 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [118/782] Loss: 0.4422 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [119/782] Loss: 0.5539 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [120/782] Loss: 0.4523 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [121/782] Loss: 0.3860 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [122/782] Loss: 0.5527 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [123/782] Loss: 0.3649 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [124/782] Loss: 0.3202 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [125/782] Loss: 0.6958 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [126/782] Loss: 0.5345 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [127/782] Loss: 0.3484 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [128/782] Loss: 0.3358 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [129/782] Loss: 0.6479 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [130/782] Loss: 0.6229 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [131/782] Loss: 0.4207 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [132/782] Loss: 0.3433 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [133/782] Loss: 0.5121 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [134/782] Loss: 0.2754 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [135/782] Loss: 0.4153 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [136/782] Loss: 0.3703 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [137/782] Loss: 0.5878 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [138/782] Loss: 0.6926 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [139/782] Loss: 0.4070 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [140/782] Loss: 0.2713 | Acc: 83.06%\n",
      "Train Epoch [76/100] Batch [141/782] Loss: 0.4293 | Acc: 83.08%\n",
      "Train Epoch [76/100] Batch [142/782] Loss: 0.4255 | Acc: 83.09%\n",
      "Train Epoch [76/100] Batch [143/782] Loss: 0.4786 | Acc: 83.06%\n",
      "Train Epoch [76/100] Batch [144/782] Loss: 0.4239 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [145/782] Loss: 0.5046 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [146/782] Loss: 0.4896 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [147/782] Loss: 0.4198 | Acc: 83.13%\n",
      "Train Epoch [76/100] Batch [148/782] Loss: 0.2976 | Acc: 83.18%\n",
      "Train Epoch [76/100] Batch [149/782] Loss: 0.3271 | Acc: 83.21%\n",
      "Train Epoch [76/100] Batch [150/782] Loss: 0.4111 | Acc: 83.22%\n",
      "Train Epoch [76/100] Batch [151/782] Loss: 0.6115 | Acc: 83.17%\n",
      "Train Epoch [76/100] Batch [152/782] Loss: 0.4843 | Acc: 83.16%\n",
      "Train Epoch [76/100] Batch [153/782] Loss: 0.4030 | Acc: 83.20%\n",
      "Train Epoch [76/100] Batch [154/782] Loss: 0.6270 | Acc: 83.16%\n",
      "Train Epoch [76/100] Batch [155/782] Loss: 0.5094 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [156/782] Loss: 0.6020 | Acc: 83.09%\n",
      "Train Epoch [76/100] Batch [157/782] Loss: 0.3975 | Acc: 83.12%\n",
      "Train Epoch [76/100] Batch [158/782] Loss: 0.3551 | Acc: 83.17%\n",
      "Train Epoch [76/100] Batch [159/782] Loss: 0.4830 | Acc: 83.16%\n",
      "Train Epoch [76/100] Batch [160/782] Loss: 0.3947 | Acc: 83.17%\n",
      "Train Epoch [76/100] Batch [161/782] Loss: 0.4455 | Acc: 83.18%\n",
      "Train Epoch [76/100] Batch [162/782] Loss: 0.4255 | Acc: 83.18%\n",
      "Train Epoch [76/100] Batch [163/782] Loss: 0.3402 | Acc: 83.22%\n",
      "Train Epoch [76/100] Batch [164/782] Loss: 0.5718 | Acc: 83.18%\n",
      "Train Epoch [76/100] Batch [165/782] Loss: 0.5067 | Acc: 83.15%\n",
      "Train Epoch [76/100] Batch [166/782] Loss: 0.6512 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [167/782] Loss: 0.5521 | Acc: 83.09%\n",
      "Train Epoch [76/100] Batch [168/782] Loss: 0.6408 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [169/782] Loss: 0.3221 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [170/782] Loss: 0.3856 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [171/782] Loss: 0.5382 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [172/782] Loss: 0.4685 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [173/782] Loss: 0.3704 | Acc: 83.15%\n",
      "Train Epoch [76/100] Batch [174/782] Loss: 0.4967 | Acc: 83.15%\n",
      "Train Epoch [76/100] Batch [175/782] Loss: 0.4831 | Acc: 83.16%\n",
      "Train Epoch [76/100] Batch [176/782] Loss: 0.4692 | Acc: 83.17%\n",
      "Train Epoch [76/100] Batch [177/782] Loss: 0.2819 | Acc: 83.22%\n",
      "Train Epoch [76/100] Batch [178/782] Loss: 0.5449 | Acc: 83.19%\n",
      "Train Epoch [76/100] Batch [179/782] Loss: 0.6073 | Acc: 83.15%\n",
      "Train Epoch [76/100] Batch [180/782] Loss: 0.5386 | Acc: 83.14%\n",
      "Train Epoch [76/100] Batch [181/782] Loss: 0.5604 | Acc: 83.11%\n",
      "Train Epoch [76/100] Batch [182/782] Loss: 0.6283 | Acc: 83.06%\n",
      "Train Epoch [76/100] Batch [183/782] Loss: 0.3044 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [184/782] Loss: 0.6981 | Acc: 83.08%\n",
      "Train Epoch [76/100] Batch [185/782] Loss: 0.4736 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [186/782] Loss: 0.3698 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [187/782] Loss: 0.4967 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [188/782] Loss: 0.7187 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [189/782] Loss: 0.5779 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [190/782] Loss: 0.5047 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [191/782] Loss: 0.6031 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [192/782] Loss: 0.3531 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [193/782] Loss: 0.3849 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [194/782] Loss: 0.5010 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [195/782] Loss: 0.4414 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [196/782] Loss: 0.4118 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [197/782] Loss: 0.3987 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [198/782] Loss: 0.4932 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [199/782] Loss: 0.3976 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [200/782] Loss: 0.3533 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [201/782] Loss: 0.5243 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [202/782] Loss: 0.3928 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [203/782] Loss: 0.5325 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [204/782] Loss: 0.4732 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [205/782] Loss: 0.4043 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [206/782] Loss: 0.4304 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [207/782] Loss: 0.7237 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [208/782] Loss: 0.4248 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [209/782] Loss: 0.4570 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [210/782] Loss: 0.3432 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [211/782] Loss: 0.6974 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [212/782] Loss: 0.4914 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [213/782] Loss: 0.4647 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [214/782] Loss: 0.3702 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [215/782] Loss: 0.3920 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [216/782] Loss: 0.4019 | Acc: 82.99%\n",
      "Train Epoch [76/100] Batch [217/782] Loss: 0.6063 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [218/782] Loss: 0.5497 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [219/782] Loss: 0.2442 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [220/782] Loss: 0.5435 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [221/782] Loss: 0.3922 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [222/782] Loss: 0.6086 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [223/782] Loss: 0.4061 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [224/782] Loss: 0.4321 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [225/782] Loss: 0.5187 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [226/782] Loss: 0.5296 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [227/782] Loss: 0.5023 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [228/782] Loss: 0.3173 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [229/782] Loss: 0.6072 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [230/782] Loss: 0.5507 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [231/782] Loss: 0.5579 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [232/782] Loss: 0.4698 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [233/782] Loss: 0.4631 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [234/782] Loss: 0.3512 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [235/782] Loss: 0.3709 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [236/782] Loss: 0.4715 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [237/782] Loss: 0.3935 | Acc: 83.08%\n",
      "Train Epoch [76/100] Batch [238/782] Loss: 0.3997 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [239/782] Loss: 0.5740 | Acc: 83.10%\n",
      "Train Epoch [76/100] Batch [240/782] Loss: 0.5926 | Acc: 83.09%\n",
      "Train Epoch [76/100] Batch [241/782] Loss: 0.5002 | Acc: 83.07%\n",
      "Train Epoch [76/100] Batch [242/782] Loss: 0.7427 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [243/782] Loss: 0.4017 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [244/782] Loss: 0.4021 | Acc: 83.04%\n",
      "Train Epoch [76/100] Batch [245/782] Loss: 0.4243 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [246/782] Loss: 0.7232 | Acc: 83.02%\n",
      "Train Epoch [76/100] Batch [247/782] Loss: 0.5578 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [248/782] Loss: 0.3702 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [249/782] Loss: 0.4871 | Acc: 83.03%\n",
      "Train Epoch [76/100] Batch [250/782] Loss: 0.2511 | Acc: 83.06%\n",
      "Train Epoch [76/100] Batch [251/782] Loss: 0.5027 | Acc: 83.05%\n",
      "Train Epoch [76/100] Batch [252/782] Loss: 0.6010 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [253/782] Loss: 0.6486 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [254/782] Loss: 0.3229 | Acc: 83.00%\n",
      "Train Epoch [76/100] Batch [255/782] Loss: 0.3776 | Acc: 83.01%\n",
      "Train Epoch [76/100] Batch [256/782] Loss: 0.7746 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [257/782] Loss: 0.6539 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [258/782] Loss: 0.4726 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [259/782] Loss: 0.3985 | Acc: 82.98%\n",
      "Train Epoch [76/100] Batch [260/782] Loss: 0.7278 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [261/782] Loss: 0.3671 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [262/782] Loss: 0.4422 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [263/782] Loss: 0.6460 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [264/782] Loss: 0.4776 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [265/782] Loss: 0.5226 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [266/782] Loss: 0.5753 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [267/782] Loss: 0.3496 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [268/782] Loss: 0.4865 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [269/782] Loss: 0.4513 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [270/782] Loss: 0.4807 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [271/782] Loss: 0.5289 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [272/782] Loss: 0.6843 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [273/782] Loss: 0.4633 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [274/782] Loss: 0.5363 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [275/782] Loss: 0.7594 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [276/782] Loss: 0.4994 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [277/782] Loss: 0.4127 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [278/782] Loss: 0.5422 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [279/782] Loss: 0.5213 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [280/782] Loss: 0.3254 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [281/782] Loss: 0.6432 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [282/782] Loss: 0.4419 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [283/782] Loss: 0.4798 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [284/782] Loss: 0.4853 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [285/782] Loss: 0.5078 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [286/782] Loss: 0.2710 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [287/782] Loss: 0.4211 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [288/782] Loss: 0.2775 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [289/782] Loss: 0.4712 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [290/782] Loss: 0.5162 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [291/782] Loss: 0.4408 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [292/782] Loss: 0.4663 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [293/782] Loss: 0.2288 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [294/782] Loss: 0.7342 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [295/782] Loss: 0.4607 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [296/782] Loss: 0.5086 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [297/782] Loss: 0.5467 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [298/782] Loss: 0.4730 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [299/782] Loss: 0.4117 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [300/782] Loss: 0.3085 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [301/782] Loss: 0.4987 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [302/782] Loss: 0.5508 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [303/782] Loss: 0.4096 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [304/782] Loss: 0.4723 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [305/782] Loss: 0.5823 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [306/782] Loss: 0.4130 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [307/782] Loss: 0.4453 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [308/782] Loss: 0.3891 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [309/782] Loss: 0.4409 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [310/782] Loss: 0.4425 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [311/782] Loss: 0.3839 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [312/782] Loss: 0.5445 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [313/782] Loss: 0.3704 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [314/782] Loss: 0.4843 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [315/782] Loss: 0.3617 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [316/782] Loss: 0.5930 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [317/782] Loss: 0.3161 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [318/782] Loss: 0.3948 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [319/782] Loss: 0.4611 | Acc: 82.97%\n",
      "Train Epoch [76/100] Batch [320/782] Loss: 0.7150 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [321/782] Loss: 0.7480 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [322/782] Loss: 0.4754 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [323/782] Loss: 0.4719 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [324/782] Loss: 0.4854 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [325/782] Loss: 0.4035 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [326/782] Loss: 0.3769 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [327/782] Loss: 0.4841 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [328/782] Loss: 0.4734 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [329/782] Loss: 0.6107 | Acc: 82.95%\n",
      "Train Epoch [76/100] Batch [330/782] Loss: 0.4275 | Acc: 82.96%\n",
      "Train Epoch [76/100] Batch [331/782] Loss: 0.6388 | Acc: 82.94%\n",
      "Train Epoch [76/100] Batch [332/782] Loss: 0.5818 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [333/782] Loss: 0.4219 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [334/782] Loss: 0.5429 | Acc: 82.92%\n",
      "Train Epoch [76/100] Batch [335/782] Loss: 0.3439 | Acc: 82.93%\n",
      "Train Epoch [76/100] Batch [336/782] Loss: 0.6334 | Acc: 82.92%\n",
      "Train Epoch [76/100] Batch [337/782] Loss: 0.4114 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [338/782] Loss: 0.6758 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [339/782] Loss: 0.4469 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [340/782] Loss: 0.5871 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [341/782] Loss: 0.4863 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [342/782] Loss: 0.5623 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [343/782] Loss: 0.6574 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [344/782] Loss: 0.5491 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [345/782] Loss: 0.4597 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [346/782] Loss: 0.4082 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [347/782] Loss: 0.5023 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [348/782] Loss: 0.5600 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [349/782] Loss: 0.5057 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [350/782] Loss: 0.5920 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [351/782] Loss: 0.5789 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [352/782] Loss: 0.3758 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [353/782] Loss: 0.3856 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [354/782] Loss: 0.4121 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [355/782] Loss: 0.6616 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [356/782] Loss: 0.5469 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [357/782] Loss: 0.4388 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [358/782] Loss: 0.4948 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [359/782] Loss: 0.4369 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [360/782] Loss: 0.4520 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [361/782] Loss: 0.4344 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [362/782] Loss: 0.4027 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [363/782] Loss: 0.5572 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [364/782] Loss: 0.7229 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [365/782] Loss: 0.3302 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [366/782] Loss: 0.4362 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [367/782] Loss: 0.3956 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [368/782] Loss: 0.5411 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [369/782] Loss: 0.4169 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [370/782] Loss: 0.7296 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [371/782] Loss: 0.6647 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [372/782] Loss: 0.5412 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [373/782] Loss: 0.3166 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [374/782] Loss: 0.4828 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [375/782] Loss: 0.4642 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [376/782] Loss: 0.3726 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [377/782] Loss: 0.4924 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [378/782] Loss: 0.5713 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [379/782] Loss: 0.3091 | Acc: 82.90%\n",
      "Train Epoch [76/100] Batch [380/782] Loss: 0.4335 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [381/782] Loss: 0.5275 | Acc: 82.91%\n",
      "Train Epoch [76/100] Batch [382/782] Loss: 0.5362 | Acc: 82.89%\n",
      "Train Epoch [76/100] Batch [383/782] Loss: 0.4675 | Acc: 82.88%\n",
      "Train Epoch [76/100] Batch [384/782] Loss: 0.5578 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [385/782] Loss: 0.4622 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [386/782] Loss: 0.6036 | Acc: 82.87%\n",
      "Train Epoch [76/100] Batch [387/782] Loss: 0.5406 | Acc: 82.86%\n",
      "Train Epoch [76/100] Batch [388/782] Loss: 0.8463 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [389/782] Loss: 0.5008 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [390/782] Loss: 0.5653 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [391/782] Loss: 0.6910 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [392/782] Loss: 0.3906 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [393/782] Loss: 0.5606 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [394/782] Loss: 0.3598 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [395/782] Loss: 0.5741 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [396/782] Loss: 0.6410 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [397/782] Loss: 0.4182 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [398/782] Loss: 0.5055 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [399/782] Loss: 0.4050 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [400/782] Loss: 0.5110 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [401/782] Loss: 0.4725 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [402/782] Loss: 0.5432 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [403/782] Loss: 0.5453 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [404/782] Loss: 0.5480 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [405/782] Loss: 0.6404 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [406/782] Loss: 0.4658 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [407/782] Loss: 0.6433 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [408/782] Loss: 0.4880 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [409/782] Loss: 0.4575 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [410/782] Loss: 0.5535 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [411/782] Loss: 0.3637 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [412/782] Loss: 0.6907 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [413/782] Loss: 0.5502 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [414/782] Loss: 0.4206 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [415/782] Loss: 0.4513 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [416/782] Loss: 0.2871 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [417/782] Loss: 0.5143 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [418/782] Loss: 0.4228 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [419/782] Loss: 0.6174 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [420/782] Loss: 0.3825 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [421/782] Loss: 0.5701 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [422/782] Loss: 0.2328 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [423/782] Loss: 0.4794 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [424/782] Loss: 0.4214 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [425/782] Loss: 0.4990 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [426/782] Loss: 0.4257 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [427/782] Loss: 0.4080 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [428/782] Loss: 0.5328 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [429/782] Loss: 0.4793 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [430/782] Loss: 0.5694 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [431/782] Loss: 0.5617 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [432/782] Loss: 0.3784 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [433/782] Loss: 0.4298 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [434/782] Loss: 0.3997 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [435/782] Loss: 0.3763 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [436/782] Loss: 0.2667 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [437/782] Loss: 0.5196 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [438/782] Loss: 0.6450 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [439/782] Loss: 0.5769 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [440/782] Loss: 0.5679 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [441/782] Loss: 0.4202 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [442/782] Loss: 0.4990 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [443/782] Loss: 0.4953 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [444/782] Loss: 0.5351 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [445/782] Loss: 0.4137 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [446/782] Loss: 0.4576 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [447/782] Loss: 0.5665 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [448/782] Loss: 0.4763 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [449/782] Loss: 0.3806 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [450/782] Loss: 0.4994 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [451/782] Loss: 0.5020 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [452/782] Loss: 0.4835 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [453/782] Loss: 0.2703 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [454/782] Loss: 0.4288 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [455/782] Loss: 0.3973 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [456/782] Loss: 0.6383 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [457/782] Loss: 0.6625 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [458/782] Loss: 0.4901 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [459/782] Loss: 0.4036 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [460/782] Loss: 0.6702 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [461/782] Loss: 0.4917 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [462/782] Loss: 0.4595 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [463/782] Loss: 0.5768 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [464/782] Loss: 0.4276 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [465/782] Loss: 0.5897 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [466/782] Loss: 0.4357 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [467/782] Loss: 0.6022 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [468/782] Loss: 0.3352 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [469/782] Loss: 0.6518 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [470/782] Loss: 0.4687 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [471/782] Loss: 0.4969 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [472/782] Loss: 0.3765 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [473/782] Loss: 0.3271 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [474/782] Loss: 0.3884 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [475/782] Loss: 0.4687 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [476/782] Loss: 0.5585 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [477/782] Loss: 0.5855 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [478/782] Loss: 0.4376 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [479/782] Loss: 0.4086 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [480/782] Loss: 0.3648 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [481/782] Loss: 0.4741 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [482/782] Loss: 0.5535 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [483/782] Loss: 0.4603 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [484/782] Loss: 0.5526 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [485/782] Loss: 0.4039 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [486/782] Loss: 0.3796 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [487/782] Loss: 0.6978 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [488/782] Loss: 0.3872 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [489/782] Loss: 0.6668 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [490/782] Loss: 0.4706 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [491/782] Loss: 0.4781 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [492/782] Loss: 0.5236 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [493/782] Loss: 0.5409 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [494/782] Loss: 0.6735 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [495/782] Loss: 0.4201 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [496/782] Loss: 0.6442 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [497/782] Loss: 0.4000 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [498/782] Loss: 0.4188 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [499/782] Loss: 0.3102 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [500/782] Loss: 0.3295 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [501/782] Loss: 0.4846 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [502/782] Loss: 0.4875 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [503/782] Loss: 0.5356 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [504/782] Loss: 0.4854 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [505/782] Loss: 0.4528 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [506/782] Loss: 0.5928 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [507/782] Loss: 0.4965 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [508/782] Loss: 0.4839 | Acc: 82.74%\n",
      "Train Epoch [76/100] Batch [509/782] Loss: 0.4054 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [510/782] Loss: 0.3212 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [511/782] Loss: 0.6051 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [512/782] Loss: 0.5351 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [513/782] Loss: 0.4346 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [514/782] Loss: 0.5604 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [515/782] Loss: 0.5146 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [516/782] Loss: 0.6053 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [517/782] Loss: 0.3958 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [518/782] Loss: 0.4345 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [519/782] Loss: 0.5342 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [520/782] Loss: 0.6089 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [521/782] Loss: 0.5437 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [522/782] Loss: 0.4624 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [523/782] Loss: 0.5642 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [524/782] Loss: 0.4861 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [525/782] Loss: 0.3927 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [526/782] Loss: 0.5078 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [527/782] Loss: 0.5141 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [528/782] Loss: 0.5601 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [529/782] Loss: 0.7501 | Acc: 82.74%\n",
      "Train Epoch [76/100] Batch [530/782] Loss: 0.5882 | Acc: 82.74%\n",
      "Train Epoch [76/100] Batch [531/782] Loss: 0.5500 | Acc: 82.73%\n",
      "Train Epoch [76/100] Batch [532/782] Loss: 0.5153 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [533/782] Loss: 0.6323 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [534/782] Loss: 0.5608 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [535/782] Loss: 0.5603 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [536/782] Loss: 0.5126 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [537/782] Loss: 0.3504 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [538/782] Loss: 0.6477 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [539/782] Loss: 0.4509 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [540/782] Loss: 0.4616 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [541/782] Loss: 0.5282 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [542/782] Loss: 0.3994 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [543/782] Loss: 0.4925 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [544/782] Loss: 0.5505 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [545/782] Loss: 0.4386 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [546/782] Loss: 0.5536 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [547/782] Loss: 0.5426 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [548/782] Loss: 0.4471 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [549/782] Loss: 0.4109 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [550/782] Loss: 0.4411 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [551/782] Loss: 0.5049 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [552/782] Loss: 0.4750 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [553/782] Loss: 0.5516 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [554/782] Loss: 0.5936 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [555/782] Loss: 0.6381 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [556/782] Loss: 0.4272 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [557/782] Loss: 0.4409 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [558/782] Loss: 0.4142 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [559/782] Loss: 0.3984 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [560/782] Loss: 0.5004 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [561/782] Loss: 0.4088 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [562/782] Loss: 0.6621 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [563/782] Loss: 0.6652 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [564/782] Loss: 0.5674 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [565/782] Loss: 0.5645 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [566/782] Loss: 0.6449 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [567/782] Loss: 0.5176 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [568/782] Loss: 0.5736 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [569/782] Loss: 0.5065 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [570/782] Loss: 0.7162 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [571/782] Loss: 0.4985 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [572/782] Loss: 0.4914 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [573/782] Loss: 0.4496 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [574/782] Loss: 0.2628 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [575/782] Loss: 0.4902 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [576/782] Loss: 0.5486 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [577/782] Loss: 0.4891 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [578/782] Loss: 0.4745 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [579/782] Loss: 0.5510 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [580/782] Loss: 0.5466 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [581/782] Loss: 0.5624 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [582/782] Loss: 0.3785 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [583/782] Loss: 0.5492 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [584/782] Loss: 0.3775 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [585/782] Loss: 0.5650 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [586/782] Loss: 0.4510 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [587/782] Loss: 0.5552 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [588/782] Loss: 0.5426 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [589/782] Loss: 0.2442 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [590/782] Loss: 0.3795 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [591/782] Loss: 0.4493 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [592/782] Loss: 0.3582 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [593/782] Loss: 0.7036 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [594/782] Loss: 0.4675 | Acc: 82.67%\n",
      "Train Epoch [76/100] Batch [595/782] Loss: 0.7462 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [596/782] Loss: 0.5252 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [597/782] Loss: 0.6938 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [598/782] Loss: 0.4485 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [599/782] Loss: 0.4980 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [600/782] Loss: 0.5407 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [601/782] Loss: 0.5796 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [602/782] Loss: 0.3554 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [603/782] Loss: 0.5204 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [604/782] Loss: 0.3517 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [605/782] Loss: 0.4633 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [606/782] Loss: 0.5246 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [607/782] Loss: 0.4638 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [608/782] Loss: 0.5024 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [609/782] Loss: 0.4809 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [610/782] Loss: 0.4294 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [611/782] Loss: 0.4802 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [612/782] Loss: 0.7272 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [613/782] Loss: 0.3761 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [614/782] Loss: 0.4422 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [615/782] Loss: 0.4441 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [616/782] Loss: 0.5213 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [617/782] Loss: 0.4436 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [618/782] Loss: 0.5579 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [619/782] Loss: 0.4445 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [620/782] Loss: 0.5563 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [621/782] Loss: 0.6728 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [622/782] Loss: 0.5401 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [623/782] Loss: 0.6729 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [624/782] Loss: 0.5109 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [625/782] Loss: 0.5141 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [626/782] Loss: 0.4399 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [627/782] Loss: 0.3860 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [628/782] Loss: 0.4725 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [629/782] Loss: 0.5453 | Acc: 82.61%\n",
      "Train Epoch [76/100] Batch [630/782] Loss: 0.5635 | Acc: 82.61%\n",
      "Train Epoch [76/100] Batch [631/782] Loss: 0.3685 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [632/782] Loss: 0.5573 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [633/782] Loss: 0.5973 | Acc: 82.61%\n",
      "Train Epoch [76/100] Batch [634/782] Loss: 0.4642 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [635/782] Loss: 0.5895 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [636/782] Loss: 0.5879 | Acc: 82.61%\n",
      "Train Epoch [76/100] Batch [637/782] Loss: 0.8846 | Acc: 82.59%\n",
      "Train Epoch [76/100] Batch [638/782] Loss: 0.4639 | Acc: 82.60%\n",
      "Train Epoch [76/100] Batch [639/782] Loss: 0.3121 | Acc: 82.60%\n",
      "Train Epoch [76/100] Batch [640/782] Loss: 0.4071 | Acc: 82.61%\n",
      "Train Epoch [76/100] Batch [641/782] Loss: 0.3469 | Acc: 82.62%\n",
      "Train Epoch [76/100] Batch [642/782] Loss: 0.4666 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [643/782] Loss: 0.3982 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [644/782] Loss: 0.6214 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [645/782] Loss: 0.4746 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [646/782] Loss: 0.4246 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [647/782] Loss: 0.6064 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [648/782] Loss: 0.4811 | Acc: 82.63%\n",
      "Train Epoch [76/100] Batch [649/782] Loss: 0.2266 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [650/782] Loss: 0.4512 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [651/782] Loss: 0.5538 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [652/782] Loss: 0.4426 | Acc: 82.64%\n",
      "Train Epoch [76/100] Batch [653/782] Loss: 0.5058 | Acc: 82.65%\n",
      "Train Epoch [76/100] Batch [654/782] Loss: 0.3119 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [655/782] Loss: 0.5072 | Acc: 82.66%\n",
      "Train Epoch [76/100] Batch [656/782] Loss: 0.3310 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [657/782] Loss: 0.3532 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [658/782] Loss: 0.4620 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [659/782] Loss: 0.4072 | Acc: 82.68%\n",
      "Train Epoch [76/100] Batch [660/782] Loss: 0.4900 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [661/782] Loss: 0.5160 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [662/782] Loss: 0.4301 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [663/782] Loss: 0.2958 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [664/782] Loss: 0.4106 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [665/782] Loss: 0.3662 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [666/782] Loss: 0.4439 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [667/782] Loss: 0.5167 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [668/782] Loss: 0.5286 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [669/782] Loss: 0.5295 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [670/782] Loss: 0.4739 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [671/782] Loss: 0.4660 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [672/782] Loss: 0.5604 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [673/782] Loss: 0.3775 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [674/782] Loss: 0.5942 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [675/782] Loss: 0.4378 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [676/782] Loss: 0.5212 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [677/782] Loss: 0.4325 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [678/782] Loss: 0.6800 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [679/782] Loss: 0.4625 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [680/782] Loss: 0.6072 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [681/782] Loss: 0.4265 | Acc: 82.69%\n",
      "Train Epoch [76/100] Batch [682/782] Loss: 0.3952 | Acc: 82.70%\n",
      "Train Epoch [76/100] Batch [683/782] Loss: 0.3198 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [684/782] Loss: 0.4360 | Acc: 82.71%\n",
      "Train Epoch [76/100] Batch [685/782] Loss: 0.4640 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [686/782] Loss: 0.4278 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [687/782] Loss: 0.4420 | Acc: 82.72%\n",
      "Train Epoch [76/100] Batch [688/782] Loss: 0.3790 | Acc: 82.73%\n",
      "Train Epoch [76/100] Batch [689/782] Loss: 0.3177 | Acc: 82.74%\n",
      "Train Epoch [76/100] Batch [690/782] Loss: 0.3543 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [691/782] Loss: 0.4406 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [692/782] Loss: 0.4083 | Acc: 82.75%\n",
      "Train Epoch [76/100] Batch [693/782] Loss: 0.4028 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [694/782] Loss: 0.5386 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [695/782] Loss: 0.5715 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [696/782] Loss: 0.4184 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [697/782] Loss: 0.6695 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [698/782] Loss: 0.5311 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [699/782] Loss: 0.5025 | Acc: 82.76%\n",
      "Train Epoch [76/100] Batch [700/782] Loss: 0.4934 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [701/782] Loss: 0.4309 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [702/782] Loss: 0.4101 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [703/782] Loss: 0.4670 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [704/782] Loss: 0.4427 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [705/782] Loss: 0.4996 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [706/782] Loss: 0.5772 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [707/782] Loss: 0.4374 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [708/782] Loss: 0.2627 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [709/782] Loss: 0.5219 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [710/782] Loss: 0.5093 | Acc: 82.78%\n",
      "Train Epoch [76/100] Batch [711/782] Loss: 0.4576 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [712/782] Loss: 0.4458 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [713/782] Loss: 0.3273 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [714/782] Loss: 0.3805 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [715/782] Loss: 0.3876 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [716/782] Loss: 0.3312 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [717/782] Loss: 0.2497 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [718/782] Loss: 0.4952 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [719/782] Loss: 0.4366 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [720/782] Loss: 0.5353 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [721/782] Loss: 0.3975 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [722/782] Loss: 0.3803 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [723/782] Loss: 0.4551 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [724/782] Loss: 0.6088 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [725/782] Loss: 0.4366 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [726/782] Loss: 0.2748 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [727/782] Loss: 0.3914 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [728/782] Loss: 0.5571 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [729/782] Loss: 0.3131 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [730/782] Loss: 0.4389 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [731/782] Loss: 0.4438 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [732/782] Loss: 0.4142 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [733/782] Loss: 0.5267 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [734/782] Loss: 0.6132 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [735/782] Loss: 0.6479 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [736/782] Loss: 0.5042 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [737/782] Loss: 0.5608 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [738/782] Loss: 0.3287 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [739/782] Loss: 0.6889 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [740/782] Loss: 0.4599 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [741/782] Loss: 0.2935 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [742/782] Loss: 0.3828 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [743/782] Loss: 0.5886 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [744/782] Loss: 0.5409 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [745/782] Loss: 0.4346 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [746/782] Loss: 0.5340 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [747/782] Loss: 0.2959 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [748/782] Loss: 0.3920 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [749/782] Loss: 0.5659 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [750/782] Loss: 0.5869 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [751/782] Loss: 0.2785 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [752/782] Loss: 0.2854 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [753/782] Loss: 0.4823 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [754/782] Loss: 0.5517 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [755/782] Loss: 0.4084 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [756/782] Loss: 0.5009 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [757/782] Loss: 0.4994 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [758/782] Loss: 0.7132 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [759/782] Loss: 0.5444 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [760/782] Loss: 0.3585 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [761/782] Loss: 0.6042 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [762/782] Loss: 0.5704 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [763/782] Loss: 0.5121 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [764/782] Loss: 0.4042 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [765/782] Loss: 0.4216 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [766/782] Loss: 0.5116 | Acc: 82.85%\n",
      "Train Epoch [76/100] Batch [767/782] Loss: 0.6363 | Acc: 82.84%\n",
      "Train Epoch [76/100] Batch [768/782] Loss: 0.5544 | Acc: 82.83%\n",
      "Train Epoch [76/100] Batch [769/782] Loss: 0.7592 | Acc: 82.82%\n",
      "Train Epoch [76/100] Batch [770/782] Loss: 0.6147 | Acc: 82.81%\n",
      "Train Epoch [76/100] Batch [771/782] Loss: 0.7532 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [772/782] Loss: 0.5458 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [773/782] Loss: 0.4070 | Acc: 82.80%\n",
      "Train Epoch [76/100] Batch [774/782] Loss: 0.5398 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [775/782] Loss: 0.4047 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [776/782] Loss: 0.4290 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [777/782] Loss: 0.4068 | Acc: 82.79%\n",
      "Train Epoch [76/100] Batch [778/782] Loss: 0.7720 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [779/782] Loss: 0.5770 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [780/782] Loss: 0.4006 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [781/782] Loss: 0.5105 | Acc: 82.77%\n",
      "Train Epoch [76/100] Batch [782/782] Loss: 0.3146 | Acc: 82.77%\n",
      "Epoch 76 completed in 31.04s.\n",
      "Test Epoch [76/100] Loss: 0.9670 | Acc: 72.56% | Inference Time: 8.71s\n",
      "Epoch 76 results saved to CSV.\n",
      "Epoch 77/100\n",
      "Train Epoch [77/100] Batch [1/782] Loss: 0.4841 | Acc: 79.69%\n",
      "Train Epoch [77/100] Batch [2/782] Loss: 0.4399 | Acc: 79.69%\n",
      "Train Epoch [77/100] Batch [3/782] Loss: 0.4483 | Acc: 80.73%\n",
      "Train Epoch [77/100] Batch [4/782] Loss: 0.4650 | Acc: 81.64%\n",
      "Train Epoch [77/100] Batch [5/782] Loss: 0.4974 | Acc: 80.94%\n",
      "Train Epoch [77/100] Batch [6/782] Loss: 0.5430 | Acc: 80.21%\n",
      "Train Epoch [77/100] Batch [7/782] Loss: 0.5716 | Acc: 79.46%\n",
      "Train Epoch [77/100] Batch [8/782] Loss: 0.8507 | Acc: 78.71%\n",
      "Train Epoch [77/100] Batch [9/782] Loss: 0.3495 | Acc: 79.69%\n",
      "Train Epoch [77/100] Batch [10/782] Loss: 0.5198 | Acc: 80.00%\n",
      "Train Epoch [77/100] Batch [11/782] Loss: 0.4105 | Acc: 80.40%\n",
      "Train Epoch [77/100] Batch [12/782] Loss: 0.3945 | Acc: 81.12%\n",
      "Train Epoch [77/100] Batch [13/782] Loss: 0.4158 | Acc: 81.49%\n",
      "Train Epoch [77/100] Batch [14/782] Loss: 0.4672 | Acc: 82.03%\n",
      "Train Epoch [77/100] Batch [15/782] Loss: 0.5521 | Acc: 82.19%\n",
      "Train Epoch [77/100] Batch [16/782] Loss: 0.4059 | Acc: 82.32%\n",
      "Train Epoch [77/100] Batch [17/782] Loss: 0.4377 | Acc: 82.44%\n",
      "Train Epoch [77/100] Batch [18/782] Loss: 0.4637 | Acc: 82.55%\n",
      "Train Epoch [77/100] Batch [19/782] Loss: 0.3728 | Acc: 83.06%\n",
      "Train Epoch [77/100] Batch [20/782] Loss: 0.4794 | Acc: 82.89%\n",
      "Train Epoch [77/100] Batch [21/782] Loss: 0.2956 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [22/782] Loss: 0.4279 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [23/782] Loss: 0.4745 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [24/782] Loss: 0.4767 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [25/782] Loss: 0.3770 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [26/782] Loss: 0.4247 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [27/782] Loss: 0.3169 | Acc: 83.85%\n",
      "Train Epoch [77/100] Batch [28/782] Loss: 0.4270 | Acc: 83.93%\n",
      "Train Epoch [77/100] Batch [29/782] Loss: 0.3375 | Acc: 84.16%\n",
      "Train Epoch [77/100] Batch [30/782] Loss: 0.6081 | Acc: 84.11%\n",
      "Train Epoch [77/100] Batch [31/782] Loss: 0.6585 | Acc: 83.87%\n",
      "Train Epoch [77/100] Batch [32/782] Loss: 0.4174 | Acc: 83.94%\n",
      "Train Epoch [77/100] Batch [33/782] Loss: 0.4053 | Acc: 84.00%\n",
      "Train Epoch [77/100] Batch [34/782] Loss: 0.4397 | Acc: 83.92%\n",
      "Train Epoch [77/100] Batch [35/782] Loss: 0.4393 | Acc: 84.02%\n",
      "Train Epoch [77/100] Batch [36/782] Loss: 0.5566 | Acc: 83.90%\n",
      "Train Epoch [77/100] Batch [37/782] Loss: 0.6529 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [38/782] Loss: 0.5819 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [39/782] Loss: 0.3505 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [40/782] Loss: 0.6148 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [41/782] Loss: 0.5604 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [42/782] Loss: 0.5634 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [43/782] Loss: 0.3102 | Acc: 83.47%\n",
      "Train Epoch [77/100] Batch [44/782] Loss: 0.3007 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [45/782] Loss: 0.4437 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [46/782] Loss: 0.4159 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [47/782] Loss: 0.6091 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [48/782] Loss: 0.2622 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [49/782] Loss: 0.4656 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [50/782] Loss: 0.4834 | Acc: 83.47%\n",
      "Train Epoch [77/100] Batch [51/782] Loss: 0.4101 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [52/782] Loss: 0.7065 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [53/782] Loss: 0.4190 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [54/782] Loss: 0.4097 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [55/782] Loss: 0.4257 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [56/782] Loss: 0.4050 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [57/782] Loss: 0.6586 | Acc: 83.14%\n",
      "Train Epoch [77/100] Batch [58/782] Loss: 0.3647 | Acc: 83.16%\n",
      "Train Epoch [77/100] Batch [59/782] Loss: 0.3045 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [60/782] Loss: 0.3655 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [61/782] Loss: 0.5876 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [62/782] Loss: 0.5126 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [63/782] Loss: 0.4917 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [64/782] Loss: 0.3177 | Acc: 83.47%\n",
      "Train Epoch [77/100] Batch [65/782] Loss: 0.3658 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [66/782] Loss: 0.5231 | Acc: 83.45%\n",
      "Train Epoch [77/100] Batch [67/782] Loss: 0.2908 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [68/782] Loss: 0.4205 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [69/782] Loss: 0.5198 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [70/782] Loss: 0.4561 | Acc: 83.50%\n",
      "Train Epoch [77/100] Batch [71/782] Loss: 0.3060 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [72/782] Loss: 0.3340 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [73/782] Loss: 0.3487 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [74/782] Loss: 0.6078 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [75/782] Loss: 0.7108 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [76/782] Loss: 0.3796 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [77/782] Loss: 0.4225 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [78/782] Loss: 0.3912 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [79/782] Loss: 0.6325 | Acc: 83.47%\n",
      "Train Epoch [77/100] Batch [80/782] Loss: 0.7093 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [81/782] Loss: 0.4636 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [82/782] Loss: 0.6763 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [83/782] Loss: 0.5018 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [84/782] Loss: 0.4899 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [85/782] Loss: 0.3762 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [86/782] Loss: 0.3496 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [87/782] Loss: 0.4611 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [88/782] Loss: 0.4104 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [89/782] Loss: 0.5360 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [90/782] Loss: 0.2884 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [91/782] Loss: 0.4045 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [92/782] Loss: 0.4837 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [93/782] Loss: 0.5853 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [94/782] Loss: 0.3313 | Acc: 83.61%\n",
      "Train Epoch [77/100] Batch [95/782] Loss: 0.3967 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [96/782] Loss: 0.4321 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [97/782] Loss: 0.3958 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [98/782] Loss: 0.3739 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [99/782] Loss: 0.4783 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [100/782] Loss: 0.6835 | Acc: 83.61%\n",
      "Train Epoch [77/100] Batch [101/782] Loss: 0.5338 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [102/782] Loss: 0.4175 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [103/782] Loss: 0.4120 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [104/782] Loss: 0.5131 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [105/782] Loss: 0.3585 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [106/782] Loss: 0.3824 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [107/782] Loss: 0.5750 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [108/782] Loss: 0.5437 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [109/782] Loss: 0.5514 | Acc: 83.49%\n",
      "Train Epoch [77/100] Batch [110/782] Loss: 0.2707 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [111/782] Loss: 0.4799 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [112/782] Loss: 0.4289 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [113/782] Loss: 0.6182 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [114/782] Loss: 0.5040 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [115/782] Loss: 0.5245 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [116/782] Loss: 0.4029 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [117/782] Loss: 0.3650 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [118/782] Loss: 0.5150 | Acc: 83.49%\n",
      "Train Epoch [77/100] Batch [119/782] Loss: 0.6273 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [120/782] Loss: 0.3282 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [121/782] Loss: 0.7765 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [122/782] Loss: 0.4213 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [123/782] Loss: 0.5283 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [124/782] Loss: 0.4101 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [125/782] Loss: 0.3566 | Acc: 83.45%\n",
      "Train Epoch [77/100] Batch [126/782] Loss: 0.3862 | Acc: 83.49%\n",
      "Train Epoch [77/100] Batch [127/782] Loss: 0.5402 | Acc: 83.49%\n",
      "Train Epoch [77/100] Batch [128/782] Loss: 0.4508 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [129/782] Loss: 0.3881 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [130/782] Loss: 0.4481 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [131/782] Loss: 0.4020 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [132/782] Loss: 0.4768 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [133/782] Loss: 0.5792 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [134/782] Loss: 0.3329 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [135/782] Loss: 0.6798 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [136/782] Loss: 0.4045 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [137/782] Loss: 0.3652 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [138/782] Loss: 0.4398 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [139/782] Loss: 0.5028 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [140/782] Loss: 0.5578 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [141/782] Loss: 0.5339 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [142/782] Loss: 0.2741 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [143/782] Loss: 0.5509 | Acc: 83.56%\n",
      "Train Epoch [77/100] Batch [144/782] Loss: 0.3210 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [145/782] Loss: 0.4662 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [146/782] Loss: 0.4316 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [147/782] Loss: 0.3201 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [148/782] Loss: 0.3760 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [149/782] Loss: 0.2966 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [150/782] Loss: 0.4800 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [151/782] Loss: 0.5861 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [152/782] Loss: 0.4274 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [153/782] Loss: 0.4596 | Acc: 83.61%\n",
      "Train Epoch [77/100] Batch [154/782] Loss: 0.5312 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [155/782] Loss: 0.2473 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [156/782] Loss: 0.4222 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [157/782] Loss: 0.4534 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [158/782] Loss: 0.6232 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [159/782] Loss: 0.4562 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [160/782] Loss: 0.5156 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [161/782] Loss: 0.3686 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [162/782] Loss: 0.3734 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [163/782] Loss: 0.5151 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [164/782] Loss: 0.3915 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [165/782] Loss: 0.3701 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [166/782] Loss: 0.5080 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [167/782] Loss: 0.4961 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [168/782] Loss: 0.4178 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [169/782] Loss: 0.3584 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [170/782] Loss: 0.5361 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [171/782] Loss: 0.5408 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [172/782] Loss: 0.3930 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [173/782] Loss: 0.3685 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [174/782] Loss: 0.5065 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [175/782] Loss: 0.5074 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [176/782] Loss: 0.3830 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [177/782] Loss: 0.3691 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [178/782] Loss: 0.3392 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [179/782] Loss: 0.2871 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [180/782] Loss: 0.3871 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [181/782] Loss: 0.3034 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [182/782] Loss: 0.5533 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [183/782] Loss: 0.5397 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [184/782] Loss: 0.4538 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [185/782] Loss: 0.5352 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [186/782] Loss: 0.4427 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [187/782] Loss: 0.4366 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [188/782] Loss: 0.3442 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [189/782] Loss: 0.4457 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [190/782] Loss: 0.5650 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [191/782] Loss: 0.4453 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [192/782] Loss: 0.6643 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [193/782] Loss: 0.3512 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [194/782] Loss: 0.5338 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [195/782] Loss: 0.5436 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [196/782] Loss: 0.4762 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [197/782] Loss: 0.6729 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [198/782] Loss: 0.5087 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [199/782] Loss: 0.5660 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [200/782] Loss: 0.5211 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [201/782] Loss: 0.4354 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [202/782] Loss: 0.3131 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [203/782] Loss: 0.5170 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [204/782] Loss: 0.5500 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [205/782] Loss: 0.4521 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [206/782] Loss: 0.3300 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [207/782] Loss: 0.3001 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [208/782] Loss: 0.3722 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [209/782] Loss: 0.5533 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [210/782] Loss: 0.4594 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [211/782] Loss: 0.5727 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [212/782] Loss: 0.3246 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [213/782] Loss: 0.4015 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [214/782] Loss: 0.6763 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [215/782] Loss: 0.4244 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [216/782] Loss: 0.3113 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [217/782] Loss: 0.3990 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [218/782] Loss: 0.5198 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [219/782] Loss: 0.3488 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [220/782] Loss: 0.4325 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [221/782] Loss: 0.2863 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [222/782] Loss: 0.4877 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [223/782] Loss: 0.6555 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [224/782] Loss: 0.3800 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [225/782] Loss: 0.3331 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [226/782] Loss: 0.3605 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [227/782] Loss: 0.5917 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [228/782] Loss: 0.5589 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [229/782] Loss: 0.3141 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [230/782] Loss: 0.6205 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [231/782] Loss: 0.3154 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [232/782] Loss: 0.5389 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [233/782] Loss: 0.7077 | Acc: 83.78%\n",
      "Train Epoch [77/100] Batch [234/782] Loss: 0.4746 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [235/782] Loss: 0.5114 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [236/782] Loss: 0.3748 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [237/782] Loss: 0.4139 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [238/782] Loss: 0.5025 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [239/782] Loss: 0.5216 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [240/782] Loss: 0.3761 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [241/782] Loss: 0.4951 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [242/782] Loss: 0.4330 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [243/782] Loss: 0.4318 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [244/782] Loss: 0.4851 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [245/782] Loss: 0.3757 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [246/782] Loss: 0.5318 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [247/782] Loss: 0.4536 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [248/782] Loss: 0.3614 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [249/782] Loss: 0.3658 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [250/782] Loss: 0.4549 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [251/782] Loss: 0.4743 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [252/782] Loss: 0.6212 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [253/782] Loss: 0.3636 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [254/782] Loss: 0.4545 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [255/782] Loss: 0.4500 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [256/782] Loss: 0.4704 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [257/782] Loss: 0.7339 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [258/782] Loss: 0.3399 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [259/782] Loss: 0.5968 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [260/782] Loss: 0.5497 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [261/782] Loss: 0.5533 | Acc: 83.70%\n",
      "Train Epoch [77/100] Batch [262/782] Loss: 0.6498 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [263/782] Loss: 0.5322 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [264/782] Loss: 0.6082 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [265/782] Loss: 0.4028 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [266/782] Loss: 0.4925 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [267/782] Loss: 0.4256 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [268/782] Loss: 0.5052 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [269/782] Loss: 0.4992 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [270/782] Loss: 0.5302 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [271/782] Loss: 0.3380 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [272/782] Loss: 0.2733 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [273/782] Loss: 0.6070 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [274/782] Loss: 0.3621 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [275/782] Loss: 0.4000 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [276/782] Loss: 0.4303 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [277/782] Loss: 0.4815 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [278/782] Loss: 0.5046 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [279/782] Loss: 0.3869 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [280/782] Loss: 0.5320 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [281/782] Loss: 0.4665 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [282/782] Loss: 0.3541 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [283/782] Loss: 0.3545 | Acc: 83.70%\n",
      "Train Epoch [77/100] Batch [284/782] Loss: 0.4335 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [285/782] Loss: 0.2946 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [286/782] Loss: 0.6254 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [287/782] Loss: 0.5613 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [288/782] Loss: 0.4724 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [289/782] Loss: 0.4355 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [290/782] Loss: 0.3409 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [291/782] Loss: 0.3355 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [292/782] Loss: 0.3926 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [293/782] Loss: 0.3713 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [294/782] Loss: 0.3995 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [295/782] Loss: 0.4792 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [296/782] Loss: 0.5551 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [297/782] Loss: 0.4653 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [298/782] Loss: 0.3732 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [299/782] Loss: 0.4096 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [300/782] Loss: 0.4026 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [301/782] Loss: 0.3019 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [302/782] Loss: 0.3596 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [303/782] Loss: 0.5072 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [304/782] Loss: 0.5960 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [305/782] Loss: 0.4530 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [306/782] Loss: 0.3299 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [307/782] Loss: 0.3456 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [308/782] Loss: 0.3857 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [309/782] Loss: 0.2926 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [310/782] Loss: 0.6005 | Acc: 83.74%\n",
      "Train Epoch [77/100] Batch [311/782] Loss: 0.4302 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [312/782] Loss: 0.5521 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [313/782] Loss: 0.3108 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [314/782] Loss: 0.4243 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [315/782] Loss: 0.4785 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [316/782] Loss: 0.3018 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [317/782] Loss: 0.5781 | Acc: 83.78%\n",
      "Train Epoch [77/100] Batch [318/782] Loss: 0.2762 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [319/782] Loss: 0.4651 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [320/782] Loss: 0.3500 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [321/782] Loss: 0.2919 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [322/782] Loss: 0.3435 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [323/782] Loss: 0.6003 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [324/782] Loss: 0.5411 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [325/782] Loss: 0.5311 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [326/782] Loss: 0.4422 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [327/782] Loss: 0.3413 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [328/782] Loss: 0.3083 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [329/782] Loss: 0.4734 | Acc: 83.87%\n",
      "Train Epoch [77/100] Batch [330/782] Loss: 0.5734 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [331/782] Loss: 0.4279 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [332/782] Loss: 0.6422 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [333/782] Loss: 0.3771 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [334/782] Loss: 0.5342 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [335/782] Loss: 0.2894 | Acc: 83.86%\n",
      "Train Epoch [77/100] Batch [336/782] Loss: 0.2923 | Acc: 83.87%\n",
      "Train Epoch [77/100] Batch [337/782] Loss: 0.3304 | Acc: 83.89%\n",
      "Train Epoch [77/100] Batch [338/782] Loss: 0.4673 | Acc: 83.88%\n",
      "Train Epoch [77/100] Batch [339/782] Loss: 0.5499 | Acc: 83.87%\n",
      "Train Epoch [77/100] Batch [340/782] Loss: 0.4628 | Acc: 83.88%\n",
      "Train Epoch [77/100] Batch [341/782] Loss: 0.6262 | Acc: 83.85%\n",
      "Train Epoch [77/100] Batch [342/782] Loss: 0.5026 | Acc: 83.85%\n",
      "Train Epoch [77/100] Batch [343/782] Loss: 0.5105 | Acc: 83.85%\n",
      "Train Epoch [77/100] Batch [344/782] Loss: 0.4514 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [345/782] Loss: 0.5447 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [346/782] Loss: 0.4317 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [347/782] Loss: 0.5219 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [348/782] Loss: 0.3306 | Acc: 83.83%\n",
      "Train Epoch [77/100] Batch [349/782] Loss: 0.4482 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [350/782] Loss: 0.3728 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [351/782] Loss: 0.5786 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [352/782] Loss: 0.5321 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [353/782] Loss: 0.4704 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [354/782] Loss: 0.5667 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [355/782] Loss: 0.4348 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [356/782] Loss: 0.5049 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [357/782] Loss: 0.4727 | Acc: 83.78%\n",
      "Train Epoch [77/100] Batch [358/782] Loss: 0.5558 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [359/782] Loss: 0.4496 | Acc: 83.78%\n",
      "Train Epoch [77/100] Batch [360/782] Loss: 0.2888 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [361/782] Loss: 0.4296 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [362/782] Loss: 0.4440 | Acc: 83.82%\n",
      "Train Epoch [77/100] Batch [363/782] Loss: 0.4700 | Acc: 83.84%\n",
      "Train Epoch [77/100] Batch [364/782] Loss: 0.5671 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [365/782] Loss: 0.4525 | Acc: 83.81%\n",
      "Train Epoch [77/100] Batch [366/782] Loss: 0.5798 | Acc: 83.79%\n",
      "Train Epoch [77/100] Batch [367/782] Loss: 0.4555 | Acc: 83.80%\n",
      "Train Epoch [77/100] Batch [368/782] Loss: 0.5282 | Acc: 83.78%\n",
      "Train Epoch [77/100] Batch [369/782] Loss: 0.5455 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [370/782] Loss: 0.5078 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [371/782] Loss: 0.4282 | Acc: 83.77%\n",
      "Train Epoch [77/100] Batch [372/782] Loss: 0.5497 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [373/782] Loss: 0.5006 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [374/782] Loss: 0.5874 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [375/782] Loss: 0.6038 | Acc: 83.75%\n",
      "Train Epoch [77/100] Batch [376/782] Loss: 0.3543 | Acc: 83.76%\n",
      "Train Epoch [77/100] Batch [377/782] Loss: 0.6512 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [378/782] Loss: 0.6271 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [379/782] Loss: 0.4818 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [380/782] Loss: 0.3280 | Acc: 83.73%\n",
      "Train Epoch [77/100] Batch [381/782] Loss: 0.5492 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [382/782] Loss: 0.4450 | Acc: 83.72%\n",
      "Train Epoch [77/100] Batch [383/782] Loss: 0.6815 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [384/782] Loss: 0.5268 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [385/782] Loss: 0.6072 | Acc: 83.71%\n",
      "Train Epoch [77/100] Batch [386/782] Loss: 0.4532 | Acc: 83.70%\n",
      "Train Epoch [77/100] Batch [387/782] Loss: 0.4278 | Acc: 83.69%\n",
      "Train Epoch [77/100] Batch [388/782] Loss: 0.5662 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [389/782] Loss: 0.5600 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [390/782] Loss: 0.5230 | Acc: 83.65%\n",
      "Train Epoch [77/100] Batch [391/782] Loss: 0.4227 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [392/782] Loss: 0.4799 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [393/782] Loss: 0.5487 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [394/782] Loss: 0.4349 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [395/782] Loss: 0.4700 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [396/782] Loss: 0.4281 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [397/782] Loss: 0.3803 | Acc: 83.68%\n",
      "Train Epoch [77/100] Batch [398/782] Loss: 0.8073 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [399/782] Loss: 0.4164 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [400/782] Loss: 0.4433 | Acc: 83.67%\n",
      "Train Epoch [77/100] Batch [401/782] Loss: 0.5689 | Acc: 83.66%\n",
      "Train Epoch [77/100] Batch [402/782] Loss: 0.5466 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [403/782] Loss: 0.4708 | Acc: 83.63%\n",
      "Train Epoch [77/100] Batch [404/782] Loss: 0.3501 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [405/782] Loss: 0.4164 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [406/782] Loss: 0.5643 | Acc: 83.64%\n",
      "Train Epoch [77/100] Batch [407/782] Loss: 0.6948 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [408/782] Loss: 0.4266 | Acc: 83.62%\n",
      "Train Epoch [77/100] Batch [409/782] Loss: 0.7848 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [410/782] Loss: 0.4430 | Acc: 83.59%\n",
      "Train Epoch [77/100] Batch [411/782] Loss: 0.3676 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [412/782] Loss: 0.4309 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [413/782] Loss: 0.5491 | Acc: 83.60%\n",
      "Train Epoch [77/100] Batch [414/782] Loss: 0.4094 | Acc: 83.61%\n",
      "Train Epoch [77/100] Batch [415/782] Loss: 0.6707 | Acc: 83.58%\n",
      "Train Epoch [77/100] Batch [416/782] Loss: 0.6359 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [417/782] Loss: 0.5064 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [418/782] Loss: 0.6485 | Acc: 83.57%\n",
      "Train Epoch [77/100] Batch [419/782] Loss: 0.5735 | Acc: 83.55%\n",
      "Train Epoch [77/100] Batch [420/782] Loss: 0.6321 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [421/782] Loss: 0.4226 | Acc: 83.54%\n",
      "Train Epoch [77/100] Batch [422/782] Loss: 0.6405 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [423/782] Loss: 0.3786 | Acc: 83.53%\n",
      "Train Epoch [77/100] Batch [424/782] Loss: 0.3679 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [425/782] Loss: 0.5752 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [426/782] Loss: 0.3920 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [427/782] Loss: 0.3991 | Acc: 83.52%\n",
      "Train Epoch [77/100] Batch [428/782] Loss: 0.5143 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [429/782] Loss: 0.4247 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [430/782] Loss: 0.4588 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [431/782] Loss: 0.4902 | Acc: 83.51%\n",
      "Train Epoch [77/100] Batch [432/782] Loss: 0.8459 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [433/782] Loss: 0.4171 | Acc: 83.48%\n",
      "Train Epoch [77/100] Batch [434/782] Loss: 0.6940 | Acc: 83.46%\n",
      "Train Epoch [77/100] Batch [435/782] Loss: 0.5660 | Acc: 83.46%\n",
      "Train Epoch [77/100] Batch [436/782] Loss: 0.6602 | Acc: 83.45%\n",
      "Train Epoch [77/100] Batch [437/782] Loss: 0.3677 | Acc: 83.46%\n",
      "Train Epoch [77/100] Batch [438/782] Loss: 0.5890 | Acc: 83.45%\n",
      "Train Epoch [77/100] Batch [439/782] Loss: 0.5114 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [440/782] Loss: 0.3919 | Acc: 83.45%\n",
      "Train Epoch [77/100] Batch [441/782] Loss: 0.4061 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [442/782] Loss: 0.7979 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [443/782] Loss: 0.3056 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [444/782] Loss: 0.6181 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [445/782] Loss: 0.4740 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [446/782] Loss: 0.4946 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [447/782] Loss: 0.3529 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [448/782] Loss: 0.6800 | Acc: 83.43%\n",
      "Train Epoch [77/100] Batch [449/782] Loss: 0.4362 | Acc: 83.44%\n",
      "Train Epoch [77/100] Batch [450/782] Loss: 0.5789 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [451/782] Loss: 0.6855 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [452/782] Loss: 0.3200 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [453/782] Loss: 0.2914 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [454/782] Loss: 0.5281 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [455/782] Loss: 0.6004 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [456/782] Loss: 0.5130 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [457/782] Loss: 0.3585 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [458/782] Loss: 0.5370 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [459/782] Loss: 0.5064 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [460/782] Loss: 0.7272 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [461/782] Loss: 0.5618 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [462/782] Loss: 0.3395 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [463/782] Loss: 0.3556 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [464/782] Loss: 0.4536 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [465/782] Loss: 0.4584 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [466/782] Loss: 0.5961 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [467/782] Loss: 0.5739 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [468/782] Loss: 0.4407 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [469/782] Loss: 0.5308 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [470/782] Loss: 0.5073 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [471/782] Loss: 0.6177 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [472/782] Loss: 0.5871 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [473/782] Loss: 0.2772 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [474/782] Loss: 0.4210 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [475/782] Loss: 0.2617 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [476/782] Loss: 0.5393 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [477/782] Loss: 0.5707 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [478/782] Loss: 0.4654 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [479/782] Loss: 0.3943 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [480/782] Loss: 0.4335 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [481/782] Loss: 0.4636 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [482/782] Loss: 0.4652 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [483/782] Loss: 0.5324 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [484/782] Loss: 0.4125 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [485/782] Loss: 0.5170 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [486/782] Loss: 0.4932 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [487/782] Loss: 0.3495 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [488/782] Loss: 0.3960 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [489/782] Loss: 0.4877 | Acc: 83.42%\n",
      "Train Epoch [77/100] Batch [490/782] Loss: 0.6606 | Acc: 83.41%\n",
      "Train Epoch [77/100] Batch [491/782] Loss: 0.5420 | Acc: 83.40%\n",
      "Train Epoch [77/100] Batch [492/782] Loss: 0.4778 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [493/782] Loss: 0.4688 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [494/782] Loss: 0.5517 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [495/782] Loss: 0.4061 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [496/782] Loss: 0.3187 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [497/782] Loss: 0.5391 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [498/782] Loss: 0.4953 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [499/782] Loss: 0.3910 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [500/782] Loss: 0.4299 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [501/782] Loss: 0.3413 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [502/782] Loss: 0.3912 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [503/782] Loss: 0.4063 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [504/782] Loss: 0.5882 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [505/782] Loss: 0.2994 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [506/782] Loss: 0.5915 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [507/782] Loss: 0.7786 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [508/782] Loss: 0.4875 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [509/782] Loss: 0.5051 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [510/782] Loss: 0.3684 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [511/782] Loss: 0.4199 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [512/782] Loss: 0.4523 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [513/782] Loss: 0.5019 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [514/782] Loss: 0.5269 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [515/782] Loss: 0.5278 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [516/782] Loss: 0.5236 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [517/782] Loss: 0.4800 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [518/782] Loss: 0.5180 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [519/782] Loss: 0.4962 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [520/782] Loss: 0.4512 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [521/782] Loss: 0.6433 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [522/782] Loss: 0.2003 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [523/782] Loss: 0.3364 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [524/782] Loss: 0.4336 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [525/782] Loss: 0.4908 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [526/782] Loss: 0.4084 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [527/782] Loss: 0.5430 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [528/782] Loss: 0.4766 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [529/782] Loss: 0.5713 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [530/782] Loss: 0.4475 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [531/782] Loss: 0.4813 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [532/782] Loss: 0.3371 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [533/782] Loss: 0.4199 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [534/782] Loss: 0.5093 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [535/782] Loss: 0.4657 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [536/782] Loss: 0.5425 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [537/782] Loss: 0.3921 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [538/782] Loss: 0.4895 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [539/782] Loss: 0.5315 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [540/782] Loss: 0.4204 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [541/782] Loss: 0.3108 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [542/782] Loss: 0.6734 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [543/782] Loss: 0.5020 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [544/782] Loss: 0.6196 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [545/782] Loss: 0.5198 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [546/782] Loss: 0.3812 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [547/782] Loss: 0.4489 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [548/782] Loss: 0.4850 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [549/782] Loss: 0.3317 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [550/782] Loss: 0.3901 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [551/782] Loss: 0.5427 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [552/782] Loss: 0.5299 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [553/782] Loss: 0.3871 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [554/782] Loss: 0.3588 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [555/782] Loss: 0.6637 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [556/782] Loss: 0.5950 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [557/782] Loss: 0.6384 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [558/782] Loss: 0.5191 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [559/782] Loss: 0.4425 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [560/782] Loss: 0.4811 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [561/782] Loss: 0.2701 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [562/782] Loss: 0.5610 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [563/782] Loss: 0.4656 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [564/782] Loss: 0.5533 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [565/782] Loss: 0.6184 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [566/782] Loss: 0.3431 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [567/782] Loss: 0.5334 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [568/782] Loss: 0.4311 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [569/782] Loss: 0.3449 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [570/782] Loss: 0.3785 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [571/782] Loss: 0.3534 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [572/782] Loss: 0.3638 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [573/782] Loss: 0.7238 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [574/782] Loss: 0.4629 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [575/782] Loss: 0.5183 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [576/782] Loss: 0.5218 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [577/782] Loss: 0.4785 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [578/782] Loss: 0.5271 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [579/782] Loss: 0.4013 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [580/782] Loss: 0.6833 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [581/782] Loss: 0.3469 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [582/782] Loss: 0.4195 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [583/782] Loss: 0.5444 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [584/782] Loss: 0.2502 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [585/782] Loss: 0.5263 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [586/782] Loss: 0.3880 | Acc: 83.30%\n",
      "Train Epoch [77/100] Batch [587/782] Loss: 0.3872 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [588/782] Loss: 0.4581 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [589/782] Loss: 0.3363 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [590/782] Loss: 0.4091 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [591/782] Loss: 0.5414 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [592/782] Loss: 0.3726 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [593/782] Loss: 0.4040 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [594/782] Loss: 0.4946 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [595/782] Loss: 0.3940 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [596/782] Loss: 0.3177 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [597/782] Loss: 0.4032 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [598/782] Loss: 0.4284 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [599/782] Loss: 0.4002 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [600/782] Loss: 0.5540 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [601/782] Loss: 0.4766 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [602/782] Loss: 0.4369 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [603/782] Loss: 0.4496 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [604/782] Loss: 0.4319 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [605/782] Loss: 0.3437 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [606/782] Loss: 0.4192 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [607/782] Loss: 0.5326 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [608/782] Loss: 0.4535 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [609/782] Loss: 0.5909 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [610/782] Loss: 0.3292 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [611/782] Loss: 0.7314 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [612/782] Loss: 0.4395 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [613/782] Loss: 0.4056 | Acc: 83.39%\n",
      "Train Epoch [77/100] Batch [614/782] Loss: 0.6590 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [615/782] Loss: 0.4179 | Acc: 83.38%\n",
      "Train Epoch [77/100] Batch [616/782] Loss: 0.5672 | Acc: 83.37%\n",
      "Train Epoch [77/100] Batch [617/782] Loss: 0.5182 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [618/782] Loss: 0.5627 | Acc: 83.36%\n",
      "Train Epoch [77/100] Batch [619/782] Loss: 0.5765 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [620/782] Loss: 0.5674 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [621/782] Loss: 0.5663 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [622/782] Loss: 0.4264 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [623/782] Loss: 0.6394 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [624/782] Loss: 0.5186 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [625/782] Loss: 0.4564 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [626/782] Loss: 0.3877 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [627/782] Loss: 0.5449 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [628/782] Loss: 0.3329 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [629/782] Loss: 0.3380 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [630/782] Loss: 0.6730 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [631/782] Loss: 0.4617 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [632/782] Loss: 0.4964 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [633/782] Loss: 0.4002 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [634/782] Loss: 0.4097 | Acc: 83.35%\n",
      "Train Epoch [77/100] Batch [635/782] Loss: 0.4836 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [636/782] Loss: 0.5664 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [637/782] Loss: 0.4058 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [638/782] Loss: 0.4918 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [639/782] Loss: 0.4058 | Acc: 83.34%\n",
      "Train Epoch [77/100] Batch [640/782] Loss: 0.5920 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [641/782] Loss: 0.3606 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [642/782] Loss: 0.5277 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [643/782] Loss: 0.4251 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [644/782] Loss: 0.4207 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [645/782] Loss: 0.5034 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [646/782] Loss: 0.5623 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [647/782] Loss: 0.4913 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [648/782] Loss: 0.3965 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [649/782] Loss: 0.5472 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [650/782] Loss: 0.5165 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [651/782] Loss: 0.5103 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [652/782] Loss: 0.5290 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [653/782] Loss: 0.3617 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [654/782] Loss: 0.5837 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [655/782] Loss: 0.7062 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [656/782] Loss: 0.4278 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [657/782] Loss: 0.4198 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [658/782] Loss: 0.5582 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [659/782] Loss: 0.3873 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [660/782] Loss: 0.3164 | Acc: 83.32%\n",
      "Train Epoch [77/100] Batch [661/782] Loss: 0.4952 | Acc: 83.33%\n",
      "Train Epoch [77/100] Batch [662/782] Loss: 0.6367 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [663/782] Loss: 0.5506 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [664/782] Loss: 0.3097 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [665/782] Loss: 0.4107 | Acc: 83.31%\n",
      "Train Epoch [77/100] Batch [666/782] Loss: 0.7392 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [667/782] Loss: 0.6975 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [668/782] Loss: 0.3990 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [669/782] Loss: 0.5056 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [670/782] Loss: 0.5847 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [671/782] Loss: 0.5768 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [672/782] Loss: 0.4423 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [673/782] Loss: 0.3231 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [674/782] Loss: 0.3273 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [675/782] Loss: 0.6220 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [676/782] Loss: 0.4925 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [677/782] Loss: 0.4056 | Acc: 83.29%\n",
      "Train Epoch [77/100] Batch [678/782] Loss: 0.6066 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [679/782] Loss: 0.4015 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [680/782] Loss: 0.4405 | Acc: 83.28%\n",
      "Train Epoch [77/100] Batch [681/782] Loss: 0.4893 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [682/782] Loss: 0.6099 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [683/782] Loss: 0.4160 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [684/782] Loss: 0.4444 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [685/782] Loss: 0.5135 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [686/782] Loss: 0.4673 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [687/782] Loss: 0.3664 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [688/782] Loss: 0.4536 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [689/782] Loss: 0.4353 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [690/782] Loss: 0.4509 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [691/782] Loss: 0.4949 | Acc: 83.25%\n",
      "Train Epoch [77/100] Batch [692/782] Loss: 0.4775 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [693/782] Loss: 0.4070 | Acc: 83.27%\n",
      "Train Epoch [77/100] Batch [694/782] Loss: 0.5476 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [695/782] Loss: 0.5633 | Acc: 83.26%\n",
      "Train Epoch [77/100] Batch [696/782] Loss: 0.5093 | Acc: 83.25%\n",
      "Train Epoch [77/100] Batch [697/782] Loss: 0.5408 | Acc: 83.25%\n",
      "Train Epoch [77/100] Batch [698/782] Loss: 0.5041 | Acc: 83.24%\n",
      "Train Epoch [77/100] Batch [699/782] Loss: 0.6019 | Acc: 83.24%\n",
      "Train Epoch [77/100] Batch [700/782] Loss: 0.5653 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [701/782] Loss: 0.4270 | Acc: 83.24%\n",
      "Train Epoch [77/100] Batch [702/782] Loss: 0.5357 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [703/782] Loss: 0.6018 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [704/782] Loss: 0.4893 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [705/782] Loss: 0.7046 | Acc: 83.22%\n",
      "Train Epoch [77/100] Batch [706/782] Loss: 0.3888 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [707/782] Loss: 0.6587 | Acc: 83.22%\n",
      "Train Epoch [77/100] Batch [708/782] Loss: 0.5042 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [709/782] Loss: 0.4323 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [710/782] Loss: 0.7362 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [711/782] Loss: 0.3102 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [712/782] Loss: 0.4472 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [713/782] Loss: 0.3289 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [714/782] Loss: 0.3858 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [715/782] Loss: 0.7008 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [716/782] Loss: 0.7085 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [717/782] Loss: 0.4025 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [718/782] Loss: 0.3185 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [719/782] Loss: 0.5257 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [720/782] Loss: 0.4865 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [721/782] Loss: 0.5643 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [722/782] Loss: 0.5248 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [723/782] Loss: 0.4485 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [724/782] Loss: 0.4763 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [725/782] Loss: 0.7328 | Acc: 83.17%\n",
      "Train Epoch [77/100] Batch [726/782] Loss: 0.4935 | Acc: 83.17%\n",
      "Train Epoch [77/100] Batch [727/782] Loss: 0.4216 | Acc: 83.17%\n",
      "Train Epoch [77/100] Batch [728/782] Loss: 0.3056 | Acc: 83.17%\n",
      "Train Epoch [77/100] Batch [729/782] Loss: 0.4265 | Acc: 83.17%\n",
      "Train Epoch [77/100] Batch [730/782] Loss: 0.3036 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [731/782] Loss: 0.5703 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [732/782] Loss: 0.5072 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [733/782] Loss: 0.6165 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [734/782] Loss: 0.4639 | Acc: 83.18%\n",
      "Train Epoch [77/100] Batch [735/782] Loss: 0.4308 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [736/782] Loss: 0.4152 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [737/782] Loss: 0.5018 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [738/782] Loss: 0.4426 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [739/782] Loss: 0.3594 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [740/782] Loss: 0.4193 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [741/782] Loss: 0.5158 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [742/782] Loss: 0.3850 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [743/782] Loss: 0.4325 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [744/782] Loss: 0.6364 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [745/782] Loss: 0.4773 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [746/782] Loss: 0.2948 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [747/782] Loss: 0.5716 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [748/782] Loss: 0.3863 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [749/782] Loss: 0.2695 | Acc: 83.22%\n",
      "Train Epoch [77/100] Batch [750/782] Loss: 0.5160 | Acc: 83.22%\n",
      "Train Epoch [77/100] Batch [751/782] Loss: 0.3392 | Acc: 83.23%\n",
      "Train Epoch [77/100] Batch [752/782] Loss: 0.8459 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [753/782] Loss: 0.4659 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [754/782] Loss: 0.3876 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [755/782] Loss: 0.5213 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [756/782] Loss: 0.4354 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [757/782] Loss: 0.4842 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [758/782] Loss: 0.4932 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [759/782] Loss: 0.6509 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [760/782] Loss: 0.5241 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [761/782] Loss: 0.3383 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [762/782] Loss: 0.5657 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [763/782] Loss: 0.4652 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [764/782] Loss: 0.3838 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [765/782] Loss: 0.5064 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [766/782] Loss: 0.2981 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [767/782] Loss: 0.3666 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [768/782] Loss: 0.3985 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [769/782] Loss: 0.4439 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [770/782] Loss: 0.4495 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [771/782] Loss: 0.4985 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [772/782] Loss: 0.3876 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [773/782] Loss: 0.3367 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [774/782] Loss: 0.4161 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [775/782] Loss: 0.4095 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [776/782] Loss: 0.7401 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [777/782] Loss: 0.5220 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [778/782] Loss: 0.4747 | Acc: 83.19%\n",
      "Train Epoch [77/100] Batch [779/782] Loss: 0.3384 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [780/782] Loss: 0.3685 | Acc: 83.21%\n",
      "Train Epoch [77/100] Batch [781/782] Loss: 0.3780 | Acc: 83.20%\n",
      "Train Epoch [77/100] Batch [782/782] Loss: 0.4015 | Acc: 83.20%\n",
      "Epoch 77 completed in 30.40s.\n",
      "Test Epoch [77/100] Loss: 0.9722 | Acc: 72.57% | Inference Time: 8.61s\n",
      "Epoch 77 results saved to CSV.\n",
      "Epoch 78/100\n",
      "Train Epoch [78/100] Batch [1/782] Loss: 0.3921 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [2/782] Loss: 0.3958 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [3/782] Loss: 0.4058 | Acc: 80.21%\n",
      "Train Epoch [78/100] Batch [4/782] Loss: 0.5123 | Acc: 79.69%\n",
      "Train Epoch [78/100] Batch [5/782] Loss: 0.7521 | Acc: 77.81%\n",
      "Train Epoch [78/100] Batch [6/782] Loss: 0.4896 | Acc: 79.43%\n",
      "Train Epoch [78/100] Batch [7/782] Loss: 0.5122 | Acc: 79.46%\n",
      "Train Epoch [78/100] Batch [8/782] Loss: 0.2934 | Acc: 80.86%\n",
      "Train Epoch [78/100] Batch [9/782] Loss: 0.3799 | Acc: 81.42%\n",
      "Train Epoch [78/100] Batch [10/782] Loss: 0.4424 | Acc: 80.94%\n",
      "Train Epoch [78/100] Batch [11/782] Loss: 0.5686 | Acc: 80.68%\n",
      "Train Epoch [78/100] Batch [12/782] Loss: 0.3951 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [13/782] Loss: 0.6255 | Acc: 81.01%\n",
      "Train Epoch [78/100] Batch [14/782] Loss: 0.4662 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [15/782] Loss: 0.6218 | Acc: 81.04%\n",
      "Train Epoch [78/100] Batch [16/782] Loss: 0.3512 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [17/782] Loss: 0.5480 | Acc: 81.25%\n",
      "Train Epoch [78/100] Batch [18/782] Loss: 0.5031 | Acc: 81.16%\n",
      "Train Epoch [78/100] Batch [19/782] Loss: 0.5399 | Acc: 81.17%\n",
      "Train Epoch [78/100] Batch [20/782] Loss: 0.6536 | Acc: 80.70%\n",
      "Train Epoch [78/100] Batch [21/782] Loss: 0.5924 | Acc: 80.80%\n",
      "Train Epoch [78/100] Batch [22/782] Loss: 0.4694 | Acc: 80.89%\n",
      "Train Epoch [78/100] Batch [23/782] Loss: 0.3999 | Acc: 80.98%\n",
      "Train Epoch [78/100] Batch [24/782] Loss: 0.5322 | Acc: 81.12%\n",
      "Train Epoch [78/100] Batch [25/782] Loss: 0.3204 | Acc: 81.44%\n",
      "Train Epoch [78/100] Batch [26/782] Loss: 0.4324 | Acc: 81.67%\n",
      "Train Epoch [78/100] Batch [27/782] Loss: 0.4387 | Acc: 81.89%\n",
      "Train Epoch [78/100] Batch [28/782] Loss: 0.5899 | Acc: 81.86%\n",
      "Train Epoch [78/100] Batch [29/782] Loss: 0.4871 | Acc: 81.90%\n",
      "Train Epoch [78/100] Batch [30/782] Loss: 0.5656 | Acc: 81.93%\n",
      "Train Epoch [78/100] Batch [31/782] Loss: 0.4354 | Acc: 82.06%\n",
      "Train Epoch [78/100] Batch [32/782] Loss: 0.3466 | Acc: 82.28%\n",
      "Train Epoch [78/100] Batch [33/782] Loss: 0.3363 | Acc: 82.43%\n",
      "Train Epoch [78/100] Batch [34/782] Loss: 0.6202 | Acc: 82.26%\n",
      "Train Epoch [78/100] Batch [35/782] Loss: 0.4324 | Acc: 82.32%\n",
      "Train Epoch [78/100] Batch [36/782] Loss: 0.7259 | Acc: 82.20%\n",
      "Train Epoch [78/100] Batch [37/782] Loss: 0.5655 | Acc: 82.09%\n",
      "Train Epoch [78/100] Batch [38/782] Loss: 0.5230 | Acc: 82.03%\n",
      "Train Epoch [78/100] Batch [39/782] Loss: 0.3870 | Acc: 82.13%\n",
      "Train Epoch [78/100] Batch [40/782] Loss: 0.4042 | Acc: 82.27%\n",
      "Train Epoch [78/100] Batch [41/782] Loss: 0.4089 | Acc: 82.39%\n",
      "Train Epoch [78/100] Batch [42/782] Loss: 0.5227 | Acc: 82.33%\n",
      "Train Epoch [78/100] Batch [43/782] Loss: 0.3325 | Acc: 82.49%\n",
      "Train Epoch [78/100] Batch [44/782] Loss: 0.4715 | Acc: 82.56%\n",
      "Train Epoch [78/100] Batch [45/782] Loss: 0.5361 | Acc: 82.57%\n",
      "Train Epoch [78/100] Batch [46/782] Loss: 0.3939 | Acc: 82.64%\n",
      "Train Epoch [78/100] Batch [47/782] Loss: 0.4225 | Acc: 82.78%\n",
      "Train Epoch [78/100] Batch [48/782] Loss: 0.6383 | Acc: 82.81%\n",
      "Train Epoch [78/100] Batch [49/782] Loss: 0.4536 | Acc: 82.88%\n",
      "Train Epoch [78/100] Batch [50/782] Loss: 0.3631 | Acc: 82.94%\n",
      "Train Epoch [78/100] Batch [51/782] Loss: 0.2826 | Acc: 83.09%\n",
      "Train Epoch [78/100] Batch [52/782] Loss: 0.4655 | Acc: 83.11%\n",
      "Train Epoch [78/100] Batch [53/782] Loss: 0.6266 | Acc: 83.05%\n",
      "Train Epoch [78/100] Batch [54/782] Loss: 0.4531 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [55/782] Loss: 0.5403 | Acc: 83.04%\n",
      "Train Epoch [78/100] Batch [56/782] Loss: 0.5431 | Acc: 82.98%\n",
      "Train Epoch [78/100] Batch [57/782] Loss: 0.5269 | Acc: 82.98%\n",
      "Train Epoch [78/100] Batch [58/782] Loss: 0.4127 | Acc: 83.05%\n",
      "Train Epoch [78/100] Batch [59/782] Loss: 0.4989 | Acc: 83.05%\n",
      "Train Epoch [78/100] Batch [60/782] Loss: 0.4434 | Acc: 82.97%\n",
      "Train Epoch [78/100] Batch [61/782] Loss: 0.3898 | Acc: 82.97%\n",
      "Train Epoch [78/100] Batch [62/782] Loss: 0.3162 | Acc: 83.09%\n",
      "Train Epoch [78/100] Batch [63/782] Loss: 0.6735 | Acc: 83.01%\n",
      "Train Epoch [78/100] Batch [64/782] Loss: 0.4063 | Acc: 83.06%\n",
      "Train Epoch [78/100] Batch [65/782] Loss: 0.4761 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [66/782] Loss: 0.4185 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [67/782] Loss: 0.4292 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [68/782] Loss: 0.4356 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [69/782] Loss: 0.5328 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [70/782] Loss: 0.4751 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [71/782] Loss: 0.6527 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [72/782] Loss: 0.2889 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [73/782] Loss: 0.3722 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [74/782] Loss: 0.5139 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [75/782] Loss: 0.5931 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [76/782] Loss: 0.3762 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [77/782] Loss: 0.4731 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [78/782] Loss: 0.5515 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [79/782] Loss: 0.5401 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [80/782] Loss: 0.2936 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [81/782] Loss: 0.5351 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [82/782] Loss: 0.5993 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [83/782] Loss: 0.5574 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [84/782] Loss: 0.4101 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [85/782] Loss: 0.5125 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [86/782] Loss: 0.4291 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [87/782] Loss: 0.5162 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [88/782] Loss: 0.2694 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [89/782] Loss: 0.3663 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [90/782] Loss: 0.3600 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [91/782] Loss: 0.3105 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [92/782] Loss: 0.4400 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [93/782] Loss: 0.4275 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [94/782] Loss: 0.7397 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [95/782] Loss: 0.5999 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [96/782] Loss: 0.4923 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [97/782] Loss: 0.4218 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [98/782] Loss: 0.4196 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [99/782] Loss: 0.4287 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [100/782] Loss: 0.6335 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [101/782] Loss: 0.5279 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [102/782] Loss: 0.5645 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [103/782] Loss: 0.5377 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [104/782] Loss: 0.5284 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [105/782] Loss: 0.3898 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [106/782] Loss: 0.3512 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [107/782] Loss: 0.4491 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [108/782] Loss: 0.3446 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [109/782] Loss: 0.5899 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [110/782] Loss: 0.4555 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [111/782] Loss: 0.4806 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [112/782] Loss: 0.5021 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [113/782] Loss: 0.4255 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [114/782] Loss: 0.3187 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [115/782] Loss: 0.4863 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [116/782] Loss: 0.6069 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [117/782] Loss: 0.4730 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [118/782] Loss: 0.4345 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [119/782] Loss: 0.5884 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [120/782] Loss: 0.2962 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [121/782] Loss: 0.4231 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [122/782] Loss: 0.5489 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [123/782] Loss: 0.2785 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [124/782] Loss: 0.6223 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [125/782] Loss: 0.2751 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [126/782] Loss: 0.5921 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [127/782] Loss: 0.2406 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [128/782] Loss: 0.5172 | Acc: 83.40%\n",
      "Train Epoch [78/100] Batch [129/782] Loss: 0.5449 | Acc: 83.41%\n",
      "Train Epoch [78/100] Batch [130/782] Loss: 0.4478 | Acc: 83.40%\n",
      "Train Epoch [78/100] Batch [131/782] Loss: 0.3869 | Acc: 83.43%\n",
      "Train Epoch [78/100] Batch [132/782] Loss: 0.4026 | Acc: 83.44%\n",
      "Train Epoch [78/100] Batch [133/782] Loss: 0.2864 | Acc: 83.48%\n",
      "Train Epoch [78/100] Batch [134/782] Loss: 0.4189 | Acc: 83.50%\n",
      "Train Epoch [78/100] Batch [135/782] Loss: 0.3883 | Acc: 83.52%\n",
      "Train Epoch [78/100] Batch [136/782] Loss: 0.5987 | Acc: 83.51%\n",
      "Train Epoch [78/100] Batch [137/782] Loss: 0.4676 | Acc: 83.49%\n",
      "Train Epoch [78/100] Batch [138/782] Loss: 0.3273 | Acc: 83.51%\n",
      "Train Epoch [78/100] Batch [139/782] Loss: 0.3901 | Acc: 83.51%\n",
      "Train Epoch [78/100] Batch [140/782] Loss: 0.4907 | Acc: 83.52%\n",
      "Train Epoch [78/100] Batch [141/782] Loss: 0.5105 | Acc: 83.50%\n",
      "Train Epoch [78/100] Batch [142/782] Loss: 0.4655 | Acc: 83.51%\n",
      "Train Epoch [78/100] Batch [143/782] Loss: 0.4906 | Acc: 83.50%\n",
      "Train Epoch [78/100] Batch [144/782] Loss: 0.4868 | Acc: 83.49%\n",
      "Train Epoch [78/100] Batch [145/782] Loss: 0.6115 | Acc: 83.45%\n",
      "Train Epoch [78/100] Batch [146/782] Loss: 0.4075 | Acc: 83.44%\n",
      "Train Epoch [78/100] Batch [147/782] Loss: 0.5461 | Acc: 83.38%\n",
      "Train Epoch [78/100] Batch [148/782] Loss: 0.4603 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [149/782] Loss: 0.4292 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [150/782] Loss: 0.4190 | Acc: 83.42%\n",
      "Train Epoch [78/100] Batch [151/782] Loss: 0.5772 | Acc: 83.41%\n",
      "Train Epoch [78/100] Batch [152/782] Loss: 0.4638 | Acc: 83.41%\n",
      "Train Epoch [78/100] Batch [153/782] Loss: 0.5494 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [154/782] Loss: 0.4265 | Acc: 83.38%\n",
      "Train Epoch [78/100] Batch [155/782] Loss: 0.6509 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [156/782] Loss: 0.4014 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [157/782] Loss: 0.5651 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [158/782] Loss: 0.4301 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [159/782] Loss: 0.4636 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [160/782] Loss: 0.7422 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [161/782] Loss: 0.3529 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [162/782] Loss: 0.3040 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [163/782] Loss: 0.6144 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [164/782] Loss: 0.4576 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [165/782] Loss: 0.3532 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [166/782] Loss: 0.3792 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [167/782] Loss: 0.3288 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [168/782] Loss: 0.5934 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [169/782] Loss: 0.5476 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [170/782] Loss: 0.3704 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [171/782] Loss: 0.3669 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [172/782] Loss: 0.4888 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [173/782] Loss: 0.4010 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [174/782] Loss: 0.4564 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [175/782] Loss: 0.3630 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [176/782] Loss: 0.6381 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [177/782] Loss: 0.5663 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [178/782] Loss: 0.5992 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [179/782] Loss: 0.4936 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [180/782] Loss: 0.6513 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [181/782] Loss: 0.5543 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [182/782] Loss: 0.4597 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [183/782] Loss: 0.3394 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [184/782] Loss: 0.3485 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [185/782] Loss: 0.5524 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [186/782] Loss: 0.5478 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [187/782] Loss: 0.4263 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [188/782] Loss: 0.5987 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [189/782] Loss: 0.7364 | Acc: 83.10%\n",
      "Train Epoch [78/100] Batch [190/782] Loss: 0.4196 | Acc: 83.10%\n",
      "Train Epoch [78/100] Batch [191/782] Loss: 0.1942 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [192/782] Loss: 0.4641 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [193/782] Loss: 0.4698 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [194/782] Loss: 0.7654 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [195/782] Loss: 0.3824 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [196/782] Loss: 0.2768 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [197/782] Loss: 0.4409 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [198/782] Loss: 0.5999 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [199/782] Loss: 0.7083 | Acc: 83.09%\n",
      "Train Epoch [78/100] Batch [200/782] Loss: 0.5670 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [201/782] Loss: 0.5458 | Acc: 83.06%\n",
      "Train Epoch [78/100] Batch [202/782] Loss: 0.3197 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [203/782] Loss: 0.4015 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [204/782] Loss: 0.3940 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [205/782] Loss: 0.4805 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [206/782] Loss: 0.4622 | Acc: 83.11%\n",
      "Train Epoch [78/100] Batch [207/782] Loss: 0.4509 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [208/782] Loss: 0.4449 | Acc: 83.11%\n",
      "Train Epoch [78/100] Batch [209/782] Loss: 0.5191 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [210/782] Loss: 0.3227 | Acc: 83.11%\n",
      "Train Epoch [78/100] Batch [211/782] Loss: 0.6903 | Acc: 83.09%\n",
      "Train Epoch [78/100] Batch [212/782] Loss: 0.3130 | Acc: 83.12%\n",
      "Train Epoch [78/100] Batch [213/782] Loss: 0.6002 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [214/782] Loss: 0.5121 | Acc: 83.06%\n",
      "Train Epoch [78/100] Batch [215/782] Loss: 0.4376 | Acc: 83.07%\n",
      "Train Epoch [78/100] Batch [216/782] Loss: 0.4027 | Acc: 83.08%\n",
      "Train Epoch [78/100] Batch [217/782] Loss: 0.4456 | Acc: 83.10%\n",
      "Train Epoch [78/100] Batch [218/782] Loss: 0.3251 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [219/782] Loss: 0.4005 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [220/782] Loss: 0.4433 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [221/782] Loss: 0.4148 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [222/782] Loss: 0.5429 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [223/782] Loss: 0.4322 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [224/782] Loss: 0.3697 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [225/782] Loss: 0.5089 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [226/782] Loss: 0.6328 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [227/782] Loss: 0.3398 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [228/782] Loss: 0.4522 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [229/782] Loss: 0.5203 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [230/782] Loss: 0.5405 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [231/782] Loss: 0.3565 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [232/782] Loss: 0.4640 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [233/782] Loss: 0.5366 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [234/782] Loss: 0.3811 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [235/782] Loss: 0.5696 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [236/782] Loss: 0.4301 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [237/782] Loss: 0.5157 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [238/782] Loss: 0.4221 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [239/782] Loss: 0.5853 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [240/782] Loss: 0.3622 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [241/782] Loss: 0.5997 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [242/782] Loss: 0.5998 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [243/782] Loss: 0.4924 | Acc: 83.14%\n",
      "Train Epoch [78/100] Batch [244/782] Loss: 0.4012 | Acc: 83.15%\n",
      "Train Epoch [78/100] Batch [245/782] Loss: 0.4677 | Acc: 83.16%\n",
      "Train Epoch [78/100] Batch [246/782] Loss: 0.2929 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [247/782] Loss: 0.2995 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [248/782] Loss: 0.4045 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [249/782] Loss: 0.4775 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [250/782] Loss: 0.4850 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [251/782] Loss: 0.3106 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [252/782] Loss: 0.5169 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [253/782] Loss: 0.4966 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [254/782] Loss: 0.3948 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [255/782] Loss: 0.3692 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [256/782] Loss: 0.3129 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [257/782] Loss: 0.4977 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [258/782] Loss: 0.4242 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [259/782] Loss: 0.5039 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [260/782] Loss: 0.3764 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [261/782] Loss: 0.4353 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [262/782] Loss: 0.2376 | Acc: 83.37%\n",
      "Train Epoch [78/100] Batch [263/782] Loss: 0.4017 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [264/782] Loss: 0.4592 | Acc: 83.38%\n",
      "Train Epoch [78/100] Batch [265/782] Loss: 0.4774 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [266/782] Loss: 0.4952 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [267/782] Loss: 0.5849 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [268/782] Loss: 0.4885 | Acc: 83.38%\n",
      "Train Epoch [78/100] Batch [269/782] Loss: 0.6270 | Acc: 83.37%\n",
      "Train Epoch [78/100] Batch [270/782] Loss: 0.3902 | Acc: 83.39%\n",
      "Train Epoch [78/100] Batch [271/782] Loss: 0.5519 | Acc: 83.40%\n",
      "Train Epoch [78/100] Batch [272/782] Loss: 0.5105 | Acc: 83.40%\n",
      "Train Epoch [78/100] Batch [273/782] Loss: 0.4795 | Acc: 83.38%\n",
      "Train Epoch [78/100] Batch [274/782] Loss: 0.7795 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [275/782] Loss: 0.4251 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [276/782] Loss: 0.6356 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [277/782] Loss: 0.4879 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [278/782] Loss: 0.3425 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [279/782] Loss: 0.5043 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [280/782] Loss: 0.6847 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [281/782] Loss: 0.5675 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [282/782] Loss: 0.5026 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [283/782] Loss: 0.6654 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [284/782] Loss: 0.5037 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [285/782] Loss: 0.4261 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [286/782] Loss: 0.4523 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [287/782] Loss: 0.3808 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [288/782] Loss: 0.5626 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [289/782] Loss: 0.4779 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [290/782] Loss: 0.5111 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [291/782] Loss: 0.4551 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [292/782] Loss: 0.4847 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [293/782] Loss: 0.3225 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [294/782] Loss: 0.3650 | Acc: 83.37%\n",
      "Train Epoch [78/100] Batch [295/782] Loss: 0.5742 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [296/782] Loss: 0.3220 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [297/782] Loss: 0.5334 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [298/782] Loss: 0.4182 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [299/782] Loss: 0.3812 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [300/782] Loss: 0.4172 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [301/782] Loss: 0.4201 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [302/782] Loss: 0.4857 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [303/782] Loss: 0.4641 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [304/782] Loss: 0.3863 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [305/782] Loss: 0.6523 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [306/782] Loss: 0.3170 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [307/782] Loss: 0.5608 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [308/782] Loss: 0.6145 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [309/782] Loss: 0.6828 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [310/782] Loss: 0.3781 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [311/782] Loss: 0.4233 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [312/782] Loss: 0.5538 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [313/782] Loss: 0.5437 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [314/782] Loss: 0.4526 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [315/782] Loss: 0.3620 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [316/782] Loss: 0.4178 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [317/782] Loss: 0.3536 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [318/782] Loss: 0.5219 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [319/782] Loss: 0.5583 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [320/782] Loss: 0.5908 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [321/782] Loss: 0.3140 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [322/782] Loss: 0.5186 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [323/782] Loss: 0.5991 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [324/782] Loss: 0.3520 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [325/782] Loss: 0.5428 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [326/782] Loss: 0.2403 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [327/782] Loss: 0.2896 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [328/782] Loss: 0.5015 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [329/782] Loss: 0.3967 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [330/782] Loss: 0.6078 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [331/782] Loss: 0.3922 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [332/782] Loss: 0.3960 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [333/782] Loss: 0.7771 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [334/782] Loss: 0.3446 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [335/782] Loss: 0.6147 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [336/782] Loss: 0.6105 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [337/782] Loss: 0.4120 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [338/782] Loss: 0.5141 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [339/782] Loss: 0.6303 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [340/782] Loss: 0.5593 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [341/782] Loss: 0.4736 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [342/782] Loss: 0.5193 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [343/782] Loss: 0.5023 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [344/782] Loss: 0.4564 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [345/782] Loss: 0.3806 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [346/782] Loss: 0.6352 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [347/782] Loss: 0.7411 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [348/782] Loss: 0.5417 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [349/782] Loss: 0.4861 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [350/782] Loss: 0.5426 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [351/782] Loss: 0.4342 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [352/782] Loss: 0.4027 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [353/782] Loss: 0.4139 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [354/782] Loss: 0.6539 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [355/782] Loss: 0.5587 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [356/782] Loss: 0.5315 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [357/782] Loss: 0.6118 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [358/782] Loss: 0.3032 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [359/782] Loss: 0.3541 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [360/782] Loss: 0.4900 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [361/782] Loss: 0.5108 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [362/782] Loss: 0.3869 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [363/782] Loss: 0.3031 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [364/782] Loss: 0.4885 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [365/782] Loss: 0.5020 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [366/782] Loss: 0.3652 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [367/782] Loss: 0.3821 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [368/782] Loss: 0.6370 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [369/782] Loss: 0.4672 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [370/782] Loss: 0.4328 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [371/782] Loss: 0.4252 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [372/782] Loss: 0.3223 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [373/782] Loss: 0.4653 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [374/782] Loss: 0.4626 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [375/782] Loss: 0.6462 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [376/782] Loss: 0.3949 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [377/782] Loss: 0.5146 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [378/782] Loss: 0.4292 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [379/782] Loss: 0.3876 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [380/782] Loss: 0.5271 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [381/782] Loss: 0.6771 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [382/782] Loss: 0.5495 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [383/782] Loss: 0.4800 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [384/782] Loss: 0.4583 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [385/782] Loss: 0.7113 | Acc: 83.17%\n",
      "Train Epoch [78/100] Batch [386/782] Loss: 0.3190 | Acc: 83.18%\n",
      "Train Epoch [78/100] Batch [387/782] Loss: 0.2911 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [388/782] Loss: 0.5657 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [389/782] Loss: 0.3920 | Acc: 83.19%\n",
      "Train Epoch [78/100] Batch [390/782] Loss: 0.3347 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [391/782] Loss: 0.4342 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [392/782] Loss: 0.5055 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [393/782] Loss: 0.4005 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [394/782] Loss: 0.4734 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [395/782] Loss: 0.5471 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [396/782] Loss: 0.5285 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [397/782] Loss: 0.5166 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [398/782] Loss: 0.4638 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [399/782] Loss: 0.4228 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [400/782] Loss: 0.4357 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [401/782] Loss: 0.3918 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [402/782] Loss: 0.3478 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [403/782] Loss: 0.3833 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [404/782] Loss: 0.5332 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [405/782] Loss: 0.5186 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [406/782] Loss: 0.3656 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [407/782] Loss: 0.5327 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [408/782] Loss: 0.4431 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [409/782] Loss: 0.3743 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [410/782] Loss: 0.3585 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [411/782] Loss: 0.3443 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [412/782] Loss: 0.4994 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [413/782] Loss: 0.4594 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [414/782] Loss: 0.3800 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [415/782] Loss: 0.6633 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [416/782] Loss: 0.3321 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [417/782] Loss: 0.3925 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [418/782] Loss: 0.5618 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [419/782] Loss: 0.3720 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [420/782] Loss: 0.4375 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [421/782] Loss: 0.4701 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [422/782] Loss: 0.4263 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [423/782] Loss: 0.5284 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [424/782] Loss: 0.3656 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [425/782] Loss: 0.4395 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [426/782] Loss: 0.7519 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [427/782] Loss: 0.4607 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [428/782] Loss: 0.5607 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [429/782] Loss: 0.6393 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [430/782] Loss: 0.4313 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [431/782] Loss: 0.4157 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [432/782] Loss: 0.3860 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [433/782] Loss: 0.4748 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [434/782] Loss: 0.2052 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [435/782] Loss: 0.3777 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [436/782] Loss: 0.6037 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [437/782] Loss: 0.3714 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [438/782] Loss: 0.6100 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [439/782] Loss: 0.4248 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [440/782] Loss: 0.5668 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [441/782] Loss: 0.4462 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [442/782] Loss: 0.3779 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [443/782] Loss: 0.5256 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [444/782] Loss: 0.5607 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [445/782] Loss: 0.5304 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [446/782] Loss: 0.4362 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [447/782] Loss: 0.6764 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [448/782] Loss: 0.4981 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [449/782] Loss: 0.4990 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [450/782] Loss: 0.4364 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [451/782] Loss: 0.2571 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [452/782] Loss: 0.6466 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [453/782] Loss: 0.5887 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [454/782] Loss: 0.5353 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [455/782] Loss: 0.4064 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [456/782] Loss: 0.4574 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [457/782] Loss: 0.4763 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [458/782] Loss: 0.4409 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [459/782] Loss: 0.5369 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [460/782] Loss: 0.5083 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [461/782] Loss: 0.3952 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [462/782] Loss: 0.5488 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [463/782] Loss: 0.4752 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [464/782] Loss: 0.3687 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [465/782] Loss: 0.4874 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [466/782] Loss: 0.4122 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [467/782] Loss: 0.3736 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [468/782] Loss: 0.3084 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [469/782] Loss: 0.3949 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [470/782] Loss: 0.3656 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [471/782] Loss: 0.3544 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [472/782] Loss: 0.2798 | Acc: 83.37%\n",
      "Train Epoch [78/100] Batch [473/782] Loss: 0.5852 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [474/782] Loss: 0.4480 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [475/782] Loss: 0.5942 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [476/782] Loss: 0.3728 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [477/782] Loss: 0.4584 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [478/782] Loss: 0.3995 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [479/782] Loss: 0.5899 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [480/782] Loss: 0.5344 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [481/782] Loss: 0.3523 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [482/782] Loss: 0.4486 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [483/782] Loss: 0.4876 | Acc: 83.37%\n",
      "Train Epoch [78/100] Batch [484/782] Loss: 0.3634 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [485/782] Loss: 0.6883 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [486/782] Loss: 0.3102 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [487/782] Loss: 0.4503 | Acc: 83.35%\n",
      "Train Epoch [78/100] Batch [488/782] Loss: 0.4437 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [489/782] Loss: 0.5201 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [490/782] Loss: 0.4796 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [491/782] Loss: 0.4378 | Acc: 83.36%\n",
      "Train Epoch [78/100] Batch [492/782] Loss: 0.7247 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [493/782] Loss: 0.7472 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [494/782] Loss: 0.3681 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [495/782] Loss: 0.5544 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [496/782] Loss: 0.4041 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [497/782] Loss: 0.3097 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [498/782] Loss: 0.3939 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [499/782] Loss: 0.4337 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [500/782] Loss: 0.4518 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [501/782] Loss: 0.4641 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [502/782] Loss: 0.3696 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [503/782] Loss: 0.5367 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [504/782] Loss: 0.5596 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [505/782] Loss: 0.5356 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [506/782] Loss: 0.3451 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [507/782] Loss: 0.2723 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [508/782] Loss: 0.4547 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [509/782] Loss: 0.6545 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [510/782] Loss: 0.3507 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [511/782] Loss: 0.5571 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [512/782] Loss: 0.7493 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [513/782] Loss: 0.4463 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [514/782] Loss: 0.4356 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [515/782] Loss: 0.4569 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [516/782] Loss: 0.4589 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [517/782] Loss: 0.3953 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [518/782] Loss: 0.4214 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [519/782] Loss: 0.4476 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [520/782] Loss: 0.5414 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [521/782] Loss: 0.4360 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [522/782] Loss: 0.4872 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [523/782] Loss: 0.4834 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [524/782] Loss: 0.4523 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [525/782] Loss: 0.3549 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [526/782] Loss: 0.5467 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [527/782] Loss: 0.3129 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [528/782] Loss: 0.4793 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [529/782] Loss: 0.3403 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [530/782] Loss: 0.5493 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [531/782] Loss: 0.3596 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [532/782] Loss: 0.4244 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [533/782] Loss: 0.3640 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [534/782] Loss: 0.5045 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [535/782] Loss: 0.5152 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [536/782] Loss: 0.4644 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [537/782] Loss: 0.5688 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [538/782] Loss: 0.5541 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [539/782] Loss: 0.2748 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [540/782] Loss: 0.5947 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [541/782] Loss: 0.4560 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [542/782] Loss: 0.3379 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [543/782] Loss: 0.3942 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [544/782] Loss: 0.4493 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [545/782] Loss: 0.3228 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [546/782] Loss: 0.5839 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [547/782] Loss: 0.4740 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [548/782] Loss: 0.5001 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [549/782] Loss: 0.4555 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [550/782] Loss: 0.7016 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [551/782] Loss: 0.3783 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [552/782] Loss: 0.4661 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [553/782] Loss: 0.3828 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [554/782] Loss: 0.5667 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [555/782] Loss: 0.6362 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [556/782] Loss: 0.3672 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [557/782] Loss: 0.4590 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [558/782] Loss: 0.5001 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [559/782] Loss: 0.4893 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [560/782] Loss: 0.6650 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [561/782] Loss: 0.4226 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [562/782] Loss: 0.5216 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [563/782] Loss: 0.3466 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [564/782] Loss: 0.2750 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [565/782] Loss: 0.6464 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [566/782] Loss: 0.3122 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [567/782] Loss: 0.4421 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [568/782] Loss: 0.3502 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [569/782] Loss: 0.3768 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [570/782] Loss: 0.5549 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [571/782] Loss: 0.4656 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [572/782] Loss: 0.3175 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [573/782] Loss: 0.3918 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [574/782] Loss: 0.5564 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [575/782] Loss: 0.4673 | Acc: 83.34%\n",
      "Train Epoch [78/100] Batch [576/782] Loss: 0.5433 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [577/782] Loss: 0.7029 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [578/782] Loss: 0.4441 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [579/782] Loss: 0.6098 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [580/782] Loss: 0.4877 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [581/782] Loss: 0.5474 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [582/782] Loss: 0.3997 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [583/782] Loss: 0.4313 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [584/782] Loss: 0.4821 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [585/782] Loss: 0.4373 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [586/782] Loss: 0.4847 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [587/782] Loss: 0.4219 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [588/782] Loss: 0.4351 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [589/782] Loss: 0.4002 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [590/782] Loss: 0.3399 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [591/782] Loss: 0.3831 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [592/782] Loss: 0.4654 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [593/782] Loss: 0.4747 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [594/782] Loss: 0.3369 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [595/782] Loss: 0.4600 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [596/782] Loss: 0.5575 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [597/782] Loss: 0.4215 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [598/782] Loss: 0.3325 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [599/782] Loss: 0.6138 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [600/782] Loss: 0.4575 | Acc: 83.28%\n",
      "Train Epoch [78/100] Batch [601/782] Loss: 0.7028 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [602/782] Loss: 0.4101 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [603/782] Loss: 0.5558 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [604/782] Loss: 0.4046 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [605/782] Loss: 0.2999 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [606/782] Loss: 0.4850 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [607/782] Loss: 0.3408 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [608/782] Loss: 0.2667 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [609/782] Loss: 0.3730 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [610/782] Loss: 0.4042 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [611/782] Loss: 0.3415 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [612/782] Loss: 0.4946 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [613/782] Loss: 0.5421 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [614/782] Loss: 0.5466 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [615/782] Loss: 0.4647 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [616/782] Loss: 0.4406 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [617/782] Loss: 0.3896 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [618/782] Loss: 0.4317 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [619/782] Loss: 0.6022 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [620/782] Loss: 0.3789 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [621/782] Loss: 0.4666 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [622/782] Loss: 0.7169 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [623/782] Loss: 0.4407 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [624/782] Loss: 0.5027 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [625/782] Loss: 0.4062 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [626/782] Loss: 0.4871 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [627/782] Loss: 0.4478 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [628/782] Loss: 0.4267 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [629/782] Loss: 0.4628 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [630/782] Loss: 0.5870 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [631/782] Loss: 0.5814 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [632/782] Loss: 0.4652 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [633/782] Loss: 0.3763 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [634/782] Loss: 0.5284 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [635/782] Loss: 0.4318 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [636/782] Loss: 0.4070 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [637/782] Loss: 0.6370 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [638/782] Loss: 0.2941 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [639/782] Loss: 0.5964 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [640/782] Loss: 0.7820 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [641/782] Loss: 0.5040 | Acc: 83.30%\n",
      "Train Epoch [78/100] Batch [642/782] Loss: 0.4634 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [643/782] Loss: 0.2641 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [644/782] Loss: 0.3198 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [645/782] Loss: 0.5636 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [646/782] Loss: 0.3897 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [647/782] Loss: 0.6109 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [648/782] Loss: 0.3378 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [649/782] Loss: 0.5220 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [650/782] Loss: 0.4497 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [651/782] Loss: 0.5058 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [652/782] Loss: 0.4802 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [653/782] Loss: 0.3820 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [654/782] Loss: 0.4431 | Acc: 83.33%\n",
      "Train Epoch [78/100] Batch [655/782] Loss: 0.4285 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [656/782] Loss: 0.3752 | Acc: 83.32%\n",
      "Train Epoch [78/100] Batch [657/782] Loss: 0.6360 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [658/782] Loss: 0.4988 | Acc: 83.31%\n",
      "Train Epoch [78/100] Batch [659/782] Loss: 0.7062 | Acc: 83.29%\n",
      "Train Epoch [78/100] Batch [660/782] Loss: 1.0232 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [661/782] Loss: 0.4636 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [662/782] Loss: 0.4722 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [663/782] Loss: 0.3802 | Acc: 83.27%\n",
      "Train Epoch [78/100] Batch [664/782] Loss: 0.6354 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [665/782] Loss: 0.4503 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [666/782] Loss: 0.4757 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [667/782] Loss: 0.3762 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [668/782] Loss: 0.6504 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [669/782] Loss: 0.4344 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [670/782] Loss: 0.5678 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [671/782] Loss: 0.5731 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [672/782] Loss: 0.5069 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [673/782] Loss: 0.5121 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [674/782] Loss: 0.6219 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [675/782] Loss: 0.3431 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [676/782] Loss: 0.4435 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [677/782] Loss: 0.3275 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [678/782] Loss: 0.5521 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [679/782] Loss: 0.4113 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [680/782] Loss: 0.4631 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [681/782] Loss: 0.4489 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [682/782] Loss: 0.4057 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [683/782] Loss: 0.4637 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [684/782] Loss: 0.5557 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [685/782] Loss: 0.2940 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [686/782] Loss: 0.5354 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [687/782] Loss: 0.5584 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [688/782] Loss: 0.4155 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [689/782] Loss: 0.3701 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [690/782] Loss: 0.4493 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [691/782] Loss: 0.6651 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [692/782] Loss: 0.5016 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [693/782] Loss: 0.4990 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [694/782] Loss: 0.3332 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [695/782] Loss: 0.4756 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [696/782] Loss: 0.2914 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [697/782] Loss: 0.3963 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [698/782] Loss: 0.4528 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [699/782] Loss: 0.5802 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [700/782] Loss: 0.3663 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [701/782] Loss: 0.5116 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [702/782] Loss: 0.4946 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [703/782] Loss: 0.4702 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [704/782] Loss: 0.4484 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [705/782] Loss: 0.4446 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [706/782] Loss: 0.4548 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [707/782] Loss: 0.4105 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [708/782] Loss: 0.4282 | Acc: 83.26%\n",
      "Train Epoch [78/100] Batch [709/782] Loss: 0.5857 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [710/782] Loss: 0.5842 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [711/782] Loss: 0.4647 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [712/782] Loss: 0.4890 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [713/782] Loss: 0.4964 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [714/782] Loss: 0.4182 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [715/782] Loss: 0.4758 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [716/782] Loss: 0.5989 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [717/782] Loss: 0.5608 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [718/782] Loss: 0.6110 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [719/782] Loss: 0.5627 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [720/782] Loss: 0.5751 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [721/782] Loss: 0.5996 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [722/782] Loss: 0.4651 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [723/782] Loss: 0.4241 | Acc: 83.20%\n",
      "Train Epoch [78/100] Batch [724/782] Loss: 0.3141 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [725/782] Loss: 0.4076 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [726/782] Loss: 0.5272 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [727/782] Loss: 0.4703 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [728/782] Loss: 0.4729 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [729/782] Loss: 0.4274 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [730/782] Loss: 0.3426 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [731/782] Loss: 0.4401 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [732/782] Loss: 0.3940 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [733/782] Loss: 0.5384 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [734/782] Loss: 0.5029 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [735/782] Loss: 0.5224 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [736/782] Loss: 0.4947 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [737/782] Loss: 0.4082 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [738/782] Loss: 0.4143 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [739/782] Loss: 0.4019 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [740/782] Loss: 0.3228 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [741/782] Loss: 0.3690 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [742/782] Loss: 0.4155 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [743/782] Loss: 0.4165 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [744/782] Loss: 0.5523 | Acc: 83.21%\n",
      "Train Epoch [78/100] Batch [745/782] Loss: 0.4809 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [746/782] Loss: 0.4638 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [747/782] Loss: 0.3515 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [748/782] Loss: 0.3636 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [749/782] Loss: 0.6365 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [750/782] Loss: 0.5739 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [751/782] Loss: 0.4069 | Acc: 83.22%\n",
      "Train Epoch [78/100] Batch [752/782] Loss: 0.3631 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [753/782] Loss: 0.4966 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [754/782] Loss: 0.3846 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [755/782] Loss: 0.5557 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [756/782] Loss: 0.3579 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [757/782] Loss: 0.4231 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [758/782] Loss: 0.6827 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [759/782] Loss: 0.2969 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [760/782] Loss: 0.3216 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [761/782] Loss: 0.5714 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [762/782] Loss: 0.6336 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [763/782] Loss: 0.3271 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [764/782] Loss: 0.5396 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [765/782] Loss: 0.5713 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [766/782] Loss: 0.5824 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [767/782] Loss: 0.5816 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [768/782] Loss: 0.3771 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [769/782] Loss: 0.5123 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [770/782] Loss: 0.5447 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [771/782] Loss: 0.3993 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [772/782] Loss: 0.5115 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [773/782] Loss: 0.4341 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [774/782] Loss: 0.4485 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [775/782] Loss: 0.5095 | Acc: 83.25%\n",
      "Train Epoch [78/100] Batch [776/782] Loss: 0.5612 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [777/782] Loss: 0.4973 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [778/782] Loss: 0.5065 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [779/782] Loss: 0.4660 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [780/782] Loss: 0.4473 | Acc: 83.23%\n",
      "Train Epoch [78/100] Batch [781/782] Loss: 0.3451 | Acc: 83.24%\n",
      "Train Epoch [78/100] Batch [782/782] Loss: 0.2957 | Acc: 83.24%\n",
      "Epoch 78 completed in 30.78s.\n",
      "Test Epoch [78/100] Loss: 0.9611 | Acc: 72.44% | Inference Time: 8.38s\n",
      "Epoch 78 results saved to CSV.\n",
      "Epoch 79/100\n",
      "Train Epoch [79/100] Batch [1/782] Loss: 0.4027 | Acc: 87.50%\n",
      "Train Epoch [79/100] Batch [2/782] Loss: 0.5263 | Acc: 86.72%\n",
      "Train Epoch [79/100] Batch [3/782] Loss: 0.4677 | Acc: 84.90%\n",
      "Train Epoch [79/100] Batch [4/782] Loss: 0.2415 | Acc: 86.33%\n",
      "Train Epoch [79/100] Batch [5/782] Loss: 0.5170 | Acc: 84.69%\n",
      "Train Epoch [79/100] Batch [6/782] Loss: 0.3390 | Acc: 85.16%\n",
      "Train Epoch [79/100] Batch [7/782] Loss: 0.4774 | Acc: 84.38%\n",
      "Train Epoch [79/100] Batch [8/782] Loss: 0.3540 | Acc: 85.16%\n",
      "Train Epoch [79/100] Batch [9/782] Loss: 0.4573 | Acc: 84.55%\n",
      "Train Epoch [79/100] Batch [10/782] Loss: 0.6476 | Acc: 83.75%\n",
      "Train Epoch [79/100] Batch [11/782] Loss: 0.4445 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [12/782] Loss: 0.4917 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [13/782] Loss: 0.4190 | Acc: 83.65%\n",
      "Train Epoch [79/100] Batch [14/782] Loss: 0.3834 | Acc: 83.82%\n",
      "Train Epoch [79/100] Batch [15/782] Loss: 0.3857 | Acc: 84.06%\n",
      "Train Epoch [79/100] Batch [16/782] Loss: 0.4067 | Acc: 84.28%\n",
      "Train Epoch [79/100] Batch [17/782] Loss: 0.2985 | Acc: 84.74%\n",
      "Train Epoch [79/100] Batch [18/782] Loss: 0.3675 | Acc: 84.72%\n",
      "Train Epoch [79/100] Batch [19/782] Loss: 0.4238 | Acc: 84.54%\n",
      "Train Epoch [79/100] Batch [20/782] Loss: 0.5305 | Acc: 84.45%\n",
      "Train Epoch [79/100] Batch [21/782] Loss: 0.4262 | Acc: 84.38%\n",
      "Train Epoch [79/100] Batch [22/782] Loss: 0.7452 | Acc: 84.09%\n",
      "Train Epoch [79/100] Batch [23/782] Loss: 0.4712 | Acc: 84.04%\n",
      "Train Epoch [79/100] Batch [24/782] Loss: 0.5926 | Acc: 83.92%\n",
      "Train Epoch [79/100] Batch [25/782] Loss: 0.5878 | Acc: 83.75%\n",
      "Train Epoch [79/100] Batch [26/782] Loss: 0.4625 | Acc: 83.71%\n",
      "Train Epoch [79/100] Batch [27/782] Loss: 0.6295 | Acc: 83.74%\n",
      "Train Epoch [79/100] Batch [28/782] Loss: 0.6498 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [29/782] Loss: 0.5412 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [30/782] Loss: 0.3815 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [31/782] Loss: 0.5957 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [32/782] Loss: 0.4884 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [33/782] Loss: 0.6925 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [34/782] Loss: 0.5325 | Acc: 83.18%\n",
      "Train Epoch [79/100] Batch [35/782] Loss: 0.3968 | Acc: 83.30%\n",
      "Train Epoch [79/100] Batch [36/782] Loss: 0.5174 | Acc: 83.16%\n",
      "Train Epoch [79/100] Batch [37/782] Loss: 0.4416 | Acc: 83.19%\n",
      "Train Epoch [79/100] Batch [38/782] Loss: 0.3398 | Acc: 83.31%\n",
      "Train Epoch [79/100] Batch [39/782] Loss: 0.4761 | Acc: 83.17%\n",
      "Train Epoch [79/100] Batch [40/782] Loss: 0.5645 | Acc: 83.09%\n",
      "Train Epoch [79/100] Batch [41/782] Loss: 0.4306 | Acc: 83.19%\n",
      "Train Epoch [79/100] Batch [42/782] Loss: 0.5349 | Acc: 83.18%\n",
      "Train Epoch [79/100] Batch [43/782] Loss: 0.2757 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [44/782] Loss: 0.3840 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [45/782] Loss: 0.5315 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [46/782] Loss: 0.6297 | Acc: 83.22%\n",
      "Train Epoch [79/100] Batch [47/782] Loss: 0.4642 | Acc: 83.21%\n",
      "Train Epoch [79/100] Batch [48/782] Loss: 0.4046 | Acc: 83.33%\n",
      "Train Epoch [79/100] Batch [49/782] Loss: 0.3417 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [50/782] Loss: 0.4152 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [51/782] Loss: 0.5685 | Acc: 83.64%\n",
      "Train Epoch [79/100] Batch [52/782] Loss: 0.4614 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [53/782] Loss: 0.4878 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [54/782] Loss: 0.3191 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [55/782] Loss: 0.3190 | Acc: 83.72%\n",
      "Train Epoch [79/100] Batch [56/782] Loss: 0.3701 | Acc: 83.71%\n",
      "Train Epoch [79/100] Batch [57/782] Loss: 0.4660 | Acc: 83.74%\n",
      "Train Epoch [79/100] Batch [58/782] Loss: 0.4482 | Acc: 83.76%\n",
      "Train Epoch [79/100] Batch [59/782] Loss: 0.6544 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [60/782] Loss: 0.4024 | Acc: 83.65%\n",
      "Train Epoch [79/100] Batch [61/782] Loss: 0.5719 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [62/782] Loss: 0.4842 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [63/782] Loss: 0.4978 | Acc: 83.31%\n",
      "Train Epoch [79/100] Batch [64/782] Loss: 0.3177 | Acc: 83.35%\n",
      "Train Epoch [79/100] Batch [65/782] Loss: 0.5704 | Acc: 83.20%\n",
      "Train Epoch [79/100] Batch [66/782] Loss: 0.6440 | Acc: 83.05%\n",
      "Train Epoch [79/100] Batch [67/782] Loss: 0.4233 | Acc: 83.05%\n",
      "Train Epoch [79/100] Batch [68/782] Loss: 0.5649 | Acc: 82.97%\n",
      "Train Epoch [79/100] Batch [69/782] Loss: 0.4721 | Acc: 82.99%\n",
      "Train Epoch [79/100] Batch [70/782] Loss: 0.4846 | Acc: 83.01%\n",
      "Train Epoch [79/100] Batch [71/782] Loss: 0.4495 | Acc: 82.94%\n",
      "Train Epoch [79/100] Batch [72/782] Loss: 0.4561 | Acc: 82.99%\n",
      "Train Epoch [79/100] Batch [73/782] Loss: 0.3250 | Acc: 83.05%\n",
      "Train Epoch [79/100] Batch [74/782] Loss: 0.6766 | Acc: 82.92%\n",
      "Train Epoch [79/100] Batch [75/782] Loss: 0.4396 | Acc: 82.90%\n",
      "Train Epoch [79/100] Batch [76/782] Loss: 0.6296 | Acc: 82.81%\n",
      "Train Epoch [79/100] Batch [77/782] Loss: 0.5349 | Acc: 82.69%\n",
      "Train Epoch [79/100] Batch [78/782] Loss: 0.4171 | Acc: 82.71%\n",
      "Train Epoch [79/100] Batch [79/782] Loss: 0.5219 | Acc: 82.69%\n",
      "Train Epoch [79/100] Batch [80/782] Loss: 0.5589 | Acc: 82.64%\n",
      "Train Epoch [79/100] Batch [81/782] Loss: 0.4750 | Acc: 82.62%\n",
      "Train Epoch [79/100] Batch [82/782] Loss: 0.6310 | Acc: 82.53%\n",
      "Train Epoch [79/100] Batch [83/782] Loss: 0.2759 | Acc: 82.62%\n",
      "Train Epoch [79/100] Batch [84/782] Loss: 0.3950 | Acc: 82.68%\n",
      "Train Epoch [79/100] Batch [85/782] Loss: 0.3790 | Acc: 82.74%\n",
      "Train Epoch [79/100] Batch [86/782] Loss: 0.7092 | Acc: 82.58%\n",
      "Train Epoch [79/100] Batch [87/782] Loss: 0.4551 | Acc: 82.63%\n",
      "Train Epoch [79/100] Batch [88/782] Loss: 0.5109 | Acc: 82.62%\n",
      "Train Epoch [79/100] Batch [89/782] Loss: 0.4709 | Acc: 82.65%\n",
      "Train Epoch [79/100] Batch [90/782] Loss: 0.5256 | Acc: 82.67%\n",
      "Train Epoch [79/100] Batch [91/782] Loss: 0.4008 | Acc: 82.68%\n",
      "Train Epoch [79/100] Batch [92/782] Loss: 0.5926 | Acc: 82.68%\n",
      "Train Epoch [79/100] Batch [93/782] Loss: 0.5653 | Acc: 82.64%\n",
      "Train Epoch [79/100] Batch [94/782] Loss: 0.2429 | Acc: 82.75%\n",
      "Train Epoch [79/100] Batch [95/782] Loss: 0.5417 | Acc: 82.71%\n",
      "Train Epoch [79/100] Batch [96/782] Loss: 0.4499 | Acc: 82.73%\n",
      "Train Epoch [79/100] Batch [97/782] Loss: 0.4221 | Acc: 82.73%\n",
      "Train Epoch [79/100] Batch [98/782] Loss: 0.4343 | Acc: 82.72%\n",
      "Train Epoch [79/100] Batch [99/782] Loss: 0.3999 | Acc: 82.78%\n",
      "Train Epoch [79/100] Batch [100/782] Loss: 0.5422 | Acc: 82.80%\n",
      "Train Epoch [79/100] Batch [101/782] Loss: 0.4618 | Acc: 82.80%\n",
      "Train Epoch [79/100] Batch [102/782] Loss: 0.4964 | Acc: 82.77%\n",
      "Train Epoch [79/100] Batch [103/782] Loss: 0.4161 | Acc: 82.78%\n",
      "Train Epoch [79/100] Batch [104/782] Loss: 0.4283 | Acc: 82.77%\n",
      "Train Epoch [79/100] Batch [105/782] Loss: 0.4583 | Acc: 82.83%\n",
      "Train Epoch [79/100] Batch [106/782] Loss: 0.4708 | Acc: 82.84%\n",
      "Train Epoch [79/100] Batch [107/782] Loss: 0.5609 | Acc: 82.81%\n",
      "Train Epoch [79/100] Batch [108/782] Loss: 0.3188 | Acc: 82.87%\n",
      "Train Epoch [79/100] Batch [109/782] Loss: 0.4889 | Acc: 82.87%\n",
      "Train Epoch [79/100] Batch [110/782] Loss: 0.5557 | Acc: 82.86%\n",
      "Train Epoch [79/100] Batch [111/782] Loss: 0.3718 | Acc: 82.91%\n",
      "Train Epoch [79/100] Batch [112/782] Loss: 0.5243 | Acc: 82.94%\n",
      "Train Epoch [79/100] Batch [113/782] Loss: 0.5173 | Acc: 82.88%\n",
      "Train Epoch [79/100] Batch [114/782] Loss: 0.4935 | Acc: 82.89%\n",
      "Train Epoch [79/100] Batch [115/782] Loss: 0.5674 | Acc: 82.87%\n",
      "Train Epoch [79/100] Batch [116/782] Loss: 0.3171 | Acc: 82.92%\n",
      "Train Epoch [79/100] Batch [117/782] Loss: 0.4571 | Acc: 82.96%\n",
      "Train Epoch [79/100] Batch [118/782] Loss: 0.4585 | Acc: 82.97%\n",
      "Train Epoch [79/100] Batch [119/782] Loss: 0.3408 | Acc: 83.01%\n",
      "Train Epoch [79/100] Batch [120/782] Loss: 0.4622 | Acc: 83.07%\n",
      "Train Epoch [79/100] Batch [121/782] Loss: 0.6108 | Acc: 83.03%\n",
      "Train Epoch [79/100] Batch [122/782] Loss: 0.3077 | Acc: 83.07%\n",
      "Train Epoch [79/100] Batch [123/782] Loss: 0.4427 | Acc: 83.09%\n",
      "Train Epoch [79/100] Batch [124/782] Loss: 0.3953 | Acc: 83.11%\n",
      "Train Epoch [79/100] Batch [125/782] Loss: 0.3874 | Acc: 83.15%\n",
      "Train Epoch [79/100] Batch [126/782] Loss: 0.3340 | Acc: 83.16%\n",
      "Train Epoch [79/100] Batch [127/782] Loss: 0.5227 | Acc: 83.12%\n",
      "Train Epoch [79/100] Batch [128/782] Loss: 0.6113 | Acc: 83.08%\n",
      "Train Epoch [79/100] Batch [129/782] Loss: 0.3308 | Acc: 83.12%\n",
      "Train Epoch [79/100] Batch [130/782] Loss: 0.3474 | Acc: 83.16%\n",
      "Train Epoch [79/100] Batch [131/782] Loss: 0.2188 | Acc: 83.24%\n",
      "Train Epoch [79/100] Batch [132/782] Loss: 0.4212 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [133/782] Loss: 0.5268 | Acc: 83.27%\n",
      "Train Epoch [79/100] Batch [134/782] Loss: 0.4578 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [135/782] Loss: 0.4134 | Acc: 83.31%\n",
      "Train Epoch [79/100] Batch [136/782] Loss: 0.4624 | Acc: 83.30%\n",
      "Train Epoch [79/100] Batch [137/782] Loss: 0.4240 | Acc: 83.34%\n",
      "Train Epoch [79/100] Batch [138/782] Loss: 0.2739 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [139/782] Loss: 0.4539 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [140/782] Loss: 0.6066 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [141/782] Loss: 0.5594 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [142/782] Loss: 0.5087 | Acc: 83.33%\n",
      "Train Epoch [79/100] Batch [143/782] Loss: 0.4244 | Acc: 83.34%\n",
      "Train Epoch [79/100] Batch [144/782] Loss: 0.3622 | Acc: 83.37%\n",
      "Train Epoch [79/100] Batch [145/782] Loss: 0.4791 | Acc: 83.36%\n",
      "Train Epoch [79/100] Batch [146/782] Loss: 0.6423 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [147/782] Loss: 0.4092 | Acc: 83.31%\n",
      "Train Epoch [79/100] Batch [148/782] Loss: 0.5836 | Acc: 83.26%\n",
      "Train Epoch [79/100] Batch [149/782] Loss: 0.3561 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [150/782] Loss: 0.4922 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [151/782] Loss: 0.5047 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [152/782] Loss: 0.3103 | Acc: 83.31%\n",
      "Train Epoch [79/100] Batch [153/782] Loss: 0.4572 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [154/782] Loss: 0.5494 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [155/782] Loss: 0.3140 | Acc: 83.32%\n",
      "Train Epoch [79/100] Batch [156/782] Loss: 0.4729 | Acc: 83.32%\n",
      "Train Epoch [79/100] Batch [157/782] Loss: 0.4552 | Acc: 83.33%\n",
      "Train Epoch [79/100] Batch [158/782] Loss: 0.7770 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [159/782] Loss: 0.4189 | Acc: 83.27%\n",
      "Train Epoch [79/100] Batch [160/782] Loss: 0.4353 | Acc: 83.25%\n",
      "Train Epoch [79/100] Batch [161/782] Loss: 0.4012 | Acc: 83.28%\n",
      "Train Epoch [79/100] Batch [162/782] Loss: 0.3598 | Acc: 83.29%\n",
      "Train Epoch [79/100] Batch [163/782] Loss: 0.6121 | Acc: 83.24%\n",
      "Train Epoch [79/100] Batch [164/782] Loss: 0.4997 | Acc: 83.23%\n",
      "Train Epoch [79/100] Batch [165/782] Loss: 0.3259 | Acc: 83.26%\n",
      "Train Epoch [79/100] Batch [166/782] Loss: 0.4744 | Acc: 83.27%\n",
      "Train Epoch [79/100] Batch [167/782] Loss: 0.3095 | Acc: 83.32%\n",
      "Train Epoch [79/100] Batch [168/782] Loss: 0.5850 | Acc: 83.30%\n",
      "Train Epoch [79/100] Batch [169/782] Loss: 0.4749 | Acc: 83.30%\n",
      "Train Epoch [79/100] Batch [170/782] Loss: 0.5295 | Acc: 83.30%\n",
      "Train Epoch [79/100] Batch [171/782] Loss: 0.3357 | Acc: 83.32%\n",
      "Train Epoch [79/100] Batch [172/782] Loss: 0.3764 | Acc: 83.34%\n",
      "Train Epoch [79/100] Batch [173/782] Loss: 0.3872 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [174/782] Loss: 0.4893 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [175/782] Loss: 0.2592 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [176/782] Loss: 0.3609 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [177/782] Loss: 0.3927 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [178/782] Loss: 0.3439 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [179/782] Loss: 0.4747 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [180/782] Loss: 0.6554 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [181/782] Loss: 0.3079 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [182/782] Loss: 0.4772 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [183/782] Loss: 0.3796 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [184/782] Loss: 0.6081 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [185/782] Loss: 0.3003 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [186/782] Loss: 0.4049 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [187/782] Loss: 0.4903 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [188/782] Loss: 0.4705 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [189/782] Loss: 0.4002 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [190/782] Loss: 0.3086 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [191/782] Loss: 0.5308 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [192/782] Loss: 0.3909 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [193/782] Loss: 0.3721 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [194/782] Loss: 0.5505 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [195/782] Loss: 0.4160 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [196/782] Loss: 0.6771 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [197/782] Loss: 0.3237 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [198/782] Loss: 0.5253 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [199/782] Loss: 0.4939 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [200/782] Loss: 0.5041 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [201/782] Loss: 0.5804 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [202/782] Loss: 0.6807 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [203/782] Loss: 0.4121 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [204/782] Loss: 0.4829 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [205/782] Loss: 0.5538 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [206/782] Loss: 0.3732 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [207/782] Loss: 0.3410 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [208/782] Loss: 0.4100 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [209/782] Loss: 0.3515 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [210/782] Loss: 0.6990 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [211/782] Loss: 0.3893 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [212/782] Loss: 0.4558 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [213/782] Loss: 0.5253 | Acc: 83.36%\n",
      "Train Epoch [79/100] Batch [214/782] Loss: 0.3625 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [215/782] Loss: 0.3596 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [216/782] Loss: 0.4192 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [217/782] Loss: 0.4576 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [218/782] Loss: 0.4699 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [219/782] Loss: 0.3050 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [220/782] Loss: 0.2464 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [221/782] Loss: 0.4032 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [222/782] Loss: 0.4085 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [223/782] Loss: 0.4920 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [224/782] Loss: 0.5025 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [225/782] Loss: 0.3647 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [226/782] Loss: 0.4414 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [227/782] Loss: 0.4584 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [228/782] Loss: 0.5272 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [229/782] Loss: 0.4935 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [230/782] Loss: 0.5281 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [231/782] Loss: 0.3685 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [232/782] Loss: 0.4406 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [233/782] Loss: 0.6827 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [234/782] Loss: 0.5380 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [235/782] Loss: 0.3071 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [236/782] Loss: 0.6142 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [237/782] Loss: 0.5012 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [238/782] Loss: 0.4184 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [239/782] Loss: 0.4100 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [240/782] Loss: 0.4188 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [241/782] Loss: 0.3763 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [242/782] Loss: 0.7546 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [243/782] Loss: 0.7158 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [244/782] Loss: 0.6502 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [245/782] Loss: 0.4229 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [246/782] Loss: 0.4121 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [247/782] Loss: 0.5045 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [248/782] Loss: 0.4063 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [249/782] Loss: 0.5541 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [250/782] Loss: 0.3513 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [251/782] Loss: 0.4997 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [252/782] Loss: 0.5841 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [253/782] Loss: 0.4818 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [254/782] Loss: 0.5253 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [255/782] Loss: 0.3635 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [256/782] Loss: 0.3196 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [257/782] Loss: 0.5964 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [258/782] Loss: 0.3559 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [259/782] Loss: 0.3396 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [260/782] Loss: 0.3836 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [261/782] Loss: 0.5408 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [262/782] Loss: 0.3929 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [263/782] Loss: 0.5233 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [264/782] Loss: 0.4976 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [265/782] Loss: 0.5149 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [266/782] Loss: 0.4339 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [267/782] Loss: 0.4336 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [268/782] Loss: 0.3468 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [269/782] Loss: 0.4332 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [270/782] Loss: 0.3149 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [271/782] Loss: 0.2302 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [272/782] Loss: 0.4279 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [273/782] Loss: 0.5018 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [274/782] Loss: 0.4595 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [275/782] Loss: 0.4323 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [276/782] Loss: 0.4234 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [277/782] Loss: 0.5853 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [278/782] Loss: 0.6218 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [279/782] Loss: 0.5037 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [280/782] Loss: 0.6315 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [281/782] Loss: 0.3411 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [282/782] Loss: 0.2658 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [283/782] Loss: 0.5776 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [284/782] Loss: 0.4701 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [285/782] Loss: 0.5074 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [286/782] Loss: 0.3432 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [287/782] Loss: 0.6012 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [288/782] Loss: 0.5572 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [289/782] Loss: 0.3697 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [290/782] Loss: 0.5142 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [291/782] Loss: 0.4736 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [292/782] Loss: 0.3565 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [293/782] Loss: 0.3753 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [294/782] Loss: 0.3086 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [295/782] Loss: 0.6349 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [296/782] Loss: 0.3490 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [297/782] Loss: 0.4254 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [298/782] Loss: 0.3705 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [299/782] Loss: 0.4295 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [300/782] Loss: 0.4380 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [301/782] Loss: 0.2939 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [302/782] Loss: 0.4286 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [303/782] Loss: 0.5271 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [304/782] Loss: 0.3334 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [305/782] Loss: 0.4431 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [306/782] Loss: 0.2575 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [307/782] Loss: 0.5942 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [308/782] Loss: 0.5156 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [309/782] Loss: 0.4468 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [310/782] Loss: 0.4234 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [311/782] Loss: 0.4125 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [312/782] Loss: 0.3509 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [313/782] Loss: 0.3752 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [314/782] Loss: 0.3514 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [315/782] Loss: 0.5137 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [316/782] Loss: 0.5451 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [317/782] Loss: 0.3637 | Acc: 83.60%\n",
      "Train Epoch [79/100] Batch [318/782] Loss: 0.5363 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [319/782] Loss: 0.5239 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [320/782] Loss: 0.6239 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [321/782] Loss: 0.4120 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [322/782] Loss: 0.4714 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [323/782] Loss: 0.5512 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [324/782] Loss: 0.3941 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [325/782] Loss: 0.3572 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [326/782] Loss: 0.4857 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [327/782] Loss: 0.4821 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [328/782] Loss: 0.4964 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [329/782] Loss: 0.3009 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [330/782] Loss: 0.3296 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [331/782] Loss: 0.3397 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [332/782] Loss: 0.3600 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [333/782] Loss: 0.5939 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [334/782] Loss: 0.5321 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [335/782] Loss: 0.4163 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [336/782] Loss: 0.5245 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [337/782] Loss: 0.3823 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [338/782] Loss: 0.5285 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [339/782] Loss: 0.4419 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [340/782] Loss: 0.6044 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [341/782] Loss: 0.5134 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [342/782] Loss: 0.4957 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [343/782] Loss: 0.3390 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [344/782] Loss: 0.4689 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [345/782] Loss: 0.3367 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [346/782] Loss: 0.4958 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [347/782] Loss: 0.3465 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [348/782] Loss: 0.5245 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [349/782] Loss: 0.4010 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [350/782] Loss: 0.4897 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [351/782] Loss: 0.3526 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [352/782] Loss: 0.3578 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [353/782] Loss: 0.6904 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [354/782] Loss: 0.6089 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [355/782] Loss: 0.4890 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [356/782] Loss: 0.6335 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [357/782] Loss: 0.5129 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [358/782] Loss: 0.4022 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [359/782] Loss: 0.5267 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [360/782] Loss: 0.3609 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [361/782] Loss: 0.4793 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [362/782] Loss: 0.3478 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [363/782] Loss: 0.4499 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [364/782] Loss: 0.3139 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [365/782] Loss: 0.6105 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [366/782] Loss: 0.5992 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [367/782] Loss: 0.6440 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [368/782] Loss: 0.4671 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [369/782] Loss: 0.5612 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [370/782] Loss: 0.3327 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [371/782] Loss: 0.4298 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [372/782] Loss: 0.3507 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [373/782] Loss: 0.4501 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [374/782] Loss: 0.4406 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [375/782] Loss: 0.4151 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [376/782] Loss: 0.3908 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [377/782] Loss: 0.3046 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [378/782] Loss: 0.3140 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [379/782] Loss: 0.3643 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [380/782] Loss: 0.4122 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [381/782] Loss: 0.4056 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [382/782] Loss: 0.6647 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [383/782] Loss: 0.6638 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [384/782] Loss: 0.3487 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [385/782] Loss: 0.3902 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [386/782] Loss: 0.3824 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [387/782] Loss: 0.4045 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [388/782] Loss: 0.3800 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [389/782] Loss: 0.3729 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [390/782] Loss: 0.6686 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [391/782] Loss: 0.3580 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [392/782] Loss: 0.4723 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [393/782] Loss: 0.5201 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [394/782] Loss: 0.4177 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [395/782] Loss: 0.3294 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [396/782] Loss: 0.5347 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [397/782] Loss: 0.4116 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [398/782] Loss: 0.4189 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [399/782] Loss: 0.3937 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [400/782] Loss: 0.3912 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [401/782] Loss: 0.3733 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [402/782] Loss: 0.5881 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [403/782] Loss: 0.5544 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [404/782] Loss: 0.2987 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [405/782] Loss: 0.5535 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [406/782] Loss: 0.6015 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [407/782] Loss: 0.4661 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [408/782] Loss: 0.4995 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [409/782] Loss: 0.4018 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [410/782] Loss: 0.6970 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [411/782] Loss: 0.4084 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [412/782] Loss: 0.5811 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [413/782] Loss: 0.6826 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [414/782] Loss: 0.6487 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [415/782] Loss: 0.3682 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [416/782] Loss: 0.4889 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [417/782] Loss: 0.5461 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [418/782] Loss: 0.6654 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [419/782] Loss: 0.5070 | Acc: 83.36%\n",
      "Train Epoch [79/100] Batch [420/782] Loss: 0.2976 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [421/782] Loss: 0.5481 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [422/782] Loss: 0.4378 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [423/782] Loss: 0.4864 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [424/782] Loss: 0.1601 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [425/782] Loss: 0.3193 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [426/782] Loss: 0.5414 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [427/782] Loss: 0.4293 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [428/782] Loss: 0.2455 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [429/782] Loss: 0.4705 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [430/782] Loss: 0.3765 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [431/782] Loss: 0.4431 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [432/782] Loss: 0.4120 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [433/782] Loss: 0.4513 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [434/782] Loss: 0.3596 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [435/782] Loss: 0.4947 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [436/782] Loss: 0.4161 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [437/782] Loss: 0.4977 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [438/782] Loss: 0.5295 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [439/782] Loss: 0.3824 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [440/782] Loss: 0.4178 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [441/782] Loss: 0.4859 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [442/782] Loss: 0.6558 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [443/782] Loss: 0.4606 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [444/782] Loss: 0.4130 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [445/782] Loss: 0.3125 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [446/782] Loss: 0.5804 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [447/782] Loss: 0.3762 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [448/782] Loss: 0.4686 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [449/782] Loss: 0.4652 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [450/782] Loss: 0.3651 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [451/782] Loss: 0.4984 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [452/782] Loss: 0.2965 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [453/782] Loss: 0.4226 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [454/782] Loss: 0.4423 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [455/782] Loss: 0.5247 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [456/782] Loss: 0.2793 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [457/782] Loss: 0.4345 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [458/782] Loss: 0.4035 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [459/782] Loss: 0.3560 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [460/782] Loss: 0.3132 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [461/782] Loss: 0.3300 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [462/782] Loss: 0.3515 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [463/782] Loss: 0.5843 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [464/782] Loss: 0.4246 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [465/782] Loss: 0.4655 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [466/782] Loss: 0.4954 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [467/782] Loss: 0.3469 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [468/782] Loss: 0.6240 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [469/782] Loss: 0.3508 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [470/782] Loss: 0.3082 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [471/782] Loss: 0.4136 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [472/782] Loss: 0.6763 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [473/782] Loss: 0.4806 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [474/782] Loss: 0.5607 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [475/782] Loss: 0.4943 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [476/782] Loss: 0.4149 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [477/782] Loss: 0.4098 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [478/782] Loss: 0.4064 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [479/782] Loss: 0.5333 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [480/782] Loss: 0.5719 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [481/782] Loss: 0.3988 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [482/782] Loss: 0.4490 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [483/782] Loss: 0.5381 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [484/782] Loss: 0.4115 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [485/782] Loss: 0.4401 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [486/782] Loss: 0.5748 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [487/782] Loss: 0.4846 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [488/782] Loss: 0.7204 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [489/782] Loss: 0.3900 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [490/782] Loss: 0.3297 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [491/782] Loss: 0.7377 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [492/782] Loss: 0.4351 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [493/782] Loss: 0.4134 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [494/782] Loss: 0.4034 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [495/782] Loss: 0.2817 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [496/782] Loss: 0.6052 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [497/782] Loss: 0.4952 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [498/782] Loss: 0.3847 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [499/782] Loss: 0.4678 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [500/782] Loss: 0.4735 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [501/782] Loss: 0.6475 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [502/782] Loss: 0.6614 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [503/782] Loss: 0.5274 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [504/782] Loss: 0.6352 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [505/782] Loss: 0.3792 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [506/782] Loss: 0.3666 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [507/782] Loss: 0.4957 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [508/782] Loss: 0.4842 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [509/782] Loss: 0.3565 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [510/782] Loss: 0.4595 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [511/782] Loss: 0.4157 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [512/782] Loss: 0.4132 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [513/782] Loss: 0.4179 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [514/782] Loss: 0.4114 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [515/782] Loss: 0.3439 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [516/782] Loss: 0.2974 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [517/782] Loss: 0.3008 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [518/782] Loss: 0.4182 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [519/782] Loss: 0.4185 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [520/782] Loss: 0.2999 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [521/782] Loss: 0.4164 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [522/782] Loss: 0.5475 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [523/782] Loss: 0.4459 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [524/782] Loss: 0.4500 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [525/782] Loss: 0.5868 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [526/782] Loss: 0.4619 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [527/782] Loss: 0.4773 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [528/782] Loss: 0.7345 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [529/782] Loss: 0.3992 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [530/782] Loss: 0.4281 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [531/782] Loss: 0.4111 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [532/782] Loss: 0.4150 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [533/782] Loss: 0.3613 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [534/782] Loss: 0.6092 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [535/782] Loss: 0.3854 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [536/782] Loss: 0.6157 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [537/782] Loss: 0.3268 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [538/782] Loss: 0.3771 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [539/782] Loss: 0.5255 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [540/782] Loss: 0.4273 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [541/782] Loss: 0.4571 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [542/782] Loss: 0.2417 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [543/782] Loss: 0.3554 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [544/782] Loss: 0.4999 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [545/782] Loss: 0.3335 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [546/782] Loss: 0.4074 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [547/782] Loss: 0.3243 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [548/782] Loss: 0.3982 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [549/782] Loss: 0.3679 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [550/782] Loss: 0.3727 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [551/782] Loss: 0.4053 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [552/782] Loss: 0.4593 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [553/782] Loss: 0.3030 | Acc: 83.60%\n",
      "Train Epoch [79/100] Batch [554/782] Loss: 0.4995 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [555/782] Loss: 0.4486 | Acc: 83.59%\n",
      "Train Epoch [79/100] Batch [556/782] Loss: 0.4231 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [557/782] Loss: 0.4631 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [558/782] Loss: 0.4997 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [559/782] Loss: 0.4155 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [560/782] Loss: 0.4712 | Acc: 83.58%\n",
      "Train Epoch [79/100] Batch [561/782] Loss: 0.5837 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [562/782] Loss: 0.4502 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [563/782] Loss: 0.4608 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [564/782] Loss: 0.6363 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [565/782] Loss: 0.2832 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [566/782] Loss: 0.4123 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [567/782] Loss: 0.5933 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [568/782] Loss: 0.5074 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [569/782] Loss: 0.3454 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [570/782] Loss: 0.4527 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [571/782] Loss: 0.3958 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [572/782] Loss: 0.4341 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [573/782] Loss: 0.4116 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [574/782] Loss: 0.3636 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [575/782] Loss: 0.4957 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [576/782] Loss: 0.5426 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [577/782] Loss: 0.3724 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [578/782] Loss: 0.5316 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [579/782] Loss: 0.3540 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [580/782] Loss: 0.4858 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [581/782] Loss: 0.6050 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [582/782] Loss: 0.4736 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [583/782] Loss: 0.4430 | Acc: 83.57%\n",
      "Train Epoch [79/100] Batch [584/782] Loss: 0.6708 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [585/782] Loss: 0.5461 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [586/782] Loss: 0.4371 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [587/782] Loss: 0.3732 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [588/782] Loss: 0.3956 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [589/782] Loss: 0.5462 | Acc: 83.56%\n",
      "Train Epoch [79/100] Batch [590/782] Loss: 0.6737 | Acc: 83.55%\n",
      "Train Epoch [79/100] Batch [591/782] Loss: 0.5490 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [592/782] Loss: 0.6660 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [593/782] Loss: 0.3863 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [594/782] Loss: 0.2400 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [595/782] Loss: 0.3834 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [596/782] Loss: 0.3098 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [597/782] Loss: 0.4808 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [598/782] Loss: 0.4949 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [599/782] Loss: 0.4389 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [600/782] Loss: 0.2994 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [601/782] Loss: 0.3917 | Acc: 83.54%\n",
      "Train Epoch [79/100] Batch [602/782] Loss: 0.6081 | Acc: 83.53%\n",
      "Train Epoch [79/100] Batch [603/782] Loss: 0.5520 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [604/782] Loss: 0.4211 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [605/782] Loss: 0.4919 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [606/782] Loss: 0.5644 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [607/782] Loss: 0.5976 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [608/782] Loss: 0.4197 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [609/782] Loss: 0.5063 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [610/782] Loss: 0.5272 | Acc: 83.52%\n",
      "Train Epoch [79/100] Batch [611/782] Loss: 0.6340 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [612/782] Loss: 0.5784 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [613/782] Loss: 0.5159 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [614/782] Loss: 0.5692 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [615/782] Loss: 0.4351 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [616/782] Loss: 0.4053 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [617/782] Loss: 0.4172 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [618/782] Loss: 0.3420 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [619/782] Loss: 0.4039 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [620/782] Loss: 0.5170 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [621/782] Loss: 0.7225 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [622/782] Loss: 0.3308 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [623/782] Loss: 0.3589 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [624/782] Loss: 0.2818 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [625/782] Loss: 0.4601 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [626/782] Loss: 0.3894 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [627/782] Loss: 0.7052 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [628/782] Loss: 0.3837 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [629/782] Loss: 0.4114 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [630/782] Loss: 0.3880 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [631/782] Loss: 0.4273 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [632/782] Loss: 0.3450 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [633/782] Loss: 0.6461 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [634/782] Loss: 0.5418 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [635/782] Loss: 0.4096 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [636/782] Loss: 0.5606 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [637/782] Loss: 0.3678 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [638/782] Loss: 0.5701 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [639/782] Loss: 0.2975 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [640/782] Loss: 0.4928 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [641/782] Loss: 0.5127 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [642/782] Loss: 0.6322 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [643/782] Loss: 0.3085 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [644/782] Loss: 0.4227 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [645/782] Loss: 0.4507 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [646/782] Loss: 0.4330 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [647/782] Loss: 0.4642 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [648/782] Loss: 0.3724 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [649/782] Loss: 0.6150 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [650/782] Loss: 0.2477 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [651/782] Loss: 0.4351 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [652/782] Loss: 0.4446 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [653/782] Loss: 0.4022 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [654/782] Loss: 0.5201 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [655/782] Loss: 0.4237 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [656/782] Loss: 0.4451 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [657/782] Loss: 0.6453 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [658/782] Loss: 0.2150 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [659/782] Loss: 0.5127 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [660/782] Loss: 0.3844 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [661/782] Loss: 0.4677 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [662/782] Loss: 0.6330 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [663/782] Loss: 0.5695 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [664/782] Loss: 0.5949 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [665/782] Loss: 0.5149 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [666/782] Loss: 0.5031 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [667/782] Loss: 0.2713 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [668/782] Loss: 0.2446 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [669/782] Loss: 0.3982 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [670/782] Loss: 0.4473 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [671/782] Loss: 0.5953 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [672/782] Loss: 0.4152 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [673/782] Loss: 0.3370 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [674/782] Loss: 0.4366 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [675/782] Loss: 0.4923 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [676/782] Loss: 0.4850 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [677/782] Loss: 0.4889 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [678/782] Loss: 0.7276 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [679/782] Loss: 0.5368 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [680/782] Loss: 0.3197 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [681/782] Loss: 0.3716 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [682/782] Loss: 0.5166 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [683/782] Loss: 0.4816 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [684/782] Loss: 0.3652 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [685/782] Loss: 0.5179 | Acc: 83.51%\n",
      "Train Epoch [79/100] Batch [686/782] Loss: 0.6353 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [687/782] Loss: 0.5573 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [688/782] Loss: 0.3334 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [689/782] Loss: 0.4363 | Acc: 83.50%\n",
      "Train Epoch [79/100] Batch [690/782] Loss: 0.6817 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [691/782] Loss: 0.3254 | Acc: 83.49%\n",
      "Train Epoch [79/100] Batch [692/782] Loss: 0.6816 | Acc: 83.48%\n",
      "Train Epoch [79/100] Batch [693/782] Loss: 0.6466 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [694/782] Loss: 0.4028 | Acc: 83.47%\n",
      "Train Epoch [79/100] Batch [695/782] Loss: 0.5596 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [696/782] Loss: 0.3025 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [697/782] Loss: 0.5893 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [698/782] Loss: 0.3700 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [699/782] Loss: 0.4250 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [700/782] Loss: 0.4619 | Acc: 83.46%\n",
      "Train Epoch [79/100] Batch [701/782] Loss: 0.5155 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [702/782] Loss: 0.3801 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [703/782] Loss: 0.5022 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [704/782] Loss: 0.5607 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [705/782] Loss: 0.4546 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [706/782] Loss: 0.4342 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [707/782] Loss: 0.4343 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [708/782] Loss: 0.6101 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [709/782] Loss: 0.3816 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [710/782] Loss: 0.4981 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [711/782] Loss: 0.4891 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [712/782] Loss: 0.2817 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [713/782] Loss: 0.5329 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [714/782] Loss: 0.4777 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [715/782] Loss: 0.5183 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [716/782] Loss: 0.4150 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [717/782] Loss: 0.5311 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [718/782] Loss: 0.4734 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [719/782] Loss: 0.6294 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [720/782] Loss: 0.4078 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [721/782] Loss: 0.3444 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [722/782] Loss: 0.6307 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [723/782] Loss: 0.5182 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [724/782] Loss: 0.5375 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [725/782] Loss: 0.4304 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [726/782] Loss: 0.4302 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [727/782] Loss: 0.5301 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [728/782] Loss: 0.5062 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [729/782] Loss: 0.3949 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [730/782] Loss: 0.5209 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [731/782] Loss: 0.5438 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [732/782] Loss: 0.2736 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [733/782] Loss: 0.4502 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [734/782] Loss: 0.5499 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [735/782] Loss: 0.3560 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [736/782] Loss: 0.4371 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [737/782] Loss: 0.4255 | Acc: 83.45%\n",
      "Train Epoch [79/100] Batch [738/782] Loss: 0.5233 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [739/782] Loss: 0.4725 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [740/782] Loss: 0.4405 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [741/782] Loss: 0.5043 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [742/782] Loss: 0.4009 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [743/782] Loss: 0.4026 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [744/782] Loss: 0.4433 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [745/782] Loss: 0.2668 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [746/782] Loss: 0.4693 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [747/782] Loss: 0.4996 | Acc: 83.44%\n",
      "Train Epoch [79/100] Batch [748/782] Loss: 0.6028 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [749/782] Loss: 0.6136 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [750/782] Loss: 0.6563 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [751/782] Loss: 0.3799 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [752/782] Loss: 0.3516 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [753/782] Loss: 0.4151 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [754/782] Loss: 0.4523 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [755/782] Loss: 0.4069 | Acc: 83.43%\n",
      "Train Epoch [79/100] Batch [756/782] Loss: 0.5336 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [757/782] Loss: 0.6101 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [758/782] Loss: 0.5937 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [759/782] Loss: 0.4604 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [760/782] Loss: 0.3185 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [761/782] Loss: 0.5005 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [762/782] Loss: 0.6052 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [763/782] Loss: 0.5577 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [764/782] Loss: 0.2989 | Acc: 83.42%\n",
      "Train Epoch [79/100] Batch [765/782] Loss: 0.5733 | Acc: 83.41%\n",
      "Train Epoch [79/100] Batch [766/782] Loss: 0.4898 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [767/782] Loss: 0.4740 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [768/782] Loss: 0.4797 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [769/782] Loss: 0.6306 | Acc: 83.40%\n",
      "Train Epoch [79/100] Batch [770/782] Loss: 0.4769 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [771/782] Loss: 0.4185 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [772/782] Loss: 0.4418 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [773/782] Loss: 0.3970 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [774/782] Loss: 0.7019 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [775/782] Loss: 0.5073 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [776/782] Loss: 0.2837 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [777/782] Loss: 0.5587 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [778/782] Loss: 0.4157 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [779/782] Loss: 0.4301 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [780/782] Loss: 0.4630 | Acc: 83.39%\n",
      "Train Epoch [79/100] Batch [781/782] Loss: 0.5889 | Acc: 83.38%\n",
      "Train Epoch [79/100] Batch [782/782] Loss: 0.3567 | Acc: 83.38%\n",
      "Epoch 79 completed in 30.69s.\n",
      "Test Epoch [79/100] Loss: 0.9721 | Acc: 72.61% | Inference Time: 8.50s\n",
      "Epoch 79 results saved to CSV.\n",
      "Epoch 80/100\n",
      "Train Epoch [80/100] Batch [1/782] Loss: 0.3339 | Acc: 92.19%\n",
      "Train Epoch [80/100] Batch [2/782] Loss: 0.3387 | Acc: 87.50%\n",
      "Train Epoch [80/100] Batch [3/782] Loss: 0.5811 | Acc: 85.42%\n",
      "Train Epoch [80/100] Batch [4/782] Loss: 0.5164 | Acc: 84.77%\n",
      "Train Epoch [80/100] Batch [5/782] Loss: 0.5011 | Acc: 84.38%\n",
      "Train Epoch [80/100] Batch [6/782] Loss: 0.5853 | Acc: 84.11%\n",
      "Train Epoch [80/100] Batch [7/782] Loss: 0.4388 | Acc: 83.93%\n",
      "Train Epoch [80/100] Batch [8/782] Loss: 0.5406 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [9/782] Loss: 0.5372 | Acc: 82.64%\n",
      "Train Epoch [80/100] Batch [10/782] Loss: 0.7549 | Acc: 82.50%\n",
      "Train Epoch [80/100] Batch [11/782] Loss: 0.4761 | Acc: 82.10%\n",
      "Train Epoch [80/100] Batch [12/782] Loss: 0.4982 | Acc: 81.90%\n",
      "Train Epoch [80/100] Batch [13/782] Loss: 0.3753 | Acc: 82.21%\n",
      "Train Epoch [80/100] Batch [14/782] Loss: 0.2420 | Acc: 82.81%\n",
      "Train Epoch [80/100] Batch [15/782] Loss: 0.5044 | Acc: 82.71%\n",
      "Train Epoch [80/100] Batch [16/782] Loss: 0.4132 | Acc: 82.71%\n",
      "Train Epoch [80/100] Batch [17/782] Loss: 0.6284 | Acc: 82.54%\n",
      "Train Epoch [80/100] Batch [18/782] Loss: 0.4804 | Acc: 82.47%\n",
      "Train Epoch [80/100] Batch [19/782] Loss: 0.5105 | Acc: 82.15%\n",
      "Train Epoch [80/100] Batch [20/782] Loss: 0.5940 | Acc: 82.34%\n",
      "Train Epoch [80/100] Batch [21/782] Loss: 0.4149 | Acc: 82.59%\n",
      "Train Epoch [80/100] Batch [22/782] Loss: 0.5509 | Acc: 82.53%\n",
      "Train Epoch [80/100] Batch [23/782] Loss: 0.5630 | Acc: 82.40%\n",
      "Train Epoch [80/100] Batch [24/782] Loss: 0.6766 | Acc: 82.10%\n",
      "Train Epoch [80/100] Batch [25/782] Loss: 0.4352 | Acc: 82.25%\n",
      "Train Epoch [80/100] Batch [26/782] Loss: 0.6561 | Acc: 81.79%\n",
      "Train Epoch [80/100] Batch [27/782] Loss: 0.3153 | Acc: 81.94%\n",
      "Train Epoch [80/100] Batch [28/782] Loss: 0.3302 | Acc: 82.25%\n",
      "Train Epoch [80/100] Batch [29/782] Loss: 0.5769 | Acc: 82.22%\n",
      "Train Epoch [80/100] Batch [30/782] Loss: 0.3695 | Acc: 82.50%\n",
      "Train Epoch [80/100] Batch [31/782] Loss: 0.4584 | Acc: 82.56%\n",
      "Train Epoch [80/100] Batch [32/782] Loss: 0.5795 | Acc: 82.42%\n",
      "Train Epoch [80/100] Batch [33/782] Loss: 0.2011 | Acc: 82.77%\n",
      "Train Epoch [80/100] Batch [34/782] Loss: 0.3104 | Acc: 83.04%\n",
      "Train Epoch [80/100] Batch [35/782] Loss: 0.4077 | Acc: 83.08%\n",
      "Train Epoch [80/100] Batch [36/782] Loss: 0.4534 | Acc: 83.12%\n",
      "Train Epoch [80/100] Batch [37/782] Loss: 0.4475 | Acc: 83.15%\n",
      "Train Epoch [80/100] Batch [38/782] Loss: 0.4875 | Acc: 83.22%\n",
      "Train Epoch [80/100] Batch [39/782] Loss: 0.3535 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [40/782] Loss: 0.5800 | Acc: 83.24%\n",
      "Train Epoch [80/100] Batch [41/782] Loss: 0.2718 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [42/782] Loss: 0.4882 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [43/782] Loss: 0.5322 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [44/782] Loss: 0.3488 | Acc: 83.42%\n",
      "Train Epoch [80/100] Batch [45/782] Loss: 0.5686 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [46/782] Loss: 0.4307 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [47/782] Loss: 0.4284 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [48/782] Loss: 0.3341 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [49/782] Loss: 0.5125 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [50/782] Loss: 0.3807 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [51/782] Loss: 0.3473 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [52/782] Loss: 0.4919 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [53/782] Loss: 0.3689 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [54/782] Loss: 0.4314 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [55/782] Loss: 0.4686 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [56/782] Loss: 0.5025 | Acc: 83.82%\n",
      "Train Epoch [80/100] Batch [57/782] Loss: 0.4441 | Acc: 83.83%\n",
      "Train Epoch [80/100] Batch [58/782] Loss: 0.6118 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [59/782] Loss: 0.4205 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [60/782] Loss: 0.2837 | Acc: 83.83%\n",
      "Train Epoch [80/100] Batch [61/782] Loss: 0.4319 | Acc: 83.86%\n",
      "Train Epoch [80/100] Batch [62/782] Loss: 0.5080 | Acc: 83.80%\n",
      "Train Epoch [80/100] Batch [63/782] Loss: 0.5804 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [64/782] Loss: 0.5735 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [65/782] Loss: 0.3991 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [66/782] Loss: 0.5805 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [67/782] Loss: 0.5618 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [68/782] Loss: 0.4055 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [69/782] Loss: 0.3905 | Acc: 83.42%\n",
      "Train Epoch [80/100] Batch [70/782] Loss: 0.4176 | Acc: 83.42%\n",
      "Train Epoch [80/100] Batch [71/782] Loss: 0.4279 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [72/782] Loss: 0.5523 | Acc: 83.42%\n",
      "Train Epoch [80/100] Batch [73/782] Loss: 0.3504 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [74/782] Loss: 0.6342 | Acc: 83.32%\n",
      "Train Epoch [80/100] Batch [75/782] Loss: 0.3596 | Acc: 83.31%\n",
      "Train Epoch [80/100] Batch [76/782] Loss: 0.3142 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [77/782] Loss: 0.6068 | Acc: 83.26%\n",
      "Train Epoch [80/100] Batch [78/782] Loss: 0.2444 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [79/782] Loss: 0.3260 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [80/782] Loss: 0.3689 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [81/782] Loss: 0.5777 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [82/782] Loss: 0.7440 | Acc: 83.25%\n",
      "Train Epoch [80/100] Batch [83/782] Loss: 0.3755 | Acc: 83.30%\n",
      "Train Epoch [80/100] Batch [84/782] Loss: 0.2609 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [85/782] Loss: 0.4481 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [86/782] Loss: 0.5293 | Acc: 83.27%\n",
      "Train Epoch [80/100] Batch [87/782] Loss: 0.4713 | Acc: 83.26%\n",
      "Train Epoch [80/100] Batch [88/782] Loss: 0.2453 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [89/782] Loss: 0.4481 | Acc: 83.34%\n",
      "Train Epoch [80/100] Batch [90/782] Loss: 0.4058 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [91/782] Loss: 0.4339 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [92/782] Loss: 0.4070 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [93/782] Loss: 0.4843 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [94/782] Loss: 0.3655 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [95/782] Loss: 0.5941 | Acc: 83.27%\n",
      "Train Epoch [80/100] Batch [96/782] Loss: 0.4105 | Acc: 83.30%\n",
      "Train Epoch [80/100] Batch [97/782] Loss: 0.6738 | Acc: 83.20%\n",
      "Train Epoch [80/100] Batch [98/782] Loss: 0.4809 | Acc: 83.18%\n",
      "Train Epoch [80/100] Batch [99/782] Loss: 0.5191 | Acc: 83.18%\n",
      "Train Epoch [80/100] Batch [100/782] Loss: 0.4901 | Acc: 83.17%\n",
      "Train Epoch [80/100] Batch [101/782] Loss: 0.4573 | Acc: 83.18%\n",
      "Train Epoch [80/100] Batch [102/782] Loss: 0.4785 | Acc: 83.15%\n",
      "Train Epoch [80/100] Batch [103/782] Loss: 0.3083 | Acc: 83.21%\n",
      "Train Epoch [80/100] Batch [104/782] Loss: 0.5895 | Acc: 83.16%\n",
      "Train Epoch [80/100] Batch [105/782] Loss: 0.5870 | Acc: 83.10%\n",
      "Train Epoch [80/100] Batch [106/782] Loss: 0.2675 | Acc: 83.18%\n",
      "Train Epoch [80/100] Batch [107/782] Loss: 0.4470 | Acc: 83.21%\n",
      "Train Epoch [80/100] Batch [108/782] Loss: 0.5426 | Acc: 83.15%\n",
      "Train Epoch [80/100] Batch [109/782] Loss: 0.5550 | Acc: 83.10%\n",
      "Train Epoch [80/100] Batch [110/782] Loss: 0.3609 | Acc: 83.11%\n",
      "Train Epoch [80/100] Batch [111/782] Loss: 0.4704 | Acc: 83.11%\n",
      "Train Epoch [80/100] Batch [112/782] Loss: 0.5368 | Acc: 83.05%\n",
      "Train Epoch [80/100] Batch [113/782] Loss: 0.5942 | Acc: 83.02%\n",
      "Train Epoch [80/100] Batch [114/782] Loss: 0.3661 | Acc: 83.03%\n",
      "Train Epoch [80/100] Batch [115/782] Loss: 0.5242 | Acc: 82.99%\n",
      "Train Epoch [80/100] Batch [116/782] Loss: 0.5034 | Acc: 82.99%\n",
      "Train Epoch [80/100] Batch [117/782] Loss: 0.5130 | Acc: 83.01%\n",
      "Train Epoch [80/100] Batch [118/782] Loss: 0.3873 | Acc: 83.05%\n",
      "Train Epoch [80/100] Batch [119/782] Loss: 0.3614 | Acc: 83.09%\n",
      "Train Epoch [80/100] Batch [120/782] Loss: 0.3209 | Acc: 83.14%\n",
      "Train Epoch [80/100] Batch [121/782] Loss: 0.3510 | Acc: 83.15%\n",
      "Train Epoch [80/100] Batch [122/782] Loss: 0.3009 | Acc: 83.18%\n",
      "Train Epoch [80/100] Batch [123/782] Loss: 0.4363 | Acc: 83.19%\n",
      "Train Epoch [80/100] Batch [124/782] Loss: 0.4216 | Acc: 83.22%\n",
      "Train Epoch [80/100] Batch [125/782] Loss: 0.4212 | Acc: 83.25%\n",
      "Train Epoch [80/100] Batch [126/782] Loss: 0.3821 | Acc: 83.27%\n",
      "Train Epoch [80/100] Batch [127/782] Loss: 0.4591 | Acc: 83.29%\n",
      "Train Epoch [80/100] Batch [128/782] Loss: 0.1768 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [129/782] Loss: 0.4665 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [130/782] Loss: 0.4208 | Acc: 83.34%\n",
      "Train Epoch [80/100] Batch [131/782] Loss: 0.4613 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [132/782] Loss: 0.4444 | Acc: 83.35%\n",
      "Train Epoch [80/100] Batch [133/782] Loss: 0.4281 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [134/782] Loss: 0.5248 | Acc: 83.28%\n",
      "Train Epoch [80/100] Batch [135/782] Loss: 0.6624 | Acc: 83.23%\n",
      "Train Epoch [80/100] Batch [136/782] Loss: 0.2902 | Acc: 83.30%\n",
      "Train Epoch [80/100] Batch [137/782] Loss: 0.3277 | Acc: 83.35%\n",
      "Train Epoch [80/100] Batch [138/782] Loss: 0.4363 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [139/782] Loss: 0.2849 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [140/782] Loss: 0.3211 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [141/782] Loss: 0.4129 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [142/782] Loss: 0.4792 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [143/782] Loss: 0.4525 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [144/782] Loss: 0.6740 | Acc: 83.34%\n",
      "Train Epoch [80/100] Batch [145/782] Loss: 0.3644 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [146/782] Loss: 0.6048 | Acc: 83.35%\n",
      "Train Epoch [80/100] Batch [147/782] Loss: 0.3821 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [148/782] Loss: 0.5712 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [149/782] Loss: 0.5379 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [150/782] Loss: 0.6922 | Acc: 83.31%\n",
      "Train Epoch [80/100] Batch [151/782] Loss: 0.4727 | Acc: 83.32%\n",
      "Train Epoch [80/100] Batch [152/782] Loss: 0.5011 | Acc: 83.34%\n",
      "Train Epoch [80/100] Batch [153/782] Loss: 0.4224 | Acc: 83.34%\n",
      "Train Epoch [80/100] Batch [154/782] Loss: 0.3006 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [155/782] Loss: 0.3528 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [156/782] Loss: 0.5292 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [157/782] Loss: 0.6040 | Acc: 83.35%\n",
      "Train Epoch [80/100] Batch [158/782] Loss: 0.3880 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [159/782] Loss: 0.4147 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [160/782] Loss: 0.2802 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [161/782] Loss: 0.3127 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [162/782] Loss: 0.5651 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [163/782] Loss: 0.3537 | Acc: 83.42%\n",
      "Train Epoch [80/100] Batch [164/782] Loss: 0.5669 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [165/782] Loss: 0.5011 | Acc: 83.33%\n",
      "Train Epoch [80/100] Batch [166/782] Loss: 0.3396 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [167/782] Loss: 0.3903 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [168/782] Loss: 0.5037 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [169/782] Loss: 0.5185 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [170/782] Loss: 0.5050 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [171/782] Loss: 0.4043 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [172/782] Loss: 0.5943 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [173/782] Loss: 0.4910 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [174/782] Loss: 0.4806 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [175/782] Loss: 0.5373 | Acc: 83.38%\n",
      "Train Epoch [80/100] Batch [176/782] Loss: 0.4634 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [177/782] Loss: 0.4372 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [178/782] Loss: 0.5349 | Acc: 83.36%\n",
      "Train Epoch [80/100] Batch [179/782] Loss: 0.2392 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [180/782] Loss: 0.4270 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [181/782] Loss: 0.4108 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [182/782] Loss: 0.4954 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [183/782] Loss: 0.5506 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [184/782] Loss: 0.3435 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [185/782] Loss: 0.5028 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [186/782] Loss: 0.5500 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [187/782] Loss: 0.3586 | Acc: 83.40%\n",
      "Train Epoch [80/100] Batch [188/782] Loss: 0.4731 | Acc: 83.39%\n",
      "Train Epoch [80/100] Batch [189/782] Loss: 0.4020 | Acc: 83.37%\n",
      "Train Epoch [80/100] Batch [190/782] Loss: 0.2864 | Acc: 83.41%\n",
      "Train Epoch [80/100] Batch [191/782] Loss: 0.3577 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [192/782] Loss: 0.3265 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [193/782] Loss: 0.3953 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [194/782] Loss: 0.3877 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [195/782] Loss: 0.6519 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [196/782] Loss: 0.4149 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [197/782] Loss: 0.4665 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [198/782] Loss: 0.3179 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [199/782] Loss: 0.3756 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [200/782] Loss: 0.5636 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [201/782] Loss: 0.5196 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [202/782] Loss: 0.4193 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [203/782] Loss: 0.4357 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [204/782] Loss: 0.3962 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [205/782] Loss: 0.3681 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [206/782] Loss: 0.5080 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [207/782] Loss: 0.4137 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [208/782] Loss: 0.6718 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [209/782] Loss: 0.3736 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [210/782] Loss: 0.5865 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [211/782] Loss: 0.3821 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [212/782] Loss: 0.3521 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [213/782] Loss: 0.5560 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [214/782] Loss: 0.6152 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [215/782] Loss: 0.4885 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [216/782] Loss: 0.4656 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [217/782] Loss: 0.3094 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [218/782] Loss: 0.6222 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [219/782] Loss: 0.5129 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [220/782] Loss: 0.3682 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [221/782] Loss: 0.3097 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [222/782] Loss: 0.4752 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [223/782] Loss: 0.3661 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [224/782] Loss: 0.3552 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [225/782] Loss: 0.4016 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [226/782] Loss: 0.2859 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [227/782] Loss: 0.3533 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [228/782] Loss: 0.3638 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [229/782] Loss: 0.2961 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [230/782] Loss: 0.2474 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [231/782] Loss: 0.4477 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [232/782] Loss: 0.3443 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [233/782] Loss: 0.6922 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [234/782] Loss: 0.3452 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [235/782] Loss: 0.4816 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [236/782] Loss: 0.4608 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [237/782] Loss: 0.4216 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [238/782] Loss: 0.2862 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [239/782] Loss: 0.4067 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [240/782] Loss: 0.2614 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [241/782] Loss: 0.4091 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [242/782] Loss: 0.3820 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [243/782] Loss: 0.3999 | Acc: 83.67%\n",
      "Train Epoch [80/100] Batch [244/782] Loss: 0.2955 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [245/782] Loss: 0.7345 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [246/782] Loss: 0.5044 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [247/782] Loss: 0.4229 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [248/782] Loss: 0.5327 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [249/782] Loss: 0.5111 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [250/782] Loss: 0.5020 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [251/782] Loss: 0.2311 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [252/782] Loss: 0.5331 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [253/782] Loss: 0.4038 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [254/782] Loss: 0.5297 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [255/782] Loss: 0.4579 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [256/782] Loss: 0.4139 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [257/782] Loss: 0.2518 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [258/782] Loss: 0.4007 | Acc: 83.67%\n",
      "Train Epoch [80/100] Batch [259/782] Loss: 0.4760 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [260/782] Loss: 0.7629 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [261/782] Loss: 0.4407 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [262/782] Loss: 0.5718 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [263/782] Loss: 0.7015 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [264/782] Loss: 0.5047 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [265/782] Loss: 0.7356 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [266/782] Loss: 0.5693 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [267/782] Loss: 0.4057 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [268/782] Loss: 0.4300 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [269/782] Loss: 0.3313 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [270/782] Loss: 0.3270 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [271/782] Loss: 0.5133 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [272/782] Loss: 0.3826 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [273/782] Loss: 0.4673 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [274/782] Loss: 0.4662 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [275/782] Loss: 0.3704 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [276/782] Loss: 0.5927 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [277/782] Loss: 0.4085 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [278/782] Loss: 0.4230 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [279/782] Loss: 0.4584 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [280/782] Loss: 0.4507 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [281/782] Loss: 0.2883 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [282/782] Loss: 0.3598 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [283/782] Loss: 0.5154 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [284/782] Loss: 0.6151 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [285/782] Loss: 0.2234 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [286/782] Loss: 0.5417 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [287/782] Loss: 0.4471 | Acc: 83.67%\n",
      "Train Epoch [80/100] Batch [288/782] Loss: 0.2806 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [289/782] Loss: 0.4308 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [290/782] Loss: 0.3274 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [291/782] Loss: 0.4556 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [292/782] Loss: 0.3776 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [293/782] Loss: 0.3722 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [294/782] Loss: 0.5797 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [295/782] Loss: 0.4967 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [296/782] Loss: 0.4414 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [297/782] Loss: 0.5886 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [298/782] Loss: 0.5979 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [299/782] Loss: 0.4377 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [300/782] Loss: 0.4194 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [301/782] Loss: 0.5073 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [302/782] Loss: 0.4407 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [303/782] Loss: 0.5089 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [304/782] Loss: 0.2677 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [305/782] Loss: 0.3473 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [306/782] Loss: 0.5843 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [307/782] Loss: 0.4869 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [308/782] Loss: 0.3710 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [309/782] Loss: 0.3554 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [310/782] Loss: 0.4486 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [311/782] Loss: 0.4196 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [312/782] Loss: 0.6188 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [313/782] Loss: 0.3196 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [314/782] Loss: 0.3988 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [315/782] Loss: 0.6950 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [316/782] Loss: 0.3743 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [317/782] Loss: 0.3588 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [318/782] Loss: 0.5369 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [319/782] Loss: 0.4830 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [320/782] Loss: 0.6018 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [321/782] Loss: 0.5128 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [322/782] Loss: 0.3636 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [323/782] Loss: 0.3386 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [324/782] Loss: 0.5466 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [325/782] Loss: 0.6187 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [326/782] Loss: 0.4856 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [327/782] Loss: 0.4190 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [328/782] Loss: 0.4457 | Acc: 83.68%\n",
      "Train Epoch [80/100] Batch [329/782] Loss: 0.3210 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [330/782] Loss: 0.5178 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [331/782] Loss: 0.5271 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [332/782] Loss: 0.7063 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [333/782] Loss: 0.4637 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [334/782] Loss: 0.4455 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [335/782] Loss: 0.3577 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [336/782] Loss: 0.5299 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [337/782] Loss: 0.4388 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [338/782] Loss: 0.3818 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [339/782] Loss: 0.3504 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [340/782] Loss: 0.3436 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [341/782] Loss: 0.4635 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [342/782] Loss: 0.6116 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [343/782] Loss: 0.5225 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [344/782] Loss: 0.6682 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [345/782] Loss: 0.1737 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [346/782] Loss: 0.5125 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [347/782] Loss: 0.3751 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [348/782] Loss: 0.3383 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [349/782] Loss: 0.3876 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [350/782] Loss: 0.4550 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [351/782] Loss: 0.4597 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [352/782] Loss: 0.3366 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [353/782] Loss: 0.6860 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [354/782] Loss: 0.5033 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [355/782] Loss: 0.3107 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [356/782] Loss: 0.2685 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [357/782] Loss: 0.3877 | Acc: 83.79%\n",
      "Train Epoch [80/100] Batch [358/782] Loss: 0.3830 | Acc: 83.80%\n",
      "Train Epoch [80/100] Batch [359/782] Loss: 0.4356 | Acc: 83.81%\n",
      "Train Epoch [80/100] Batch [360/782] Loss: 0.3945 | Acc: 83.82%\n",
      "Train Epoch [80/100] Batch [361/782] Loss: 0.2749 | Acc: 83.85%\n",
      "Train Epoch [80/100] Batch [362/782] Loss: 0.5005 | Acc: 83.84%\n",
      "Train Epoch [80/100] Batch [363/782] Loss: 0.5166 | Acc: 83.82%\n",
      "Train Epoch [80/100] Batch [364/782] Loss: 0.5373 | Acc: 83.81%\n",
      "Train Epoch [80/100] Batch [365/782] Loss: 0.4144 | Acc: 83.81%\n",
      "Train Epoch [80/100] Batch [366/782] Loss: 0.3608 | Acc: 83.81%\n",
      "Train Epoch [80/100] Batch [367/782] Loss: 0.3392 | Acc: 83.82%\n",
      "Train Epoch [80/100] Batch [368/782] Loss: 0.5412 | Acc: 83.81%\n",
      "Train Epoch [80/100] Batch [369/782] Loss: 0.4082 | Acc: 83.80%\n",
      "Train Epoch [80/100] Batch [370/782] Loss: 0.3562 | Acc: 83.80%\n",
      "Train Epoch [80/100] Batch [371/782] Loss: 0.5817 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [372/782] Loss: 0.4779 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [373/782] Loss: 0.5035 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [374/782] Loss: 0.5882 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [375/782] Loss: 0.3682 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [376/782] Loss: 0.4226 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [377/782] Loss: 0.4507 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [378/782] Loss: 0.4310 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [379/782] Loss: 0.3954 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [380/782] Loss: 0.3345 | Acc: 83.78%\n",
      "Train Epoch [80/100] Batch [381/782] Loss: 0.5447 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [382/782] Loss: 0.6050 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [383/782] Loss: 0.4996 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [384/782] Loss: 0.4878 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [385/782] Loss: 0.3777 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [386/782] Loss: 0.4620 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [387/782] Loss: 0.5056 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [388/782] Loss: 0.5387 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [389/782] Loss: 0.5265 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [390/782] Loss: 0.4468 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [391/782] Loss: 0.4794 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [392/782] Loss: 0.3913 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [393/782] Loss: 0.4402 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [394/782] Loss: 0.5303 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [395/782] Loss: 0.4122 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [396/782] Loss: 0.6076 | Acc: 83.72%\n",
      "Train Epoch [80/100] Batch [397/782] Loss: 0.4417 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [398/782] Loss: 0.3619 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [399/782] Loss: 0.2772 | Acc: 83.74%\n",
      "Train Epoch [80/100] Batch [400/782] Loss: 0.5421 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [401/782] Loss: 0.4105 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [402/782] Loss: 0.5408 | Acc: 83.76%\n",
      "Train Epoch [80/100] Batch [403/782] Loss: 0.3474 | Acc: 83.77%\n",
      "Train Epoch [80/100] Batch [404/782] Loss: 0.6215 | Acc: 83.75%\n",
      "Train Epoch [80/100] Batch [405/782] Loss: 0.5225 | Acc: 83.73%\n",
      "Train Epoch [80/100] Batch [406/782] Loss: 0.5994 | Acc: 83.70%\n",
      "Train Epoch [80/100] Batch [407/782] Loss: 0.4213 | Acc: 83.71%\n",
      "Train Epoch [80/100] Batch [408/782] Loss: 0.6843 | Acc: 83.69%\n",
      "Train Epoch [80/100] Batch [409/782] Loss: 0.7577 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [410/782] Loss: 0.5088 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [411/782] Loss: 0.6221 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [412/782] Loss: 0.3932 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [413/782] Loss: 0.2894 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [414/782] Loss: 0.4702 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [415/782] Loss: 0.4841 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [416/782] Loss: 0.6291 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [417/782] Loss: 0.4899 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [418/782] Loss: 0.4815 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [419/782] Loss: 0.4365 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [420/782] Loss: 0.5635 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [421/782] Loss: 0.5170 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [422/782] Loss: 0.4992 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [423/782] Loss: 0.6052 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [424/782] Loss: 0.5568 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [425/782] Loss: 0.5197 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [426/782] Loss: 0.4059 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [427/782] Loss: 0.2855 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [428/782] Loss: 0.2865 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [429/782] Loss: 0.4529 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [430/782] Loss: 0.3508 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [431/782] Loss: 0.3108 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [432/782] Loss: 0.4276 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [433/782] Loss: 0.3882 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [434/782] Loss: 0.3962 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [435/782] Loss: 0.4611 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [436/782] Loss: 0.4070 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [437/782] Loss: 0.5723 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [438/782] Loss: 0.4648 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [439/782] Loss: 0.4269 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [440/782] Loss: 0.5327 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [441/782] Loss: 0.2626 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [442/782] Loss: 0.4289 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [443/782] Loss: 0.3612 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [444/782] Loss: 0.3670 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [445/782] Loss: 0.5342 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [446/782] Loss: 0.4869 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [447/782] Loss: 0.3749 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [448/782] Loss: 0.3327 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [449/782] Loss: 0.4157 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [450/782] Loss: 0.2834 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [451/782] Loss: 0.2981 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [452/782] Loss: 0.4045 | Acc: 83.67%\n",
      "Train Epoch [80/100] Batch [453/782] Loss: 0.5981 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [454/782] Loss: 0.7045 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [455/782] Loss: 0.5817 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [456/782] Loss: 0.5158 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [457/782] Loss: 0.5941 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [458/782] Loss: 0.3576 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [459/782] Loss: 0.4071 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [460/782] Loss: 0.4469 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [461/782] Loss: 0.4202 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [462/782] Loss: 0.3568 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [463/782] Loss: 0.4966 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [464/782] Loss: 0.3494 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [465/782] Loss: 0.3679 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [466/782] Loss: 0.4011 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [467/782] Loss: 0.4266 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [468/782] Loss: 0.3826 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [469/782] Loss: 0.3217 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [470/782] Loss: 0.3551 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [471/782] Loss: 0.6949 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [472/782] Loss: 0.3305 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [473/782] Loss: 0.2876 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [474/782] Loss: 0.4204 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [475/782] Loss: 0.3867 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [476/782] Loss: 0.5013 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [477/782] Loss: 0.4635 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [478/782] Loss: 0.5611 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [479/782] Loss: 0.3766 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [480/782] Loss: 0.3983 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [481/782] Loss: 0.6624 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [482/782] Loss: 0.4197 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [483/782] Loss: 0.3190 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [484/782] Loss: 0.6079 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [485/782] Loss: 0.5693 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [486/782] Loss: 0.5928 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [487/782] Loss: 0.6353 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [488/782] Loss: 0.6123 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [489/782] Loss: 0.5317 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [490/782] Loss: 0.3424 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [491/782] Loss: 0.3992 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [492/782] Loss: 0.4165 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [493/782] Loss: 0.3063 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [494/782] Loss: 0.3693 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [495/782] Loss: 0.5566 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [496/782] Loss: 0.4414 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [497/782] Loss: 0.4519 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [498/782] Loss: 0.5273 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [499/782] Loss: 0.3518 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [500/782] Loss: 0.4904 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [501/782] Loss: 0.3664 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [502/782] Loss: 0.3195 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [503/782] Loss: 0.4647 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [504/782] Loss: 0.5030 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [505/782] Loss: 0.5781 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [506/782] Loss: 0.3365 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [507/782] Loss: 0.4003 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [508/782] Loss: 0.3956 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [509/782] Loss: 0.5186 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [510/782] Loss: 0.5210 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [511/782] Loss: 0.5680 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [512/782] Loss: 0.2996 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [513/782] Loss: 0.3712 | Acc: 83.63%\n",
      "Train Epoch [80/100] Batch [514/782] Loss: 0.4518 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [515/782] Loss: 0.3930 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [516/782] Loss: 0.3837 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [517/782] Loss: 0.2942 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [518/782] Loss: 0.3618 | Acc: 83.66%\n",
      "Train Epoch [80/100] Batch [519/782] Loss: 0.5903 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [520/782] Loss: 0.3649 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [521/782] Loss: 0.4387 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [522/782] Loss: 0.4294 | Acc: 83.65%\n",
      "Train Epoch [80/100] Batch [523/782] Loss: 0.5368 | Acc: 83.64%\n",
      "Train Epoch [80/100] Batch [524/782] Loss: 0.6363 | Acc: 83.62%\n",
      "Train Epoch [80/100] Batch [525/782] Loss: 0.5373 | Acc: 83.61%\n",
      "Train Epoch [80/100] Batch [526/782] Loss: 0.4422 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [527/782] Loss: 0.4487 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [528/782] Loss: 0.3426 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [529/782] Loss: 0.6522 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [530/782] Loss: 0.4468 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [531/782] Loss: 0.3363 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [532/782] Loss: 0.4910 | Acc: 83.60%\n",
      "Train Epoch [80/100] Batch [533/782] Loss: 0.6462 | Acc: 83.59%\n",
      "Train Epoch [80/100] Batch [534/782] Loss: 0.5968 | Acc: 83.58%\n",
      "Train Epoch [80/100] Batch [535/782] Loss: 0.6585 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [536/782] Loss: 0.4836 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [537/782] Loss: 0.5201 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [538/782] Loss: 0.4445 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [539/782] Loss: 0.5157 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [540/782] Loss: 0.4176 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [541/782] Loss: 0.4327 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [542/782] Loss: 0.6448 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [543/782] Loss: 0.4593 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [544/782] Loss: 0.5201 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [545/782] Loss: 0.1945 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [546/782] Loss: 0.6003 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [547/782] Loss: 0.5647 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [548/782] Loss: 0.3361 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [549/782] Loss: 0.4251 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [550/782] Loss: 0.5613 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [551/782] Loss: 0.4583 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [552/782] Loss: 0.4562 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [553/782] Loss: 0.3105 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [554/782] Loss: 0.6731 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [555/782] Loss: 0.3116 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [556/782] Loss: 0.3928 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [557/782] Loss: 0.3776 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [558/782] Loss: 0.4609 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [559/782] Loss: 0.5963 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [560/782] Loss: 0.5363 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [561/782] Loss: 0.4895 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [562/782] Loss: 0.4336 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [563/782] Loss: 0.4084 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [564/782] Loss: 0.4153 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [565/782] Loss: 0.6896 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [566/782] Loss: 0.3998 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [567/782] Loss: 0.3576 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [568/782] Loss: 0.3917 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [569/782] Loss: 0.4579 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [570/782] Loss: 0.6463 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [571/782] Loss: 0.5801 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [572/782] Loss: 0.3970 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [573/782] Loss: 0.4062 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [574/782] Loss: 0.5756 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [575/782] Loss: 0.4276 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [576/782] Loss: 0.4953 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [577/782] Loss: 0.3645 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [578/782] Loss: 0.5228 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [579/782] Loss: 0.3525 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [580/782] Loss: 0.3504 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [581/782] Loss: 0.5303 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [582/782] Loss: 0.5327 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [583/782] Loss: 0.3888 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [584/782] Loss: 0.2639 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [585/782] Loss: 0.4503 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [586/782] Loss: 0.4256 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [587/782] Loss: 0.3856 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [588/782] Loss: 0.4589 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [589/782] Loss: 0.4726 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [590/782] Loss: 0.4582 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [591/782] Loss: 0.3942 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [592/782] Loss: 0.4828 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [593/782] Loss: 0.4339 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [594/782] Loss: 0.4937 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [595/782] Loss: 0.5506 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [596/782] Loss: 0.4578 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [597/782] Loss: 0.6444 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [598/782] Loss: 0.4209 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [599/782] Loss: 0.4524 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [600/782] Loss: 0.4217 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [601/782] Loss: 0.6255 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [602/782] Loss: 0.4737 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [603/782] Loss: 0.7776 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [604/782] Loss: 0.3849 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [605/782] Loss: 0.3442 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [606/782] Loss: 0.6185 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [607/782] Loss: 0.4515 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [608/782] Loss: 0.5272 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [609/782] Loss: 0.3625 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [610/782] Loss: 0.5486 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [611/782] Loss: 0.4305 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [612/782] Loss: 0.6128 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [613/782] Loss: 0.5589 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [614/782] Loss: 0.4203 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [615/782] Loss: 0.4636 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [616/782] Loss: 0.5653 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [617/782] Loss: 0.5059 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [618/782] Loss: 0.3920 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [619/782] Loss: 0.4688 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [620/782] Loss: 0.3277 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [621/782] Loss: 0.5419 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [622/782] Loss: 0.5048 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [623/782] Loss: 0.3026 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [624/782] Loss: 0.5882 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [625/782] Loss: 0.5823 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [626/782] Loss: 0.5153 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [627/782] Loss: 0.4263 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [628/782] Loss: 0.4562 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [629/782] Loss: 0.5302 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [630/782] Loss: 0.5978 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [631/782] Loss: 0.3788 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [632/782] Loss: 0.5391 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [633/782] Loss: 0.3909 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [634/782] Loss: 0.5049 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [635/782] Loss: 0.5124 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [636/782] Loss: 0.3470 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [637/782] Loss: 0.5052 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [638/782] Loss: 0.5068 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [639/782] Loss: 0.5048 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [640/782] Loss: 0.3863 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [641/782] Loss: 0.6789 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [642/782] Loss: 0.3551 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [643/782] Loss: 0.4770 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [644/782] Loss: 0.2607 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [645/782] Loss: 0.3699 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [646/782] Loss: 0.4723 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [647/782] Loss: 0.4518 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [648/782] Loss: 0.3881 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [649/782] Loss: 0.6436 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [650/782] Loss: 0.5621 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [651/782] Loss: 0.4010 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [652/782] Loss: 0.5500 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [653/782] Loss: 0.4746 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [654/782] Loss: 0.3924 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [655/782] Loss: 0.3402 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [656/782] Loss: 0.6309 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [657/782] Loss: 0.4835 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [658/782] Loss: 0.4501 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [659/782] Loss: 0.5023 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [660/782] Loss: 0.4184 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [661/782] Loss: 0.5310 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [662/782] Loss: 0.4269 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [663/782] Loss: 0.4294 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [664/782] Loss: 0.6892 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [665/782] Loss: 0.5078 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [666/782] Loss: 0.4460 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [667/782] Loss: 0.4845 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [668/782] Loss: 0.4134 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [669/782] Loss: 0.6415 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [670/782] Loss: 0.2756 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [671/782] Loss: 0.4310 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [672/782] Loss: 0.5214 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [673/782] Loss: 0.4613 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [674/782] Loss: 0.4947 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [675/782] Loss: 0.5499 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [676/782] Loss: 0.4443 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [677/782] Loss: 0.3482 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [678/782] Loss: 0.4366 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [679/782] Loss: 0.3421 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [680/782] Loss: 0.3026 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [681/782] Loss: 0.3960 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [682/782] Loss: 0.4552 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [683/782] Loss: 0.3862 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [684/782] Loss: 0.5401 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [685/782] Loss: 0.7447 | Acc: 83.43%\n",
      "Train Epoch [80/100] Batch [686/782] Loss: 0.2486 | Acc: 83.44%\n",
      "Train Epoch [80/100] Batch [687/782] Loss: 0.4498 | Acc: 83.45%\n",
      "Train Epoch [80/100] Batch [688/782] Loss: 0.3080 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [689/782] Loss: 0.5562 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [690/782] Loss: 0.3912 | Acc: 83.46%\n",
      "Train Epoch [80/100] Batch [691/782] Loss: 0.3799 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [692/782] Loss: 0.3703 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [693/782] Loss: 0.6201 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [694/782] Loss: 0.5417 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [695/782] Loss: 0.4090 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [696/782] Loss: 0.3620 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [697/782] Loss: 0.3708 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [698/782] Loss: 0.5128 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [699/782] Loss: 0.6078 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [700/782] Loss: 0.4790 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [701/782] Loss: 0.4874 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [702/782] Loss: 0.5108 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [703/782] Loss: 0.4141 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [704/782] Loss: 0.4394 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [705/782] Loss: 0.4843 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [706/782] Loss: 0.4205 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [707/782] Loss: 0.6159 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [708/782] Loss: 0.5310 | Acc: 83.47%\n",
      "Train Epoch [80/100] Batch [709/782] Loss: 0.3378 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [710/782] Loss: 0.4818 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [711/782] Loss: 0.4223 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [712/782] Loss: 0.5300 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [713/782] Loss: 0.4726 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [714/782] Loss: 0.3321 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [715/782] Loss: 0.4244 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [716/782] Loss: 0.2888 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [717/782] Loss: 0.4395 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [718/782] Loss: 0.2888 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [719/782] Loss: 0.4679 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [720/782] Loss: 0.4102 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [721/782] Loss: 0.3802 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [722/782] Loss: 0.4951 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [723/782] Loss: 0.5476 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [724/782] Loss: 0.4760 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [725/782] Loss: 0.5552 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [726/782] Loss: 0.4827 | Acc: 83.48%\n",
      "Train Epoch [80/100] Batch [727/782] Loss: 0.3719 | Acc: 83.49%\n",
      "Train Epoch [80/100] Batch [728/782] Loss: 0.3084 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [729/782] Loss: 0.4305 | Acc: 83.50%\n",
      "Train Epoch [80/100] Batch [730/782] Loss: 0.3145 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [731/782] Loss: 0.4031 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [732/782] Loss: 0.3814 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [733/782] Loss: 0.4946 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [734/782] Loss: 0.6720 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [735/782] Loss: 0.4647 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [736/782] Loss: 0.6212 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [737/782] Loss: 0.5407 | Acc: 83.51%\n",
      "Train Epoch [80/100] Batch [738/782] Loss: 0.2658 | Acc: 83.52%\n",
      "Train Epoch [80/100] Batch [739/782] Loss: 0.2128 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [740/782] Loss: 0.6100 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [741/782] Loss: 0.3135 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [742/782] Loss: 0.3624 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [743/782] Loss: 0.2300 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [744/782] Loss: 0.4061 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [745/782] Loss: 0.3953 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [746/782] Loss: 0.4941 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [747/782] Loss: 0.5040 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [748/782] Loss: 0.3143 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [749/782] Loss: 0.4690 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [750/782] Loss: 0.4992 | Acc: 83.57%\n",
      "Train Epoch [80/100] Batch [751/782] Loss: 0.5061 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [752/782] Loss: 0.6406 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [753/782] Loss: 0.3620 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [754/782] Loss: 0.5045 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [755/782] Loss: 0.5953 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [756/782] Loss: 0.4908 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [757/782] Loss: 0.5488 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [758/782] Loss: 0.5405 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [759/782] Loss: 0.3388 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [760/782] Loss: 0.4113 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [761/782] Loss: 0.3740 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [762/782] Loss: 0.5114 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [763/782] Loss: 0.4748 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [764/782] Loss: 0.3271 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [765/782] Loss: 0.3467 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [766/782] Loss: 0.5414 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [767/782] Loss: 0.3731 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [768/782] Loss: 0.6357 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [769/782] Loss: 0.3995 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [770/782] Loss: 0.5553 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [771/782] Loss: 0.4637 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [772/782] Loss: 0.7101 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [773/782] Loss: 0.4776 | Acc: 83.53%\n",
      "Train Epoch [80/100] Batch [774/782] Loss: 0.3030 | Acc: 83.54%\n",
      "Train Epoch [80/100] Batch [775/782] Loss: 0.3369 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [776/782] Loss: 0.4317 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [777/782] Loss: 0.2258 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [778/782] Loss: 0.5868 | Acc: 83.56%\n",
      "Train Epoch [80/100] Batch [779/782] Loss: 0.5433 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [780/782] Loss: 0.3945 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [781/782] Loss: 0.4015 | Acc: 83.55%\n",
      "Train Epoch [80/100] Batch [782/782] Loss: 0.3721 | Acc: 83.55%\n",
      "Epoch 80 completed in 30.00s.\n",
      "Test Epoch [80/100] Loss: 0.9785 | Acc: 72.46% | Inference Time: 8.68s\n",
      "Epoch 80 results saved to CSV.\n",
      "Epoch 81/100\n",
      "Train Epoch [81/100] Batch [1/782] Loss: 0.4658 | Acc: 82.81%\n",
      "Train Epoch [81/100] Batch [2/782] Loss: 0.5899 | Acc: 81.25%\n",
      "Train Epoch [81/100] Batch [3/782] Loss: 0.4191 | Acc: 82.81%\n",
      "Train Epoch [81/100] Batch [4/782] Loss: 0.5141 | Acc: 82.81%\n",
      "Train Epoch [81/100] Batch [5/782] Loss: 0.6101 | Acc: 82.50%\n",
      "Train Epoch [81/100] Batch [6/782] Loss: 0.5363 | Acc: 82.29%\n",
      "Train Epoch [81/100] Batch [7/782] Loss: 0.3529 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [8/782] Loss: 0.4528 | Acc: 83.20%\n",
      "Train Epoch [81/100] Batch [9/782] Loss: 0.4857 | Acc: 83.33%\n",
      "Train Epoch [81/100] Batch [10/782] Loss: 0.4276 | Acc: 82.81%\n",
      "Train Epoch [81/100] Batch [11/782] Loss: 0.3037 | Acc: 83.38%\n",
      "Train Epoch [81/100] Batch [12/782] Loss: 0.3799 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [13/782] Loss: 0.4823 | Acc: 83.17%\n",
      "Train Epoch [81/100] Batch [14/782] Loss: 0.3413 | Acc: 83.37%\n",
      "Train Epoch [81/100] Batch [15/782] Loss: 0.4794 | Acc: 83.33%\n",
      "Train Epoch [81/100] Batch [16/782] Loss: 0.3037 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [17/782] Loss: 0.3686 | Acc: 83.92%\n",
      "Train Epoch [81/100] Batch [18/782] Loss: 0.4815 | Acc: 83.94%\n",
      "Train Epoch [81/100] Batch [19/782] Loss: 0.3695 | Acc: 83.96%\n",
      "Train Epoch [81/100] Batch [20/782] Loss: 0.3878 | Acc: 84.14%\n",
      "Train Epoch [81/100] Batch [21/782] Loss: 0.5686 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [22/782] Loss: 0.4194 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [23/782] Loss: 0.5753 | Acc: 83.42%\n",
      "Train Epoch [81/100] Batch [24/782] Loss: 0.3219 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [25/782] Loss: 0.5038 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [26/782] Loss: 0.4664 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [27/782] Loss: 0.5477 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [28/782] Loss: 0.3988 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [29/782] Loss: 0.5120 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [30/782] Loss: 0.7059 | Acc: 83.54%\n",
      "Train Epoch [81/100] Batch [31/782] Loss: 0.5440 | Acc: 83.47%\n",
      "Train Epoch [81/100] Batch [32/782] Loss: 0.4499 | Acc: 83.40%\n",
      "Train Epoch [81/100] Batch [33/782] Loss: 0.3801 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [34/782] Loss: 0.5028 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [35/782] Loss: 0.2312 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [36/782] Loss: 0.3974 | Acc: 83.90%\n",
      "Train Epoch [81/100] Batch [37/782] Loss: 0.6365 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [38/782] Loss: 0.5679 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [39/782] Loss: 0.3788 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [40/782] Loss: 0.4907 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [41/782] Loss: 0.3472 | Acc: 83.92%\n",
      "Train Epoch [81/100] Batch [42/782] Loss: 0.4871 | Acc: 83.97%\n",
      "Train Epoch [81/100] Batch [43/782] Loss: 0.4330 | Acc: 83.94%\n",
      "Train Epoch [81/100] Batch [44/782] Loss: 0.2913 | Acc: 84.09%\n",
      "Train Epoch [81/100] Batch [45/782] Loss: 0.3980 | Acc: 84.10%\n",
      "Train Epoch [81/100] Batch [46/782] Loss: 0.4237 | Acc: 84.04%\n",
      "Train Epoch [81/100] Batch [47/782] Loss: 0.4247 | Acc: 84.04%\n",
      "Train Epoch [81/100] Batch [48/782] Loss: 0.4554 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [49/782] Loss: 0.4906 | Acc: 83.93%\n",
      "Train Epoch [81/100] Batch [50/782] Loss: 0.5097 | Acc: 83.91%\n",
      "Train Epoch [81/100] Batch [51/782] Loss: 0.6783 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [52/782] Loss: 0.6452 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [53/782] Loss: 0.4002 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [54/782] Loss: 0.3250 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [55/782] Loss: 0.3976 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [56/782] Loss: 0.4347 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [57/782] Loss: 0.5062 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [58/782] Loss: 0.4671 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [59/782] Loss: 0.3623 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [60/782] Loss: 0.4085 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [61/782] Loss: 0.4344 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [62/782] Loss: 0.4476 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [63/782] Loss: 0.4362 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [64/782] Loss: 0.5343 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [65/782] Loss: 0.4127 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [66/782] Loss: 0.5008 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [67/782] Loss: 0.4388 | Acc: 83.56%\n",
      "Train Epoch [81/100] Batch [68/782] Loss: 0.5482 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [69/782] Loss: 0.5342 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [70/782] Loss: 0.3276 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [71/782] Loss: 0.5255 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [72/782] Loss: 0.5391 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [73/782] Loss: 0.3562 | Acc: 83.58%\n",
      "Train Epoch [81/100] Batch [74/782] Loss: 0.3523 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [75/782] Loss: 0.5384 | Acc: 83.56%\n",
      "Train Epoch [81/100] Batch [76/782] Loss: 0.5709 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [77/782] Loss: 0.4840 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [78/782] Loss: 0.3697 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [79/782] Loss: 0.6045 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [80/782] Loss: 0.3350 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [81/782] Loss: 0.4515 | Acc: 83.49%\n",
      "Train Epoch [81/100] Batch [82/782] Loss: 0.4506 | Acc: 83.54%\n",
      "Train Epoch [81/100] Batch [83/782] Loss: 0.6616 | Acc: 83.41%\n",
      "Train Epoch [81/100] Batch [84/782] Loss: 0.3538 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [85/782] Loss: 0.6284 | Acc: 83.42%\n",
      "Train Epoch [81/100] Batch [86/782] Loss: 0.3888 | Acc: 83.47%\n",
      "Train Epoch [81/100] Batch [87/782] Loss: 0.3728 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [88/782] Loss: 0.3139 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [89/782] Loss: 0.4632 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [90/782] Loss: 0.4408 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [91/782] Loss: 0.6583 | Acc: 83.53%\n",
      "Train Epoch [81/100] Batch [92/782] Loss: 0.2545 | Acc: 83.58%\n",
      "Train Epoch [81/100] Batch [93/782] Loss: 0.4487 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [94/782] Loss: 0.5275 | Acc: 83.54%\n",
      "Train Epoch [81/100] Batch [95/782] Loss: 0.3655 | Acc: 83.60%\n",
      "Train Epoch [81/100] Batch [96/782] Loss: 0.5883 | Acc: 83.58%\n",
      "Train Epoch [81/100] Batch [97/782] Loss: 0.6525 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [98/782] Loss: 0.6360 | Acc: 83.45%\n",
      "Train Epoch [81/100] Batch [99/782] Loss: 0.5196 | Acc: 83.38%\n",
      "Train Epoch [81/100] Batch [100/782] Loss: 0.2513 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [101/782] Loss: 0.4565 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [102/782] Loss: 0.4647 | Acc: 83.43%\n",
      "Train Epoch [81/100] Batch [103/782] Loss: 0.5082 | Acc: 83.42%\n",
      "Train Epoch [81/100] Batch [104/782] Loss: 0.3374 | Acc: 83.46%\n",
      "Train Epoch [81/100] Batch [105/782] Loss: 0.4298 | Acc: 83.41%\n",
      "Train Epoch [81/100] Batch [106/782] Loss: 0.5427 | Acc: 83.37%\n",
      "Train Epoch [81/100] Batch [107/782] Loss: 0.3642 | Acc: 83.40%\n",
      "Train Epoch [81/100] Batch [108/782] Loss: 0.4612 | Acc: 83.42%\n",
      "Train Epoch [81/100] Batch [109/782] Loss: 0.4208 | Acc: 83.41%\n",
      "Train Epoch [81/100] Batch [110/782] Loss: 0.3412 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [111/782] Loss: 0.5475 | Acc: 83.47%\n",
      "Train Epoch [81/100] Batch [112/782] Loss: 0.3810 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [113/782] Loss: 0.4221 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [114/782] Loss: 0.4254 | Acc: 83.53%\n",
      "Train Epoch [81/100] Batch [115/782] Loss: 0.5363 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [116/782] Loss: 0.6215 | Acc: 83.47%\n",
      "Train Epoch [81/100] Batch [117/782] Loss: 0.4222 | Acc: 83.47%\n",
      "Train Epoch [81/100] Batch [118/782] Loss: 0.5085 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [119/782] Loss: 0.4461 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [120/782] Loss: 0.4417 | Acc: 83.45%\n",
      "Train Epoch [81/100] Batch [121/782] Loss: 0.2986 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [122/782] Loss: 0.2540 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [123/782] Loss: 0.6529 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [124/782] Loss: 0.5223 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [125/782] Loss: 0.3550 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [126/782] Loss: 0.3960 | Acc: 83.53%\n",
      "Train Epoch [81/100] Batch [127/782] Loss: 0.5471 | Acc: 83.48%\n",
      "Train Epoch [81/100] Batch [128/782] Loss: 0.5590 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [129/782] Loss: 0.3755 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [130/782] Loss: 0.3983 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [131/782] Loss: 0.5043 | Acc: 83.49%\n",
      "Train Epoch [81/100] Batch [132/782] Loss: 0.4928 | Acc: 83.46%\n",
      "Train Epoch [81/100] Batch [133/782] Loss: 0.3153 | Acc: 83.51%\n",
      "Train Epoch [81/100] Batch [134/782] Loss: 0.3208 | Acc: 83.55%\n",
      "Train Epoch [81/100] Batch [135/782] Loss: 0.5775 | Acc: 83.50%\n",
      "Train Epoch [81/100] Batch [136/782] Loss: 0.4458 | Acc: 83.52%\n",
      "Train Epoch [81/100] Batch [137/782] Loss: 0.3024 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [138/782] Loss: 0.2577 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [139/782] Loss: 0.3729 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [140/782] Loss: 0.6121 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [141/782] Loss: 0.4952 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [142/782] Loss: 0.4762 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [143/782] Loss: 0.5675 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [144/782] Loss: 0.5243 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [145/782] Loss: 0.3033 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [146/782] Loss: 0.3471 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [147/782] Loss: 0.4405 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [148/782] Loss: 0.3881 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [149/782] Loss: 0.3920 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [150/782] Loss: 0.2942 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [151/782] Loss: 0.4576 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [152/782] Loss: 0.4863 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [153/782] Loss: 0.3948 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [154/782] Loss: 0.6010 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [155/782] Loss: 0.2498 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [156/782] Loss: 0.3472 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [157/782] Loss: 0.3346 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [158/782] Loss: 0.3324 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [159/782] Loss: 0.3510 | Acc: 83.90%\n",
      "Train Epoch [81/100] Batch [160/782] Loss: 0.5709 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [161/782] Loss: 0.1943 | Acc: 83.96%\n",
      "Train Epoch [81/100] Batch [162/782] Loss: 0.3257 | Acc: 83.96%\n",
      "Train Epoch [81/100] Batch [163/782] Loss: 0.4347 | Acc: 83.98%\n",
      "Train Epoch [81/100] Batch [164/782] Loss: 0.3184 | Acc: 83.98%\n",
      "Train Epoch [81/100] Batch [165/782] Loss: 0.5679 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [166/782] Loss: 0.5084 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [167/782] Loss: 0.4913 | Acc: 83.94%\n",
      "Train Epoch [81/100] Batch [168/782] Loss: 0.3538 | Acc: 83.98%\n",
      "Train Epoch [81/100] Batch [169/782] Loss: 0.3763 | Acc: 83.99%\n",
      "Train Epoch [81/100] Batch [170/782] Loss: 0.4372 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [171/782] Loss: 0.3562 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [172/782] Loss: 0.5502 | Acc: 83.95%\n",
      "Train Epoch [81/100] Batch [173/782] Loss: 0.5794 | Acc: 83.91%\n",
      "Train Epoch [81/100] Batch [174/782] Loss: 0.4552 | Acc: 83.92%\n",
      "Train Epoch [81/100] Batch [175/782] Loss: 0.5076 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [176/782] Loss: 0.5692 | Acc: 83.90%\n",
      "Train Epoch [81/100] Batch [177/782] Loss: 0.7210 | Acc: 83.86%\n",
      "Train Epoch [81/100] Batch [178/782] Loss: 0.2530 | Acc: 83.90%\n",
      "Train Epoch [81/100] Batch [179/782] Loss: 0.8561 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [180/782] Loss: 0.3216 | Acc: 83.87%\n",
      "Train Epoch [81/100] Batch [181/782] Loss: 0.4201 | Acc: 83.87%\n",
      "Train Epoch [81/100] Batch [182/782] Loss: 0.4409 | Acc: 83.86%\n",
      "Train Epoch [81/100] Batch [183/782] Loss: 0.2478 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [184/782] Loss: 0.3262 | Acc: 83.91%\n",
      "Train Epoch [81/100] Batch [185/782] Loss: 0.5437 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [186/782] Loss: 0.5023 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [187/782] Loss: 0.3766 | Acc: 83.87%\n",
      "Train Epoch [81/100] Batch [188/782] Loss: 0.5540 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [189/782] Loss: 0.3745 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [190/782] Loss: 0.4017 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [191/782] Loss: 0.6001 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [192/782] Loss: 0.3180 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [193/782] Loss: 0.5061 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [194/782] Loss: 0.6887 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [195/782] Loss: 0.5622 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [196/782] Loss: 0.7185 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [197/782] Loss: 0.4759 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [198/782] Loss: 0.4896 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [199/782] Loss: 0.5290 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [200/782] Loss: 0.3506 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [201/782] Loss: 0.4945 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [202/782] Loss: 0.5828 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [203/782] Loss: 0.4322 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [204/782] Loss: 0.5053 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [205/782] Loss: 0.3008 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [206/782] Loss: 0.4687 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [207/782] Loss: 0.4047 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [208/782] Loss: 0.4739 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [209/782] Loss: 0.4372 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [210/782] Loss: 0.5373 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [211/782] Loss: 0.4860 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [212/782] Loss: 0.4421 | Acc: 83.86%\n",
      "Train Epoch [81/100] Batch [213/782] Loss: 0.4607 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [214/782] Loss: 0.4948 | Acc: 83.86%\n",
      "Train Epoch [81/100] Batch [215/782] Loss: 0.3319 | Acc: 83.89%\n",
      "Train Epoch [81/100] Batch [216/782] Loss: 0.4948 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [217/782] Loss: 0.4399 | Acc: 83.91%\n",
      "Train Epoch [81/100] Batch [218/782] Loss: 0.3134 | Acc: 83.94%\n",
      "Train Epoch [81/100] Batch [219/782] Loss: 0.5791 | Acc: 83.90%\n",
      "Train Epoch [81/100] Batch [220/782] Loss: 0.6775 | Acc: 83.86%\n",
      "Train Epoch [81/100] Batch [221/782] Loss: 0.3646 | Acc: 83.88%\n",
      "Train Epoch [81/100] Batch [222/782] Loss: 0.5480 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [223/782] Loss: 0.3913 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [224/782] Loss: 0.4625 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [225/782] Loss: 0.3922 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [226/782] Loss: 0.4738 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [227/782] Loss: 0.7142 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [228/782] Loss: 0.3982 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [229/782] Loss: 0.3743 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [230/782] Loss: 0.3920 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [231/782] Loss: 0.3531 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [232/782] Loss: 0.4567 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [233/782] Loss: 0.5438 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [234/782] Loss: 0.5613 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [235/782] Loss: 0.3237 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [236/782] Loss: 0.7424 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [237/782] Loss: 0.5475 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [238/782] Loss: 0.5508 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [239/782] Loss: 0.6369 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [240/782] Loss: 0.2573 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [241/782] Loss: 0.3664 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [242/782] Loss: 0.5690 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [243/782] Loss: 0.5716 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [244/782] Loss: 0.4123 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [245/782] Loss: 0.3781 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [246/782] Loss: 0.3321 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [247/782] Loss: 0.5523 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [248/782] Loss: 0.6401 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [249/782] Loss: 0.4613 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [250/782] Loss: 0.3243 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [251/782] Loss: 0.6025 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [252/782] Loss: 0.3341 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [253/782] Loss: 0.4272 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [254/782] Loss: 0.3354 | Acc: 83.62%\n",
      "Train Epoch [81/100] Batch [255/782] Loss: 0.4546 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [256/782] Loss: 0.4046 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [257/782] Loss: 0.4492 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [258/782] Loss: 0.4436 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [259/782] Loss: 0.5217 | Acc: 83.60%\n",
      "Train Epoch [81/100] Batch [260/782] Loss: 0.6533 | Acc: 83.59%\n",
      "Train Epoch [81/100] Batch [261/782] Loss: 0.3595 | Acc: 83.60%\n",
      "Train Epoch [81/100] Batch [262/782] Loss: 0.5398 | Acc: 83.58%\n",
      "Train Epoch [81/100] Batch [263/782] Loss: 0.4221 | Acc: 83.60%\n",
      "Train Epoch [81/100] Batch [264/782] Loss: 0.3948 | Acc: 83.61%\n",
      "Train Epoch [81/100] Batch [265/782] Loss: 0.3634 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [266/782] Loss: 0.4018 | Acc: 83.63%\n",
      "Train Epoch [81/100] Batch [267/782] Loss: 0.3885 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [268/782] Loss: 0.4048 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [269/782] Loss: 0.3408 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [270/782] Loss: 0.6641 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [271/782] Loss: 0.5759 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [272/782] Loss: 0.5496 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [273/782] Loss: 0.5682 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [274/782] Loss: 0.4818 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [275/782] Loss: 0.2871 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [276/782] Loss: 0.4646 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [277/782] Loss: 0.6576 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [278/782] Loss: 0.3242 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [279/782] Loss: 0.5905 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [280/782] Loss: 0.3040 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [281/782] Loss: 0.3172 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [282/782] Loss: 0.3373 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [283/782] Loss: 0.6882 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [284/782] Loss: 0.6376 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [285/782] Loss: 0.3125 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [286/782] Loss: 0.5278 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [287/782] Loss: 0.6250 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [288/782] Loss: 0.4432 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [289/782] Loss: 0.3956 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [290/782] Loss: 0.6019 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [291/782] Loss: 0.3918 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [292/782] Loss: 0.4138 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [293/782] Loss: 0.4251 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [294/782] Loss: 0.4115 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [295/782] Loss: 0.2151 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [296/782] Loss: 0.2782 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [297/782] Loss: 0.5340 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [298/782] Loss: 0.5888 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [299/782] Loss: 0.4067 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [300/782] Loss: 0.3623 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [301/782] Loss: 0.4582 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [302/782] Loss: 0.6483 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [303/782] Loss: 0.5354 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [304/782] Loss: 0.4724 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [305/782] Loss: 0.7084 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [306/782] Loss: 0.5967 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [307/782] Loss: 0.3605 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [308/782] Loss: 0.3034 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [309/782] Loss: 0.4295 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [310/782] Loss: 0.5375 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [311/782] Loss: 0.5494 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [312/782] Loss: 0.4728 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [313/782] Loss: 0.3777 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [314/782] Loss: 0.6831 | Acc: 83.66%\n",
      "Train Epoch [81/100] Batch [315/782] Loss: 0.6126 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [316/782] Loss: 0.5682 | Acc: 83.64%\n",
      "Train Epoch [81/100] Batch [317/782] Loss: 0.3157 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [318/782] Loss: 0.2605 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [319/782] Loss: 0.4355 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [320/782] Loss: 0.4505 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [321/782] Loss: 0.4996 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [322/782] Loss: 0.3647 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [323/782] Loss: 0.5783 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [324/782] Loss: 0.5389 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [325/782] Loss: 0.5809 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [326/782] Loss: 0.5060 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [327/782] Loss: 0.4425 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [328/782] Loss: 0.4176 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [329/782] Loss: 0.4458 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [330/782] Loss: 0.3587 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [331/782] Loss: 0.3823 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [332/782] Loss: 0.3376 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [333/782] Loss: 0.4225 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [334/782] Loss: 0.3290 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [335/782] Loss: 0.6859 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [336/782] Loss: 0.3706 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [337/782] Loss: 0.6471 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [338/782] Loss: 0.2993 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [339/782] Loss: 0.5026 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [340/782] Loss: 0.5908 | Acc: 83.65%\n",
      "Train Epoch [81/100] Batch [341/782] Loss: 0.3129 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [342/782] Loss: 0.3758 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [343/782] Loss: 0.5534 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [344/782] Loss: 0.3989 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [345/782] Loss: 0.4458 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [346/782] Loss: 0.4054 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [347/782] Loss: 0.4064 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [348/782] Loss: 0.6785 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [349/782] Loss: 0.5575 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [350/782] Loss: 0.5236 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [351/782] Loss: 0.3829 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [352/782] Loss: 0.2532 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [353/782] Loss: 0.4399 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [354/782] Loss: 0.4229 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [355/782] Loss: 0.4448 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [356/782] Loss: 0.4528 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [357/782] Loss: 0.3627 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [358/782] Loss: 0.3758 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [359/782] Loss: 0.3858 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [360/782] Loss: 0.3866 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [361/782] Loss: 0.5043 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [362/782] Loss: 0.2886 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [363/782] Loss: 0.4413 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [364/782] Loss: 0.4344 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [365/782] Loss: 0.3402 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [366/782] Loss: 0.5822 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [367/782] Loss: 0.5211 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [368/782] Loss: 0.4818 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [369/782] Loss: 0.3988 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [370/782] Loss: 0.4019 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [371/782] Loss: 0.3591 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [372/782] Loss: 0.4735 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [373/782] Loss: 0.4712 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [374/782] Loss: 0.5942 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [375/782] Loss: 0.3681 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [376/782] Loss: 0.2426 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [377/782] Loss: 0.3832 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [378/782] Loss: 0.5184 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [379/782] Loss: 0.5930 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [380/782] Loss: 0.4660 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [381/782] Loss: 0.3557 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [382/782] Loss: 0.4737 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [383/782] Loss: 0.4562 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [384/782] Loss: 0.5359 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [385/782] Loss: 0.6048 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [386/782] Loss: 0.4421 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [387/782] Loss: 0.5094 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [388/782] Loss: 0.4178 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [389/782] Loss: 0.4923 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [390/782] Loss: 0.3670 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [391/782] Loss: 0.4183 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [392/782] Loss: 0.4861 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [393/782] Loss: 0.5472 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [394/782] Loss: 0.3562 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [395/782] Loss: 0.3321 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [396/782] Loss: 0.7370 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [397/782] Loss: 0.6084 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [398/782] Loss: 0.3787 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [399/782] Loss: 0.4119 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [400/782] Loss: 0.5149 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [401/782] Loss: 0.4448 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [402/782] Loss: 0.5607 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [403/782] Loss: 0.4448 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [404/782] Loss: 0.3774 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [405/782] Loss: 0.3703 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [406/782] Loss: 0.3882 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [407/782] Loss: 0.4534 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [408/782] Loss: 0.4660 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [409/782] Loss: 0.4975 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [410/782] Loss: 0.4421 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [411/782] Loss: 0.4862 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [412/782] Loss: 0.5909 | Acc: 83.67%\n",
      "Train Epoch [81/100] Batch [413/782] Loss: 0.2267 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [414/782] Loss: 0.4099 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [415/782] Loss: 0.3555 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [416/782] Loss: 0.3307 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [417/782] Loss: 0.2792 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [418/782] Loss: 0.4949 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [419/782] Loss: 0.5525 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [420/782] Loss: 0.3096 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [421/782] Loss: 0.5041 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [422/782] Loss: 0.4887 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [423/782] Loss: 0.5153 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [424/782] Loss: 0.4458 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [425/782] Loss: 0.6257 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [426/782] Loss: 0.3721 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [427/782] Loss: 0.5974 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [428/782] Loss: 0.4545 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [429/782] Loss: 0.5045 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [430/782] Loss: 0.4311 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [431/782] Loss: 0.4495 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [432/782] Loss: 0.4356 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [433/782] Loss: 0.5116 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [434/782] Loss: 0.3594 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [435/782] Loss: 0.4897 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [436/782] Loss: 0.4982 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [437/782] Loss: 0.4897 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [438/782] Loss: 0.3214 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [439/782] Loss: 0.5044 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [440/782] Loss: 0.5172 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [441/782] Loss: 0.5897 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [442/782] Loss: 0.7430 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [443/782] Loss: 0.3129 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [444/782] Loss: 0.6738 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [445/782] Loss: 0.4267 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [446/782] Loss: 0.3860 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [447/782] Loss: 0.4599 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [448/782] Loss: 0.4409 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [449/782] Loss: 0.8380 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [450/782] Loss: 0.2830 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [451/782] Loss: 0.4564 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [452/782] Loss: 0.4521 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [453/782] Loss: 0.2687 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [454/782] Loss: 0.4501 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [455/782] Loss: 0.4036 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [456/782] Loss: 0.4774 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [457/782] Loss: 0.3623 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [458/782] Loss: 0.3637 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [459/782] Loss: 0.4911 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [460/782] Loss: 0.2881 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [461/782] Loss: 0.5252 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [462/782] Loss: 0.4967 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [463/782] Loss: 0.5747 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [464/782] Loss: 0.5604 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [465/782] Loss: 0.6805 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [466/782] Loss: 0.3982 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [467/782] Loss: 0.4391 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [468/782] Loss: 0.4214 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [469/782] Loss: 0.4727 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [470/782] Loss: 0.6401 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [471/782] Loss: 0.3124 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [472/782] Loss: 0.3465 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [473/782] Loss: 0.4282 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [474/782] Loss: 0.4406 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [475/782] Loss: 0.6397 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [476/782] Loss: 0.5072 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [477/782] Loss: 0.5139 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [478/782] Loss: 0.3706 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [479/782] Loss: 0.4026 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [480/782] Loss: 0.3301 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [481/782] Loss: 0.4078 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [482/782] Loss: 0.6530 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [483/782] Loss: 0.5228 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [484/782] Loss: 0.3300 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [485/782] Loss: 0.4477 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [486/782] Loss: 0.5580 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [487/782] Loss: 0.4920 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [488/782] Loss: 0.5253 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [489/782] Loss: 0.4805 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [490/782] Loss: 0.3772 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [491/782] Loss: 0.2765 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [492/782] Loss: 0.4912 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [493/782] Loss: 0.5653 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [494/782] Loss: 0.3934 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [495/782] Loss: 0.4612 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [496/782] Loss: 0.5050 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [497/782] Loss: 0.2873 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [498/782] Loss: 0.4069 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [499/782] Loss: 0.5253 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [500/782] Loss: 0.5198 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [501/782] Loss: 0.4021 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [502/782] Loss: 0.2883 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [503/782] Loss: 0.3471 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [504/782] Loss: 0.4007 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [505/782] Loss: 0.5705 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [506/782] Loss: 0.4052 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [507/782] Loss: 0.3715 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [508/782] Loss: 0.4721 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [509/782] Loss: 0.6286 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [510/782] Loss: 0.4131 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [511/782] Loss: 0.4758 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [512/782] Loss: 0.4724 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [513/782] Loss: 0.3999 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [514/782] Loss: 0.8385 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [515/782] Loss: 0.2698 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [516/782] Loss: 0.4525 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [517/782] Loss: 0.5797 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [518/782] Loss: 0.2738 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [519/782] Loss: 0.4400 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [520/782] Loss: 0.2760 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [521/782] Loss: 0.6451 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [522/782] Loss: 0.4752 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [523/782] Loss: 0.5588 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [524/782] Loss: 0.5131 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [525/782] Loss: 0.3695 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [526/782] Loss: 0.3522 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [527/782] Loss: 0.5207 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [528/782] Loss: 0.2935 | Acc: 83.85%\n",
      "Train Epoch [81/100] Batch [529/782] Loss: 0.6430 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [530/782] Loss: 0.4453 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [531/782] Loss: 0.5880 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [532/782] Loss: 0.3370 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [533/782] Loss: 0.4202 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [534/782] Loss: 0.3789 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [535/782] Loss: 0.3995 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [536/782] Loss: 0.3339 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [537/782] Loss: 0.6030 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [538/782] Loss: 0.4294 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [539/782] Loss: 0.3755 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [540/782] Loss: 0.5105 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [541/782] Loss: 0.4799 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [542/782] Loss: 0.5559 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [543/782] Loss: 0.3799 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [544/782] Loss: 0.3200 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [545/782] Loss: 0.3841 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [546/782] Loss: 0.2784 | Acc: 83.84%\n",
      "Train Epoch [81/100] Batch [547/782] Loss: 0.7130 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [548/782] Loss: 0.5103 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [549/782] Loss: 0.4143 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [550/782] Loss: 0.5567 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [551/782] Loss: 0.4063 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [552/782] Loss: 0.4851 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [553/782] Loss: 0.3891 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [554/782] Loss: 0.7189 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [555/782] Loss: 0.5394 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [556/782] Loss: 0.4833 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [557/782] Loss: 0.7291 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [558/782] Loss: 0.4718 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [559/782] Loss: 0.2280 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [560/782] Loss: 0.4829 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [561/782] Loss: 0.5060 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [562/782] Loss: 0.6094 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [563/782] Loss: 0.4618 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [564/782] Loss: 0.5377 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [565/782] Loss: 0.4376 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [566/782] Loss: 0.3612 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [567/782] Loss: 0.4635 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [568/782] Loss: 0.5049 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [569/782] Loss: 0.5062 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [570/782] Loss: 0.4560 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [571/782] Loss: 0.4411 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [572/782] Loss: 0.3587 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [573/782] Loss: 0.4535 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [574/782] Loss: 0.4449 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [575/782] Loss: 0.2947 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [576/782] Loss: 0.5438 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [577/782] Loss: 0.4073 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [578/782] Loss: 0.4050 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [579/782] Loss: 0.3534 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [580/782] Loss: 0.4981 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [581/782] Loss: 0.3803 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [582/782] Loss: 0.4063 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [583/782] Loss: 0.5797 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [584/782] Loss: 0.5084 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [585/782] Loss: 0.3375 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [586/782] Loss: 0.4395 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [587/782] Loss: 0.1991 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [588/782] Loss: 0.5272 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [589/782] Loss: 0.6462 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [590/782] Loss: 0.3997 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [591/782] Loss: 0.4591 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [592/782] Loss: 0.4550 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [593/782] Loss: 0.4201 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [594/782] Loss: 0.3877 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [595/782] Loss: 0.3253 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [596/782] Loss: 0.4178 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [597/782] Loss: 0.2304 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [598/782] Loss: 0.5439 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [599/782] Loss: 0.3469 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [600/782] Loss: 0.4519 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [601/782] Loss: 0.5268 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [602/782] Loss: 0.4736 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [603/782] Loss: 0.4142 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [604/782] Loss: 0.6572 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [605/782] Loss: 0.5494 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [606/782] Loss: 0.3716 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [607/782] Loss: 0.4081 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [608/782] Loss: 0.5813 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [609/782] Loss: 0.5502 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [610/782] Loss: 0.6028 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [611/782] Loss: 0.5002 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [612/782] Loss: 0.6739 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [613/782] Loss: 0.4133 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [614/782] Loss: 0.5039 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [615/782] Loss: 0.3830 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [616/782] Loss: 0.4424 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [617/782] Loss: 0.4494 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [618/782] Loss: 0.5168 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [619/782] Loss: 0.3796 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [620/782] Loss: 0.3560 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [621/782] Loss: 0.5521 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [622/782] Loss: 0.3629 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [623/782] Loss: 0.4407 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [624/782] Loss: 0.6113 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [625/782] Loss: 0.4707 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [626/782] Loss: 0.5311 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [627/782] Loss: 0.4003 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [628/782] Loss: 0.5209 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [629/782] Loss: 0.4867 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [630/782] Loss: 0.4086 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [631/782] Loss: 0.4991 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [632/782] Loss: 0.4512 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [633/782] Loss: 0.4396 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [634/782] Loss: 0.6772 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [635/782] Loss: 0.3928 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [636/782] Loss: 0.3468 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [637/782] Loss: 0.5113 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [638/782] Loss: 0.3690 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [639/782] Loss: 0.5032 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [640/782] Loss: 0.3803 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [641/782] Loss: 0.3377 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [642/782] Loss: 0.5371 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [643/782] Loss: 0.4407 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [644/782] Loss: 0.3507 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [645/782] Loss: 0.5254 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [646/782] Loss: 0.5141 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [647/782] Loss: 0.3726 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [648/782] Loss: 0.4316 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [649/782] Loss: 0.4425 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [650/782] Loss: 0.3500 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [651/782] Loss: 0.6260 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [652/782] Loss: 0.3830 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [653/782] Loss: 0.8003 | Acc: 83.68%\n",
      "Train Epoch [81/100] Batch [654/782] Loss: 0.3214 | Acc: 83.69%\n",
      "Train Epoch [81/100] Batch [655/782] Loss: 0.2664 | Acc: 83.70%\n",
      "Train Epoch [81/100] Batch [656/782] Loss: 0.2455 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [657/782] Loss: 0.4834 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [658/782] Loss: 0.3750 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [659/782] Loss: 0.3929 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [660/782] Loss: 0.5366 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [661/782] Loss: 0.5223 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [662/782] Loss: 0.5121 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [663/782] Loss: 0.3230 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [664/782] Loss: 0.5798 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [665/782] Loss: 0.2925 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [666/782] Loss: 0.3443 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [667/782] Loss: 0.3956 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [668/782] Loss: 0.4783 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [669/782] Loss: 0.5046 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [670/782] Loss: 0.4197 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [671/782] Loss: 0.5033 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [672/782] Loss: 0.5617 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [673/782] Loss: 0.5865 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [674/782] Loss: 0.4063 | Acc: 83.71%\n",
      "Train Epoch [81/100] Batch [675/782] Loss: 0.4278 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [676/782] Loss: 0.4253 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [677/782] Loss: 0.4597 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [678/782] Loss: 0.5411 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [679/782] Loss: 0.3489 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [680/782] Loss: 0.3685 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [681/782] Loss: 0.3827 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [682/782] Loss: 0.4332 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [683/782] Loss: 0.5158 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [684/782] Loss: 0.4953 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [685/782] Loss: 0.5186 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [686/782] Loss: 0.4259 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [687/782] Loss: 0.4172 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [688/782] Loss: 0.3906 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [689/782] Loss: 0.5988 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [690/782] Loss: 0.5772 | Acc: 83.72%\n",
      "Train Epoch [81/100] Batch [691/782] Loss: 0.4134 | Acc: 83.73%\n",
      "Train Epoch [81/100] Batch [692/782] Loss: 0.2244 | Acc: 83.74%\n",
      "Train Epoch [81/100] Batch [693/782] Loss: 0.3847 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [694/782] Loss: 0.3387 | Acc: 83.75%\n",
      "Train Epoch [81/100] Batch [695/782] Loss: 0.2723 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [696/782] Loss: 0.3557 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [697/782] Loss: 0.4589 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [698/782] Loss: 0.2586 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [699/782] Loss: 0.5837 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [700/782] Loss: 0.4814 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [701/782] Loss: 0.4492 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [702/782] Loss: 0.3259 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [703/782] Loss: 0.6451 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [704/782] Loss: 0.3616 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [705/782] Loss: 0.5229 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [706/782] Loss: 0.5671 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [707/782] Loss: 0.4350 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [708/782] Loss: 0.5994 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [709/782] Loss: 0.3709 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [710/782] Loss: 0.3834 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [711/782] Loss: 0.3441 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [712/782] Loss: 0.3180 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [713/782] Loss: 0.2848 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [714/782] Loss: 0.3678 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [715/782] Loss: 0.5095 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [716/782] Loss: 0.4977 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [717/782] Loss: 0.4125 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [718/782] Loss: 0.4620 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [719/782] Loss: 0.4512 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [720/782] Loss: 0.3144 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [721/782] Loss: 0.5948 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [722/782] Loss: 0.3966 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [723/782] Loss: 0.3532 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [724/782] Loss: 0.6561 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [725/782] Loss: 0.4713 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [726/782] Loss: 0.3718 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [727/782] Loss: 0.3993 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [728/782] Loss: 0.3526 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [729/782] Loss: 0.5225 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [730/782] Loss: 0.4295 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [731/782] Loss: 0.4172 | Acc: 83.83%\n",
      "Train Epoch [81/100] Batch [732/782] Loss: 0.5328 | Acc: 83.82%\n",
      "Train Epoch [81/100] Batch [733/782] Loss: 0.5186 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [734/782] Loss: 0.5212 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [735/782] Loss: 0.4529 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [736/782] Loss: 0.6847 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [737/782] Loss: 0.5096 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [738/782] Loss: 0.4764 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [739/782] Loss: 0.4204 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [740/782] Loss: 0.4195 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [741/782] Loss: 0.6361 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [742/782] Loss: 0.6322 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [743/782] Loss: 0.2239 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [744/782] Loss: 0.5253 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [745/782] Loss: 0.3920 | Acc: 83.81%\n",
      "Train Epoch [81/100] Batch [746/782] Loss: 0.6167 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [747/782] Loss: 0.5524 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [748/782] Loss: 0.6591 | Acc: 83.80%\n",
      "Train Epoch [81/100] Batch [749/782] Loss: 0.6732 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [750/782] Loss: 0.4635 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [751/782] Loss: 0.4316 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [752/782] Loss: 0.3609 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [753/782] Loss: 0.4800 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [754/782] Loss: 0.5333 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [755/782] Loss: 0.2711 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [756/782] Loss: 0.5021 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [757/782] Loss: 0.6887 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [758/782] Loss: 0.4196 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [759/782] Loss: 0.4164 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [760/782] Loss: 0.4532 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [761/782] Loss: 0.3557 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [762/782] Loss: 0.6550 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [763/782] Loss: 0.3373 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [764/782] Loss: 0.3384 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [765/782] Loss: 0.4464 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [766/782] Loss: 0.6185 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [767/782] Loss: 0.4572 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [768/782] Loss: 0.3344 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [769/782] Loss: 0.3813 | Acc: 83.79%\n",
      "Train Epoch [81/100] Batch [770/782] Loss: 0.5111 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [771/782] Loss: 0.6321 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [772/782] Loss: 0.4310 | Acc: 83.78%\n",
      "Train Epoch [81/100] Batch [773/782] Loss: 0.6849 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [774/782] Loss: 0.3459 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [775/782] Loss: 0.4636 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [776/782] Loss: 0.2723 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [777/782] Loss: 0.4432 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [778/782] Loss: 0.4645 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [779/782] Loss: 0.3881 | Acc: 83.77%\n",
      "Train Epoch [81/100] Batch [780/782] Loss: 0.3404 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [781/782] Loss: 0.4503 | Acc: 83.76%\n",
      "Train Epoch [81/100] Batch [782/782] Loss: 0.3044 | Acc: 83.76%\n",
      "Epoch 81 completed in 30.20s.\n",
      "Test Epoch [81/100] Loss: 0.9769 | Acc: 72.32% | Inference Time: 8.73s\n",
      "Epoch 81 results saved to CSV.\n",
      "Epoch 82/100\n",
      "Train Epoch [82/100] Batch [1/782] Loss: 0.3883 | Acc: 85.94%\n",
      "Train Epoch [82/100] Batch [2/782] Loss: 0.3929 | Acc: 85.16%\n",
      "Train Epoch [82/100] Batch [3/782] Loss: 0.4335 | Acc: 84.38%\n",
      "Train Epoch [82/100] Batch [4/782] Loss: 0.6133 | Acc: 82.81%\n",
      "Train Epoch [82/100] Batch [5/782] Loss: 0.3557 | Acc: 83.44%\n",
      "Train Epoch [82/100] Batch [6/782] Loss: 0.4644 | Acc: 82.55%\n",
      "Train Epoch [82/100] Batch [7/782] Loss: 0.3340 | Acc: 83.26%\n",
      "Train Epoch [82/100] Batch [8/782] Loss: 0.4480 | Acc: 83.01%\n",
      "Train Epoch [82/100] Batch [9/782] Loss: 0.5110 | Acc: 82.12%\n",
      "Train Epoch [82/100] Batch [10/782] Loss: 0.4239 | Acc: 82.50%\n",
      "Train Epoch [82/100] Batch [11/782] Loss: 0.3917 | Acc: 82.81%\n",
      "Train Epoch [82/100] Batch [12/782] Loss: 0.4620 | Acc: 83.07%\n",
      "Train Epoch [82/100] Batch [13/782] Loss: 0.3726 | Acc: 83.41%\n",
      "Train Epoch [82/100] Batch [14/782] Loss: 0.3743 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [15/782] Loss: 0.4887 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [16/782] Loss: 0.3067 | Acc: 83.89%\n",
      "Train Epoch [82/100] Batch [17/782] Loss: 0.4204 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [18/782] Loss: 0.4433 | Acc: 84.11%\n",
      "Train Epoch [82/100] Batch [19/782] Loss: 0.3038 | Acc: 84.38%\n",
      "Train Epoch [82/100] Batch [20/782] Loss: 0.3670 | Acc: 84.30%\n",
      "Train Epoch [82/100] Batch [21/782] Loss: 0.2253 | Acc: 84.45%\n",
      "Train Epoch [82/100] Batch [22/782] Loss: 0.3556 | Acc: 84.73%\n",
      "Train Epoch [82/100] Batch [23/782] Loss: 0.2357 | Acc: 85.05%\n",
      "Train Epoch [82/100] Batch [24/782] Loss: 0.4375 | Acc: 85.16%\n",
      "Train Epoch [82/100] Batch [25/782] Loss: 0.5351 | Acc: 84.94%\n",
      "Train Epoch [82/100] Batch [26/782] Loss: 0.4115 | Acc: 84.92%\n",
      "Train Epoch [82/100] Batch [27/782] Loss: 0.4232 | Acc: 84.90%\n",
      "Train Epoch [82/100] Batch [28/782] Loss: 0.3850 | Acc: 84.88%\n",
      "Train Epoch [82/100] Batch [29/782] Loss: 0.4181 | Acc: 84.86%\n",
      "Train Epoch [82/100] Batch [30/782] Loss: 0.3707 | Acc: 84.84%\n",
      "Train Epoch [82/100] Batch [31/782] Loss: 0.3380 | Acc: 84.98%\n",
      "Train Epoch [82/100] Batch [32/782] Loss: 0.2786 | Acc: 85.11%\n",
      "Train Epoch [82/100] Batch [33/782] Loss: 0.5754 | Acc: 84.90%\n",
      "Train Epoch [82/100] Batch [34/782] Loss: 0.4260 | Acc: 84.79%\n",
      "Train Epoch [82/100] Batch [35/782] Loss: 0.3047 | Acc: 84.87%\n",
      "Train Epoch [82/100] Batch [36/782] Loss: 0.3889 | Acc: 84.98%\n",
      "Train Epoch [82/100] Batch [37/782] Loss: 0.5160 | Acc: 84.97%\n",
      "Train Epoch [82/100] Batch [38/782] Loss: 0.8846 | Acc: 84.58%\n",
      "Train Epoch [82/100] Batch [39/782] Loss: 0.5673 | Acc: 84.46%\n",
      "Train Epoch [82/100] Batch [40/782] Loss: 0.5547 | Acc: 84.18%\n",
      "Train Epoch [82/100] Batch [41/782] Loss: 0.4206 | Acc: 84.22%\n",
      "Train Epoch [82/100] Batch [42/782] Loss: 0.6849 | Acc: 84.11%\n",
      "Train Epoch [82/100] Batch [43/782] Loss: 0.4783 | Acc: 84.05%\n",
      "Train Epoch [82/100] Batch [44/782] Loss: 0.7302 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [45/782] Loss: 0.5780 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [46/782] Loss: 0.4478 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [47/782] Loss: 0.5111 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [48/782] Loss: 0.2802 | Acc: 83.92%\n",
      "Train Epoch [82/100] Batch [49/782] Loss: 0.5368 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [50/782] Loss: 0.4519 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [51/782] Loss: 0.4017 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [52/782] Loss: 0.6619 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [53/782] Loss: 0.3430 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [54/782] Loss: 0.3609 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [55/782] Loss: 0.4795 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [56/782] Loss: 0.4812 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [57/782] Loss: 0.5376 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [58/782] Loss: 0.5158 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [59/782] Loss: 0.4318 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [60/782] Loss: 0.4414 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [61/782] Loss: 0.4886 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [62/782] Loss: 0.3804 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [63/782] Loss: 0.4461 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [64/782] Loss: 0.5353 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [65/782] Loss: 0.3514 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [66/782] Loss: 0.3779 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [67/782] Loss: 0.4284 | Acc: 83.93%\n",
      "Train Epoch [82/100] Batch [68/782] Loss: 0.4955 | Acc: 83.89%\n",
      "Train Epoch [82/100] Batch [69/782] Loss: 0.5323 | Acc: 83.90%\n",
      "Train Epoch [82/100] Batch [70/782] Loss: 0.6406 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [71/782] Loss: 0.3518 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [72/782] Loss: 0.4374 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [73/782] Loss: 0.4843 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [74/782] Loss: 0.6159 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [75/782] Loss: 0.4973 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [76/782] Loss: 0.3838 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [77/782] Loss: 0.6572 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [78/782] Loss: 0.6457 | Acc: 83.55%\n",
      "Train Epoch [82/100] Batch [79/782] Loss: 0.4495 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [80/782] Loss: 0.6533 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [81/782] Loss: 0.4394 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [82/782] Loss: 0.4496 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [83/782] Loss: 0.5349 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [84/782] Loss: 0.3665 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [85/782] Loss: 0.4615 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [86/782] Loss: 0.3302 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [87/782] Loss: 0.4642 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [88/782] Loss: 0.4283 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [89/782] Loss: 0.4317 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [90/782] Loss: 0.3189 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [91/782] Loss: 0.6080 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [92/782] Loss: 0.3880 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [93/782] Loss: 0.5379 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [94/782] Loss: 0.5443 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [95/782] Loss: 0.4291 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [96/782] Loss: 0.5045 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [97/782] Loss: 0.4640 | Acc: 83.46%\n",
      "Train Epoch [82/100] Batch [98/782] Loss: 0.5852 | Acc: 83.43%\n",
      "Train Epoch [82/100] Batch [99/782] Loss: 0.5622 | Acc: 83.41%\n",
      "Train Epoch [82/100] Batch [100/782] Loss: 0.6145 | Acc: 83.33%\n",
      "Train Epoch [82/100] Batch [101/782] Loss: 0.4500 | Acc: 83.29%\n",
      "Train Epoch [82/100] Batch [102/782] Loss: 0.3231 | Acc: 83.33%\n",
      "Train Epoch [82/100] Batch [103/782] Loss: 0.4556 | Acc: 83.28%\n",
      "Train Epoch [82/100] Batch [104/782] Loss: 0.6034 | Acc: 83.25%\n",
      "Train Epoch [82/100] Batch [105/782] Loss: 0.4347 | Acc: 83.29%\n",
      "Train Epoch [82/100] Batch [106/782] Loss: 0.6500 | Acc: 83.23%\n",
      "Train Epoch [82/100] Batch [107/782] Loss: 0.3833 | Acc: 83.29%\n",
      "Train Epoch [82/100] Batch [108/782] Loss: 0.5334 | Acc: 83.28%\n",
      "Train Epoch [82/100] Batch [109/782] Loss: 0.6500 | Acc: 83.26%\n",
      "Train Epoch [82/100] Batch [110/782] Loss: 0.2648 | Acc: 83.32%\n",
      "Train Epoch [82/100] Batch [111/782] Loss: 0.5696 | Acc: 83.31%\n",
      "Train Epoch [82/100] Batch [112/782] Loss: 0.3989 | Acc: 83.36%\n",
      "Train Epoch [82/100] Batch [113/782] Loss: 0.3192 | Acc: 83.38%\n",
      "Train Epoch [82/100] Batch [114/782] Loss: 0.5358 | Acc: 83.37%\n",
      "Train Epoch [82/100] Batch [115/782] Loss: 0.4018 | Acc: 83.42%\n",
      "Train Epoch [82/100] Batch [116/782] Loss: 0.4959 | Acc: 83.39%\n",
      "Train Epoch [82/100] Batch [117/782] Loss: 0.4869 | Acc: 83.40%\n",
      "Train Epoch [82/100] Batch [118/782] Loss: 0.3039 | Acc: 83.45%\n",
      "Train Epoch [82/100] Batch [119/782] Loss: 0.2670 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [120/782] Loss: 0.4025 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [121/782] Loss: 0.1938 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [122/782] Loss: 0.3198 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [123/782] Loss: 0.3296 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [124/782] Loss: 0.6375 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [125/782] Loss: 0.4415 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [126/782] Loss: 0.4084 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [127/782] Loss: 0.4823 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [128/782] Loss: 0.4845 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [129/782] Loss: 0.4300 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [130/782] Loss: 0.6025 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [131/782] Loss: 0.3624 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [132/782] Loss: 0.3888 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [133/782] Loss: 0.3337 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [134/782] Loss: 0.5181 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [135/782] Loss: 0.4232 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [136/782] Loss: 0.4386 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [137/782] Loss: 0.3528 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [138/782] Loss: 0.5509 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [139/782] Loss: 0.4283 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [140/782] Loss: 0.5682 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [141/782] Loss: 0.3190 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [142/782] Loss: 0.4104 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [143/782] Loss: 0.4344 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [144/782] Loss: 0.4144 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [145/782] Loss: 0.6885 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [146/782] Loss: 0.5549 | Acc: 83.47%\n",
      "Train Epoch [82/100] Batch [147/782] Loss: 0.4529 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [148/782] Loss: 0.4109 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [149/782] Loss: 0.4325 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [150/782] Loss: 0.4088 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [151/782] Loss: 0.4238 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [152/782] Loss: 0.4859 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [153/782] Loss: 0.4503 | Acc: 83.51%\n",
      "Train Epoch [82/100] Batch [154/782] Loss: 0.4448 | Acc: 83.51%\n",
      "Train Epoch [82/100] Batch [155/782] Loss: 0.4354 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [156/782] Loss: 0.4093 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [157/782] Loss: 0.3704 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [158/782] Loss: 0.4363 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [159/782] Loss: 0.6465 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [160/782] Loss: 0.4012 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [161/782] Loss: 0.4032 | Acc: 83.48%\n",
      "Train Epoch [82/100] Batch [162/782] Loss: 0.4623 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [163/782] Loss: 0.5925 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [164/782] Loss: 0.3630 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [165/782] Loss: 0.4801 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [166/782] Loss: 0.3424 | Acc: 83.55%\n",
      "Train Epoch [82/100] Batch [167/782] Loss: 0.5828 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [168/782] Loss: 0.4250 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [169/782] Loss: 0.5381 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [170/782] Loss: 0.5853 | Acc: 83.51%\n",
      "Train Epoch [82/100] Batch [171/782] Loss: 0.6210 | Acc: 83.47%\n",
      "Train Epoch [82/100] Batch [172/782] Loss: 0.3103 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [173/782] Loss: 0.4675 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [174/782] Loss: 0.3546 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [175/782] Loss: 0.5397 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [176/782] Loss: 0.5024 | Acc: 83.47%\n",
      "Train Epoch [82/100] Batch [177/782] Loss: 0.3612 | Acc: 83.46%\n",
      "Train Epoch [82/100] Batch [178/782] Loss: 0.4451 | Acc: 83.46%\n",
      "Train Epoch [82/100] Batch [179/782] Loss: 0.5269 | Acc: 83.44%\n",
      "Train Epoch [82/100] Batch [180/782] Loss: 0.4194 | Acc: 83.46%\n",
      "Train Epoch [82/100] Batch [181/782] Loss: 0.3819 | Acc: 83.47%\n",
      "Train Epoch [82/100] Batch [182/782] Loss: 0.3660 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [183/782] Loss: 0.3889 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [184/782] Loss: 0.4042 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [185/782] Loss: 0.3565 | Acc: 83.55%\n",
      "Train Epoch [82/100] Batch [186/782] Loss: 0.4125 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [187/782] Loss: 0.5017 | Acc: 83.51%\n",
      "Train Epoch [82/100] Batch [188/782] Loss: 0.5065 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [189/782] Loss: 0.3504 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [190/782] Loss: 0.4927 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [191/782] Loss: 0.3173 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [192/782] Loss: 0.4476 | Acc: 83.48%\n",
      "Train Epoch [82/100] Batch [193/782] Loss: 0.5043 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [194/782] Loss: 0.4456 | Acc: 83.50%\n",
      "Train Epoch [82/100] Batch [195/782] Loss: 0.4932 | Acc: 83.49%\n",
      "Train Epoch [82/100] Batch [196/782] Loss: 0.3607 | Acc: 83.52%\n",
      "Train Epoch [82/100] Batch [197/782] Loss: 0.2154 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [198/782] Loss: 0.4132 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [199/782] Loss: 0.4599 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [200/782] Loss: 0.3376 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [201/782] Loss: 0.6844 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [202/782] Loss: 0.4017 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [203/782] Loss: 0.3959 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [204/782] Loss: 0.3107 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [205/782] Loss: 0.3797 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [206/782] Loss: 0.3874 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [207/782] Loss: 0.4468 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [208/782] Loss: 0.3650 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [209/782] Loss: 0.3733 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [210/782] Loss: 0.3764 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [211/782] Loss: 0.4268 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [212/782] Loss: 0.3985 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [213/782] Loss: 0.2326 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [214/782] Loss: 0.3892 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [215/782] Loss: 0.5431 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [216/782] Loss: 0.5098 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [217/782] Loss: 0.3747 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [218/782] Loss: 0.4002 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [219/782] Loss: 0.2344 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [220/782] Loss: 0.4512 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [221/782] Loss: 0.4370 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [222/782] Loss: 0.3500 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [223/782] Loss: 0.6008 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [224/782] Loss: 0.4855 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [225/782] Loss: 0.4996 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [226/782] Loss: 0.4337 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [227/782] Loss: 0.5044 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [228/782] Loss: 0.4952 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [229/782] Loss: 0.5720 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [230/782] Loss: 0.4818 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [231/782] Loss: 0.6444 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [232/782] Loss: 0.4178 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [233/782] Loss: 0.4030 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [234/782] Loss: 0.4904 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [235/782] Loss: 0.4407 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [236/782] Loss: 0.4030 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [237/782] Loss: 0.7765 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [238/782] Loss: 0.3030 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [239/782] Loss: 0.3243 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [240/782] Loss: 0.5312 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [241/782] Loss: 0.5498 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [242/782] Loss: 0.4238 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [243/782] Loss: 0.4532 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [244/782] Loss: 0.3857 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [245/782] Loss: 0.5092 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [246/782] Loss: 0.3506 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [247/782] Loss: 0.4085 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [248/782] Loss: 0.5921 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [249/782] Loss: 0.5399 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [250/782] Loss: 0.5657 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [251/782] Loss: 0.5054 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [252/782] Loss: 0.5727 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [253/782] Loss: 0.5198 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [254/782] Loss: 0.4426 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [255/782] Loss: 0.5817 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [256/782] Loss: 0.4275 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [257/782] Loss: 0.4741 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [258/782] Loss: 0.4182 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [259/782] Loss: 0.3942 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [260/782] Loss: 0.5369 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [261/782] Loss: 0.4788 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [262/782] Loss: 0.4726 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [263/782] Loss: 0.4940 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [264/782] Loss: 0.5338 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [265/782] Loss: 0.4413 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [266/782] Loss: 0.2496 | Acc: 83.56%\n",
      "Train Epoch [82/100] Batch [267/782] Loss: 0.5159 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [268/782] Loss: 0.4528 | Acc: 83.55%\n",
      "Train Epoch [82/100] Batch [269/782] Loss: 0.5276 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [270/782] Loss: 0.4736 | Acc: 83.54%\n",
      "Train Epoch [82/100] Batch [271/782] Loss: 0.5234 | Acc: 83.53%\n",
      "Train Epoch [82/100] Batch [272/782] Loss: 0.3550 | Acc: 83.55%\n",
      "Train Epoch [82/100] Batch [273/782] Loss: 0.2891 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [274/782] Loss: 0.3503 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [275/782] Loss: 0.5344 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [276/782] Loss: 0.3649 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [277/782] Loss: 0.3383 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [278/782] Loss: 0.6901 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [279/782] Loss: 0.4571 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [280/782] Loss: 0.5007 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [281/782] Loss: 0.3443 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [282/782] Loss: 0.3948 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [283/782] Loss: 0.4008 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [284/782] Loss: 0.5433 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [285/782] Loss: 0.5129 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [286/782] Loss: 0.4042 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [287/782] Loss: 0.5328 | Acc: 83.57%\n",
      "Train Epoch [82/100] Batch [288/782] Loss: 0.3693 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [289/782] Loss: 0.5089 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [290/782] Loss: 0.5293 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [291/782] Loss: 0.5005 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [292/782] Loss: 0.5643 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [293/782] Loss: 0.6146 | Acc: 83.58%\n",
      "Train Epoch [82/100] Batch [294/782] Loss: 0.3449 | Acc: 83.59%\n",
      "Train Epoch [82/100] Batch [295/782] Loss: 0.5050 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [296/782] Loss: 0.4481 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [297/782] Loss: 0.3812 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [298/782] Loss: 0.5634 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [299/782] Loss: 0.4711 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [300/782] Loss: 0.3484 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [301/782] Loss: 0.3910 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [302/782] Loss: 0.2421 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [303/782] Loss: 0.4783 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [304/782] Loss: 0.3544 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [305/782] Loss: 0.3367 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [306/782] Loss: 0.4337 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [307/782] Loss: 0.4710 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [308/782] Loss: 0.5531 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [309/782] Loss: 0.3781 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [310/782] Loss: 0.5995 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [311/782] Loss: 0.4173 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [312/782] Loss: 0.4550 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [313/782] Loss: 0.4838 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [314/782] Loss: 0.4086 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [315/782] Loss: 0.3561 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [316/782] Loss: 0.3619 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [317/782] Loss: 0.6188 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [318/782] Loss: 0.3624 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [319/782] Loss: 0.3536 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [320/782] Loss: 0.5517 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [321/782] Loss: 0.5611 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [322/782] Loss: 0.4559 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [323/782] Loss: 0.5080 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [324/782] Loss: 0.3274 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [325/782] Loss: 0.4087 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [326/782] Loss: 0.4667 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [327/782] Loss: 0.6772 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [328/782] Loss: 0.4133 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [329/782] Loss: 0.5958 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [330/782] Loss: 0.3947 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [331/782] Loss: 0.5878 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [332/782] Loss: 0.4780 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [333/782] Loss: 0.4037 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [334/782] Loss: 0.5610 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [335/782] Loss: 0.4659 | Acc: 83.60%\n",
      "Train Epoch [82/100] Batch [336/782] Loss: 0.2769 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [337/782] Loss: 0.4200 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [338/782] Loss: 0.4952 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [339/782] Loss: 0.3488 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [340/782] Loss: 0.3555 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [341/782] Loss: 0.6314 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [342/782] Loss: 0.3146 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [343/782] Loss: 0.4887 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [344/782] Loss: 0.2535 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [345/782] Loss: 0.4086 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [346/782] Loss: 0.3340 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [347/782] Loss: 0.3815 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [348/782] Loss: 0.4748 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [349/782] Loss: 0.7321 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [350/782] Loss: 0.3563 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [351/782] Loss: 0.4356 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [352/782] Loss: 0.3974 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [353/782] Loss: 0.4916 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [354/782] Loss: 0.2489 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [355/782] Loss: 0.6995 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [356/782] Loss: 0.4449 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [357/782] Loss: 0.4049 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [358/782] Loss: 0.3364 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [359/782] Loss: 0.5073 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [360/782] Loss: 0.3384 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [361/782] Loss: 0.4910 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [362/782] Loss: 0.4828 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [363/782] Loss: 0.4339 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [364/782] Loss: 0.5544 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [365/782] Loss: 0.3652 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [366/782] Loss: 0.4800 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [367/782] Loss: 0.4932 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [368/782] Loss: 0.4067 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [369/782] Loss: 0.3516 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [370/782] Loss: 0.5049 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [371/782] Loss: 0.4655 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [372/782] Loss: 0.5081 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [373/782] Loss: 0.2647 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [374/782] Loss: 0.3547 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [375/782] Loss: 0.4305 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [376/782] Loss: 0.4020 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [377/782] Loss: 0.5301 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [378/782] Loss: 0.5513 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [379/782] Loss: 0.4045 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [380/782] Loss: 0.2723 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [381/782] Loss: 0.4970 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [382/782] Loss: 0.4261 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [383/782] Loss: 0.5473 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [384/782] Loss: 0.3916 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [385/782] Loss: 0.6358 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [386/782] Loss: 0.4042 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [387/782] Loss: 0.5193 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [388/782] Loss: 0.2921 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [389/782] Loss: 0.4911 | Acc: 83.61%\n",
      "Train Epoch [82/100] Batch [390/782] Loss: 0.3917 | Acc: 83.62%\n",
      "Train Epoch [82/100] Batch [391/782] Loss: 0.2700 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [392/782] Loss: 0.3864 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [393/782] Loss: 0.3777 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [394/782] Loss: 0.5183 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [395/782] Loss: 0.2323 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [396/782] Loss: 0.5587 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [397/782] Loss: 0.6112 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [398/782] Loss: 0.6955 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [399/782] Loss: 0.3130 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [400/782] Loss: 0.3391 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [401/782] Loss: 0.5405 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [402/782] Loss: 0.6294 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [403/782] Loss: 0.5258 | Acc: 83.63%\n",
      "Train Epoch [82/100] Batch [404/782] Loss: 0.4609 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [405/782] Loss: 0.4171 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [406/782] Loss: 0.2362 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [407/782] Loss: 0.2966 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [408/782] Loss: 0.4929 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [409/782] Loss: 0.3894 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [410/782] Loss: 0.6603 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [411/782] Loss: 0.4964 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [412/782] Loss: 0.3403 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [413/782] Loss: 0.5268 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [414/782] Loss: 0.4420 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [415/782] Loss: 0.4851 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [416/782] Loss: 0.2809 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [417/782] Loss: 0.5515 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [418/782] Loss: 0.5478 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [419/782] Loss: 0.5284 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [420/782] Loss: 0.3217 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [421/782] Loss: 0.5565 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [422/782] Loss: 0.3891 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [423/782] Loss: 0.4351 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [424/782] Loss: 0.3775 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [425/782] Loss: 0.4371 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [426/782] Loss: 0.3784 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [427/782] Loss: 0.4602 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [428/782] Loss: 0.4790 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [429/782] Loss: 0.3665 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [430/782] Loss: 0.5988 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [431/782] Loss: 0.4442 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [432/782] Loss: 0.5037 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [433/782] Loss: 0.3185 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [434/782] Loss: 0.6116 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [435/782] Loss: 0.4609 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [436/782] Loss: 0.4524 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [437/782] Loss: 0.3705 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [438/782] Loss: 0.6219 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [439/782] Loss: 0.4152 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [440/782] Loss: 0.5830 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [441/782] Loss: 0.3348 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [442/782] Loss: 0.4959 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [443/782] Loss: 0.5311 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [444/782] Loss: 0.4314 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [445/782] Loss: 0.3330 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [446/782] Loss: 0.2967 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [447/782] Loss: 0.6478 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [448/782] Loss: 0.5960 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [449/782] Loss: 0.2554 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [450/782] Loss: 0.4231 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [451/782] Loss: 0.3817 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [452/782] Loss: 0.3500 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [453/782] Loss: 0.4370 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [454/782] Loss: 0.4360 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [455/782] Loss: 0.4765 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [456/782] Loss: 0.4325 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [457/782] Loss: 0.6505 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [458/782] Loss: 0.4016 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [459/782] Loss: 0.3919 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [460/782] Loss: 0.4621 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [461/782] Loss: 0.7254 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [462/782] Loss: 0.4465 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [463/782] Loss: 0.4331 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [464/782] Loss: 0.4908 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [465/782] Loss: 0.3667 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [466/782] Loss: 0.3802 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [467/782] Loss: 0.3844 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [468/782] Loss: 0.4584 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [469/782] Loss: 0.3824 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [470/782] Loss: 0.6280 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [471/782] Loss: 0.4965 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [472/782] Loss: 0.3515 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [473/782] Loss: 0.5164 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [474/782] Loss: 0.3995 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [475/782] Loss: 0.2087 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [476/782] Loss: 0.4954 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [477/782] Loss: 0.4906 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [478/782] Loss: 0.4130 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [479/782] Loss: 0.4954 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [480/782] Loss: 0.4597 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [481/782] Loss: 0.5436 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [482/782] Loss: 0.4224 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [483/782] Loss: 0.4416 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [484/782] Loss: 0.2528 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [485/782] Loss: 0.4881 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [486/782] Loss: 0.5401 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [487/782] Loss: 0.5431 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [488/782] Loss: 0.2495 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [489/782] Loss: 0.4002 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [490/782] Loss: 0.4966 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [491/782] Loss: 0.3353 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [492/782] Loss: 0.5404 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [493/782] Loss: 0.4417 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [494/782] Loss: 0.4614 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [495/782] Loss: 0.4182 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [496/782] Loss: 0.5433 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [497/782] Loss: 0.4776 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [498/782] Loss: 0.4518 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [499/782] Loss: 0.4610 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [500/782] Loss: 0.2876 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [501/782] Loss: 0.5689 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [502/782] Loss: 0.3565 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [503/782] Loss: 0.7055 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [504/782] Loss: 0.3720 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [505/782] Loss: 0.4685 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [506/782] Loss: 0.4592 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [507/782] Loss: 0.2563 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [508/782] Loss: 0.4224 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [509/782] Loss: 0.2325 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [510/782] Loss: 0.5700 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [511/782] Loss: 0.4704 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [512/782] Loss: 0.3745 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [513/782] Loss: 0.5197 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [514/782] Loss: 0.5955 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [515/782] Loss: 0.5218 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [516/782] Loss: 0.3482 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [517/782] Loss: 0.3962 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [518/782] Loss: 0.3058 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [519/782] Loss: 0.5297 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [520/782] Loss: 0.4450 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [521/782] Loss: 0.4068 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [522/782] Loss: 0.2189 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [523/782] Loss: 0.6629 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [524/782] Loss: 0.6277 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [525/782] Loss: 0.4662 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [526/782] Loss: 0.5227 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [527/782] Loss: 0.4517 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [528/782] Loss: 0.4207 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [529/782] Loss: 0.5822 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [530/782] Loss: 0.4250 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [531/782] Loss: 0.4392 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [532/782] Loss: 0.3562 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [533/782] Loss: 0.5243 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [534/782] Loss: 0.4394 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [535/782] Loss: 0.4663 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [536/782] Loss: 0.5591 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [537/782] Loss: 0.5851 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [538/782] Loss: 0.4018 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [539/782] Loss: 0.4540 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [540/782] Loss: 0.4439 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [541/782] Loss: 0.4731 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [542/782] Loss: 0.3528 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [543/782] Loss: 0.2944 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [544/782] Loss: 0.5960 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [545/782] Loss: 0.5828 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [546/782] Loss: 0.5335 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [547/782] Loss: 0.3187 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [548/782] Loss: 0.3156 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [549/782] Loss: 0.4261 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [550/782] Loss: 0.5424 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [551/782] Loss: 0.3795 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [552/782] Loss: 0.3090 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [553/782] Loss: 0.4136 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [554/782] Loss: 0.4983 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [555/782] Loss: 0.3477 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [556/782] Loss: 0.6096 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [557/782] Loss: 0.5948 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [558/782] Loss: 0.3207 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [559/782] Loss: 0.4986 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [560/782] Loss: 0.4692 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [561/782] Loss: 0.5029 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [562/782] Loss: 0.5701 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [563/782] Loss: 0.6075 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [564/782] Loss: 0.2313 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [565/782] Loss: 0.4941 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [566/782] Loss: 0.4822 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [567/782] Loss: 0.6086 | Acc: 83.64%\n",
      "Train Epoch [82/100] Batch [568/782] Loss: 0.4288 | Acc: 83.65%\n",
      "Train Epoch [82/100] Batch [569/782] Loss: 0.2957 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [570/782] Loss: 0.3047 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [571/782] Loss: 0.4357 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [572/782] Loss: 0.4692 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [573/782] Loss: 0.3889 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [574/782] Loss: 0.4181 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [575/782] Loss: 0.3533 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [576/782] Loss: 0.4813 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [577/782] Loss: 0.5061 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [578/782] Loss: 0.4209 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [579/782] Loss: 0.5958 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [580/782] Loss: 0.3307 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [581/782] Loss: 0.4031 | Acc: 83.67%\n",
      "Train Epoch [82/100] Batch [582/782] Loss: 0.4906 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [583/782] Loss: 0.4571 | Acc: 83.66%\n",
      "Train Epoch [82/100] Batch [584/782] Loss: 0.2177 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [585/782] Loss: 0.4336 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [586/782] Loss: 0.4514 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [587/782] Loss: 0.4969 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [588/782] Loss: 0.3800 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [589/782] Loss: 0.5995 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [590/782] Loss: 0.4683 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [591/782] Loss: 0.5540 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [592/782] Loss: 0.4002 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [593/782] Loss: 0.4433 | Acc: 83.68%\n",
      "Train Epoch [82/100] Batch [594/782] Loss: 0.1765 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [595/782] Loss: 0.6395 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [596/782] Loss: 0.3852 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [597/782] Loss: 0.2977 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [598/782] Loss: 0.7871 | Acc: 83.69%\n",
      "Train Epoch [82/100] Batch [599/782] Loss: 0.4259 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [600/782] Loss: 0.3329 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [601/782] Loss: 0.4224 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [602/782] Loss: 0.3393 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [603/782] Loss: 0.4403 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [604/782] Loss: 0.3456 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [605/782] Loss: 0.3416 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [606/782] Loss: 0.5700 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [607/782] Loss: 0.4988 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [608/782] Loss: 0.3405 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [609/782] Loss: 0.3973 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [610/782] Loss: 0.3430 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [611/782] Loss: 0.4606 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [612/782] Loss: 0.6284 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [613/782] Loss: 0.4580 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [614/782] Loss: 0.3882 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [615/782] Loss: 0.5587 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [616/782] Loss: 0.3142 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [617/782] Loss: 0.3148 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [618/782] Loss: 0.3498 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [619/782] Loss: 0.4214 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [620/782] Loss: 0.3523 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [621/782] Loss: 0.4461 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [622/782] Loss: 0.3481 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [623/782] Loss: 0.4737 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [624/782] Loss: 0.4809 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [625/782] Loss: 0.4291 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [626/782] Loss: 0.5146 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [627/782] Loss: 0.3257 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [628/782] Loss: 0.4982 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [629/782] Loss: 0.4166 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [630/782] Loss: 0.4949 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [631/782] Loss: 0.4056 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [632/782] Loss: 0.3943 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [633/782] Loss: 0.6104 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [634/782] Loss: 0.4149 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [635/782] Loss: 0.4378 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [636/782] Loss: 0.3017 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [637/782] Loss: 0.4385 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [638/782] Loss: 0.4356 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [639/782] Loss: 0.4827 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [640/782] Loss: 0.4445 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [641/782] Loss: 0.6896 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [642/782] Loss: 0.4518 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [643/782] Loss: 0.3326 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [644/782] Loss: 0.4992 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [645/782] Loss: 0.2008 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [646/782] Loss: 0.4419 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [647/782] Loss: 0.3269 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [648/782] Loss: 0.2707 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [649/782] Loss: 0.4052 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [650/782] Loss: 0.3681 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [651/782] Loss: 0.4049 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [652/782] Loss: 0.5298 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [653/782] Loss: 0.3067 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [654/782] Loss: 0.4748 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [655/782] Loss: 0.4232 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [656/782] Loss: 0.4668 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [657/782] Loss: 0.4599 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [658/782] Loss: 0.4232 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [659/782] Loss: 0.7106 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [660/782] Loss: 0.4851 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [661/782] Loss: 0.2608 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [662/782] Loss: 0.3645 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [663/782] Loss: 0.5223 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [664/782] Loss: 0.5799 | Acc: 83.77%\n",
      "Train Epoch [82/100] Batch [665/782] Loss: 0.7299 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [666/782] Loss: 0.3076 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [667/782] Loss: 0.5078 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [668/782] Loss: 0.3922 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [669/782] Loss: 0.5894 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [670/782] Loss: 0.5463 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [671/782] Loss: 0.5792 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [672/782] Loss: 0.3843 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [673/782] Loss: 0.5168 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [674/782] Loss: 0.3816 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [675/782] Loss: 0.5668 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [676/782] Loss: 0.3279 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [677/782] Loss: 0.4311 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [678/782] Loss: 0.4770 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [679/782] Loss: 0.5312 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [680/782] Loss: 0.6202 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [681/782] Loss: 0.5726 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [682/782] Loss: 0.3545 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [683/782] Loss: 0.5765 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [684/782] Loss: 0.3785 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [685/782] Loss: 0.4762 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [686/782] Loss: 0.4915 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [687/782] Loss: 0.3153 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [688/782] Loss: 0.4861 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [689/782] Loss: 0.4881 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [690/782] Loss: 0.4708 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [691/782] Loss: 0.3226 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [692/782] Loss: 0.5406 | Acc: 83.70%\n",
      "Train Epoch [82/100] Batch [693/782] Loss: 0.2638 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [694/782] Loss: 0.3817 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [695/782] Loss: 0.4917 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [696/782] Loss: 0.3967 | Acc: 83.71%\n",
      "Train Epoch [82/100] Batch [697/782] Loss: 0.3485 | Acc: 83.72%\n",
      "Train Epoch [82/100] Batch [698/782] Loss: 0.4073 | Acc: 83.73%\n",
      "Train Epoch [82/100] Batch [699/782] Loss: 0.3962 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [700/782] Loss: 0.5017 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [701/782] Loss: 0.3057 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [702/782] Loss: 0.3889 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [703/782] Loss: 0.4094 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [704/782] Loss: 0.3218 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [705/782] Loss: 0.6256 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [706/782] Loss: 0.3766 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [707/782] Loss: 0.5082 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [708/782] Loss: 0.2917 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [709/782] Loss: 0.4981 | Acc: 83.74%\n",
      "Train Epoch [82/100] Batch [710/782] Loss: 0.3889 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [711/782] Loss: 0.3212 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [712/782] Loss: 0.3946 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [713/782] Loss: 0.3957 | Acc: 83.75%\n",
      "Train Epoch [82/100] Batch [714/782] Loss: 0.2539 | Acc: 83.76%\n",
      "Train Epoch [82/100] Batch [715/782] Loss: 0.2621 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [716/782] Loss: 0.5449 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [717/782] Loss: 0.6147 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [718/782] Loss: 0.4174 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [719/782] Loss: 0.5166 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [720/782] Loss: 0.4498 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [721/782] Loss: 0.4410 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [722/782] Loss: 0.4589 | Acc: 83.78%\n",
      "Train Epoch [82/100] Batch [723/782] Loss: 0.3229 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [724/782] Loss: 0.3707 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [725/782] Loss: 0.3734 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [726/782] Loss: 0.3931 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [727/782] Loss: 0.5095 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [728/782] Loss: 0.4348 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [729/782] Loss: 0.5224 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [730/782] Loss: 0.4730 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [731/782] Loss: 0.5804 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [732/782] Loss: 0.3954 | Acc: 83.79%\n",
      "Train Epoch [82/100] Batch [733/782] Loss: 0.4162 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [734/782] Loss: 0.5436 | Acc: 83.80%\n",
      "Train Epoch [82/100] Batch [735/782] Loss: 0.3324 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [736/782] Loss: 0.4463 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [737/782] Loss: 0.5060 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [738/782] Loss: 0.4219 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [739/782] Loss: 0.4187 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [740/782] Loss: 0.3480 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [741/782] Loss: 0.4816 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [742/782] Loss: 0.4791 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [743/782] Loss: 0.4384 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [744/782] Loss: 0.5053 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [745/782] Loss: 0.3767 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [746/782] Loss: 0.4822 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [747/782] Loss: 0.5060 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [748/782] Loss: 0.7172 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [749/782] Loss: 0.3945 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [750/782] Loss: 0.4565 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [751/782] Loss: 0.4099 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [752/782] Loss: 0.5478 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [753/782] Loss: 0.5861 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [754/782] Loss: 0.2307 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [755/782] Loss: 0.6240 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [756/782] Loss: 0.5767 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [757/782] Loss: 0.3669 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [758/782] Loss: 0.4008 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [759/782] Loss: 0.3952 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [760/782] Loss: 0.4729 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [761/782] Loss: 0.4525 | Acc: 83.81%\n",
      "Train Epoch [82/100] Batch [762/782] Loss: 0.2997 | Acc: 83.82%\n",
      "Train Epoch [82/100] Batch [763/782] Loss: 0.5132 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [764/782] Loss: 0.3015 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [765/782] Loss: 0.4644 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [766/782] Loss: 0.5181 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [767/782] Loss: 0.3275 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [768/782] Loss: 0.3475 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [769/782] Loss: 0.4317 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [770/782] Loss: 0.4734 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [771/782] Loss: 0.3619 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [772/782] Loss: 0.3087 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [773/782] Loss: 0.4037 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [774/782] Loss: 0.4731 | Acc: 83.85%\n",
      "Train Epoch [82/100] Batch [775/782] Loss: 0.6208 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [776/782] Loss: 0.4163 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [777/782] Loss: 0.5461 | Acc: 83.83%\n",
      "Train Epoch [82/100] Batch [778/782] Loss: 0.3836 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [779/782] Loss: 0.4605 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [780/782] Loss: 0.4042 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [781/782] Loss: 0.5208 | Acc: 83.84%\n",
      "Train Epoch [82/100] Batch [782/782] Loss: 0.6888 | Acc: 83.83%\n",
      "Epoch 82 completed in 30.75s.\n",
      "Test Epoch [82/100] Loss: 0.9916 | Acc: 72.45% | Inference Time: 8.22s\n",
      "Epoch 82 results saved to CSV.\n",
      "Epoch 83/100\n",
      "Train Epoch [83/100] Batch [1/782] Loss: 0.3899 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [2/782] Loss: 0.5039 | Acc: 83.59%\n",
      "Train Epoch [83/100] Batch [3/782] Loss: 0.4928 | Acc: 82.29%\n",
      "Train Epoch [83/100] Batch [4/782] Loss: 0.4010 | Acc: 83.59%\n",
      "Train Epoch [83/100] Batch [5/782] Loss: 0.4785 | Acc: 82.81%\n",
      "Train Epoch [83/100] Batch [6/782] Loss: 0.3528 | Acc: 83.07%\n",
      "Train Epoch [83/100] Batch [7/782] Loss: 0.5830 | Acc: 81.92%\n",
      "Train Epoch [83/100] Batch [8/782] Loss: 0.5056 | Acc: 81.84%\n",
      "Train Epoch [83/100] Batch [9/782] Loss: 0.3537 | Acc: 82.29%\n",
      "Train Epoch [83/100] Batch [10/782] Loss: 0.3765 | Acc: 82.81%\n",
      "Train Epoch [83/100] Batch [11/782] Loss: 0.3912 | Acc: 83.10%\n",
      "Train Epoch [83/100] Batch [12/782] Loss: 0.6919 | Acc: 82.55%\n",
      "Train Epoch [83/100] Batch [13/782] Loss: 0.3473 | Acc: 82.69%\n",
      "Train Epoch [83/100] Batch [14/782] Loss: 0.5062 | Acc: 82.59%\n",
      "Train Epoch [83/100] Batch [15/782] Loss: 0.2289 | Acc: 83.12%\n",
      "Train Epoch [83/100] Batch [16/782] Loss: 0.3760 | Acc: 83.40%\n",
      "Train Epoch [83/100] Batch [17/782] Loss: 0.5045 | Acc: 83.09%\n",
      "Train Epoch [83/100] Batch [18/782] Loss: 0.6266 | Acc: 82.90%\n",
      "Train Epoch [83/100] Batch [19/782] Loss: 0.5665 | Acc: 82.73%\n",
      "Train Epoch [83/100] Batch [20/782] Loss: 0.3696 | Acc: 83.05%\n",
      "Train Epoch [83/100] Batch [21/782] Loss: 0.6648 | Acc: 82.89%\n",
      "Train Epoch [83/100] Batch [22/782] Loss: 0.4067 | Acc: 83.03%\n",
      "Train Epoch [83/100] Batch [23/782] Loss: 0.5503 | Acc: 82.74%\n",
      "Train Epoch [83/100] Batch [24/782] Loss: 0.4165 | Acc: 82.94%\n",
      "Train Epoch [83/100] Batch [25/782] Loss: 0.4261 | Acc: 83.06%\n",
      "Train Epoch [83/100] Batch [26/782] Loss: 0.5194 | Acc: 83.11%\n",
      "Train Epoch [83/100] Batch [27/782] Loss: 0.3999 | Acc: 83.39%\n",
      "Train Epoch [83/100] Batch [28/782] Loss: 0.5104 | Acc: 83.20%\n",
      "Train Epoch [83/100] Batch [29/782] Loss: 0.5298 | Acc: 83.08%\n",
      "Train Epoch [83/100] Batch [30/782] Loss: 0.3129 | Acc: 83.39%\n",
      "Train Epoch [83/100] Batch [31/782] Loss: 0.6025 | Acc: 83.37%\n",
      "Train Epoch [83/100] Batch [32/782] Loss: 0.3630 | Acc: 83.54%\n",
      "Train Epoch [83/100] Batch [33/782] Loss: 0.5240 | Acc: 83.43%\n",
      "Train Epoch [83/100] Batch [34/782] Loss: 0.4028 | Acc: 83.46%\n",
      "Train Epoch [83/100] Batch [35/782] Loss: 0.3766 | Acc: 83.57%\n",
      "Train Epoch [83/100] Batch [36/782] Loss: 0.5381 | Acc: 83.59%\n",
      "Train Epoch [83/100] Batch [37/782] Loss: 0.5728 | Acc: 83.61%\n",
      "Train Epoch [83/100] Batch [38/782] Loss: 0.2244 | Acc: 83.92%\n",
      "Train Epoch [83/100] Batch [39/782] Loss: 0.5201 | Acc: 83.85%\n",
      "Train Epoch [83/100] Batch [40/782] Loss: 0.5324 | Acc: 83.75%\n",
      "Train Epoch [83/100] Batch [41/782] Loss: 0.2895 | Acc: 83.99%\n",
      "Train Epoch [83/100] Batch [42/782] Loss: 0.3810 | Acc: 84.00%\n",
      "Train Epoch [83/100] Batch [43/782] Loss: 0.3992 | Acc: 84.16%\n",
      "Train Epoch [83/100] Batch [44/782] Loss: 0.4433 | Acc: 84.16%\n",
      "Train Epoch [83/100] Batch [45/782] Loss: 0.4300 | Acc: 84.10%\n",
      "Train Epoch [83/100] Batch [46/782] Loss: 0.6485 | Acc: 83.97%\n",
      "Train Epoch [83/100] Batch [47/782] Loss: 0.3437 | Acc: 84.01%\n",
      "Train Epoch [83/100] Batch [48/782] Loss: 0.2786 | Acc: 84.21%\n",
      "Train Epoch [83/100] Batch [49/782] Loss: 0.5932 | Acc: 84.15%\n",
      "Train Epoch [83/100] Batch [50/782] Loss: 0.5429 | Acc: 84.09%\n",
      "Train Epoch [83/100] Batch [51/782] Loss: 0.5644 | Acc: 84.01%\n",
      "Train Epoch [83/100] Batch [52/782] Loss: 0.3750 | Acc: 84.04%\n",
      "Train Epoch [83/100] Batch [53/782] Loss: 0.3353 | Acc: 84.17%\n",
      "Train Epoch [83/100] Batch [54/782] Loss: 0.4633 | Acc: 84.14%\n",
      "Train Epoch [83/100] Batch [55/782] Loss: 0.4382 | Acc: 84.06%\n",
      "Train Epoch [83/100] Batch [56/782] Loss: 0.3518 | Acc: 84.12%\n",
      "Train Epoch [83/100] Batch [57/782] Loss: 0.4629 | Acc: 84.16%\n",
      "Train Epoch [83/100] Batch [58/782] Loss: 0.4300 | Acc: 84.19%\n",
      "Train Epoch [83/100] Batch [59/782] Loss: 0.4028 | Acc: 84.24%\n",
      "Train Epoch [83/100] Batch [60/782] Loss: 0.3878 | Acc: 84.24%\n",
      "Train Epoch [83/100] Batch [61/782] Loss: 0.3852 | Acc: 84.25%\n",
      "Train Epoch [83/100] Batch [62/782] Loss: 0.4961 | Acc: 84.17%\n",
      "Train Epoch [83/100] Batch [63/782] Loss: 0.4932 | Acc: 84.13%\n",
      "Train Epoch [83/100] Batch [64/782] Loss: 0.4758 | Acc: 84.16%\n",
      "Train Epoch [83/100] Batch [65/782] Loss: 0.5029 | Acc: 84.11%\n",
      "Train Epoch [83/100] Batch [66/782] Loss: 0.5289 | Acc: 84.04%\n",
      "Train Epoch [83/100] Batch [67/782] Loss: 0.6708 | Acc: 83.98%\n",
      "Train Epoch [83/100] Batch [68/782] Loss: 0.3564 | Acc: 84.08%\n",
      "Train Epoch [83/100] Batch [69/782] Loss: 0.3845 | Acc: 84.04%\n",
      "Train Epoch [83/100] Batch [70/782] Loss: 0.5767 | Acc: 84.00%\n",
      "Train Epoch [83/100] Batch [71/782] Loss: 0.4697 | Acc: 83.98%\n",
      "Train Epoch [83/100] Batch [72/782] Loss: 0.4673 | Acc: 84.01%\n",
      "Train Epoch [83/100] Batch [73/782] Loss: 0.3331 | Acc: 84.05%\n",
      "Train Epoch [83/100] Batch [74/782] Loss: 0.4327 | Acc: 84.10%\n",
      "Train Epoch [83/100] Batch [75/782] Loss: 0.2494 | Acc: 84.19%\n",
      "Train Epoch [83/100] Batch [76/782] Loss: 0.3863 | Acc: 84.17%\n",
      "Train Epoch [83/100] Batch [77/782] Loss: 0.3245 | Acc: 84.27%\n",
      "Train Epoch [83/100] Batch [78/782] Loss: 0.3706 | Acc: 84.29%\n",
      "Train Epoch [83/100] Batch [79/782] Loss: 0.3088 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [80/782] Loss: 0.4213 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [81/782] Loss: 0.5976 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [82/782] Loss: 0.5937 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [83/782] Loss: 0.4928 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [84/782] Loss: 0.5785 | Acc: 84.26%\n",
      "Train Epoch [83/100] Batch [85/782] Loss: 0.5140 | Acc: 84.26%\n",
      "Train Epoch [83/100] Batch [86/782] Loss: 0.3871 | Acc: 84.25%\n",
      "Train Epoch [83/100] Batch [87/782] Loss: 0.3952 | Acc: 84.29%\n",
      "Train Epoch [83/100] Batch [88/782] Loss: 0.5910 | Acc: 84.23%\n",
      "Train Epoch [83/100] Batch [89/782] Loss: 0.4083 | Acc: 84.25%\n",
      "Train Epoch [83/100] Batch [90/782] Loss: 0.3115 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [91/782] Loss: 0.3755 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [92/782] Loss: 0.4047 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [93/782] Loss: 0.3769 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [94/782] Loss: 0.5608 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [95/782] Loss: 0.4380 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [96/782] Loss: 0.4004 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [97/782] Loss: 0.5508 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [98/782] Loss: 0.3760 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [99/782] Loss: 0.5599 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [100/782] Loss: 0.3242 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [101/782] Loss: 0.4052 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [102/782] Loss: 0.3020 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [103/782] Loss: 0.3731 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [104/782] Loss: 0.3575 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [105/782] Loss: 0.6229 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [106/782] Loss: 0.5023 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [107/782] Loss: 0.3642 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [108/782] Loss: 0.4909 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [109/782] Loss: 0.3453 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [110/782] Loss: 0.4852 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [111/782] Loss: 0.4776 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [112/782] Loss: 0.4642 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [113/782] Loss: 0.5694 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [114/782] Loss: 0.4334 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [115/782] Loss: 0.5027 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [116/782] Loss: 0.3794 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [117/782] Loss: 0.3315 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [118/782] Loss: 0.2093 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [119/782] Loss: 0.4472 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [120/782] Loss: 0.4033 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [121/782] Loss: 0.4292 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [122/782] Loss: 0.3363 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [123/782] Loss: 0.3069 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [124/782] Loss: 0.5020 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [125/782] Loss: 0.5776 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [126/782] Loss: 0.4995 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [127/782] Loss: 0.2452 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [128/782] Loss: 0.4635 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [129/782] Loss: 0.5003 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [130/782] Loss: 0.5297 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [131/782] Loss: 0.5316 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [132/782] Loss: 0.5227 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [133/782] Loss: 0.2475 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [134/782] Loss: 0.4079 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [135/782] Loss: 0.4076 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [136/782] Loss: 0.6885 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [137/782] Loss: 0.3092 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [138/782] Loss: 0.5307 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [139/782] Loss: 0.3956 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [140/782] Loss: 0.4520 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [141/782] Loss: 0.4185 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [142/782] Loss: 0.3144 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [143/782] Loss: 0.3387 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [144/782] Loss: 0.4527 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [145/782] Loss: 0.4139 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [146/782] Loss: 0.4518 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [147/782] Loss: 0.5300 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [148/782] Loss: 0.3390 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [149/782] Loss: 0.3480 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [150/782] Loss: 0.4381 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [151/782] Loss: 0.4170 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [152/782] Loss: 0.2766 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [153/782] Loss: 0.5346 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [154/782] Loss: 0.4174 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [155/782] Loss: 0.5191 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [156/782] Loss: 0.5570 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [157/782] Loss: 0.3698 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [158/782] Loss: 0.1959 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [159/782] Loss: 0.5562 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [160/782] Loss: 0.3408 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [161/782] Loss: 0.2923 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [162/782] Loss: 0.3239 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [163/782] Loss: 0.4018 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [164/782] Loss: 0.3482 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [165/782] Loss: 0.4871 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [166/782] Loss: 0.5888 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [167/782] Loss: 0.4440 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [168/782] Loss: 0.5193 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [169/782] Loss: 0.3303 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [170/782] Loss: 0.4532 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [171/782] Loss: 0.5434 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [172/782] Loss: 0.4393 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [173/782] Loss: 0.4250 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [174/782] Loss: 0.2122 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [175/782] Loss: 0.3830 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [176/782] Loss: 0.4382 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [177/782] Loss: 0.5115 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [178/782] Loss: 0.5385 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [179/782] Loss: 0.4501 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [180/782] Loss: 0.3643 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [181/782] Loss: 0.3689 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [182/782] Loss: 0.5800 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [183/782] Loss: 0.6001 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [184/782] Loss: 0.4531 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [185/782] Loss: 0.4549 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [186/782] Loss: 0.4775 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [187/782] Loss: 0.3749 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [188/782] Loss: 0.6390 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [189/782] Loss: 0.2998 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [190/782] Loss: 0.4239 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [191/782] Loss: 0.3352 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [192/782] Loss: 0.4475 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [193/782] Loss: 0.5614 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [194/782] Loss: 0.7769 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [195/782] Loss: 0.3500 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [196/782] Loss: 0.3918 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [197/782] Loss: 0.3558 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [198/782] Loss: 0.6021 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [199/782] Loss: 0.4046 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [200/782] Loss: 0.5360 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [201/782] Loss: 0.3537 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [202/782] Loss: 0.5351 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [203/782] Loss: 0.4433 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [204/782] Loss: 0.3271 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [205/782] Loss: 0.5328 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [206/782] Loss: 0.4413 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [207/782] Loss: 0.5578 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [208/782] Loss: 0.2740 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [209/782] Loss: 0.4513 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [210/782] Loss: 0.3878 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [211/782] Loss: 0.4703 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [212/782] Loss: 0.4184 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [213/782] Loss: 0.4956 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [214/782] Loss: 0.5010 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [215/782] Loss: 0.4681 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [216/782] Loss: 0.4773 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [217/782] Loss: 0.3902 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [218/782] Loss: 0.4859 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [219/782] Loss: 0.4748 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [220/782] Loss: 0.1754 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [221/782] Loss: 0.2987 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [222/782] Loss: 0.2302 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [223/782] Loss: 0.5508 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [224/782] Loss: 0.6207 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [225/782] Loss: 0.2670 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [226/782] Loss: 0.5024 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [227/782] Loss: 0.4323 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [228/782] Loss: 0.3774 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [229/782] Loss: 0.6018 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [230/782] Loss: 0.3481 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [231/782] Loss: 0.6065 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [232/782] Loss: 0.3865 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [233/782] Loss: 0.5802 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [234/782] Loss: 0.3463 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [235/782] Loss: 0.4526 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [236/782] Loss: 0.4604 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [237/782] Loss: 0.4544 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [238/782] Loss: 0.5499 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [239/782] Loss: 0.3842 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [240/782] Loss: 0.3910 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [241/782] Loss: 0.3244 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [242/782] Loss: 0.5125 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [243/782] Loss: 0.4649 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [244/782] Loss: 0.4727 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [245/782] Loss: 0.3314 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [246/782] Loss: 0.3662 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [247/782] Loss: 0.5698 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [248/782] Loss: 0.2695 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [249/782] Loss: 0.4180 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [250/782] Loss: 0.3193 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [251/782] Loss: 0.5921 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [252/782] Loss: 0.3018 | Acc: 84.58%\n",
      "Train Epoch [83/100] Batch [253/782] Loss: 0.3778 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [254/782] Loss: 0.3045 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [255/782] Loss: 0.3487 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [256/782] Loss: 0.5878 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [257/782] Loss: 0.4935 | Acc: 84.59%\n",
      "Train Epoch [83/100] Batch [258/782] Loss: 0.3511 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [259/782] Loss: 0.2818 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [260/782] Loss: 0.5553 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [261/782] Loss: 0.3187 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [262/782] Loss: 0.4215 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [263/782] Loss: 0.3330 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [264/782] Loss: 0.4351 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [265/782] Loss: 0.3364 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [266/782] Loss: 0.4198 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [267/782] Loss: 0.4808 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [268/782] Loss: 0.3603 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [269/782] Loss: 0.4004 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [270/782] Loss: 0.3453 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [271/782] Loss: 0.3582 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [272/782] Loss: 0.3866 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [273/782] Loss: 0.4185 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [274/782] Loss: 0.4735 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [275/782] Loss: 0.4737 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [276/782] Loss: 0.3978 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [277/782] Loss: 0.3600 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [278/782] Loss: 0.4033 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [279/782] Loss: 0.4412 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [280/782] Loss: 0.3090 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [281/782] Loss: 0.4803 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [282/782] Loss: 0.3369 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [283/782] Loss: 0.5747 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [284/782] Loss: 0.5039 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [285/782] Loss: 0.3689 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [286/782] Loss: 0.4612 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [287/782] Loss: 0.4896 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [288/782] Loss: 0.3415 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [289/782] Loss: 0.5840 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [290/782] Loss: 0.4947 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [291/782] Loss: 0.4970 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [292/782] Loss: 0.3110 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [293/782] Loss: 0.3635 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [294/782] Loss: 0.2458 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [295/782] Loss: 0.4405 | Acc: 84.67%\n",
      "Train Epoch [83/100] Batch [296/782] Loss: 0.4776 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [297/782] Loss: 0.3377 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [298/782] Loss: 0.4432 | Acc: 84.66%\n",
      "Train Epoch [83/100] Batch [299/782] Loss: 0.3297 | Acc: 84.67%\n",
      "Train Epoch [83/100] Batch [300/782] Loss: 0.6310 | Acc: 84.65%\n",
      "Train Epoch [83/100] Batch [301/782] Loss: 0.4969 | Acc: 84.62%\n",
      "Train Epoch [83/100] Batch [302/782] Loss: 0.3635 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [303/782] Loss: 0.5906 | Acc: 84.61%\n",
      "Train Epoch [83/100] Batch [304/782] Loss: 0.3334 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [305/782] Loss: 0.3283 | Acc: 84.64%\n",
      "Train Epoch [83/100] Batch [306/782] Loss: 0.4352 | Acc: 84.63%\n",
      "Train Epoch [83/100] Batch [307/782] Loss: 0.6652 | Acc: 84.60%\n",
      "Train Epoch [83/100] Batch [308/782] Loss: 0.7023 | Acc: 84.56%\n",
      "Train Epoch [83/100] Batch [309/782] Loss: 0.3677 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [310/782] Loss: 0.3795 | Acc: 84.57%\n",
      "Train Epoch [83/100] Batch [311/782] Loss: 0.5366 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [312/782] Loss: 0.6110 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [313/782] Loss: 0.4750 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [314/782] Loss: 0.4578 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [315/782] Loss: 0.3910 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [316/782] Loss: 0.3919 | Acc: 84.55%\n",
      "Train Epoch [83/100] Batch [317/782] Loss: 0.5436 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [318/782] Loss: 0.3681 | Acc: 84.54%\n",
      "Train Epoch [83/100] Batch [319/782] Loss: 0.5188 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [320/782] Loss: 0.5958 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [321/782] Loss: 0.2917 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [322/782] Loss: 0.5735 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [323/782] Loss: 0.3851 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [324/782] Loss: 0.4410 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [325/782] Loss: 0.3302 | Acc: 84.53%\n",
      "Train Epoch [83/100] Batch [326/782] Loss: 0.6000 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [327/782] Loss: 0.6955 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [328/782] Loss: 0.4984 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [329/782] Loss: 0.4441 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [330/782] Loss: 0.4133 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [331/782] Loss: 0.3653 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [332/782] Loss: 0.4003 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [333/782] Loss: 0.3438 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [334/782] Loss: 0.6116 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [335/782] Loss: 0.4689 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [336/782] Loss: 0.3798 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [337/782] Loss: 0.4847 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [338/782] Loss: 0.4412 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [339/782] Loss: 0.5125 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [340/782] Loss: 0.3119 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [341/782] Loss: 0.5421 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [342/782] Loss: 0.4257 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [343/782] Loss: 0.3772 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [344/782] Loss: 0.5640 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [345/782] Loss: 0.3707 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [346/782] Loss: 0.5485 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [347/782] Loss: 0.4476 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [348/782] Loss: 0.5939 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [349/782] Loss: 0.4877 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [350/782] Loss: 0.4039 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [351/782] Loss: 0.1657 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [352/782] Loss: 0.3509 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [353/782] Loss: 0.5974 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [354/782] Loss: 0.5920 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [355/782] Loss: 0.6738 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [356/782] Loss: 0.3829 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [357/782] Loss: 0.5356 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [358/782] Loss: 0.5991 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [359/782] Loss: 0.5511 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [360/782] Loss: 0.3764 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [361/782] Loss: 0.3842 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [362/782] Loss: 0.3019 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [363/782] Loss: 0.4926 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [364/782] Loss: 0.4424 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [365/782] Loss: 0.6095 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [366/782] Loss: 0.4478 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [367/782] Loss: 0.3974 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [368/782] Loss: 0.4204 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [369/782] Loss: 0.5071 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [370/782] Loss: 0.4798 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [371/782] Loss: 0.3633 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [372/782] Loss: 0.2966 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [373/782] Loss: 0.3885 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [374/782] Loss: 0.7092 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [375/782] Loss: 0.6575 | Acc: 84.35%\n",
      "Train Epoch [83/100] Batch [376/782] Loss: 0.4890 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [377/782] Loss: 0.3678 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [378/782] Loss: 0.6017 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [379/782] Loss: 0.5136 | Acc: 84.30%\n",
      "Train Epoch [83/100] Batch [380/782] Loss: 0.4325 | Acc: 84.30%\n",
      "Train Epoch [83/100] Batch [381/782] Loss: 0.3381 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [382/782] Loss: 0.2646 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [383/782] Loss: 0.3761 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [384/782] Loss: 0.4733 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [385/782] Loss: 0.4715 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [386/782] Loss: 0.2475 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [387/782] Loss: 0.5476 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [388/782] Loss: 0.5261 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [389/782] Loss: 0.3904 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [390/782] Loss: 0.6417 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [391/782] Loss: 0.5684 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [392/782] Loss: 0.3452 | Acc: 84.30%\n",
      "Train Epoch [83/100] Batch [393/782] Loss: 0.4974 | Acc: 84.29%\n",
      "Train Epoch [83/100] Batch [394/782] Loss: 0.3917 | Acc: 84.30%\n",
      "Train Epoch [83/100] Batch [395/782] Loss: 0.2986 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [396/782] Loss: 0.2804 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [397/782] Loss: 0.5806 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [398/782] Loss: 0.3501 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [399/782] Loss: 0.3255 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [400/782] Loss: 0.4321 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [401/782] Loss: 0.3966 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [402/782] Loss: 0.4331 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [403/782] Loss: 0.5282 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [404/782] Loss: 0.3863 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [405/782] Loss: 0.4052 | Acc: 84.35%\n",
      "Train Epoch [83/100] Batch [406/782] Loss: 0.4465 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [407/782] Loss: 0.5524 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [408/782] Loss: 0.3588 | Acc: 84.34%\n",
      "Train Epoch [83/100] Batch [409/782] Loss: 0.4456 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [410/782] Loss: 0.4976 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [411/782] Loss: 0.3972 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [412/782] Loss: 0.6318 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [413/782] Loss: 0.4958 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [414/782] Loss: 0.4496 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [415/782] Loss: 0.5748 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [416/782] Loss: 0.3857 | Acc: 84.31%\n",
      "Train Epoch [83/100] Batch [417/782] Loss: 0.3955 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [418/782] Loss: 0.4141 | Acc: 84.32%\n",
      "Train Epoch [83/100] Batch [419/782] Loss: 0.4780 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [420/782] Loss: 0.4114 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [421/782] Loss: 0.3386 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [422/782] Loss: 0.4490 | Acc: 84.33%\n",
      "Train Epoch [83/100] Batch [423/782] Loss: 0.2221 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [424/782] Loss: 0.2974 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [425/782] Loss: 0.3920 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [426/782] Loss: 0.4652 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [427/782] Loss: 0.5124 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [428/782] Loss: 0.3462 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [429/782] Loss: 0.3522 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [430/782] Loss: 0.4829 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [431/782] Loss: 0.5229 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [432/782] Loss: 0.2482 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [433/782] Loss: 0.4696 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [434/782] Loss: 0.4913 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [435/782] Loss: 0.4486 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [436/782] Loss: 0.1998 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [437/782] Loss: 0.4671 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [438/782] Loss: 0.4808 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [439/782] Loss: 0.4527 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [440/782] Loss: 0.4261 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [441/782] Loss: 0.4143 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [442/782] Loss: 0.4868 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [443/782] Loss: 0.6004 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [444/782] Loss: 0.3825 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [445/782] Loss: 0.5417 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [446/782] Loss: 0.4134 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [447/782] Loss: 0.3987 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [448/782] Loss: 0.5224 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [449/782] Loss: 0.2513 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [450/782] Loss: 0.4660 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [451/782] Loss: 0.6608 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [452/782] Loss: 0.5308 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [453/782] Loss: 0.4023 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [454/782] Loss: 0.4903 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [455/782] Loss: 0.4264 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [456/782] Loss: 0.3950 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [457/782] Loss: 0.5156 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [458/782] Loss: 0.3501 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [459/782] Loss: 0.3876 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [460/782] Loss: 0.3722 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [461/782] Loss: 0.4590 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [462/782] Loss: 0.5136 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [463/782] Loss: 0.3013 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [464/782] Loss: 0.5177 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [465/782] Loss: 0.4065 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [466/782] Loss: 0.4707 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [467/782] Loss: 0.3904 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [468/782] Loss: 0.4906 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [469/782] Loss: 0.5457 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [470/782] Loss: 0.4537 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [471/782] Loss: 0.6218 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [472/782] Loss: 0.4956 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [473/782] Loss: 0.4430 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [474/782] Loss: 0.4360 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [475/782] Loss: 0.4943 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [476/782] Loss: 0.3218 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [477/782] Loss: 0.4766 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [478/782] Loss: 0.3400 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [479/782] Loss: 0.4405 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [480/782] Loss: 0.4000 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [481/782] Loss: 0.3898 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [482/782] Loss: 0.4252 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [483/782] Loss: 0.4718 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [484/782] Loss: 0.5387 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [485/782] Loss: 0.3641 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [486/782] Loss: 0.3584 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [487/782] Loss: 0.3422 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [488/782] Loss: 0.2904 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [489/782] Loss: 0.3978 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [490/782] Loss: 0.5420 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [491/782] Loss: 0.2748 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [492/782] Loss: 0.4407 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [493/782] Loss: 0.4756 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [494/782] Loss: 0.4009 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [495/782] Loss: 0.5735 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [496/782] Loss: 0.3728 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [497/782] Loss: 0.3089 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [498/782] Loss: 0.5053 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [499/782] Loss: 0.5590 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [500/782] Loss: 0.3517 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [501/782] Loss: 0.4752 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [502/782] Loss: 0.5090 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [503/782] Loss: 0.3679 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [504/782] Loss: 0.4115 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [505/782] Loss: 0.5033 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [506/782] Loss: 0.7058 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [507/782] Loss: 0.3681 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [508/782] Loss: 0.3720 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [509/782] Loss: 0.4741 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [510/782] Loss: 0.4956 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [511/782] Loss: 0.3643 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [512/782] Loss: 0.3927 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [513/782] Loss: 0.2889 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [514/782] Loss: 0.3772 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [515/782] Loss: 0.5656 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [516/782] Loss: 0.3453 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [517/782] Loss: 0.4236 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [518/782] Loss: 0.3519 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [519/782] Loss: 0.4203 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [520/782] Loss: 0.3595 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [521/782] Loss: 0.3719 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [522/782] Loss: 0.1856 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [523/782] Loss: 0.3685 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [524/782] Loss: 0.4314 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [525/782] Loss: 0.4211 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [526/782] Loss: 0.3910 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [527/782] Loss: 0.3570 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [528/782] Loss: 0.2950 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [529/782] Loss: 0.6278 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [530/782] Loss: 0.4761 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [531/782] Loss: 0.3826 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [532/782] Loss: 0.3565 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [533/782] Loss: 0.5601 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [534/782] Loss: 0.3778 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [535/782] Loss: 0.3779 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [536/782] Loss: 0.3329 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [537/782] Loss: 0.4480 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [538/782] Loss: 0.5178 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [539/782] Loss: 0.4294 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [540/782] Loss: 0.4990 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [541/782] Loss: 0.5990 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [542/782] Loss: 0.2350 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [543/782] Loss: 0.5534 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [544/782] Loss: 0.6251 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [545/782] Loss: 0.3952 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [546/782] Loss: 0.4407 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [547/782] Loss: 0.3767 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [548/782] Loss: 0.5572 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [549/782] Loss: 0.5791 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [550/782] Loss: 0.4338 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [551/782] Loss: 0.3803 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [552/782] Loss: 0.4261 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [553/782] Loss: 0.3503 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [554/782] Loss: 0.2678 | Acc: 84.52%\n",
      "Train Epoch [83/100] Batch [555/782] Loss: 0.4347 | Acc: 84.51%\n",
      "Train Epoch [83/100] Batch [556/782] Loss: 0.5137 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [557/782] Loss: 0.5618 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [558/782] Loss: 0.5698 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [559/782] Loss: 0.4804 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [560/782] Loss: 0.4272 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [561/782] Loss: 0.4276 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [562/782] Loss: 0.6021 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [563/782] Loss: 0.3652 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [564/782] Loss: 0.3898 | Acc: 84.49%\n",
      "Train Epoch [83/100] Batch [565/782] Loss: 0.3322 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [566/782] Loss: 0.4988 | Acc: 84.50%\n",
      "Train Epoch [83/100] Batch [567/782] Loss: 0.5805 | Acc: 84.48%\n",
      "Train Epoch [83/100] Batch [568/782] Loss: 0.4906 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [569/782] Loss: 0.4988 | Acc: 84.47%\n",
      "Train Epoch [83/100] Batch [570/782] Loss: 0.6219 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [571/782] Loss: 0.4642 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [572/782] Loss: 0.3950 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [573/782] Loss: 0.3225 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [574/782] Loss: 0.3330 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [575/782] Loss: 0.5764 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [576/782] Loss: 0.6405 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [577/782] Loss: 0.3246 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [578/782] Loss: 0.3819 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [579/782] Loss: 0.5023 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [580/782] Loss: 0.6661 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [581/782] Loss: 0.4755 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [582/782] Loss: 0.9057 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [583/782] Loss: 0.3530 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [584/782] Loss: 0.4749 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [585/782] Loss: 0.5740 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [586/782] Loss: 0.6974 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [587/782] Loss: 0.3982 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [588/782] Loss: 0.5682 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [589/782] Loss: 0.3829 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [590/782] Loss: 0.3354 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [591/782] Loss: 0.5700 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [592/782] Loss: 0.4084 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [593/782] Loss: 0.4672 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [594/782] Loss: 0.3646 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [595/782] Loss: 0.3903 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [596/782] Loss: 0.3888 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [597/782] Loss: 0.3326 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [598/782] Loss: 0.3578 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [599/782] Loss: 0.4843 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [600/782] Loss: 0.3955 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [601/782] Loss: 0.4082 | Acc: 84.36%\n",
      "Train Epoch [83/100] Batch [602/782] Loss: 0.2769 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [603/782] Loss: 0.4968 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [604/782] Loss: 0.4113 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [605/782] Loss: 0.5359 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [606/782] Loss: 0.4665 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [607/782] Loss: 0.4382 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [608/782] Loss: 0.2756 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [609/782] Loss: 0.3811 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [610/782] Loss: 0.3442 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [611/782] Loss: 0.4351 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [612/782] Loss: 0.4219 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [613/782] Loss: 0.3386 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [614/782] Loss: 0.3891 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [615/782] Loss: 0.5297 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [616/782] Loss: 0.3250 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [617/782] Loss: 0.3732 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [618/782] Loss: 0.7009 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [619/782] Loss: 0.2949 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [620/782] Loss: 0.3611 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [621/782] Loss: 0.3274 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [622/782] Loss: 0.3367 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [623/782] Loss: 0.4521 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [624/782] Loss: 0.4181 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [625/782] Loss: 0.4325 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [626/782] Loss: 0.3511 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [627/782] Loss: 0.5121 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [628/782] Loss: 0.4226 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [629/782] Loss: 0.4240 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [630/782] Loss: 0.4493 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [631/782] Loss: 0.5300 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [632/782] Loss: 0.5358 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [633/782] Loss: 0.4685 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [634/782] Loss: 0.5393 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [635/782] Loss: 0.2999 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [636/782] Loss: 0.3278 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [637/782] Loss: 0.4951 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [638/782] Loss: 0.4280 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [639/782] Loss: 0.4077 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [640/782] Loss: 0.4051 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [641/782] Loss: 0.4026 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [642/782] Loss: 0.6002 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [643/782] Loss: 0.4513 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [644/782] Loss: 0.5145 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [645/782] Loss: 0.4666 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [646/782] Loss: 0.4525 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [647/782] Loss: 0.4951 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [648/782] Loss: 0.5314 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [649/782] Loss: 0.4011 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [650/782] Loss: 0.2863 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [651/782] Loss: 0.3970 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [652/782] Loss: 0.5995 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [653/782] Loss: 0.3804 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [654/782] Loss: 0.5120 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [655/782] Loss: 0.4255 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [656/782] Loss: 0.5022 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [657/782] Loss: 0.6082 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [658/782] Loss: 0.2898 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [659/782] Loss: 0.3959 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [660/782] Loss: 0.6433 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [661/782] Loss: 0.4672 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [662/782] Loss: 0.4369 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [663/782] Loss: 0.5129 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [664/782] Loss: 0.3703 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [665/782] Loss: 0.4462 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [666/782] Loss: 0.4196 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [667/782] Loss: 0.4283 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [668/782] Loss: 0.6060 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [669/782] Loss: 0.4906 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [670/782] Loss: 0.2498 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [671/782] Loss: 0.3084 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [672/782] Loss: 0.3940 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [673/782] Loss: 0.5391 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [674/782] Loss: 0.4005 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [675/782] Loss: 0.3880 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [676/782] Loss: 0.3481 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [677/782] Loss: 0.5325 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [678/782] Loss: 0.3734 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [679/782] Loss: 0.6458 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [680/782] Loss: 0.4302 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [681/782] Loss: 0.4469 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [682/782] Loss: 0.4693 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [683/782] Loss: 0.2756 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [684/782] Loss: 0.4504 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [685/782] Loss: 0.4639 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [686/782] Loss: 0.3742 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [687/782] Loss: 0.4591 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [688/782] Loss: 0.4584 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [689/782] Loss: 0.5451 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [690/782] Loss: 0.3409 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [691/782] Loss: 0.7195 | Acc: 84.37%\n",
      "Train Epoch [83/100] Batch [692/782] Loss: 0.3652 | Acc: 84.38%\n",
      "Train Epoch [83/100] Batch [693/782] Loss: 0.2910 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [694/782] Loss: 0.2836 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [695/782] Loss: 0.4413 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [696/782] Loss: 0.4968 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [697/782] Loss: 0.4307 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [698/782] Loss: 0.3241 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [699/782] Loss: 0.3508 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [700/782] Loss: 0.4065 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [701/782] Loss: 0.4233 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [702/782] Loss: 0.6595 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [703/782] Loss: 0.4808 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [704/782] Loss: 0.3618 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [705/782] Loss: 0.4355 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [706/782] Loss: 0.5211 | Acc: 84.39%\n",
      "Train Epoch [83/100] Batch [707/782] Loss: 0.4711 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [708/782] Loss: 0.2467 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [709/782] Loss: 0.4407 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [710/782] Loss: 0.3592 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [711/782] Loss: 0.2251 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [712/782] Loss: 0.3945 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [713/782] Loss: 0.6567 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [714/782] Loss: 0.3271 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [715/782] Loss: 0.3237 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [716/782] Loss: 0.4242 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [717/782] Loss: 0.3061 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [718/782] Loss: 0.5468 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [719/782] Loss: 0.5434 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [720/782] Loss: 0.2493 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [721/782] Loss: 0.4995 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [722/782] Loss: 0.4686 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [723/782] Loss: 0.3352 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [724/782] Loss: 0.3862 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [725/782] Loss: 0.5284 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [726/782] Loss: 0.4353 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [727/782] Loss: 0.4949 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [728/782] Loss: 0.4925 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [729/782] Loss: 0.3848 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [730/782] Loss: 0.5731 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [731/782] Loss: 0.5031 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [732/782] Loss: 0.5850 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [733/782] Loss: 0.6968 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [734/782] Loss: 0.4842 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [735/782] Loss: 0.4016 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [736/782] Loss: 0.5354 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [737/782] Loss: 0.5885 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [738/782] Loss: 0.4909 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [739/782] Loss: 0.3299 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [740/782] Loss: 0.3470 | Acc: 84.40%\n",
      "Train Epoch [83/100] Batch [741/782] Loss: 0.2628 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [742/782] Loss: 0.2793 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [743/782] Loss: 0.3363 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [744/782] Loss: 0.5374 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [745/782] Loss: 0.2375 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [746/782] Loss: 0.2170 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [747/782] Loss: 0.3791 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [748/782] Loss: 0.3240 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [749/782] Loss: 0.3796 | Acc: 84.46%\n",
      "Train Epoch [83/100] Batch [750/782] Loss: 0.5158 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [751/782] Loss: 0.5869 | Acc: 84.45%\n",
      "Train Epoch [83/100] Batch [752/782] Loss: 0.6121 | Acc: 84.44%\n",
      "Train Epoch [83/100] Batch [753/782] Loss: 0.5673 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [754/782] Loss: 0.5377 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [755/782] Loss: 0.4165 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [756/782] Loss: 0.2462 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [757/782] Loss: 0.5340 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [758/782] Loss: 0.4121 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [759/782] Loss: 0.3387 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [760/782] Loss: 0.4740 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [761/782] Loss: 0.5457 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [762/782] Loss: 0.5005 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [763/782] Loss: 0.3758 | Acc: 84.41%\n",
      "Train Epoch [83/100] Batch [764/782] Loss: 0.3218 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [765/782] Loss: 0.3815 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [766/782] Loss: 0.3624 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [767/782] Loss: 0.4179 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [768/782] Loss: 0.3207 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [769/782] Loss: 0.5960 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [770/782] Loss: 0.3788 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [771/782] Loss: 0.2797 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [772/782] Loss: 0.4657 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [773/782] Loss: 0.3780 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [774/782] Loss: 0.5629 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [775/782] Loss: 0.5819 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [776/782] Loss: 0.2328 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [777/782] Loss: 0.4260 | Acc: 84.43%\n",
      "Train Epoch [83/100] Batch [778/782] Loss: 0.4637 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [779/782] Loss: 0.4565 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [780/782] Loss: 0.5205 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [781/782] Loss: 0.3443 | Acc: 84.42%\n",
      "Train Epoch [83/100] Batch [782/782] Loss: 0.2959 | Acc: 84.42%\n",
      "Epoch 83 completed in 30.67s.\n",
      "Test Epoch [83/100] Loss: 0.9886 | Acc: 72.22% | Inference Time: 8.55s\n",
      "Epoch 83 results saved to CSV.\n",
      "Epoch 84/100\n",
      "Train Epoch [84/100] Batch [1/782] Loss: 0.4591 | Acc: 85.94%\n",
      "Train Epoch [84/100] Batch [2/782] Loss: 0.4707 | Acc: 85.16%\n",
      "Train Epoch [84/100] Batch [3/782] Loss: 0.6014 | Acc: 79.69%\n",
      "Train Epoch [84/100] Batch [4/782] Loss: 0.3777 | Acc: 81.25%\n",
      "Train Epoch [84/100] Batch [5/782] Loss: 0.3386 | Acc: 81.88%\n",
      "Train Epoch [84/100] Batch [6/782] Loss: 0.3368 | Acc: 82.81%\n",
      "Train Epoch [84/100] Batch [7/782] Loss: 0.3344 | Acc: 83.04%\n",
      "Train Epoch [84/100] Batch [8/782] Loss: 0.4699 | Acc: 83.40%\n",
      "Train Epoch [84/100] Batch [9/782] Loss: 0.3755 | Acc: 83.85%\n",
      "Train Epoch [84/100] Batch [10/782] Loss: 0.3138 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [11/782] Loss: 0.4323 | Acc: 84.80%\n",
      "Train Epoch [84/100] Batch [12/782] Loss: 0.3904 | Acc: 85.03%\n",
      "Train Epoch [84/100] Batch [13/782] Loss: 0.3842 | Acc: 84.86%\n",
      "Train Epoch [84/100] Batch [14/782] Loss: 0.4407 | Acc: 84.82%\n",
      "Train Epoch [84/100] Batch [15/782] Loss: 0.2457 | Acc: 85.31%\n",
      "Train Epoch [84/100] Batch [16/782] Loss: 0.6401 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [17/782] Loss: 0.4447 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [18/782] Loss: 0.2346 | Acc: 84.81%\n",
      "Train Epoch [84/100] Batch [19/782] Loss: 0.4764 | Acc: 84.79%\n",
      "Train Epoch [84/100] Batch [20/782] Loss: 0.3665 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [21/782] Loss: 0.4688 | Acc: 85.04%\n",
      "Train Epoch [84/100] Batch [22/782] Loss: 0.4697 | Acc: 84.87%\n",
      "Train Epoch [84/100] Batch [23/782] Loss: 0.3251 | Acc: 84.78%\n",
      "Train Epoch [84/100] Batch [24/782] Loss: 0.5534 | Acc: 84.83%\n",
      "Train Epoch [84/100] Batch [25/782] Loss: 0.4025 | Acc: 84.88%\n",
      "Train Epoch [84/100] Batch [26/782] Loss: 0.3092 | Acc: 85.04%\n",
      "Train Epoch [84/100] Batch [27/782] Loss: 0.4905 | Acc: 84.95%\n",
      "Train Epoch [84/100] Batch [28/782] Loss: 0.3622 | Acc: 84.99%\n",
      "Train Epoch [84/100] Batch [29/782] Loss: 0.5008 | Acc: 84.91%\n",
      "Train Epoch [84/100] Batch [30/782] Loss: 0.4768 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [31/782] Loss: 0.3244 | Acc: 85.03%\n",
      "Train Epoch [84/100] Batch [32/782] Loss: 0.4179 | Acc: 84.86%\n",
      "Train Epoch [84/100] Batch [33/782] Loss: 0.4503 | Acc: 84.85%\n",
      "Train Epoch [84/100] Batch [34/782] Loss: 0.4031 | Acc: 84.97%\n",
      "Train Epoch [84/100] Batch [35/782] Loss: 0.4463 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [36/782] Loss: 0.4817 | Acc: 84.94%\n",
      "Train Epoch [84/100] Batch [37/782] Loss: 0.3944 | Acc: 85.01%\n",
      "Train Epoch [84/100] Batch [38/782] Loss: 0.2946 | Acc: 85.12%\n",
      "Train Epoch [84/100] Batch [39/782] Loss: 0.4890 | Acc: 84.90%\n",
      "Train Epoch [84/100] Batch [40/782] Loss: 0.7053 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [41/782] Loss: 0.5527 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [42/782] Loss: 0.3262 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [43/782] Loss: 0.3732 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [44/782] Loss: 0.4421 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [45/782] Loss: 0.4406 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [46/782] Loss: 0.6219 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [47/782] Loss: 0.4763 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [48/782] Loss: 0.3975 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [49/782] Loss: 0.4884 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [50/782] Loss: 0.1936 | Acc: 84.81%\n",
      "Train Epoch [84/100] Batch [51/782] Loss: 0.3414 | Acc: 84.93%\n",
      "Train Epoch [84/100] Batch [52/782] Loss: 0.1876 | Acc: 85.10%\n",
      "Train Epoch [84/100] Batch [53/782] Loss: 0.3903 | Acc: 85.08%\n",
      "Train Epoch [84/100] Batch [54/782] Loss: 0.3559 | Acc: 85.10%\n",
      "Train Epoch [84/100] Batch [55/782] Loss: 0.2479 | Acc: 85.23%\n",
      "Train Epoch [84/100] Batch [56/782] Loss: 0.4779 | Acc: 85.18%\n",
      "Train Epoch [84/100] Batch [57/782] Loss: 0.4910 | Acc: 85.09%\n",
      "Train Epoch [84/100] Batch [58/782] Loss: 0.5643 | Acc: 85.08%\n",
      "Train Epoch [84/100] Batch [59/782] Loss: 0.2348 | Acc: 85.20%\n",
      "Train Epoch [84/100] Batch [60/782] Loss: 0.4734 | Acc: 85.16%\n",
      "Train Epoch [84/100] Batch [61/782] Loss: 0.4438 | Acc: 85.17%\n",
      "Train Epoch [84/100] Batch [62/782] Loss: 0.5018 | Acc: 85.13%\n",
      "Train Epoch [84/100] Batch [63/782] Loss: 0.6785 | Acc: 85.04%\n",
      "Train Epoch [84/100] Batch [64/782] Loss: 0.4978 | Acc: 85.03%\n",
      "Train Epoch [84/100] Batch [65/782] Loss: 0.3391 | Acc: 85.10%\n",
      "Train Epoch [84/100] Batch [66/782] Loss: 0.3461 | Acc: 85.13%\n",
      "Train Epoch [84/100] Batch [67/782] Loss: 0.5044 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [68/782] Loss: 0.3336 | Acc: 85.06%\n",
      "Train Epoch [84/100] Batch [69/782] Loss: 0.3699 | Acc: 85.12%\n",
      "Train Epoch [84/100] Batch [70/782] Loss: 0.4371 | Acc: 85.16%\n",
      "Train Epoch [84/100] Batch [71/782] Loss: 0.4755 | Acc: 85.19%\n",
      "Train Epoch [84/100] Batch [72/782] Loss: 0.5272 | Acc: 85.16%\n",
      "Train Epoch [84/100] Batch [73/782] Loss: 0.4022 | Acc: 85.17%\n",
      "Train Epoch [84/100] Batch [74/782] Loss: 0.3389 | Acc: 85.20%\n",
      "Train Epoch [84/100] Batch [75/782] Loss: 0.4625 | Acc: 85.23%\n",
      "Train Epoch [84/100] Batch [76/782] Loss: 0.5531 | Acc: 85.09%\n",
      "Train Epoch [84/100] Batch [77/782] Loss: 0.5205 | Acc: 85.06%\n",
      "Train Epoch [84/100] Batch [78/782] Loss: 0.3966 | Acc: 85.06%\n",
      "Train Epoch [84/100] Batch [79/782] Loss: 0.5071 | Acc: 85.03%\n",
      "Train Epoch [84/100] Batch [80/782] Loss: 0.3869 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [81/782] Loss: 0.4337 | Acc: 84.97%\n",
      "Train Epoch [84/100] Batch [82/782] Loss: 0.3842 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [83/782] Loss: 0.4407 | Acc: 85.00%\n",
      "Train Epoch [84/100] Batch [84/782] Loss: 0.5211 | Acc: 84.91%\n",
      "Train Epoch [84/100] Batch [85/782] Loss: 0.4290 | Acc: 84.91%\n",
      "Train Epoch [84/100] Batch [86/782] Loss: 0.4963 | Acc: 84.87%\n",
      "Train Epoch [84/100] Batch [87/782] Loss: 0.4884 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [88/782] Loss: 0.5095 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [89/782] Loss: 0.7020 | Acc: 84.73%\n",
      "Train Epoch [84/100] Batch [90/782] Loss: 0.6326 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [91/782] Loss: 0.4207 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [92/782] Loss: 0.3247 | Acc: 84.80%\n",
      "Train Epoch [84/100] Batch [93/782] Loss: 0.3999 | Acc: 84.80%\n",
      "Train Epoch [84/100] Batch [94/782] Loss: 0.4511 | Acc: 84.76%\n",
      "Train Epoch [84/100] Batch [95/782] Loss: 0.5427 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [96/782] Loss: 0.4504 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [97/782] Loss: 0.4667 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [98/782] Loss: 0.2609 | Acc: 84.79%\n",
      "Train Epoch [84/100] Batch [99/782] Loss: 0.5699 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [100/782] Loss: 0.2044 | Acc: 84.78%\n",
      "Train Epoch [84/100] Batch [101/782] Loss: 0.3785 | Acc: 84.81%\n",
      "Train Epoch [84/100] Batch [102/782] Loss: 0.3735 | Acc: 84.82%\n",
      "Train Epoch [84/100] Batch [103/782] Loss: 0.4131 | Acc: 84.81%\n",
      "Train Epoch [84/100] Batch [104/782] Loss: 0.2984 | Acc: 84.86%\n",
      "Train Epoch [84/100] Batch [105/782] Loss: 0.4343 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [106/782] Loss: 0.5634 | Acc: 84.80%\n",
      "Train Epoch [84/100] Batch [107/782] Loss: 0.4229 | Acc: 84.78%\n",
      "Train Epoch [84/100] Batch [108/782] Loss: 0.6052 | Acc: 84.77%\n",
      "Train Epoch [84/100] Batch [109/782] Loss: 0.3673 | Acc: 84.81%\n",
      "Train Epoch [84/100] Batch [110/782] Loss: 0.4505 | Acc: 84.80%\n",
      "Train Epoch [84/100] Batch [111/782] Loss: 0.3761 | Acc: 84.78%\n",
      "Train Epoch [84/100] Batch [112/782] Loss: 0.3194 | Acc: 84.84%\n",
      "Train Epoch [84/100] Batch [113/782] Loss: 0.4661 | Acc: 84.76%\n",
      "Train Epoch [84/100] Batch [114/782] Loss: 0.3947 | Acc: 84.75%\n",
      "Train Epoch [84/100] Batch [115/782] Loss: 0.4913 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [116/782] Loss: 0.4302 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [117/782] Loss: 0.4275 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [118/782] Loss: 0.4629 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [119/782] Loss: 0.3992 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [120/782] Loss: 0.3143 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [121/782] Loss: 0.3547 | Acc: 84.76%\n",
      "Train Epoch [84/100] Batch [122/782] Loss: 0.3024 | Acc: 84.78%\n",
      "Train Epoch [84/100] Batch [123/782] Loss: 0.6456 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [124/782] Loss: 0.5050 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [125/782] Loss: 0.7205 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [126/782] Loss: 0.3077 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [127/782] Loss: 0.4555 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [128/782] Loss: 0.3665 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [129/782] Loss: 0.5572 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [130/782] Loss: 0.3162 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [131/782] Loss: 0.3309 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [132/782] Loss: 0.3600 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [133/782] Loss: 0.5129 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [134/782] Loss: 0.6658 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [135/782] Loss: 0.4465 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [136/782] Loss: 0.4689 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [137/782] Loss: 0.3881 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [138/782] Loss: 0.3587 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [139/782] Loss: 0.4883 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [140/782] Loss: 0.4485 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [141/782] Loss: 0.3658 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [142/782] Loss: 0.5255 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [143/782] Loss: 0.5119 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [144/782] Loss: 0.5674 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [145/782] Loss: 0.3309 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [146/782] Loss: 0.3148 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [147/782] Loss: 0.7444 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [148/782] Loss: 0.3952 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [149/782] Loss: 0.4470 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [150/782] Loss: 0.3718 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [151/782] Loss: 0.5112 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [152/782] Loss: 0.2749 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [153/782] Loss: 0.4370 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [154/782] Loss: 0.3110 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [155/782] Loss: 0.3960 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [156/782] Loss: 0.3908 | Acc: 84.73%\n",
      "Train Epoch [84/100] Batch [157/782] Loss: 0.5059 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [158/782] Loss: 0.4661 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [159/782] Loss: 0.4011 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [160/782] Loss: 0.2227 | Acc: 84.74%\n",
      "Train Epoch [84/100] Batch [161/782] Loss: 0.7600 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [162/782] Loss: 0.3688 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [163/782] Loss: 0.4155 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [164/782] Loss: 0.3404 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [165/782] Loss: 0.4816 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [166/782] Loss: 0.4180 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [167/782] Loss: 0.2317 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [168/782] Loss: 0.3562 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [169/782] Loss: 0.4889 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [170/782] Loss: 0.4643 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [171/782] Loss: 0.3683 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [172/782] Loss: 0.2841 | Acc: 84.70%\n",
      "Train Epoch [84/100] Batch [173/782] Loss: 0.5148 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [174/782] Loss: 0.3253 | Acc: 84.73%\n",
      "Train Epoch [84/100] Batch [175/782] Loss: 0.3043 | Acc: 84.76%\n",
      "Train Epoch [84/100] Batch [176/782] Loss: 0.5197 | Acc: 84.73%\n",
      "Train Epoch [84/100] Batch [177/782] Loss: 0.3770 | Acc: 84.74%\n",
      "Train Epoch [84/100] Batch [178/782] Loss: 0.5159 | Acc: 84.73%\n",
      "Train Epoch [84/100] Batch [179/782] Loss: 0.3458 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [180/782] Loss: 0.5188 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [181/782] Loss: 0.4856 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [182/782] Loss: 0.4331 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [183/782] Loss: 0.4680 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [184/782] Loss: 0.4372 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [185/782] Loss: 0.3180 | Acc: 84.71%\n",
      "Train Epoch [84/100] Batch [186/782] Loss: 0.5899 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [187/782] Loss: 0.3635 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [188/782] Loss: 0.2971 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [189/782] Loss: 0.4680 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [190/782] Loss: 0.3695 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [191/782] Loss: 0.4497 | Acc: 84.69%\n",
      "Train Epoch [84/100] Batch [192/782] Loss: 0.2683 | Acc: 84.72%\n",
      "Train Epoch [84/100] Batch [193/782] Loss: 0.2788 | Acc: 84.74%\n",
      "Train Epoch [84/100] Batch [194/782] Loss: 0.6088 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [195/782] Loss: 0.4095 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [196/782] Loss: 0.5000 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [197/782] Loss: 0.3977 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [198/782] Loss: 0.2783 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [199/782] Loss: 0.3327 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [200/782] Loss: 0.4966 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [201/782] Loss: 0.5236 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [202/782] Loss: 0.3730 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [203/782] Loss: 0.4708 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [204/782] Loss: 0.8108 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [205/782] Loss: 0.2170 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [206/782] Loss: 0.4300 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [207/782] Loss: 0.5310 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [208/782] Loss: 0.5161 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [209/782] Loss: 0.4093 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [210/782] Loss: 0.3950 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [211/782] Loss: 0.5019 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [212/782] Loss: 0.4995 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [213/782] Loss: 0.4655 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [214/782] Loss: 0.4895 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [215/782] Loss: 0.3941 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [216/782] Loss: 0.5313 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [217/782] Loss: 0.3025 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [218/782] Loss: 0.3846 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [219/782] Loss: 0.4181 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [220/782] Loss: 0.5662 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [221/782] Loss: 0.3928 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [222/782] Loss: 0.4534 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [223/782] Loss: 0.3932 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [224/782] Loss: 0.6189 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [225/782] Loss: 0.3664 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [226/782] Loss: 0.3532 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [227/782] Loss: 0.4424 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [228/782] Loss: 0.5299 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [229/782] Loss: 0.5128 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [230/782] Loss: 0.1843 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [231/782] Loss: 0.4981 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [232/782] Loss: 0.3689 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [233/782] Loss: 0.4886 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [234/782] Loss: 0.3394 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [235/782] Loss: 0.3489 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [236/782] Loss: 0.3264 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [237/782] Loss: 0.4643 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [238/782] Loss: 0.5076 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [239/782] Loss: 0.5323 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [240/782] Loss: 0.3820 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [241/782] Loss: 0.3090 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [242/782] Loss: 0.4975 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [243/782] Loss: 0.5303 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [244/782] Loss: 0.3940 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [245/782] Loss: 0.4802 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [246/782] Loss: 0.4369 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [247/782] Loss: 0.5038 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [248/782] Loss: 0.5159 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [249/782] Loss: 0.6255 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [250/782] Loss: 0.5458 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [251/782] Loss: 0.5631 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [252/782] Loss: 0.4120 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [253/782] Loss: 0.6294 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [254/782] Loss: 0.4136 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [255/782] Loss: 0.5770 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [256/782] Loss: 0.4471 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [257/782] Loss: 0.4120 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [258/782] Loss: 0.5485 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [259/782] Loss: 0.5199 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [260/782] Loss: 0.4668 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [261/782] Loss: 0.3894 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [262/782] Loss: 0.5747 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [263/782] Loss: 0.3439 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [264/782] Loss: 0.3821 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [265/782] Loss: 0.3362 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [266/782] Loss: 0.5406 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [267/782] Loss: 0.5030 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [268/782] Loss: 0.3013 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [269/782] Loss: 0.3899 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [270/782] Loss: 0.5505 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [271/782] Loss: 0.4007 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [272/782] Loss: 0.3515 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [273/782] Loss: 0.4970 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [274/782] Loss: 0.2885 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [275/782] Loss: 0.4678 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [276/782] Loss: 0.4272 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [277/782] Loss: 0.4614 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [278/782] Loss: 0.3322 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [279/782] Loss: 0.3642 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [280/782] Loss: 0.5793 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [281/782] Loss: 0.5839 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [282/782] Loss: 0.4072 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [283/782] Loss: 0.2422 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [284/782] Loss: 0.3979 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [285/782] Loss: 0.5621 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [286/782] Loss: 0.3955 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [287/782] Loss: 0.5008 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [288/782] Loss: 0.4093 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [289/782] Loss: 0.3759 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [290/782] Loss: 0.3562 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [291/782] Loss: 0.3673 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [292/782] Loss: 0.3913 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [293/782] Loss: 0.3913 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [294/782] Loss: 0.3971 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [295/782] Loss: 0.3987 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [296/782] Loss: 0.3351 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [297/782] Loss: 0.3335 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [298/782] Loss: 0.2249 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [299/782] Loss: 0.3642 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [300/782] Loss: 0.4837 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [301/782] Loss: 0.4305 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [302/782] Loss: 0.3571 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [303/782] Loss: 0.3877 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [304/782] Loss: 0.6809 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [305/782] Loss: 0.4501 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [306/782] Loss: 0.3287 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [307/782] Loss: 0.3641 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [308/782] Loss: 0.4989 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [309/782] Loss: 0.2923 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [310/782] Loss: 0.3230 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [311/782] Loss: 0.5626 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [312/782] Loss: 0.3936 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [313/782] Loss: 0.5271 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [314/782] Loss: 0.3387 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [315/782] Loss: 0.4195 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [316/782] Loss: 0.3709 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [317/782] Loss: 0.4947 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [318/782] Loss: 0.4772 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [319/782] Loss: 0.4531 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [320/782] Loss: 0.3831 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [321/782] Loss: 0.3597 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [322/782] Loss: 0.4980 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [323/782] Loss: 0.3680 | Acc: 84.54%\n",
      "Train Epoch [84/100] Batch [324/782] Loss: 0.4548 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [325/782] Loss: 0.3369 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [326/782] Loss: 0.3342 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [327/782] Loss: 0.3057 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [328/782] Loss: 0.4496 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [329/782] Loss: 0.4453 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [330/782] Loss: 0.3772 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [331/782] Loss: 0.5904 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [332/782] Loss: 0.5752 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [333/782] Loss: 0.2315 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [334/782] Loss: 0.4100 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [335/782] Loss: 0.4183 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [336/782] Loss: 0.3593 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [337/782] Loss: 0.3350 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [338/782] Loss: 0.4423 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [339/782] Loss: 0.4543 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [340/782] Loss: 0.5199 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [341/782] Loss: 0.5137 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [342/782] Loss: 0.5317 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [343/782] Loss: 0.5216 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [344/782] Loss: 0.2501 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [345/782] Loss: 0.4817 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [346/782] Loss: 0.6567 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [347/782] Loss: 0.5310 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [348/782] Loss: 0.4757 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [349/782] Loss: 0.4109 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [350/782] Loss: 0.2834 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [351/782] Loss: 0.3773 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [352/782] Loss: 0.3550 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [353/782] Loss: 0.4459 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [354/782] Loss: 0.3805 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [355/782] Loss: 0.5360 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [356/782] Loss: 0.5107 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [357/782] Loss: 0.4232 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [358/782] Loss: 0.4275 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [359/782] Loss: 0.4211 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [360/782] Loss: 0.3478 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [361/782] Loss: 0.2356 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [362/782] Loss: 0.3806 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [363/782] Loss: 0.4521 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [364/782] Loss: 0.3871 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [365/782] Loss: 0.3562 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [366/782] Loss: 0.5585 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [367/782] Loss: 0.4681 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [368/782] Loss: 0.3983 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [369/782] Loss: 0.5214 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [370/782] Loss: 0.5283 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [371/782] Loss: 0.5214 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [372/782] Loss: 0.5142 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [373/782] Loss: 0.4369 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [374/782] Loss: 0.4185 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [375/782] Loss: 0.3366 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [376/782] Loss: 0.5559 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [377/782] Loss: 0.4096 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [378/782] Loss: 0.2984 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [379/782] Loss: 0.4034 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [380/782] Loss: 0.3982 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [381/782] Loss: 0.3754 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [382/782] Loss: 0.3697 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [383/782] Loss: 0.2492 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [384/782] Loss: 0.6454 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [385/782] Loss: 0.6140 | Acc: 84.59%\n",
      "Train Epoch [84/100] Batch [386/782] Loss: 0.2355 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [387/782] Loss: 0.3232 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [388/782] Loss: 0.5357 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [389/782] Loss: 0.4549 | Acc: 84.61%\n",
      "Train Epoch [84/100] Batch [390/782] Loss: 0.4640 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [391/782] Loss: 0.6331 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [392/782] Loss: 0.1905 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [393/782] Loss: 0.3973 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [394/782] Loss: 0.5010 | Acc: 84.62%\n",
      "Train Epoch [84/100] Batch [395/782] Loss: 0.2697 | Acc: 84.64%\n",
      "Train Epoch [84/100] Batch [396/782] Loss: 0.3352 | Acc: 84.65%\n",
      "Train Epoch [84/100] Batch [397/782] Loss: 0.3884 | Acc: 84.67%\n",
      "Train Epoch [84/100] Batch [398/782] Loss: 0.3494 | Acc: 84.68%\n",
      "Train Epoch [84/100] Batch [399/782] Loss: 0.5906 | Acc: 84.66%\n",
      "Train Epoch [84/100] Batch [400/782] Loss: 0.5732 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [401/782] Loss: 0.4707 | Acc: 84.63%\n",
      "Train Epoch [84/100] Batch [402/782] Loss: 0.5511 | Acc: 84.60%\n",
      "Train Epoch [84/100] Batch [403/782] Loss: 1.0230 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [404/782] Loss: 0.3269 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [405/782] Loss: 0.3942 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [406/782] Loss: 0.4242 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [407/782] Loss: 0.3066 | Acc: 84.58%\n",
      "Train Epoch [84/100] Batch [408/782] Loss: 0.5600 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [409/782] Loss: 0.4093 | Acc: 84.56%\n",
      "Train Epoch [84/100] Batch [410/782] Loss: 0.3840 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [411/782] Loss: 0.3805 | Acc: 84.57%\n",
      "Train Epoch [84/100] Batch [412/782] Loss: 0.5101 | Acc: 84.55%\n",
      "Train Epoch [84/100] Batch [413/782] Loss: 0.5828 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [414/782] Loss: 0.6087 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [415/782] Loss: 0.4231 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [416/782] Loss: 0.4798 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [417/782] Loss: 0.5083 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [418/782] Loss: 0.5279 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [419/782] Loss: 0.2782 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [420/782] Loss: 0.4744 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [421/782] Loss: 0.4721 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [422/782] Loss: 0.3657 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [423/782] Loss: 0.5087 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [424/782] Loss: 0.4547 | Acc: 84.53%\n",
      "Train Epoch [84/100] Batch [425/782] Loss: 0.5953 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [426/782] Loss: 0.4545 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [427/782] Loss: 0.4195 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [428/782] Loss: 0.4101 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [429/782] Loss: 0.6091 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [430/782] Loss: 0.5639 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [431/782] Loss: 0.2992 | Acc: 84.51%\n",
      "Train Epoch [84/100] Batch [432/782] Loss: 0.4188 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [433/782] Loss: 0.4798 | Acc: 84.52%\n",
      "Train Epoch [84/100] Batch [434/782] Loss: 0.6606 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [435/782] Loss: 0.4350 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [436/782] Loss: 0.3588 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [437/782] Loss: 0.4266 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [438/782] Loss: 0.3952 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [439/782] Loss: 0.5829 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [440/782] Loss: 0.3621 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [441/782] Loss: 0.4768 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [442/782] Loss: 0.3096 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [443/782] Loss: 0.4523 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [444/782] Loss: 0.4093 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [445/782] Loss: 0.4836 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [446/782] Loss: 0.2954 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [447/782] Loss: 0.3661 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [448/782] Loss: 0.5754 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [449/782] Loss: 0.5645 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [450/782] Loss: 0.3722 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [451/782] Loss: 0.6025 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [452/782] Loss: 0.3520 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [453/782] Loss: 0.3851 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [454/782] Loss: 0.4582 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [455/782] Loss: 0.4549 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [456/782] Loss: 0.6135 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [457/782] Loss: 0.3812 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [458/782] Loss: 0.3356 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [459/782] Loss: 0.4840 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [460/782] Loss: 0.3396 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [461/782] Loss: 0.3923 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [462/782] Loss: 0.4839 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [463/782] Loss: 0.3788 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [464/782] Loss: 0.6574 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [465/782] Loss: 0.3360 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [466/782] Loss: 0.5577 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [467/782] Loss: 0.6592 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [468/782] Loss: 0.2742 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [469/782] Loss: 0.3855 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [470/782] Loss: 0.2823 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [471/782] Loss: 0.5535 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [472/782] Loss: 0.5348 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [473/782] Loss: 0.4221 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [474/782] Loss: 0.5553 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [475/782] Loss: 0.2797 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [476/782] Loss: 0.4009 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [477/782] Loss: 0.3975 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [478/782] Loss: 0.5200 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [479/782] Loss: 0.3961 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [480/782] Loss: 0.4102 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [481/782] Loss: 0.2964 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [482/782] Loss: 0.5159 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [483/782] Loss: 0.6500 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [484/782] Loss: 0.3010 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [485/782] Loss: 0.2690 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [486/782] Loss: 0.5515 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [487/782] Loss: 0.3584 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [488/782] Loss: 0.3439 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [489/782] Loss: 0.3056 | Acc: 84.50%\n",
      "Train Epoch [84/100] Batch [490/782] Loss: 0.4547 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [491/782] Loss: 0.4273 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [492/782] Loss: 0.3670 | Acc: 84.49%\n",
      "Train Epoch [84/100] Batch [493/782] Loss: 0.4765 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [494/782] Loss: 0.4058 | Acc: 84.48%\n",
      "Train Epoch [84/100] Batch [495/782] Loss: 0.3669 | Acc: 84.47%\n",
      "Train Epoch [84/100] Batch [496/782] Loss: 0.7702 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [497/782] Loss: 0.3765 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [498/782] Loss: 0.3875 | Acc: 84.45%\n",
      "Train Epoch [84/100] Batch [499/782] Loss: 0.4978 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [500/782] Loss: 0.4568 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [501/782] Loss: 0.4507 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [502/782] Loss: 0.3325 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [503/782] Loss: 0.3543 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [504/782] Loss: 0.5136 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [505/782] Loss: 0.2939 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [506/782] Loss: 0.4713 | Acc: 84.46%\n",
      "Train Epoch [84/100] Batch [507/782] Loss: 0.6554 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [508/782] Loss: 0.6376 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [509/782] Loss: 0.2939 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [510/782] Loss: 0.3498 | Acc: 84.44%\n",
      "Train Epoch [84/100] Batch [511/782] Loss: 0.5415 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [512/782] Loss: 0.3663 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [513/782] Loss: 0.4822 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [514/782] Loss: 0.5505 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [515/782] Loss: 0.6900 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [516/782] Loss: 0.3941 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [517/782] Loss: 0.4069 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [518/782] Loss: 0.4856 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [519/782] Loss: 0.1936 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [520/782] Loss: 0.6416 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [521/782] Loss: 0.3030 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [522/782] Loss: 0.4089 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [523/782] Loss: 0.3725 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [524/782] Loss: 0.4590 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [525/782] Loss: 0.5034 | Acc: 84.42%\n",
      "Train Epoch [84/100] Batch [526/782] Loss: 0.4145 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [527/782] Loss: 0.4301 | Acc: 84.43%\n",
      "Train Epoch [84/100] Batch [528/782] Loss: 0.5871 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [529/782] Loss: 0.4522 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [530/782] Loss: 0.3549 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [531/782] Loss: 0.4707 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [532/782] Loss: 0.4604 | Acc: 84.41%\n",
      "Train Epoch [84/100] Batch [533/782] Loss: 0.5555 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [534/782] Loss: 0.4639 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [535/782] Loss: 0.4359 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [536/782] Loss: 0.5891 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [537/782] Loss: 0.5427 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [538/782] Loss: 0.5321 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [539/782] Loss: 0.4269 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [540/782] Loss: 0.3894 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [541/782] Loss: 0.6642 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [542/782] Loss: 0.5802 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [543/782] Loss: 0.4298 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [544/782] Loss: 0.5159 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [545/782] Loss: 0.5784 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [546/782] Loss: 0.3086 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [547/782] Loss: 0.4727 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [548/782] Loss: 0.2963 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [549/782] Loss: 0.3981 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [550/782] Loss: 0.3877 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [551/782] Loss: 0.4008 | Acc: 84.40%\n",
      "Train Epoch [84/100] Batch [552/782] Loss: 0.5315 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [553/782] Loss: 0.4063 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [554/782] Loss: 0.3980 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [555/782] Loss: 0.5837 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [556/782] Loss: 0.4239 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [557/782] Loss: 0.5108 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [558/782] Loss: 0.3106 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [559/782] Loss: 0.5212 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [560/782] Loss: 0.3376 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [561/782] Loss: 0.5520 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [562/782] Loss: 0.5219 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [563/782] Loss: 0.4511 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [564/782] Loss: 0.5124 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [565/782] Loss: 0.3712 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [566/782] Loss: 0.5297 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [567/782] Loss: 0.6103 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [568/782] Loss: 0.4373 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [569/782] Loss: 0.4459 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [570/782] Loss: 0.5283 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [571/782] Loss: 0.4679 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [572/782] Loss: 0.2610 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [573/782] Loss: 0.3745 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [574/782] Loss: 0.5429 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [575/782] Loss: 0.3803 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [576/782] Loss: 0.5043 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [577/782] Loss: 0.4601 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [578/782] Loss: 0.4081 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [579/782] Loss: 0.4929 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [580/782] Loss: 0.3296 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [581/782] Loss: 0.3985 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [582/782] Loss: 0.3363 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [583/782] Loss: 0.4560 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [584/782] Loss: 0.5217 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [585/782] Loss: 0.4121 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [586/782] Loss: 0.3963 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [587/782] Loss: 0.4761 | Acc: 84.39%\n",
      "Train Epoch [84/100] Batch [588/782] Loss: 0.6592 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [589/782] Loss: 0.4442 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [590/782] Loss: 0.3528 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [591/782] Loss: 0.4843 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [592/782] Loss: 0.4217 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [593/782] Loss: 0.4381 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [594/782] Loss: 0.4430 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [595/782] Loss: 0.3219 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [596/782] Loss: 0.3805 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [597/782] Loss: 0.5370 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [598/782] Loss: 0.2445 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [599/782] Loss: 0.5086 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [600/782] Loss: 0.5431 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [601/782] Loss: 0.5181 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [602/782] Loss: 0.3712 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [603/782] Loss: 0.3607 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [604/782] Loss: 0.5573 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [605/782] Loss: 0.5159 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [606/782] Loss: 0.4512 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [607/782] Loss: 0.3781 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [608/782] Loss: 0.4571 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [609/782] Loss: 0.3543 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [610/782] Loss: 0.3444 | Acc: 84.38%\n",
      "Train Epoch [84/100] Batch [611/782] Loss: 0.4727 | Acc: 84.37%\n",
      "Train Epoch [84/100] Batch [612/782] Loss: 0.4967 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [613/782] Loss: 0.3510 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [614/782] Loss: 0.4557 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [615/782] Loss: 0.4481 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [616/782] Loss: 0.4799 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [617/782] Loss: 0.5460 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [618/782] Loss: 0.5982 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [619/782] Loss: 0.2744 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [620/782] Loss: 0.5568 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [621/782] Loss: 0.4239 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [622/782] Loss: 0.3665 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [623/782] Loss: 0.4945 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [624/782] Loss: 0.4930 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [625/782] Loss: 0.6274 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [626/782] Loss: 0.5567 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [627/782] Loss: 0.5311 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [628/782] Loss: 0.5755 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [629/782] Loss: 0.4353 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [630/782] Loss: 0.5188 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [631/782] Loss: 0.2678 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [632/782] Loss: 0.3398 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [633/782] Loss: 0.4218 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [634/782] Loss: 0.5501 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [635/782] Loss: 0.5650 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [636/782] Loss: 0.4185 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [637/782] Loss: 0.3825 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [638/782] Loss: 0.2482 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [639/782] Loss: 0.3443 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [640/782] Loss: 0.3944 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [641/782] Loss: 0.3193 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [642/782] Loss: 0.3614 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [643/782] Loss: 0.3707 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [644/782] Loss: 0.4898 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [645/782] Loss: 0.6475 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [646/782] Loss: 0.3996 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [647/782] Loss: 0.2534 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [648/782] Loss: 0.4069 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [649/782] Loss: 0.3387 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [650/782] Loss: 0.5392 | Acc: 84.36%\n",
      "Train Epoch [84/100] Batch [651/782] Loss: 0.4365 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [652/782] Loss: 0.5956 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [653/782] Loss: 0.4090 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [654/782] Loss: 0.3978 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [655/782] Loss: 0.4418 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [656/782] Loss: 0.4376 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [657/782] Loss: 0.4729 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [658/782] Loss: 0.4485 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [659/782] Loss: 0.4715 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [660/782] Loss: 0.4142 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [661/782] Loss: 0.4616 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [662/782] Loss: 0.3490 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [663/782] Loss: 0.5256 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [664/782] Loss: 0.3295 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [665/782] Loss: 0.4336 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [666/782] Loss: 0.4577 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [667/782] Loss: 0.4154 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [668/782] Loss: 0.3489 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [669/782] Loss: 0.3916 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [670/782] Loss: 0.4645 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [671/782] Loss: 0.4187 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [672/782] Loss: 0.4413 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [673/782] Loss: 0.4417 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [674/782] Loss: 0.7367 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [675/782] Loss: 0.4361 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [676/782] Loss: 0.6445 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [677/782] Loss: 0.5335 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [678/782] Loss: 0.2930 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [679/782] Loss: 0.5514 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [680/782] Loss: 0.4389 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [681/782] Loss: 0.4013 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [682/782] Loss: 0.5164 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [683/782] Loss: 0.2442 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [684/782] Loss: 0.4210 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [685/782] Loss: 0.3938 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [686/782] Loss: 0.4977 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [687/782] Loss: 0.4960 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [688/782] Loss: 0.4325 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [689/782] Loss: 0.3673 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [690/782] Loss: 0.4187 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [691/782] Loss: 0.4622 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [692/782] Loss: 0.5215 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [693/782] Loss: 0.4120 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [694/782] Loss: 0.3558 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [695/782] Loss: 0.4010 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [696/782] Loss: 0.2662 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [697/782] Loss: 0.3349 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [698/782] Loss: 0.4744 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [699/782] Loss: 0.3909 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [700/782] Loss: 0.4196 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [701/782] Loss: 0.4980 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [702/782] Loss: 0.4453 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [703/782] Loss: 0.5314 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [704/782] Loss: 0.4359 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [705/782] Loss: 0.4455 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [706/782] Loss: 0.2676 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [707/782] Loss: 0.6416 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [708/782] Loss: 0.8785 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [709/782] Loss: 0.5279 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [710/782] Loss: 0.4666 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [711/782] Loss: 0.3434 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [712/782] Loss: 0.3582 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [713/782] Loss: 0.4361 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [714/782] Loss: 0.3351 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [715/782] Loss: 0.3458 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [716/782] Loss: 0.3753 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [717/782] Loss: 0.4532 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [718/782] Loss: 0.4075 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [719/782] Loss: 0.4547 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [720/782] Loss: 0.3447 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [721/782] Loss: 0.4623 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [722/782] Loss: 0.5754 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [723/782] Loss: 0.5145 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [724/782] Loss: 0.4298 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [725/782] Loss: 0.5518 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [726/782] Loss: 0.4625 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [727/782] Loss: 0.4076 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [728/782] Loss: 0.6264 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [729/782] Loss: 0.4323 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [730/782] Loss: 0.3639 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [731/782] Loss: 0.3305 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [732/782] Loss: 0.4154 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [733/782] Loss: 0.5098 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [734/782] Loss: 0.6514 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [735/782] Loss: 0.4973 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [736/782] Loss: 0.5369 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [737/782] Loss: 0.4608 | Acc: 84.28%\n",
      "Train Epoch [84/100] Batch [738/782] Loss: 0.4799 | Acc: 84.28%\n",
      "Train Epoch [84/100] Batch [739/782] Loss: 0.3636 | Acc: 84.28%\n",
      "Train Epoch [84/100] Batch [740/782] Loss: 0.3099 | Acc: 84.29%\n",
      "Train Epoch [84/100] Batch [741/782] Loss: 0.4367 | Acc: 84.30%\n",
      "Train Epoch [84/100] Batch [742/782] Loss: 0.2207 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [743/782] Loss: 0.5457 | Acc: 84.31%\n",
      "Train Epoch [84/100] Batch [744/782] Loss: 0.1577 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [745/782] Loss: 0.3760 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [746/782] Loss: 0.4240 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [747/782] Loss: 0.3898 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [748/782] Loss: 0.4487 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [749/782] Loss: 0.4049 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [750/782] Loss: 0.5159 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [751/782] Loss: 0.3155 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [752/782] Loss: 0.4209 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [753/782] Loss: 0.6312 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [754/782] Loss: 0.3696 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [755/782] Loss: 0.3274 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [756/782] Loss: 0.5795 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [757/782] Loss: 0.3677 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [758/782] Loss: 0.3082 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [759/782] Loss: 0.3430 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [760/782] Loss: 0.5314 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [761/782] Loss: 0.3206 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [762/782] Loss: 0.3664 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [763/782] Loss: 0.4520 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [764/782] Loss: 0.6283 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [765/782] Loss: 0.2698 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [766/782] Loss: 0.5037 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [767/782] Loss: 0.5373 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [768/782] Loss: 0.3991 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [769/782] Loss: 0.2724 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [770/782] Loss: 0.3444 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [771/782] Loss: 0.4897 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [772/782] Loss: 0.4415 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [773/782] Loss: 0.2969 | Acc: 84.35%\n",
      "Train Epoch [84/100] Batch [774/782] Loss: 0.5449 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [775/782] Loss: 0.4850 | Acc: 84.34%\n",
      "Train Epoch [84/100] Batch [776/782] Loss: 0.5575 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [777/782] Loss: 0.5276 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [778/782] Loss: 0.5500 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [779/782] Loss: 0.4827 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [780/782] Loss: 0.5888 | Acc: 84.32%\n",
      "Train Epoch [84/100] Batch [781/782] Loss: 0.3392 | Acc: 84.33%\n",
      "Train Epoch [84/100] Batch [782/782] Loss: 0.4042 | Acc: 84.33%\n",
      "Epoch 84 completed in 30.45s.\n",
      "Test Epoch [84/100] Loss: 1.0054 | Acc: 72.15% | Inference Time: 8.57s\n",
      "Epoch 84 results saved to CSV.\n",
      "Epoch 85/100\n",
      "Train Epoch [85/100] Batch [1/782] Loss: 0.5648 | Acc: 78.12%\n",
      "Train Epoch [85/100] Batch [2/782] Loss: 0.2896 | Acc: 85.16%\n",
      "Train Epoch [85/100] Batch [3/782] Loss: 0.5241 | Acc: 83.33%\n",
      "Train Epoch [85/100] Batch [4/782] Loss: 0.4453 | Acc: 83.98%\n",
      "Train Epoch [85/100] Batch [5/782] Loss: 0.4183 | Acc: 83.75%\n",
      "Train Epoch [85/100] Batch [6/782] Loss: 0.4956 | Acc: 83.85%\n",
      "Train Epoch [85/100] Batch [7/782] Loss: 0.3248 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [8/782] Loss: 0.4891 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [9/782] Loss: 0.4251 | Acc: 84.20%\n",
      "Train Epoch [85/100] Batch [10/782] Loss: 0.3544 | Acc: 84.06%\n",
      "Train Epoch [85/100] Batch [11/782] Loss: 0.4102 | Acc: 84.09%\n",
      "Train Epoch [85/100] Batch [12/782] Loss: 0.5109 | Acc: 84.11%\n",
      "Train Epoch [85/100] Batch [13/782] Loss: 0.3589 | Acc: 84.25%\n",
      "Train Epoch [85/100] Batch [14/782] Loss: 0.5922 | Acc: 84.15%\n",
      "Train Epoch [85/100] Batch [15/782] Loss: 0.5907 | Acc: 84.06%\n",
      "Train Epoch [85/100] Batch [16/782] Loss: 0.3528 | Acc: 83.89%\n",
      "Train Epoch [85/100] Batch [17/782] Loss: 0.5261 | Acc: 83.55%\n",
      "Train Epoch [85/100] Batch [18/782] Loss: 0.4348 | Acc: 83.59%\n",
      "Train Epoch [85/100] Batch [19/782] Loss: 0.4262 | Acc: 83.63%\n",
      "Train Epoch [85/100] Batch [20/782] Loss: 0.4749 | Acc: 83.59%\n",
      "Train Epoch [85/100] Batch [21/782] Loss: 0.4896 | Acc: 83.33%\n",
      "Train Epoch [85/100] Batch [22/782] Loss: 0.5268 | Acc: 83.24%\n",
      "Train Epoch [85/100] Batch [23/782] Loss: 0.4920 | Acc: 83.36%\n",
      "Train Epoch [85/100] Batch [24/782] Loss: 0.3758 | Acc: 83.72%\n",
      "Train Epoch [85/100] Batch [25/782] Loss: 0.4605 | Acc: 83.75%\n",
      "Train Epoch [85/100] Batch [26/782] Loss: 0.4573 | Acc: 83.77%\n",
      "Train Epoch [85/100] Batch [27/782] Loss: 0.4506 | Acc: 83.80%\n",
      "Train Epoch [85/100] Batch [28/782] Loss: 0.7078 | Acc: 83.59%\n",
      "Train Epoch [85/100] Batch [29/782] Loss: 0.3665 | Acc: 83.73%\n",
      "Train Epoch [85/100] Batch [30/782] Loss: 0.3771 | Acc: 83.80%\n",
      "Train Epoch [85/100] Batch [31/782] Loss: 0.4950 | Acc: 83.72%\n",
      "Train Epoch [85/100] Batch [32/782] Loss: 0.4178 | Acc: 83.59%\n",
      "Train Epoch [85/100] Batch [33/782] Loss: 0.4705 | Acc: 83.66%\n",
      "Train Epoch [85/100] Batch [34/782] Loss: 0.6506 | Acc: 83.55%\n",
      "Train Epoch [85/100] Batch [35/782] Loss: 0.4230 | Acc: 83.53%\n",
      "Train Epoch [85/100] Batch [36/782] Loss: 0.3651 | Acc: 83.59%\n",
      "Train Epoch [85/100] Batch [37/782] Loss: 0.3751 | Acc: 83.61%\n",
      "Train Epoch [85/100] Batch [38/782] Loss: 0.5204 | Acc: 83.43%\n",
      "Train Epoch [85/100] Batch [39/782] Loss: 0.4605 | Acc: 83.33%\n",
      "Train Epoch [85/100] Batch [40/782] Loss: 0.2970 | Acc: 83.44%\n",
      "Train Epoch [85/100] Batch [41/782] Loss: 0.3407 | Acc: 83.57%\n",
      "Train Epoch [85/100] Batch [42/782] Loss: 0.4973 | Acc: 83.56%\n",
      "Train Epoch [85/100] Batch [43/782] Loss: 0.2858 | Acc: 83.72%\n",
      "Train Epoch [85/100] Batch [44/782] Loss: 0.4236 | Acc: 83.74%\n",
      "Train Epoch [85/100] Batch [45/782] Loss: 0.3952 | Acc: 83.82%\n",
      "Train Epoch [85/100] Batch [46/782] Loss: 0.3584 | Acc: 83.87%\n",
      "Train Epoch [85/100] Batch [47/782] Loss: 0.3383 | Acc: 83.91%\n",
      "Train Epoch [85/100] Batch [48/782] Loss: 0.4187 | Acc: 83.89%\n",
      "Train Epoch [85/100] Batch [49/782] Loss: 0.4239 | Acc: 83.86%\n",
      "Train Epoch [85/100] Batch [50/782] Loss: 0.5015 | Acc: 83.94%\n",
      "Train Epoch [85/100] Batch [51/782] Loss: 0.3143 | Acc: 84.07%\n",
      "Train Epoch [85/100] Batch [52/782] Loss: 0.3462 | Acc: 84.13%\n",
      "Train Epoch [85/100] Batch [53/782] Loss: 0.2315 | Acc: 84.29%\n",
      "Train Epoch [85/100] Batch [54/782] Loss: 0.5033 | Acc: 84.32%\n",
      "Train Epoch [85/100] Batch [55/782] Loss: 0.6621 | Acc: 84.32%\n",
      "Train Epoch [85/100] Batch [56/782] Loss: 0.5041 | Acc: 84.26%\n",
      "Train Epoch [85/100] Batch [57/782] Loss: 0.3496 | Acc: 84.27%\n",
      "Train Epoch [85/100] Batch [58/782] Loss: 0.5828 | Acc: 84.16%\n",
      "Train Epoch [85/100] Batch [59/782] Loss: 0.4684 | Acc: 84.11%\n",
      "Train Epoch [85/100] Batch [60/782] Loss: 0.3530 | Acc: 84.17%\n",
      "Train Epoch [85/100] Batch [61/782] Loss: 0.4724 | Acc: 84.20%\n",
      "Train Epoch [85/100] Batch [62/782] Loss: 0.2522 | Acc: 84.30%\n",
      "Train Epoch [85/100] Batch [63/782] Loss: 0.3634 | Acc: 84.30%\n",
      "Train Epoch [85/100] Batch [64/782] Loss: 0.3096 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [65/782] Loss: 0.5032 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [66/782] Loss: 0.3596 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [67/782] Loss: 0.2271 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [68/782] Loss: 0.3314 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [69/782] Loss: 0.2782 | Acc: 84.69%\n",
      "Train Epoch [85/100] Batch [70/782] Loss: 0.6367 | Acc: 84.67%\n",
      "Train Epoch [85/100] Batch [71/782] Loss: 0.3932 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [72/782] Loss: 0.2915 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [73/782] Loss: 0.4744 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [74/782] Loss: 0.4311 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [75/782] Loss: 0.3171 | Acc: 84.69%\n",
      "Train Epoch [85/100] Batch [76/782] Loss: 0.7015 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [77/782] Loss: 0.4304 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [78/782] Loss: 0.3282 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [79/782] Loss: 0.3323 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [80/782] Loss: 0.2898 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [81/782] Loss: 0.3819 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [82/782] Loss: 0.6326 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [83/782] Loss: 0.3236 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [84/782] Loss: 0.2900 | Acc: 84.71%\n",
      "Train Epoch [85/100] Batch [85/782] Loss: 0.5338 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [86/782] Loss: 0.3166 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [87/782] Loss: 0.4816 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [88/782] Loss: 0.5330 | Acc: 84.55%\n",
      "Train Epoch [85/100] Batch [89/782] Loss: 0.6459 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [90/782] Loss: 0.4538 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [91/782] Loss: 0.3331 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [92/782] Loss: 0.7007 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [93/782] Loss: 0.3407 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [94/782] Loss: 0.3901 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [95/782] Loss: 0.5093 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [96/782] Loss: 0.6260 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [97/782] Loss: 0.6148 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [98/782] Loss: 0.2509 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [99/782] Loss: 0.4904 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [100/782] Loss: 0.4888 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [101/782] Loss: 0.3156 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [102/782] Loss: 0.3129 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [103/782] Loss: 0.4872 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [104/782] Loss: 0.4138 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [105/782] Loss: 0.3667 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [106/782] Loss: 0.3326 | Acc: 84.55%\n",
      "Train Epoch [85/100] Batch [107/782] Loss: 0.5450 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [108/782] Loss: 0.4975 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [109/782] Loss: 0.2931 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [110/782] Loss: 0.4205 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [111/782] Loss: 0.6154 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [112/782] Loss: 0.4150 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [113/782] Loss: 0.4988 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [114/782] Loss: 0.5594 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [115/782] Loss: 0.4630 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [116/782] Loss: 0.4991 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [117/782] Loss: 0.4263 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [118/782] Loss: 0.3598 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [119/782] Loss: 0.3609 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [120/782] Loss: 0.4689 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [121/782] Loss: 0.3459 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [122/782] Loss: 0.5895 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [123/782] Loss: 0.3201 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [124/782] Loss: 0.4275 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [125/782] Loss: 0.4826 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [126/782] Loss: 0.3510 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [127/782] Loss: 0.3782 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [128/782] Loss: 0.3168 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [129/782] Loss: 0.1943 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [130/782] Loss: 0.3920 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [131/782] Loss: 0.1664 | Acc: 84.70%\n",
      "Train Epoch [85/100] Batch [132/782] Loss: 0.4941 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [133/782] Loss: 0.3989 | Acc: 84.67%\n",
      "Train Epoch [85/100] Batch [134/782] Loss: 0.3167 | Acc: 84.71%\n",
      "Train Epoch [85/100] Batch [135/782] Loss: 0.6430 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [136/782] Loss: 0.3217 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [137/782] Loss: 0.2905 | Acc: 84.74%\n",
      "Train Epoch [85/100] Batch [138/782] Loss: 0.4279 | Acc: 84.73%\n",
      "Train Epoch [85/100] Batch [139/782] Loss: 0.4914 | Acc: 84.69%\n",
      "Train Epoch [85/100] Batch [140/782] Loss: 0.3554 | Acc: 84.70%\n",
      "Train Epoch [85/100] Batch [141/782] Loss: 0.3305 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [142/782] Loss: 0.4553 | Acc: 84.69%\n",
      "Train Epoch [85/100] Batch [143/782] Loss: 0.5750 | Acc: 84.66%\n",
      "Train Epoch [85/100] Batch [144/782] Loss: 0.5136 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [145/782] Loss: 0.3563 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [146/782] Loss: 0.3579 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [147/782] Loss: 0.5321 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [148/782] Loss: 0.4161 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [149/782] Loss: 0.4504 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [150/782] Loss: 0.4714 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [151/782] Loss: 0.4635 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [152/782] Loss: 0.4538 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [153/782] Loss: 0.3295 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [154/782] Loss: 0.4613 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [155/782] Loss: 0.4051 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [156/782] Loss: 0.3128 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [157/782] Loss: 0.2963 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [158/782] Loss: 0.5852 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [159/782] Loss: 0.3543 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [160/782] Loss: 0.4181 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [161/782] Loss: 0.3970 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [162/782] Loss: 0.4928 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [163/782] Loss: 0.5736 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [164/782] Loss: 0.4115 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [165/782] Loss: 0.4808 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [166/782] Loss: 0.4070 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [167/782] Loss: 0.2471 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [168/782] Loss: 0.3679 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [169/782] Loss: 0.3988 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [170/782] Loss: 0.1776 | Acc: 84.67%\n",
      "Train Epoch [85/100] Batch [171/782] Loss: 0.3434 | Acc: 84.71%\n",
      "Train Epoch [85/100] Batch [172/782] Loss: 0.3758 | Acc: 84.73%\n",
      "Train Epoch [85/100] Batch [173/782] Loss: 0.3196 | Acc: 84.75%\n",
      "Train Epoch [85/100] Batch [174/782] Loss: 0.4890 | Acc: 84.74%\n",
      "Train Epoch [85/100] Batch [175/782] Loss: 0.5231 | Acc: 84.71%\n",
      "Train Epoch [85/100] Batch [176/782] Loss: 0.3156 | Acc: 84.74%\n",
      "Train Epoch [85/100] Batch [177/782] Loss: 0.2358 | Acc: 84.75%\n",
      "Train Epoch [85/100] Batch [178/782] Loss: 0.4627 | Acc: 84.73%\n",
      "Train Epoch [85/100] Batch [179/782] Loss: 0.5143 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [180/782] Loss: 0.3280 | Acc: 84.75%\n",
      "Train Epoch [85/100] Batch [181/782] Loss: 0.6022 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [182/782] Loss: 0.4021 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [183/782] Loss: 0.4550 | Acc: 84.73%\n",
      "Train Epoch [85/100] Batch [184/782] Loss: 0.5179 | Acc: 84.75%\n",
      "Train Epoch [85/100] Batch [185/782] Loss: 0.3914 | Acc: 84.76%\n",
      "Train Epoch [85/100] Batch [186/782] Loss: 0.5029 | Acc: 84.74%\n",
      "Train Epoch [85/100] Batch [187/782] Loss: 0.3666 | Acc: 84.74%\n",
      "Train Epoch [85/100] Batch [188/782] Loss: 0.3702 | Acc: 84.72%\n",
      "Train Epoch [85/100] Batch [189/782] Loss: 0.2950 | Acc: 84.76%\n",
      "Train Epoch [85/100] Batch [190/782] Loss: 0.5154 | Acc: 84.75%\n",
      "Train Epoch [85/100] Batch [191/782] Loss: 0.5873 | Acc: 84.73%\n",
      "Train Epoch [85/100] Batch [192/782] Loss: 0.5870 | Acc: 84.71%\n",
      "Train Epoch [85/100] Batch [193/782] Loss: 0.5785 | Acc: 84.67%\n",
      "Train Epoch [85/100] Batch [194/782] Loss: 0.3316 | Acc: 84.70%\n",
      "Train Epoch [85/100] Batch [195/782] Loss: 0.5028 | Acc: 84.68%\n",
      "Train Epoch [85/100] Batch [196/782] Loss: 0.4696 | Acc: 84.69%\n",
      "Train Epoch [85/100] Batch [197/782] Loss: 0.6283 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [198/782] Loss: 0.5656 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [199/782] Loss: 0.3099 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [200/782] Loss: 0.3919 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [201/782] Loss: 0.6463 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [202/782] Loss: 0.3793 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [203/782] Loss: 0.3824 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [204/782] Loss: 0.4473 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [205/782] Loss: 0.2741 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [206/782] Loss: 0.2747 | Acc: 84.68%\n",
      "Train Epoch [85/100] Batch [207/782] Loss: 0.5016 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [208/782] Loss: 0.5218 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [209/782] Loss: 0.3793 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [210/782] Loss: 0.4210 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [211/782] Loss: 0.4871 | Acc: 84.64%\n",
      "Train Epoch [85/100] Batch [212/782] Loss: 0.3798 | Acc: 84.65%\n",
      "Train Epoch [85/100] Batch [213/782] Loss: 0.4943 | Acc: 84.62%\n",
      "Train Epoch [85/100] Batch [214/782] Loss: 0.5747 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [215/782] Loss: 0.5570 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [216/782] Loss: 0.4795 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [217/782] Loss: 0.4732 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [218/782] Loss: 0.3104 | Acc: 84.62%\n",
      "Train Epoch [85/100] Batch [219/782] Loss: 0.4951 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [220/782] Loss: 0.3722 | Acc: 84.62%\n",
      "Train Epoch [85/100] Batch [221/782] Loss: 0.5024 | Acc: 84.62%\n",
      "Train Epoch [85/100] Batch [222/782] Loss: 0.5639 | Acc: 84.61%\n",
      "Train Epoch [85/100] Batch [223/782] Loss: 0.3448 | Acc: 84.63%\n",
      "Train Epoch [85/100] Batch [224/782] Loss: 0.6433 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [225/782] Loss: 0.3541 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [226/782] Loss: 0.5842 | Acc: 84.55%\n",
      "Train Epoch [85/100] Batch [227/782] Loss: 0.4126 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [228/782] Loss: 0.3282 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [229/782] Loss: 0.3341 | Acc: 84.59%\n",
      "Train Epoch [85/100] Batch [230/782] Loss: 0.5853 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [231/782] Loss: 0.3288 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [232/782] Loss: 0.3604 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [233/782] Loss: 0.4077 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [234/782] Loss: 0.6023 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [235/782] Loss: 0.3857 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [236/782] Loss: 0.4040 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [237/782] Loss: 0.3956 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [238/782] Loss: 0.5694 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [239/782] Loss: 0.4396 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [240/782] Loss: 0.3078 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [241/782] Loss: 0.4774 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [242/782] Loss: 0.5258 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [243/782] Loss: 0.5286 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [244/782] Loss: 0.4462 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [245/782] Loss: 0.3096 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [246/782] Loss: 0.4607 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [247/782] Loss: 0.3870 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [248/782] Loss: 0.4748 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [249/782] Loss: 0.3600 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [250/782] Loss: 0.3785 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [251/782] Loss: 0.3835 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [252/782] Loss: 0.5290 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [253/782] Loss: 0.4551 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [254/782] Loss: 0.3769 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [255/782] Loss: 0.3302 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [256/782] Loss: 0.4369 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [257/782] Loss: 0.3870 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [258/782] Loss: 0.3823 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [259/782] Loss: 0.3299 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [260/782] Loss: 0.5606 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [261/782] Loss: 0.3919 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [262/782] Loss: 0.5078 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [263/782] Loss: 0.3118 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [264/782] Loss: 0.4757 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [265/782] Loss: 0.4351 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [266/782] Loss: 0.3374 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [267/782] Loss: 0.5755 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [268/782] Loss: 0.3693 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [269/782] Loss: 0.3773 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [270/782] Loss: 0.4064 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [271/782] Loss: 0.4693 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [272/782] Loss: 0.3243 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [273/782] Loss: 0.2530 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [274/782] Loss: 0.4232 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [275/782] Loss: 0.4945 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [276/782] Loss: 0.3469 | Acc: 84.60%\n",
      "Train Epoch [85/100] Batch [277/782] Loss: 0.7241 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [278/782] Loss: 0.5610 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [279/782] Loss: 0.4722 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [280/782] Loss: 0.6759 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [281/782] Loss: 0.5337 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [282/782] Loss: 0.4700 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [283/782] Loss: 0.4561 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [284/782] Loss: 0.5319 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [285/782] Loss: 0.3592 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [286/782] Loss: 0.4545 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [287/782] Loss: 0.4656 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [288/782] Loss: 0.4570 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [289/782] Loss: 0.6054 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [290/782] Loss: 0.2910 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [291/782] Loss: 0.3884 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [292/782] Loss: 0.5491 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [293/782] Loss: 0.3254 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [294/782] Loss: 0.4502 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [295/782] Loss: 0.4903 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [296/782] Loss: 0.3558 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [297/782] Loss: 0.5134 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [298/782] Loss: 0.4969 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [299/782] Loss: 0.4143 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [300/782] Loss: 0.4054 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [301/782] Loss: 0.4427 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [302/782] Loss: 0.4730 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [303/782] Loss: 0.3797 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [304/782] Loss: 0.4179 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [305/782] Loss: 0.4432 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [306/782] Loss: 0.4375 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [307/782] Loss: 0.3041 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [308/782] Loss: 0.3312 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [309/782] Loss: 0.4163 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [310/782] Loss: 0.3898 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [311/782] Loss: 0.4883 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [312/782] Loss: 0.3679 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [313/782] Loss: 0.3962 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [314/782] Loss: 0.3057 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [315/782] Loss: 0.2045 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [316/782] Loss: 0.4349 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [317/782] Loss: 0.3842 | Acc: 84.57%\n",
      "Train Epoch [85/100] Batch [318/782] Loss: 0.5510 | Acc: 84.58%\n",
      "Train Epoch [85/100] Batch [319/782] Loss: 0.5617 | Acc: 84.56%\n",
      "Train Epoch [85/100] Batch [320/782] Loss: 0.5606 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [321/782] Loss: 0.4756 | Acc: 84.54%\n",
      "Train Epoch [85/100] Batch [322/782] Loss: 0.4578 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [323/782] Loss: 0.7610 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [324/782] Loss: 0.3967 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [325/782] Loss: 0.3852 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [326/782] Loss: 0.3608 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [327/782] Loss: 0.4858 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [328/782] Loss: 0.4597 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [329/782] Loss: 0.3761 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [330/782] Loss: 0.6476 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [331/782] Loss: 0.4006 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [332/782] Loss: 0.4928 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [333/782] Loss: 0.3272 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [334/782] Loss: 0.5102 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [335/782] Loss: 0.4881 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [336/782] Loss: 0.3861 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [337/782] Loss: 0.3613 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [338/782] Loss: 0.3779 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [339/782] Loss: 0.4398 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [340/782] Loss: 0.3881 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [341/782] Loss: 0.4250 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [342/782] Loss: 0.3882 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [343/782] Loss: 0.6002 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [344/782] Loss: 0.4347 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [345/782] Loss: 0.3370 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [346/782] Loss: 0.4743 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [347/782] Loss: 0.4199 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [348/782] Loss: 0.3160 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [349/782] Loss: 0.4464 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [350/782] Loss: 0.3061 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [351/782] Loss: 0.4513 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [352/782] Loss: 0.3563 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [353/782] Loss: 0.4288 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [354/782] Loss: 0.4655 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [355/782] Loss: 0.4215 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [356/782] Loss: 0.3735 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [357/782] Loss: 0.5015 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [358/782] Loss: 0.4604 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [359/782] Loss: 0.7270 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [360/782] Loss: 0.4521 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [361/782] Loss: 0.3845 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [362/782] Loss: 0.4657 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [363/782] Loss: 0.2854 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [364/782] Loss: 0.5762 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [365/782] Loss: 0.5343 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [366/782] Loss: 0.3820 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [367/782] Loss: 0.4347 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [368/782] Loss: 0.4102 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [369/782] Loss: 0.4294 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [370/782] Loss: 0.6134 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [371/782] Loss: 0.5830 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [372/782] Loss: 0.4828 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [373/782] Loss: 0.3804 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [374/782] Loss: 0.3626 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [375/782] Loss: 0.2732 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [376/782] Loss: 0.4438 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [377/782] Loss: 0.4221 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [378/782] Loss: 0.4229 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [379/782] Loss: 0.4232 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [380/782] Loss: 0.4724 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [381/782] Loss: 0.4325 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [382/782] Loss: 0.6113 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [383/782] Loss: 0.4871 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [384/782] Loss: 0.3703 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [385/782] Loss: 0.3765 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [386/782] Loss: 0.1984 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [387/782] Loss: 0.6600 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [388/782] Loss: 0.3042 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [389/782] Loss: 0.5441 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [390/782] Loss: 0.5780 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [391/782] Loss: 0.3820 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [392/782] Loss: 0.3302 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [393/782] Loss: 0.4067 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [394/782] Loss: 0.4481 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [395/782] Loss: 0.2139 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [396/782] Loss: 0.4973 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [397/782] Loss: 0.2805 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [398/782] Loss: 0.3616 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [399/782] Loss: 0.4369 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [400/782] Loss: 0.3656 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [401/782] Loss: 0.3614 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [402/782] Loss: 0.3931 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [403/782] Loss: 0.4060 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [404/782] Loss: 0.5146 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [405/782] Loss: 0.6358 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [406/782] Loss: 0.4265 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [407/782] Loss: 0.4639 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [408/782] Loss: 0.5467 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [409/782] Loss: 0.5423 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [410/782] Loss: 0.6764 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [411/782] Loss: 0.7320 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [412/782] Loss: 0.4631 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [413/782] Loss: 0.5053 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [414/782] Loss: 0.2972 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [415/782] Loss: 0.5198 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [416/782] Loss: 0.7910 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [417/782] Loss: 0.4203 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [418/782] Loss: 0.3143 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [419/782] Loss: 0.2879 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [420/782] Loss: 0.3454 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [421/782] Loss: 0.5330 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [422/782] Loss: 0.3548 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [423/782] Loss: 0.5276 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [424/782] Loss: 0.3594 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [425/782] Loss: 0.4528 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [426/782] Loss: 0.4399 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [427/782] Loss: 0.2321 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [428/782] Loss: 0.4602 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [429/782] Loss: 0.3430 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [430/782] Loss: 0.4413 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [431/782] Loss: 0.5301 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [432/782] Loss: 0.4038 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [433/782] Loss: 0.4446 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [434/782] Loss: 0.6960 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [435/782] Loss: 0.4601 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [436/782] Loss: 0.5376 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [437/782] Loss: 0.2344 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [438/782] Loss: 0.4408 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [439/782] Loss: 0.5484 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [440/782] Loss: 0.4294 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [441/782] Loss: 0.3478 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [442/782] Loss: 0.5961 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [443/782] Loss: 0.3501 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [444/782] Loss: 0.3978 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [445/782] Loss: 0.4918 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [446/782] Loss: 0.5310 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [447/782] Loss: 0.5152 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [448/782] Loss: 0.3146 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [449/782] Loss: 0.3327 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [450/782] Loss: 0.3435 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [451/782] Loss: 0.5931 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [452/782] Loss: 0.4216 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [453/782] Loss: 0.5189 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [454/782] Loss: 0.3771 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [455/782] Loss: 0.4790 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [456/782] Loss: 0.4197 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [457/782] Loss: 0.5111 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [458/782] Loss: 0.5554 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [459/782] Loss: 0.4723 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [460/782] Loss: 0.4286 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [461/782] Loss: 0.4099 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [462/782] Loss: 0.2160 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [463/782] Loss: 0.4006 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [464/782] Loss: 0.5127 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [465/782] Loss: 0.3090 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [466/782] Loss: 0.3594 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [467/782] Loss: 0.4496 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [468/782] Loss: 0.4320 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [469/782] Loss: 0.5007 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [470/782] Loss: 0.3932 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [471/782] Loss: 0.3911 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [472/782] Loss: 0.3394 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [473/782] Loss: 0.5602 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [474/782] Loss: 0.4668 | Acc: 84.35%\n",
      "Train Epoch [85/100] Batch [475/782] Loss: 0.4782 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [476/782] Loss: 0.5130 | Acc: 84.35%\n",
      "Train Epoch [85/100] Batch [477/782] Loss: 0.3521 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [478/782] Loss: 0.4321 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [479/782] Loss: 0.2763 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [480/782] Loss: 0.4155 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [481/782] Loss: 0.4160 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [482/782] Loss: 0.3991 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [483/782] Loss: 0.5346 | Acc: 84.35%\n",
      "Train Epoch [85/100] Batch [484/782] Loss: 0.4859 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [485/782] Loss: 0.3317 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [486/782] Loss: 0.5017 | Acc: 84.35%\n",
      "Train Epoch [85/100] Batch [487/782] Loss: 0.4476 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [488/782] Loss: 0.4183 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [489/782] Loss: 0.4843 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [490/782] Loss: 0.4381 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [491/782] Loss: 0.4880 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [492/782] Loss: 0.4109 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [493/782] Loss: 0.4153 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [494/782] Loss: 0.4782 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [495/782] Loss: 0.3457 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [496/782] Loss: 0.6506 | Acc: 84.32%\n",
      "Train Epoch [85/100] Batch [497/782] Loss: 0.3151 | Acc: 84.33%\n",
      "Train Epoch [85/100] Batch [498/782] Loss: 0.4189 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [499/782] Loss: 0.3813 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [500/782] Loss: 0.4226 | Acc: 84.34%\n",
      "Train Epoch [85/100] Batch [501/782] Loss: 0.3514 | Acc: 84.35%\n",
      "Train Epoch [85/100] Batch [502/782] Loss: 0.2022 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [503/782] Loss: 0.3447 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [504/782] Loss: 0.3251 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [505/782] Loss: 0.4525 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [506/782] Loss: 0.5767 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [507/782] Loss: 0.3876 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [508/782] Loss: 0.3366 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [509/782] Loss: 0.4767 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [510/782] Loss: 0.4896 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [511/782] Loss: 0.3992 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [512/782] Loss: 0.4178 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [513/782] Loss: 0.4391 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [514/782] Loss: 0.4449 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [515/782] Loss: 0.3936 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [516/782] Loss: 0.4718 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [517/782] Loss: 0.3383 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [518/782] Loss: 0.3957 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [519/782] Loss: 0.3624 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [520/782] Loss: 0.6432 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [521/782] Loss: 0.3473 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [522/782] Loss: 0.4559 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [523/782] Loss: 0.3627 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [524/782] Loss: 0.5815 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [525/782] Loss: 0.4501 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [526/782] Loss: 0.3282 | Acc: 84.36%\n",
      "Train Epoch [85/100] Batch [527/782] Loss: 0.3186 | Acc: 84.37%\n",
      "Train Epoch [85/100] Batch [528/782] Loss: 0.3947 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [529/782] Loss: 0.3320 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [530/782] Loss: 0.4520 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [531/782] Loss: 0.1895 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [532/782] Loss: 0.3661 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [533/782] Loss: 0.3891 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [534/782] Loss: 0.3140 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [535/782] Loss: 0.4505 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [536/782] Loss: 0.3085 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [537/782] Loss: 0.4527 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [538/782] Loss: 0.2625 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [539/782] Loss: 0.3702 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [540/782] Loss: 0.4681 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [541/782] Loss: 0.6037 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [542/782] Loss: 0.3481 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [543/782] Loss: 0.4715 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [544/782] Loss: 0.4566 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [545/782] Loss: 0.3632 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [546/782] Loss: 0.3615 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [547/782] Loss: 0.1848 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [548/782] Loss: 0.5272 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [549/782] Loss: 0.3478 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [550/782] Loss: 0.5755 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [551/782] Loss: 0.2918 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [552/782] Loss: 0.3517 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [553/782] Loss: 0.3624 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [554/782] Loss: 0.4237 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [555/782] Loss: 0.3753 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [556/782] Loss: 0.2916 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [557/782] Loss: 0.4119 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [558/782] Loss: 0.4218 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [559/782] Loss: 0.4855 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [560/782] Loss: 0.7692 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [561/782] Loss: 0.5905 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [562/782] Loss: 0.3931 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [563/782] Loss: 0.2775 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [564/782] Loss: 0.4669 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [565/782] Loss: 0.4872 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [566/782] Loss: 0.3925 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [567/782] Loss: 0.4410 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [568/782] Loss: 0.4893 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [569/782] Loss: 0.4441 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [570/782] Loss: 0.3734 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [571/782] Loss: 0.5817 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [572/782] Loss: 0.3106 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [573/782] Loss: 0.4950 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [574/782] Loss: 0.4410 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [575/782] Loss: 0.3535 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [576/782] Loss: 0.8310 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [577/782] Loss: 0.3498 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [578/782] Loss: 0.3152 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [579/782] Loss: 0.3158 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [580/782] Loss: 0.3535 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [581/782] Loss: 0.4559 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [582/782] Loss: 0.4696 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [583/782] Loss: 0.3208 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [584/782] Loss: 0.2243 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [585/782] Loss: 0.3544 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [586/782] Loss: 0.2973 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [587/782] Loss: 0.2988 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [588/782] Loss: 0.2798 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [589/782] Loss: 0.5070 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [590/782] Loss: 0.3455 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [591/782] Loss: 0.6020 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [592/782] Loss: 0.4307 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [593/782] Loss: 0.3161 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [594/782] Loss: 0.4728 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [595/782] Loss: 0.4287 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [596/782] Loss: 0.3467 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [597/782] Loss: 0.4199 | Acc: 84.53%\n",
      "Train Epoch [85/100] Batch [598/782] Loss: 0.6716 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [599/782] Loss: 0.5053 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [600/782] Loss: 0.4176 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [601/782] Loss: 0.4329 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [602/782] Loss: 0.5185 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [603/782] Loss: 0.2943 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [604/782] Loss: 0.6265 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [605/782] Loss: 0.4039 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [606/782] Loss: 0.5122 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [607/782] Loss: 0.5282 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [608/782] Loss: 0.4585 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [609/782] Loss: 0.4957 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [610/782] Loss: 0.2185 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [611/782] Loss: 0.5033 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [612/782] Loss: 0.5012 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [613/782] Loss: 0.3677 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [614/782] Loss: 0.5721 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [615/782] Loss: 0.3170 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [616/782] Loss: 0.4242 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [617/782] Loss: 0.3368 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [618/782] Loss: 0.4456 | Acc: 84.52%\n",
      "Train Epoch [85/100] Batch [619/782] Loss: 0.6443 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [620/782] Loss: 0.6969 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [621/782] Loss: 0.6032 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [622/782] Loss: 0.3429 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [623/782] Loss: 0.5308 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [624/782] Loss: 0.6845 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [625/782] Loss: 0.2831 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [626/782] Loss: 0.5465 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [627/782] Loss: 0.2474 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [628/782] Loss: 0.4680 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [629/782] Loss: 0.4183 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [630/782] Loss: 0.3395 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [631/782] Loss: 0.4599 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [632/782] Loss: 0.3814 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [633/782] Loss: 0.4431 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [634/782] Loss: 0.4085 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [635/782] Loss: 0.6548 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [636/782] Loss: 0.3381 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [637/782] Loss: 0.4418 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [638/782] Loss: 0.3877 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [639/782] Loss: 0.2063 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [640/782] Loss: 0.3659 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [641/782] Loss: 0.3464 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [642/782] Loss: 0.3327 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [643/782] Loss: 0.3720 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [644/782] Loss: 0.5990 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [645/782] Loss: 0.4784 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [646/782] Loss: 0.4731 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [647/782] Loss: 0.4589 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [648/782] Loss: 0.3938 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [649/782] Loss: 0.3916 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [650/782] Loss: 0.4064 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [651/782] Loss: 0.4185 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [652/782] Loss: 0.5514 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [653/782] Loss: 0.3940 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [654/782] Loss: 0.7315 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [655/782] Loss: 0.4712 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [656/782] Loss: 0.4469 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [657/782] Loss: 0.6237 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [658/782] Loss: 0.3198 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [659/782] Loss: 0.3076 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [660/782] Loss: 0.5568 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [661/782] Loss: 0.5036 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [662/782] Loss: 0.3639 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [663/782] Loss: 0.4246 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [664/782] Loss: 0.4350 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [665/782] Loss: 0.4743 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [666/782] Loss: 0.5123 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [667/782] Loss: 0.4614 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [668/782] Loss: 0.4033 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [669/782] Loss: 0.4481 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [670/782] Loss: 0.2021 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [671/782] Loss: 0.3266 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [672/782] Loss: 0.4139 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [673/782] Loss: 0.4469 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [674/782] Loss: 0.5169 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [675/782] Loss: 0.4699 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [676/782] Loss: 0.4734 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [677/782] Loss: 0.7205 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [678/782] Loss: 0.5068 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [679/782] Loss: 0.3298 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [680/782] Loss: 0.4268 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [681/782] Loss: 0.4119 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [682/782] Loss: 0.4675 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [683/782] Loss: 0.3722 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [684/782] Loss: 0.6381 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [685/782] Loss: 0.4351 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [686/782] Loss: 0.4548 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [687/782] Loss: 0.4189 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [688/782] Loss: 0.2920 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [689/782] Loss: 0.4410 | Acc: 84.51%\n",
      "Train Epoch [85/100] Batch [690/782] Loss: 0.5216 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [691/782] Loss: 0.4077 | Acc: 84.50%\n",
      "Train Epoch [85/100] Batch [692/782] Loss: 0.4955 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [693/782] Loss: 0.4429 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [694/782] Loss: 0.4179 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [695/782] Loss: 0.4584 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [696/782] Loss: 0.4302 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [697/782] Loss: 0.4605 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [698/782] Loss: 0.5743 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [699/782] Loss: 0.4749 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [700/782] Loss: 0.3764 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [701/782] Loss: 0.4052 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [702/782] Loss: 0.4573 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [703/782] Loss: 0.3212 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [704/782] Loss: 0.3504 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [705/782] Loss: 0.5505 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [706/782] Loss: 0.5006 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [707/782] Loss: 0.3047 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [708/782] Loss: 0.3872 | Acc: 84.49%\n",
      "Train Epoch [85/100] Batch [709/782] Loss: 0.4154 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [710/782] Loss: 0.5415 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [711/782] Loss: 0.4967 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [712/782] Loss: 0.3906 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [713/782] Loss: 0.5966 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [714/782] Loss: 0.4424 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [715/782] Loss: 0.4503 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [716/782] Loss: 0.3394 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [717/782] Loss: 0.5517 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [718/782] Loss: 0.4066 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [719/782] Loss: 0.4114 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [720/782] Loss: 0.5197 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [721/782] Loss: 0.3738 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [722/782] Loss: 0.5019 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [723/782] Loss: 0.3678 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [724/782] Loss: 0.4145 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [725/782] Loss: 0.3586 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [726/782] Loss: 0.3337 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [727/782] Loss: 0.3562 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [728/782] Loss: 0.3424 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [729/782] Loss: 0.4036 | Acc: 84.48%\n",
      "Train Epoch [85/100] Batch [730/782] Loss: 0.6666 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [731/782] Loss: 0.3915 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [732/782] Loss: 0.4179 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [733/782] Loss: 0.4238 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [734/782] Loss: 0.2893 | Acc: 84.47%\n",
      "Train Epoch [85/100] Batch [735/782] Loss: 0.6106 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [736/782] Loss: 0.5073 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [737/782] Loss: 0.5503 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [738/782] Loss: 0.6173 | Acc: 84.46%\n",
      "Train Epoch [85/100] Batch [739/782] Loss: 0.4957 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [740/782] Loss: 0.4923 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [741/782] Loss: 0.4048 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [742/782] Loss: 0.5490 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [743/782] Loss: 0.2972 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [744/782] Loss: 0.3831 | Acc: 84.45%\n",
      "Train Epoch [85/100] Batch [745/782] Loss: 0.6552 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [746/782] Loss: 0.3298 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [747/782] Loss: 0.6504 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [748/782] Loss: 0.4902 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [749/782] Loss: 0.5032 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [750/782] Loss: 0.3945 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [751/782] Loss: 0.2759 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [752/782] Loss: 0.4530 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [753/782] Loss: 0.4384 | Acc: 84.44%\n",
      "Train Epoch [85/100] Batch [754/782] Loss: 0.5072 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [755/782] Loss: 0.5004 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [756/782] Loss: 0.3830 | Acc: 84.43%\n",
      "Train Epoch [85/100] Batch [757/782] Loss: 0.5674 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [758/782] Loss: 0.3337 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [759/782] Loss: 0.3977 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [760/782] Loss: 0.3381 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [761/782] Loss: 0.3876 | Acc: 84.42%\n",
      "Train Epoch [85/100] Batch [762/782] Loss: 0.4827 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [763/782] Loss: 0.5510 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [764/782] Loss: 0.3211 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [765/782] Loss: 0.4659 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [766/782] Loss: 0.5214 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [767/782] Loss: 0.3601 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [768/782] Loss: 0.3876 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [769/782] Loss: 0.5831 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [770/782] Loss: 0.3428 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [771/782] Loss: 0.2619 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [772/782] Loss: 0.4379 | Acc: 84.41%\n",
      "Train Epoch [85/100] Batch [773/782] Loss: 0.5963 | Acc: 84.40%\n",
      "Train Epoch [85/100] Batch [774/782] Loss: 0.6410 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [775/782] Loss: 0.4990 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [776/782] Loss: 0.3232 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [777/782] Loss: 0.4453 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [778/782] Loss: 0.5751 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [779/782] Loss: 0.5923 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [780/782] Loss: 0.3570 | Acc: 84.39%\n",
      "Train Epoch [85/100] Batch [781/782] Loss: 0.6524 | Acc: 84.38%\n",
      "Train Epoch [85/100] Batch [782/782] Loss: 0.3784 | Acc: 84.38%\n",
      "Epoch 85 completed in 30.26s.\n",
      "Test Epoch [85/100] Loss: 0.9896 | Acc: 72.57% | Inference Time: 8.46s\n",
      "Epoch 85 results saved to CSV.\n",
      "Epoch 86/100\n",
      "Train Epoch [86/100] Batch [1/782] Loss: 0.3516 | Acc: 87.50%\n",
      "Train Epoch [86/100] Batch [2/782] Loss: 0.2940 | Acc: 89.84%\n",
      "Train Epoch [86/100] Batch [3/782] Loss: 0.4170 | Acc: 87.50%\n",
      "Train Epoch [86/100] Batch [4/782] Loss: 0.4421 | Acc: 86.33%\n",
      "Train Epoch [86/100] Batch [5/782] Loss: 0.4474 | Acc: 85.62%\n",
      "Train Epoch [86/100] Batch [6/782] Loss: 0.4038 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [7/782] Loss: 0.4089 | Acc: 86.38%\n",
      "Train Epoch [86/100] Batch [8/782] Loss: 0.3787 | Acc: 86.52%\n",
      "Train Epoch [86/100] Batch [9/782] Loss: 0.2766 | Acc: 87.33%\n",
      "Train Epoch [86/100] Batch [10/782] Loss: 0.3917 | Acc: 87.03%\n",
      "Train Epoch [86/100] Batch [11/782] Loss: 0.4985 | Acc: 86.65%\n",
      "Train Epoch [86/100] Batch [12/782] Loss: 0.4758 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [13/782] Loss: 0.4120 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [14/782] Loss: 0.4115 | Acc: 85.83%\n",
      "Train Epoch [86/100] Batch [15/782] Loss: 0.3725 | Acc: 85.73%\n",
      "Train Epoch [86/100] Batch [16/782] Loss: 0.3763 | Acc: 85.74%\n",
      "Train Epoch [86/100] Batch [17/782] Loss: 0.3579 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [18/782] Loss: 0.4170 | Acc: 86.20%\n",
      "Train Epoch [86/100] Batch [19/782] Loss: 0.3251 | Acc: 86.51%\n",
      "Train Epoch [86/100] Batch [20/782] Loss: 0.7280 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [21/782] Loss: 0.3655 | Acc: 86.01%\n",
      "Train Epoch [86/100] Batch [22/782] Loss: 0.5362 | Acc: 86.01%\n",
      "Train Epoch [86/100] Batch [23/782] Loss: 0.5102 | Acc: 85.94%\n",
      "Train Epoch [86/100] Batch [24/782] Loss: 0.4700 | Acc: 85.87%\n",
      "Train Epoch [86/100] Batch [25/782] Loss: 0.4032 | Acc: 85.88%\n",
      "Train Epoch [86/100] Batch [26/782] Loss: 0.6034 | Acc: 85.58%\n",
      "Train Epoch [86/100] Batch [27/782] Loss: 0.3272 | Acc: 85.59%\n",
      "Train Epoch [86/100] Batch [28/782] Loss: 0.4834 | Acc: 85.44%\n",
      "Train Epoch [86/100] Batch [29/782] Loss: 0.5182 | Acc: 85.24%\n",
      "Train Epoch [86/100] Batch [30/782] Loss: 0.2979 | Acc: 85.47%\n",
      "Train Epoch [86/100] Batch [31/782] Loss: 0.4097 | Acc: 85.38%\n",
      "Train Epoch [86/100] Batch [32/782] Loss: 0.4360 | Acc: 85.30%\n",
      "Train Epoch [86/100] Batch [33/782] Loss: 0.3330 | Acc: 85.37%\n",
      "Train Epoch [86/100] Batch [34/782] Loss: 0.2833 | Acc: 85.57%\n",
      "Train Epoch [86/100] Batch [35/782] Loss: 0.5226 | Acc: 85.36%\n",
      "Train Epoch [86/100] Batch [36/782] Loss: 0.2428 | Acc: 85.42%\n",
      "Train Epoch [86/100] Batch [37/782] Loss: 0.4900 | Acc: 85.30%\n",
      "Train Epoch [86/100] Batch [38/782] Loss: 0.3822 | Acc: 85.40%\n",
      "Train Epoch [86/100] Batch [39/782] Loss: 0.4029 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [40/782] Loss: 0.3434 | Acc: 85.35%\n",
      "Train Epoch [86/100] Batch [41/782] Loss: 0.5728 | Acc: 85.21%\n",
      "Train Epoch [86/100] Batch [42/782] Loss: 0.3808 | Acc: 85.23%\n",
      "Train Epoch [86/100] Batch [43/782] Loss: 0.3855 | Acc: 85.21%\n",
      "Train Epoch [86/100] Batch [44/782] Loss: 0.4147 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [45/782] Loss: 0.2399 | Acc: 85.49%\n",
      "Train Epoch [86/100] Batch [46/782] Loss: 0.3592 | Acc: 85.50%\n",
      "Train Epoch [86/100] Batch [47/782] Loss: 0.3982 | Acc: 85.54%\n",
      "Train Epoch [86/100] Batch [48/782] Loss: 0.3315 | Acc: 85.55%\n",
      "Train Epoch [86/100] Batch [49/782] Loss: 0.5005 | Acc: 85.43%\n",
      "Train Epoch [86/100] Batch [50/782] Loss: 0.4416 | Acc: 85.47%\n",
      "Train Epoch [86/100] Batch [51/782] Loss: 0.4404 | Acc: 85.48%\n",
      "Train Epoch [86/100] Batch [52/782] Loss: 0.5571 | Acc: 85.37%\n",
      "Train Epoch [86/100] Batch [53/782] Loss: 0.3603 | Acc: 85.47%\n",
      "Train Epoch [86/100] Batch [54/782] Loss: 0.6036 | Acc: 85.42%\n",
      "Train Epoch [86/100] Batch [55/782] Loss: 0.3036 | Acc: 85.51%\n",
      "Train Epoch [86/100] Batch [56/782] Loss: 0.4158 | Acc: 85.57%\n",
      "Train Epoch [86/100] Batch [57/782] Loss: 0.4604 | Acc: 85.50%\n",
      "Train Epoch [86/100] Batch [58/782] Loss: 0.4434 | Acc: 85.45%\n",
      "Train Epoch [86/100] Batch [59/782] Loss: 0.5171 | Acc: 85.38%\n",
      "Train Epoch [86/100] Batch [60/782] Loss: 0.2759 | Acc: 85.49%\n",
      "Train Epoch [86/100] Batch [61/782] Loss: 0.4043 | Acc: 85.50%\n",
      "Train Epoch [86/100] Batch [62/782] Loss: 0.5379 | Acc: 85.43%\n",
      "Train Epoch [86/100] Batch [63/782] Loss: 0.3988 | Acc: 85.44%\n",
      "Train Epoch [86/100] Batch [64/782] Loss: 0.6630 | Acc: 85.30%\n",
      "Train Epoch [86/100] Batch [65/782] Loss: 0.4166 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [66/782] Loss: 0.5064 | Acc: 85.27%\n",
      "Train Epoch [86/100] Batch [67/782] Loss: 0.3630 | Acc: 85.33%\n",
      "Train Epoch [86/100] Batch [68/782] Loss: 0.5336 | Acc: 85.25%\n",
      "Train Epoch [86/100] Batch [69/782] Loss: 0.5925 | Acc: 85.17%\n",
      "Train Epoch [86/100] Batch [70/782] Loss: 0.4331 | Acc: 85.13%\n",
      "Train Epoch [86/100] Batch [71/782] Loss: 0.2613 | Acc: 85.23%\n",
      "Train Epoch [86/100] Batch [72/782] Loss: 0.4494 | Acc: 85.20%\n",
      "Train Epoch [86/100] Batch [73/782] Loss: 0.5527 | Acc: 85.08%\n",
      "Train Epoch [86/100] Batch [74/782] Loss: 0.5406 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [75/782] Loss: 0.3504 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [76/782] Loss: 0.5829 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [77/782] Loss: 0.4302 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [78/782] Loss: 0.5051 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [79/782] Loss: 0.3715 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [80/782] Loss: 0.3305 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [81/782] Loss: 0.5315 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [82/782] Loss: 0.3347 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [83/782] Loss: 0.4037 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [84/782] Loss: 0.3430 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [85/782] Loss: 0.4486 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [86/782] Loss: 0.3568 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [87/782] Loss: 0.3860 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [88/782] Loss: 0.4109 | Acc: 85.05%\n",
      "Train Epoch [86/100] Batch [89/782] Loss: 0.2314 | Acc: 85.13%\n",
      "Train Epoch [86/100] Batch [90/782] Loss: 0.3488 | Acc: 85.05%\n",
      "Train Epoch [86/100] Batch [91/782] Loss: 0.3192 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [92/782] Loss: 0.5197 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [93/782] Loss: 0.6683 | Acc: 85.06%\n",
      "Train Epoch [86/100] Batch [94/782] Loss: 0.2974 | Acc: 85.14%\n",
      "Train Epoch [86/100] Batch [95/782] Loss: 0.4694 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [96/782] Loss: 0.4592 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [97/782] Loss: 0.3394 | Acc: 85.16%\n",
      "Train Epoch [86/100] Batch [98/782] Loss: 0.5648 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [99/782] Loss: 0.6113 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [100/782] Loss: 0.6707 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [101/782] Loss: 0.5144 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [102/782] Loss: 0.3563 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [103/782] Loss: 0.2869 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [104/782] Loss: 0.4783 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [105/782] Loss: 0.3750 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [106/782] Loss: 0.1472 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [107/782] Loss: 0.4235 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [108/782] Loss: 0.3803 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [109/782] Loss: 0.4370 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [110/782] Loss: 0.3264 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [111/782] Loss: 0.3556 | Acc: 85.06%\n",
      "Train Epoch [86/100] Batch [112/782] Loss: 0.4405 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [113/782] Loss: 0.3429 | Acc: 85.08%\n",
      "Train Epoch [86/100] Batch [114/782] Loss: 0.4190 | Acc: 85.10%\n",
      "Train Epoch [86/100] Batch [115/782] Loss: 0.4396 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [116/782] Loss: 0.4694 | Acc: 85.10%\n",
      "Train Epoch [86/100] Batch [117/782] Loss: 0.2536 | Acc: 85.18%\n",
      "Train Epoch [86/100] Batch [118/782] Loss: 0.2921 | Acc: 85.20%\n",
      "Train Epoch [86/100] Batch [119/782] Loss: 0.3691 | Acc: 85.22%\n",
      "Train Epoch [86/100] Batch [120/782] Loss: 0.3399 | Acc: 85.27%\n",
      "Train Epoch [86/100] Batch [121/782] Loss: 0.3803 | Acc: 85.27%\n",
      "Train Epoch [86/100] Batch [122/782] Loss: 0.5623 | Acc: 85.21%\n",
      "Train Epoch [86/100] Batch [123/782] Loss: 0.3054 | Acc: 85.24%\n",
      "Train Epoch [86/100] Batch [124/782] Loss: 0.6663 | Acc: 85.13%\n",
      "Train Epoch [86/100] Batch [125/782] Loss: 0.2630 | Acc: 85.16%\n",
      "Train Epoch [86/100] Batch [126/782] Loss: 0.5097 | Acc: 85.18%\n",
      "Train Epoch [86/100] Batch [127/782] Loss: 0.5315 | Acc: 85.21%\n",
      "Train Epoch [86/100] Batch [128/782] Loss: 0.3365 | Acc: 85.25%\n",
      "Train Epoch [86/100] Batch [129/782] Loss: 0.4988 | Acc: 85.21%\n",
      "Train Epoch [86/100] Batch [130/782] Loss: 0.3167 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [131/782] Loss: 0.5161 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [132/782] Loss: 0.3846 | Acc: 85.23%\n",
      "Train Epoch [86/100] Batch [133/782] Loss: 0.3086 | Acc: 85.26%\n",
      "Train Epoch [86/100] Batch [134/782] Loss: 0.4076 | Acc: 85.27%\n",
      "Train Epoch [86/100] Batch [135/782] Loss: 0.7162 | Acc: 85.17%\n",
      "Train Epoch [86/100] Batch [136/782] Loss: 0.6668 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [137/782] Loss: 0.5614 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [138/782] Loss: 0.3799 | Acc: 85.05%\n",
      "Train Epoch [86/100] Batch [139/782] Loss: 0.2898 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [140/782] Loss: 0.2936 | Acc: 85.10%\n",
      "Train Epoch [86/100] Batch [141/782] Loss: 0.3631 | Acc: 85.10%\n",
      "Train Epoch [86/100] Batch [142/782] Loss: 0.3946 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [143/782] Loss: 0.3718 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [144/782] Loss: 0.5161 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [145/782] Loss: 0.4231 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [146/782] Loss: 0.3660 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [147/782] Loss: 0.4464 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [148/782] Loss: 0.3966 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [149/782] Loss: 0.3986 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [150/782] Loss: 0.4247 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [151/782] Loss: 0.3920 | Acc: 85.13%\n",
      "Train Epoch [86/100] Batch [152/782] Loss: 0.5398 | Acc: 85.08%\n",
      "Train Epoch [86/100] Batch [153/782] Loss: 0.3134 | Acc: 85.10%\n",
      "Train Epoch [86/100] Batch [154/782] Loss: 0.3928 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [155/782] Loss: 0.3657 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [156/782] Loss: 0.4686 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [157/782] Loss: 0.4232 | Acc: 85.05%\n",
      "Train Epoch [86/100] Batch [158/782] Loss: 0.5194 | Acc: 85.05%\n",
      "Train Epoch [86/100] Batch [159/782] Loss: 0.5077 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [160/782] Loss: 0.3596 | Acc: 85.06%\n",
      "Train Epoch [86/100] Batch [161/782] Loss: 0.5027 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [162/782] Loss: 0.3963 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [163/782] Loss: 0.2857 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [164/782] Loss: 0.4117 | Acc: 85.08%\n",
      "Train Epoch [86/100] Batch [165/782] Loss: 0.4880 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [166/782] Loss: 0.3212 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [167/782] Loss: 0.3607 | Acc: 85.12%\n",
      "Train Epoch [86/100] Batch [168/782] Loss: 0.3866 | Acc: 85.13%\n",
      "Train Epoch [86/100] Batch [169/782] Loss: 0.4974 | Acc: 85.11%\n",
      "Train Epoch [86/100] Batch [170/782] Loss: 0.5156 | Acc: 85.06%\n",
      "Train Epoch [86/100] Batch [171/782] Loss: 0.5781 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [172/782] Loss: 0.3449 | Acc: 85.07%\n",
      "Train Epoch [86/100] Batch [173/782] Loss: 0.3647 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [174/782] Loss: 0.5437 | Acc: 85.08%\n",
      "Train Epoch [86/100] Batch [175/782] Loss: 0.4616 | Acc: 85.09%\n",
      "Train Epoch [86/100] Batch [176/782] Loss: 0.7242 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [177/782] Loss: 0.4732 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [178/782] Loss: 0.4321 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [179/782] Loss: 0.3125 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [180/782] Loss: 0.4089 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [181/782] Loss: 0.3393 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [182/782] Loss: 0.5057 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [183/782] Loss: 0.4591 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [184/782] Loss: 0.4135 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [185/782] Loss: 0.3996 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [186/782] Loss: 0.5440 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [187/782] Loss: 0.5231 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [188/782] Loss: 0.3783 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [189/782] Loss: 0.4749 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [190/782] Loss: 0.3508 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [191/782] Loss: 0.5595 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [192/782] Loss: 0.4469 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [193/782] Loss: 0.4233 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [194/782] Loss: 0.4155 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [195/782] Loss: 0.5614 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [196/782] Loss: 0.3439 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [197/782] Loss: 0.3259 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [198/782] Loss: 0.5004 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [199/782] Loss: 0.3192 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [200/782] Loss: 0.5488 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [201/782] Loss: 0.4383 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [202/782] Loss: 0.4044 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [203/782] Loss: 0.3378 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [204/782] Loss: 0.3126 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [205/782] Loss: 0.3631 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [206/782] Loss: 0.3683 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [207/782] Loss: 0.3940 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [208/782] Loss: 0.4541 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [209/782] Loss: 0.3579 | Acc: 85.04%\n",
      "Train Epoch [86/100] Batch [210/782] Loss: 0.4211 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [211/782] Loss: 0.6389 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [212/782] Loss: 0.4495 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [213/782] Loss: 0.5132 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [214/782] Loss: 0.2807 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [215/782] Loss: 0.4075 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [216/782] Loss: 0.3746 | Acc: 85.03%\n",
      "Train Epoch [86/100] Batch [217/782] Loss: 0.4944 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [218/782] Loss: 0.5165 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [219/782] Loss: 0.4019 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [220/782] Loss: 0.5399 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [221/782] Loss: 0.5498 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [222/782] Loss: 0.5214 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [223/782] Loss: 0.3892 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [224/782] Loss: 0.3690 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [225/782] Loss: 0.6027 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [226/782] Loss: 0.4292 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [227/782] Loss: 0.4766 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [228/782] Loss: 0.4380 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [229/782] Loss: 0.5040 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [230/782] Loss: 0.5482 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [231/782] Loss: 0.2921 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [232/782] Loss: 0.4215 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [233/782] Loss: 0.2881 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [234/782] Loss: 0.5234 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [235/782] Loss: 0.2020 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [236/782] Loss: 0.2978 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [237/782] Loss: 0.3355 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [238/782] Loss: 0.2943 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [239/782] Loss: 0.5034 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [240/782] Loss: 0.5135 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [241/782] Loss: 0.4187 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [242/782] Loss: 0.5040 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [243/782] Loss: 0.2523 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [244/782] Loss: 0.3199 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [245/782] Loss: 0.3902 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [246/782] Loss: 0.3066 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [247/782] Loss: 0.4603 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [248/782] Loss: 0.3690 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [249/782] Loss: 0.3852 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [250/782] Loss: 0.4472 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [251/782] Loss: 0.3116 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [252/782] Loss: 0.3053 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [253/782] Loss: 0.3291 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [254/782] Loss: 0.5822 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [255/782] Loss: 0.4225 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [256/782] Loss: 0.4096 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [257/782] Loss: 0.3030 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [258/782] Loss: 0.3569 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [259/782] Loss: 0.3928 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [260/782] Loss: 0.3790 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [261/782] Loss: 0.3570 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [262/782] Loss: 0.3501 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [263/782] Loss: 0.4169 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [264/782] Loss: 0.5173 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [265/782] Loss: 0.3207 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [266/782] Loss: 0.4806 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [267/782] Loss: 0.3173 | Acc: 85.02%\n",
      "Train Epoch [86/100] Batch [268/782] Loss: 0.3874 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [269/782] Loss: 0.4197 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [270/782] Loss: 0.4233 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [271/782] Loss: 0.5038 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [272/782] Loss: 0.5282 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [273/782] Loss: 0.3713 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [274/782] Loss: 0.3556 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [275/782] Loss: 0.3602 | Acc: 85.01%\n",
      "Train Epoch [86/100] Batch [276/782] Loss: 0.4869 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [277/782] Loss: 0.3827 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [278/782] Loss: 0.4112 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [279/782] Loss: 0.4573 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [280/782] Loss: 0.3269 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [281/782] Loss: 0.4532 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [282/782] Loss: 0.5760 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [283/782] Loss: 0.5311 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [284/782] Loss: 0.3258 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [285/782] Loss: 0.3776 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [286/782] Loss: 0.2955 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [287/782] Loss: 0.5608 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [288/782] Loss: 0.3611 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [289/782] Loss: 0.3457 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [290/782] Loss: 0.3094 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [291/782] Loss: 0.1835 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [292/782] Loss: 0.3228 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [293/782] Loss: 0.5287 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [294/782] Loss: 0.3434 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [295/782] Loss: 0.3658 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [296/782] Loss: 0.3922 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [297/782] Loss: 0.2128 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [298/782] Loss: 0.3723 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [299/782] Loss: 0.5070 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [300/782] Loss: 0.4457 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [301/782] Loss: 0.4127 | Acc: 84.97%\n",
      "Train Epoch [86/100] Batch [302/782] Loss: 0.3637 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [303/782] Loss: 0.3677 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [304/782] Loss: 0.4132 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [305/782] Loss: 0.5723 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [306/782] Loss: 0.5909 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [307/782] Loss: 0.4047 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [308/782] Loss: 0.3294 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [309/782] Loss: 0.5244 | Acc: 84.98%\n",
      "Train Epoch [86/100] Batch [310/782] Loss: 0.5140 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [311/782] Loss: 0.5586 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [312/782] Loss: 0.4828 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [313/782] Loss: 0.3548 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [314/782] Loss: 0.2570 | Acc: 84.99%\n",
      "Train Epoch [86/100] Batch [315/782] Loss: 0.3701 | Acc: 85.00%\n",
      "Train Epoch [86/100] Batch [316/782] Loss: 0.6221 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [317/782] Loss: 0.6367 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [318/782] Loss: 0.4941 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [319/782] Loss: 0.4443 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [320/782] Loss: 0.5740 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [321/782] Loss: 0.4859 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [322/782] Loss: 0.2954 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [323/782] Loss: 0.3633 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [324/782] Loss: 0.4822 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [325/782] Loss: 0.3721 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [326/782] Loss: 0.4279 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [327/782] Loss: 0.3659 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [328/782] Loss: 0.5954 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [329/782] Loss: 0.5354 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [330/782] Loss: 0.4262 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [331/782] Loss: 0.4095 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [332/782] Loss: 0.4420 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [333/782] Loss: 0.3839 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [334/782] Loss: 0.4832 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [335/782] Loss: 0.2830 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [336/782] Loss: 0.4720 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [337/782] Loss: 0.3827 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [338/782] Loss: 0.5480 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [339/782] Loss: 0.4300 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [340/782] Loss: 0.2596 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [341/782] Loss: 0.4137 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [342/782] Loss: 0.5610 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [343/782] Loss: 0.3616 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [344/782] Loss: 0.3009 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [345/782] Loss: 0.4276 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [346/782] Loss: 0.6874 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [347/782] Loss: 0.6567 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [348/782] Loss: 0.4599 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [349/782] Loss: 0.5608 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [350/782] Loss: 0.5610 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [351/782] Loss: 0.5580 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [352/782] Loss: 0.3381 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [353/782] Loss: 0.6001 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [354/782] Loss: 0.4773 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [355/782] Loss: 0.4176 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [356/782] Loss: 0.4249 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [357/782] Loss: 0.5113 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [358/782] Loss: 0.3413 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [359/782] Loss: 0.3980 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [360/782] Loss: 0.3885 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [361/782] Loss: 0.4384 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [362/782] Loss: 0.4875 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [363/782] Loss: 0.4205 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [364/782] Loss: 0.3912 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [365/782] Loss: 0.3214 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [366/782] Loss: 0.5734 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [367/782] Loss: 0.6342 | Acc: 84.75%\n",
      "Train Epoch [86/100] Batch [368/782] Loss: 0.4187 | Acc: 84.74%\n",
      "Train Epoch [86/100] Batch [369/782] Loss: 0.4756 | Acc: 84.73%\n",
      "Train Epoch [86/100] Batch [370/782] Loss: 0.3917 | Acc: 84.74%\n",
      "Train Epoch [86/100] Batch [371/782] Loss: 0.3721 | Acc: 84.75%\n",
      "Train Epoch [86/100] Batch [372/782] Loss: 0.3442 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [373/782] Loss: 0.4651 | Acc: 84.75%\n",
      "Train Epoch [86/100] Batch [374/782] Loss: 0.3585 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [375/782] Loss: 0.3113 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [376/782] Loss: 0.3863 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [377/782] Loss: 0.5345 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [378/782] Loss: 0.2722 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [379/782] Loss: 0.4114 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [380/782] Loss: 0.3855 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [381/782] Loss: 0.4250 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [382/782] Loss: 0.3093 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [383/782] Loss: 0.5648 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [384/782] Loss: 0.4336 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [385/782] Loss: 0.5098 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [386/782] Loss: 0.4401 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [387/782] Loss: 0.5503 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [388/782] Loss: 0.4376 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [389/782] Loss: 0.4549 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [390/782] Loss: 0.3310 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [391/782] Loss: 0.4073 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [392/782] Loss: 0.6848 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [393/782] Loss: 0.2423 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [394/782] Loss: 0.5353 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [395/782] Loss: 0.3398 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [396/782] Loss: 0.4944 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [397/782] Loss: 0.4611 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [398/782] Loss: 0.3588 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [399/782] Loss: 0.4371 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [400/782] Loss: 0.3660 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [401/782] Loss: 0.4855 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [402/782] Loss: 0.4545 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [403/782] Loss: 0.2660 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [404/782] Loss: 0.3760 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [405/782] Loss: 0.3919 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [406/782] Loss: 0.3906 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [407/782] Loss: 0.3940 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [408/782] Loss: 0.4393 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [409/782] Loss: 0.4787 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [410/782] Loss: 0.4228 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [411/782] Loss: 0.3785 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [412/782] Loss: 0.3940 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [413/782] Loss: 0.4182 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [414/782] Loss: 0.3998 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [415/782] Loss: 0.4371 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [416/782] Loss: 0.4738 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [417/782] Loss: 0.5493 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [418/782] Loss: 0.4470 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [419/782] Loss: 0.4995 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [420/782] Loss: 0.4989 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [421/782] Loss: 0.6847 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [422/782] Loss: 0.5908 | Acc: 84.75%\n",
      "Train Epoch [86/100] Batch [423/782] Loss: 0.5061 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [424/782] Loss: 0.3624 | Acc: 84.76%\n",
      "Train Epoch [86/100] Batch [425/782] Loss: 0.3110 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [426/782] Loss: 0.4708 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [427/782] Loss: 0.4998 | Acc: 84.77%\n",
      "Train Epoch [86/100] Batch [428/782] Loss: 0.2482 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [429/782] Loss: 0.4478 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [430/782] Loss: 0.4381 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [431/782] Loss: 0.3427 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [432/782] Loss: 0.3791 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [433/782] Loss: 0.5045 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [434/782] Loss: 0.3582 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [435/782] Loss: 0.4418 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [436/782] Loss: 0.3192 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [437/782] Loss: 0.4131 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [438/782] Loss: 0.5692 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [439/782] Loss: 0.4170 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [440/782] Loss: 0.3736 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [441/782] Loss: 0.4172 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [442/782] Loss: 0.4525 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [443/782] Loss: 0.4589 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [444/782] Loss: 0.3607 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [445/782] Loss: 0.4157 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [446/782] Loss: 0.3130 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [447/782] Loss: 0.4490 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [448/782] Loss: 0.2898 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [449/782] Loss: 0.2311 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [450/782] Loss: 0.2706 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [451/782] Loss: 0.4652 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [452/782] Loss: 0.2190 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [453/782] Loss: 0.3981 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [454/782] Loss: 0.3218 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [455/782] Loss: 0.3438 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [456/782] Loss: 0.2930 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [457/782] Loss: 0.2954 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [458/782] Loss: 0.5611 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [459/782] Loss: 0.2829 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [460/782] Loss: 0.3613 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [461/782] Loss: 0.3046 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [462/782] Loss: 0.5823 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [463/782] Loss: 0.6225 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [464/782] Loss: 0.5269 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [465/782] Loss: 0.4376 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [466/782] Loss: 0.4403 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [467/782] Loss: 0.2377 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [468/782] Loss: 0.4146 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [469/782] Loss: 0.6375 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [470/782] Loss: 0.2759 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [471/782] Loss: 0.2824 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [472/782] Loss: 0.4419 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [473/782] Loss: 0.3978 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [474/782] Loss: 0.4003 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [475/782] Loss: 0.2768 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [476/782] Loss: 0.4110 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [477/782] Loss: 0.3036 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [478/782] Loss: 0.3938 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [479/782] Loss: 0.3145 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [480/782] Loss: 0.6298 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [481/782] Loss: 0.4462 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [482/782] Loss: 0.3941 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [483/782] Loss: 0.5140 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [484/782] Loss: 0.5688 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [485/782] Loss: 0.3774 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [486/782] Loss: 0.1961 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [487/782] Loss: 0.4316 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [488/782] Loss: 0.4258 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [489/782] Loss: 0.6212 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [490/782] Loss: 0.3957 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [491/782] Loss: 0.3307 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [492/782] Loss: 0.4906 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [493/782] Loss: 0.3524 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [494/782] Loss: 0.2897 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [495/782] Loss: 0.4164 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [496/782] Loss: 0.4392 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [497/782] Loss: 0.3784 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [498/782] Loss: 0.4703 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [499/782] Loss: 0.5128 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [500/782] Loss: 0.4917 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [501/782] Loss: 0.4590 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [502/782] Loss: 0.3945 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [503/782] Loss: 0.6370 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [504/782] Loss: 0.3662 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [505/782] Loss: 0.5232 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [506/782] Loss: 0.4562 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [507/782] Loss: 0.4397 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [508/782] Loss: 0.3080 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [509/782] Loss: 0.3539 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [510/782] Loss: 0.3417 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [511/782] Loss: 0.4189 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [512/782] Loss: 0.4000 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [513/782] Loss: 0.5890 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [514/782] Loss: 0.4441 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [515/782] Loss: 0.5398 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [516/782] Loss: 0.3716 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [517/782] Loss: 0.3293 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [518/782] Loss: 0.3696 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [519/782] Loss: 0.5258 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [520/782] Loss: 0.3598 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [521/782] Loss: 0.3496 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [522/782] Loss: 0.4402 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [523/782] Loss: 0.4666 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [524/782] Loss: 0.4028 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [525/782] Loss: 0.4257 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [526/782] Loss: 0.4057 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [527/782] Loss: 0.4037 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [528/782] Loss: 0.4633 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [529/782] Loss: 0.3159 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [530/782] Loss: 0.4053 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [531/782] Loss: 0.3759 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [532/782] Loss: 0.3414 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [533/782] Loss: 0.3278 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [534/782] Loss: 0.4105 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [535/782] Loss: 0.3487 | Acc: 84.96%\n",
      "Train Epoch [86/100] Batch [536/782] Loss: 0.6838 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [537/782] Loss: 0.2698 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [538/782] Loss: 0.4609 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [539/782] Loss: 0.6974 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [540/782] Loss: 0.4567 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [541/782] Loss: 0.5629 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [542/782] Loss: 0.5329 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [543/782] Loss: 0.4712 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [544/782] Loss: 0.3706 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [545/782] Loss: 0.5275 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [546/782] Loss: 0.4051 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [547/782] Loss: 0.3273 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [548/782] Loss: 0.3031 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [549/782] Loss: 0.3927 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [550/782] Loss: 0.3399 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [551/782] Loss: 0.4312 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [552/782] Loss: 0.4368 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [553/782] Loss: 0.4221 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [554/782] Loss: 0.3693 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [555/782] Loss: 0.3700 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [556/782] Loss: 0.2067 | Acc: 84.95%\n",
      "Train Epoch [86/100] Batch [557/782] Loss: 0.4204 | Acc: 84.94%\n",
      "Train Epoch [86/100] Batch [558/782] Loss: 0.4446 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [559/782] Loss: 0.4190 | Acc: 84.93%\n",
      "Train Epoch [86/100] Batch [560/782] Loss: 0.4793 | Acc: 84.92%\n",
      "Train Epoch [86/100] Batch [561/782] Loss: 0.4765 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [562/782] Loss: 0.5583 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [563/782] Loss: 0.3820 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [564/782] Loss: 0.5857 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [565/782] Loss: 0.4904 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [566/782] Loss: 0.4806 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [567/782] Loss: 0.4203 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [568/782] Loss: 0.5436 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [569/782] Loss: 0.4067 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [570/782] Loss: 0.3544 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [571/782] Loss: 0.3851 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [572/782] Loss: 0.2201 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [573/782] Loss: 0.4635 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [574/782] Loss: 0.4302 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [575/782] Loss: 0.4036 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [576/782] Loss: 0.5948 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [577/782] Loss: 0.4794 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [578/782] Loss: 0.3148 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [579/782] Loss: 0.3425 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [580/782] Loss: 0.6014 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [581/782] Loss: 0.3515 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [582/782] Loss: 0.4248 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [583/782] Loss: 0.6545 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [584/782] Loss: 0.3470 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [585/782] Loss: 0.4385 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [586/782] Loss: 0.4030 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [587/782] Loss: 0.5337 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [588/782] Loss: 0.5475 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [589/782] Loss: 0.4350 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [590/782] Loss: 0.5179 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [591/782] Loss: 0.4379 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [592/782] Loss: 0.4044 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [593/782] Loss: 0.4184 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [594/782] Loss: 0.4191 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [595/782] Loss: 0.5708 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [596/782] Loss: 0.5526 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [597/782] Loss: 0.5976 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [598/782] Loss: 0.7156 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [599/782] Loss: 0.3556 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [600/782] Loss: 0.5278 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [601/782] Loss: 0.4569 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [602/782] Loss: 0.4497 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [603/782] Loss: 0.3145 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [604/782] Loss: 0.5152 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [605/782] Loss: 0.3802 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [606/782] Loss: 0.2426 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [607/782] Loss: 0.4698 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [608/782] Loss: 0.3953 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [609/782] Loss: 0.4022 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [610/782] Loss: 0.4078 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [611/782] Loss: 0.3306 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [612/782] Loss: 0.6529 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [613/782] Loss: 0.6030 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [614/782] Loss: 0.3923 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [615/782] Loss: 0.2694 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [616/782] Loss: 0.3059 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [617/782] Loss: 0.4721 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [618/782] Loss: 0.2908 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [619/782] Loss: 0.3498 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [620/782] Loss: 0.3036 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [621/782] Loss: 0.4892 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [622/782] Loss: 0.3951 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [623/782] Loss: 0.2857 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [624/782] Loss: 0.3671 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [625/782] Loss: 0.5473 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [626/782] Loss: 0.4080 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [627/782] Loss: 0.4218 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [628/782] Loss: 0.4646 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [629/782] Loss: 0.5963 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [630/782] Loss: 0.4084 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [631/782] Loss: 0.5500 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [632/782] Loss: 0.3870 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [633/782] Loss: 0.1971 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [634/782] Loss: 0.5474 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [635/782] Loss: 0.1865 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [636/782] Loss: 0.3783 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [637/782] Loss: 0.4959 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [638/782] Loss: 0.2958 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [639/782] Loss: 0.6390 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [640/782] Loss: 0.3807 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [641/782] Loss: 0.4135 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [642/782] Loss: 0.2465 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [643/782] Loss: 0.3936 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [644/782] Loss: 0.4975 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [645/782] Loss: 0.3688 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [646/782] Loss: 0.3975 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [647/782] Loss: 0.3751 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [648/782] Loss: 0.4752 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [649/782] Loss: 0.4133 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [650/782] Loss: 0.3281 | Acc: 84.91%\n",
      "Train Epoch [86/100] Batch [651/782] Loss: 0.7237 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [652/782] Loss: 0.4532 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [653/782] Loss: 0.4206 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [654/782] Loss: 0.3598 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [655/782] Loss: 0.5723 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [656/782] Loss: 0.3724 | Acc: 84.90%\n",
      "Train Epoch [86/100] Batch [657/782] Loss: 0.4905 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [658/782] Loss: 0.4799 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [659/782] Loss: 0.6058 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [660/782] Loss: 0.6087 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [661/782] Loss: 0.3809 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [662/782] Loss: 0.4787 | Acc: 84.89%\n",
      "Train Epoch [86/100] Batch [663/782] Loss: 0.7180 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [664/782] Loss: 0.3106 | Acc: 84.88%\n",
      "Train Epoch [86/100] Batch [665/782] Loss: 0.4634 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [666/782] Loss: 0.4940 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [667/782] Loss: 0.4062 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [668/782] Loss: 0.6159 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [669/782] Loss: 0.5879 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [670/782] Loss: 0.4158 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [671/782] Loss: 0.3641 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [672/782] Loss: 0.4485 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [673/782] Loss: 0.4113 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [674/782] Loss: 0.3809 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [675/782] Loss: 0.4324 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [676/782] Loss: 0.4039 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [677/782] Loss: 0.4385 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [678/782] Loss: 0.3920 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [679/782] Loss: 0.3170 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [680/782] Loss: 0.4103 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [681/782] Loss: 0.4328 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [682/782] Loss: 0.3747 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [683/782] Loss: 0.7338 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [684/782] Loss: 0.3515 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [685/782] Loss: 0.5168 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [686/782] Loss: 0.3927 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [687/782] Loss: 0.4602 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [688/782] Loss: 0.4218 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [689/782] Loss: 0.6152 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [690/782] Loss: 0.5057 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [691/782] Loss: 0.4750 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [692/782] Loss: 0.3873 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [693/782] Loss: 0.3718 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [694/782] Loss: 0.4252 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [695/782] Loss: 0.4177 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [696/782] Loss: 0.4349 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [697/782] Loss: 0.3424 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [698/782] Loss: 0.4825 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [699/782] Loss: 0.5018 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [700/782] Loss: 0.3771 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [701/782] Loss: 0.5500 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [702/782] Loss: 0.5595 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [703/782] Loss: 0.3502 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [704/782] Loss: 0.6114 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [705/782] Loss: 0.2932 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [706/782] Loss: 0.5333 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [707/782] Loss: 0.3300 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [708/782] Loss: 0.3984 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [709/782] Loss: 0.2865 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [710/782] Loss: 0.3637 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [711/782] Loss: 0.6867 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [712/782] Loss: 0.3664 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [713/782] Loss: 0.4064 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [714/782] Loss: 0.2968 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [715/782] Loss: 0.5198 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [716/782] Loss: 0.4840 | Acc: 84.79%\n",
      "Train Epoch [86/100] Batch [717/782] Loss: 0.5096 | Acc: 84.78%\n",
      "Train Epoch [86/100] Batch [718/782] Loss: 0.1488 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [719/782] Loss: 0.3725 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [720/782] Loss: 0.5432 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [721/782] Loss: 0.3948 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [722/782] Loss: 0.4547 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [723/782] Loss: 0.4491 | Acc: 84.80%\n",
      "Train Epoch [86/100] Batch [724/782] Loss: 0.3397 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [725/782] Loss: 0.3058 | Acc: 84.81%\n",
      "Train Epoch [86/100] Batch [726/782] Loss: 0.3115 | Acc: 84.82%\n",
      "Train Epoch [86/100] Batch [727/782] Loss: 0.2417 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [728/782] Loss: 0.3287 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [729/782] Loss: 0.3471 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [730/782] Loss: 0.3870 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [731/782] Loss: 0.3189 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [732/782] Loss: 0.5133 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [733/782] Loss: 0.1928 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [734/782] Loss: 0.4760 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [735/782] Loss: 0.5178 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [736/782] Loss: 0.6051 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [737/782] Loss: 0.4187 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [738/782] Loss: 0.5169 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [739/782] Loss: 0.5221 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [740/782] Loss: 0.3908 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [741/782] Loss: 0.4800 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [742/782] Loss: 0.5788 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [743/782] Loss: 0.4488 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [744/782] Loss: 0.4796 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [745/782] Loss: 0.3375 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [746/782] Loss: 0.5730 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [747/782] Loss: 0.2901 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [748/782] Loss: 0.2850 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [749/782] Loss: 0.2446 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [750/782] Loss: 0.5441 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [751/782] Loss: 0.4254 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [752/782] Loss: 0.4489 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [753/782] Loss: 0.4936 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [754/782] Loss: 0.4635 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [755/782] Loss: 0.3609 | Acc: 84.86%\n",
      "Train Epoch [86/100] Batch [756/782] Loss: 0.6939 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [757/782] Loss: 0.3850 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [758/782] Loss: 0.4837 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [759/782] Loss: 0.3203 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [760/782] Loss: 0.3807 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [761/782] Loss: 0.6130 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [762/782] Loss: 0.2476 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [763/782] Loss: 0.4773 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [764/782] Loss: 0.5342 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [765/782] Loss: 0.4956 | Acc: 84.83%\n",
      "Train Epoch [86/100] Batch [766/782] Loss: 0.4134 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [767/782] Loss: 0.3952 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [768/782] Loss: 0.2862 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [769/782] Loss: 0.2896 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [770/782] Loss: 0.2481 | Acc: 84.87%\n",
      "Train Epoch [86/100] Batch [771/782] Loss: 0.6291 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [772/782] Loss: 0.5069 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [773/782] Loss: 0.3907 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [774/782] Loss: 0.4833 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [775/782] Loss: 0.5928 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [776/782] Loss: 0.2606 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [777/782] Loss: 0.4096 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [778/782] Loss: 0.4916 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [779/782] Loss: 0.2679 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [780/782] Loss: 0.3700 | Acc: 84.85%\n",
      "Train Epoch [86/100] Batch [781/782] Loss: 0.4304 | Acc: 84.84%\n",
      "Train Epoch [86/100] Batch [782/782] Loss: 0.8691 | Acc: 84.84%\n",
      "Epoch 86 completed in 30.38s.\n",
      "Test Epoch [86/100] Loss: 1.0056 | Acc: 72.16% | Inference Time: 8.38s\n",
      "Epoch 86 results saved to CSV.\n",
      "Epoch 87/100\n",
      "Train Epoch [87/100] Batch [1/782] Loss: 0.4163 | Acc: 85.94%\n",
      "Train Epoch [87/100] Batch [2/782] Loss: 0.5076 | Acc: 83.59%\n",
      "Train Epoch [87/100] Batch [3/782] Loss: 0.6441 | Acc: 80.21%\n",
      "Train Epoch [87/100] Batch [4/782] Loss: 0.4798 | Acc: 81.25%\n",
      "Train Epoch [87/100] Batch [5/782] Loss: 0.2709 | Acc: 83.44%\n",
      "Train Epoch [87/100] Batch [6/782] Loss: 0.3025 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [7/782] Loss: 0.4416 | Acc: 83.26%\n",
      "Train Epoch [87/100] Batch [8/782] Loss: 0.4424 | Acc: 83.59%\n",
      "Train Epoch [87/100] Batch [9/782] Loss: 0.4108 | Acc: 83.16%\n",
      "Train Epoch [87/100] Batch [10/782] Loss: 0.3325 | Acc: 83.75%\n",
      "Train Epoch [87/100] Batch [11/782] Loss: 0.4426 | Acc: 83.81%\n",
      "Train Epoch [87/100] Batch [12/782] Loss: 0.4490 | Acc: 84.11%\n",
      "Train Epoch [87/100] Batch [13/782] Loss: 0.3333 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [14/782] Loss: 0.4579 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [15/782] Loss: 0.6063 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [16/782] Loss: 0.4297 | Acc: 84.28%\n",
      "Train Epoch [87/100] Batch [17/782] Loss: 0.3231 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [18/782] Loss: 0.4295 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [19/782] Loss: 0.3593 | Acc: 84.70%\n",
      "Train Epoch [87/100] Batch [20/782] Loss: 0.5226 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [21/782] Loss: 0.2321 | Acc: 84.75%\n",
      "Train Epoch [87/100] Batch [22/782] Loss: 0.3748 | Acc: 84.80%\n",
      "Train Epoch [87/100] Batch [23/782] Loss: 0.4473 | Acc: 84.85%\n",
      "Train Epoch [87/100] Batch [24/782] Loss: 0.4892 | Acc: 84.70%\n",
      "Train Epoch [87/100] Batch [25/782] Loss: 0.3588 | Acc: 85.00%\n",
      "Train Epoch [87/100] Batch [26/782] Loss: 0.2989 | Acc: 84.98%\n",
      "Train Epoch [87/100] Batch [27/782] Loss: 0.2846 | Acc: 85.13%\n",
      "Train Epoch [87/100] Batch [28/782] Loss: 0.2933 | Acc: 85.38%\n",
      "Train Epoch [87/100] Batch [29/782] Loss: 0.5002 | Acc: 85.13%\n",
      "Train Epoch [87/100] Batch [30/782] Loss: 0.5263 | Acc: 84.90%\n",
      "Train Epoch [87/100] Batch [31/782] Loss: 0.5600 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [32/782] Loss: 0.4947 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [33/782] Loss: 0.2741 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [34/782] Loss: 0.4712 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [35/782] Loss: 0.3084 | Acc: 84.78%\n",
      "Train Epoch [87/100] Batch [36/782] Loss: 0.2705 | Acc: 84.94%\n",
      "Train Epoch [87/100] Batch [37/782] Loss: 0.4592 | Acc: 84.84%\n",
      "Train Epoch [87/100] Batch [38/782] Loss: 0.4726 | Acc: 84.75%\n",
      "Train Epoch [87/100] Batch [39/782] Loss: 0.5124 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [40/782] Loss: 0.4168 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [41/782] Loss: 0.5926 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [42/782] Loss: 0.3902 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [43/782] Loss: 0.2502 | Acc: 84.81%\n",
      "Train Epoch [87/100] Batch [44/782] Loss: 0.3332 | Acc: 84.80%\n",
      "Train Epoch [87/100] Batch [45/782] Loss: 0.5403 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [46/782] Loss: 0.3841 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [47/782] Loss: 0.3927 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [48/782] Loss: 0.6301 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [49/782] Loss: 0.6004 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [50/782] Loss: 0.5094 | Acc: 84.28%\n",
      "Train Epoch [87/100] Batch [51/782] Loss: 0.4105 | Acc: 84.31%\n",
      "Train Epoch [87/100] Batch [52/782] Loss: 0.3838 | Acc: 84.28%\n",
      "Train Epoch [87/100] Batch [53/782] Loss: 0.6462 | Acc: 84.26%\n",
      "Train Epoch [87/100] Batch [54/782] Loss: 0.2930 | Acc: 84.32%\n",
      "Train Epoch [87/100] Batch [55/782] Loss: 0.4537 | Acc: 84.32%\n",
      "Train Epoch [87/100] Batch [56/782] Loss: 0.7423 | Acc: 84.18%\n",
      "Train Epoch [87/100] Batch [57/782] Loss: 0.3782 | Acc: 84.21%\n",
      "Train Epoch [87/100] Batch [58/782] Loss: 0.3373 | Acc: 84.32%\n",
      "Train Epoch [87/100] Batch [59/782] Loss: 0.2639 | Acc: 84.40%\n",
      "Train Epoch [87/100] Batch [60/782] Loss: 0.4932 | Acc: 84.35%\n",
      "Train Epoch [87/100] Batch [61/782] Loss: 0.5197 | Acc: 84.25%\n",
      "Train Epoch [87/100] Batch [62/782] Loss: 0.5192 | Acc: 84.15%\n",
      "Train Epoch [87/100] Batch [63/782] Loss: 0.5472 | Acc: 84.08%\n",
      "Train Epoch [87/100] Batch [64/782] Loss: 0.6765 | Acc: 83.91%\n",
      "Train Epoch [87/100] Batch [65/782] Loss: 0.3348 | Acc: 83.97%\n",
      "Train Epoch [87/100] Batch [66/782] Loss: 0.2648 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [67/782] Loss: 0.4954 | Acc: 84.03%\n",
      "Train Epoch [87/100] Batch [68/782] Loss: 0.5114 | Acc: 84.03%\n",
      "Train Epoch [87/100] Batch [69/782] Loss: 0.4530 | Acc: 83.97%\n",
      "Train Epoch [87/100] Batch [70/782] Loss: 0.4558 | Acc: 84.00%\n",
      "Train Epoch [87/100] Batch [71/782] Loss: 0.5351 | Acc: 83.87%\n",
      "Train Epoch [87/100] Batch [72/782] Loss: 0.4642 | Acc: 83.83%\n",
      "Train Epoch [87/100] Batch [73/782] Loss: 0.4375 | Acc: 83.90%\n",
      "Train Epoch [87/100] Batch [74/782] Loss: 0.3431 | Acc: 83.93%\n",
      "Train Epoch [87/100] Batch [75/782] Loss: 0.3275 | Acc: 83.98%\n",
      "Train Epoch [87/100] Batch [76/782] Loss: 0.3484 | Acc: 84.00%\n",
      "Train Epoch [87/100] Batch [77/782] Loss: 0.3583 | Acc: 83.99%\n",
      "Train Epoch [87/100] Batch [78/782] Loss: 0.4004 | Acc: 84.01%\n",
      "Train Epoch [87/100] Batch [79/782] Loss: 0.3394 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [80/782] Loss: 0.4456 | Acc: 84.00%\n",
      "Train Epoch [87/100] Batch [81/782] Loss: 0.3625 | Acc: 84.05%\n",
      "Train Epoch [87/100] Batch [82/782] Loss: 0.3679 | Acc: 84.01%\n",
      "Train Epoch [87/100] Batch [83/782] Loss: 0.4342 | Acc: 83.96%\n",
      "Train Epoch [87/100] Batch [84/782] Loss: 0.6368 | Acc: 83.91%\n",
      "Train Epoch [87/100] Batch [85/782] Loss: 0.4809 | Acc: 83.95%\n",
      "Train Epoch [87/100] Batch [86/782] Loss: 0.3609 | Acc: 83.98%\n",
      "Train Epoch [87/100] Batch [87/782] Loss: 0.3678 | Acc: 84.02%\n",
      "Train Epoch [87/100] Batch [88/782] Loss: 0.5555 | Acc: 83.93%\n",
      "Train Epoch [87/100] Batch [89/782] Loss: 0.3355 | Acc: 83.97%\n",
      "Train Epoch [87/100] Batch [90/782] Loss: 0.4002 | Acc: 83.96%\n",
      "Train Epoch [87/100] Batch [91/782] Loss: 0.4324 | Acc: 83.93%\n",
      "Train Epoch [87/100] Batch [92/782] Loss: 0.3795 | Acc: 83.95%\n",
      "Train Epoch [87/100] Batch [93/782] Loss: 0.5857 | Acc: 83.99%\n",
      "Train Epoch [87/100] Batch [94/782] Loss: 0.5028 | Acc: 83.98%\n",
      "Train Epoch [87/100] Batch [95/782] Loss: 0.3795 | Acc: 84.01%\n",
      "Train Epoch [87/100] Batch [96/782] Loss: 0.3236 | Acc: 84.10%\n",
      "Train Epoch [87/100] Batch [97/782] Loss: 0.3431 | Acc: 84.15%\n",
      "Train Epoch [87/100] Batch [98/782] Loss: 0.5347 | Acc: 84.14%\n",
      "Train Epoch [87/100] Batch [99/782] Loss: 0.5334 | Acc: 84.08%\n",
      "Train Epoch [87/100] Batch [100/782] Loss: 0.5642 | Acc: 84.00%\n",
      "Train Epoch [87/100] Batch [101/782] Loss: 0.5948 | Acc: 83.96%\n",
      "Train Epoch [87/100] Batch [102/782] Loss: 0.5523 | Acc: 83.92%\n",
      "Train Epoch [87/100] Batch [103/782] Loss: 0.5537 | Acc: 83.87%\n",
      "Train Epoch [87/100] Batch [104/782] Loss: 0.2749 | Acc: 83.97%\n",
      "Train Epoch [87/100] Batch [105/782] Loss: 0.3962 | Acc: 84.03%\n",
      "Train Epoch [87/100] Batch [106/782] Loss: 0.5818 | Acc: 83.99%\n",
      "Train Epoch [87/100] Batch [107/782] Loss: 0.3430 | Acc: 84.05%\n",
      "Train Epoch [87/100] Batch [108/782] Loss: 0.4576 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [109/782] Loss: 0.4485 | Acc: 84.07%\n",
      "Train Epoch [87/100] Batch [110/782] Loss: 0.2860 | Acc: 84.16%\n",
      "Train Epoch [87/100] Batch [111/782] Loss: 0.5215 | Acc: 84.18%\n",
      "Train Epoch [87/100] Batch [112/782] Loss: 0.5842 | Acc: 84.12%\n",
      "Train Epoch [87/100] Batch [113/782] Loss: 0.4564 | Acc: 84.07%\n",
      "Train Epoch [87/100] Batch [114/782] Loss: 0.5061 | Acc: 84.09%\n",
      "Train Epoch [87/100] Batch [115/782] Loss: 0.4325 | Acc: 84.10%\n",
      "Train Epoch [87/100] Batch [116/782] Loss: 0.3219 | Acc: 84.13%\n",
      "Train Epoch [87/100] Batch [117/782] Loss: 0.3088 | Acc: 84.16%\n",
      "Train Epoch [87/100] Batch [118/782] Loss: 0.3793 | Acc: 84.22%\n",
      "Train Epoch [87/100] Batch [119/782] Loss: 0.7916 | Acc: 84.13%\n",
      "Train Epoch [87/100] Batch [120/782] Loss: 0.4243 | Acc: 84.14%\n",
      "Train Epoch [87/100] Batch [121/782] Loss: 0.7369 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [122/782] Loss: 0.5069 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [123/782] Loss: 0.4056 | Acc: 84.02%\n",
      "Train Epoch [87/100] Batch [124/782] Loss: 0.5987 | Acc: 83.96%\n",
      "Train Epoch [87/100] Batch [125/782] Loss: 0.3692 | Acc: 83.96%\n",
      "Train Epoch [87/100] Batch [126/782] Loss: 0.3873 | Acc: 83.98%\n",
      "Train Epoch [87/100] Batch [127/782] Loss: 0.5417 | Acc: 83.94%\n",
      "Train Epoch [87/100] Batch [128/782] Loss: 0.7255 | Acc: 83.90%\n",
      "Train Epoch [87/100] Batch [129/782] Loss: 0.2557 | Acc: 83.95%\n",
      "Train Epoch [87/100] Batch [130/782] Loss: 0.3973 | Acc: 83.98%\n",
      "Train Epoch [87/100] Batch [131/782] Loss: 0.3363 | Acc: 83.99%\n",
      "Train Epoch [87/100] Batch [132/782] Loss: 0.3231 | Acc: 84.02%\n",
      "Train Epoch [87/100] Batch [133/782] Loss: 0.5857 | Acc: 83.95%\n",
      "Train Epoch [87/100] Batch [134/782] Loss: 0.4461 | Acc: 83.94%\n",
      "Train Epoch [87/100] Batch [135/782] Loss: 0.4115 | Acc: 83.92%\n",
      "Train Epoch [87/100] Batch [136/782] Loss: 0.4640 | Acc: 83.93%\n",
      "Train Epoch [87/100] Batch [137/782] Loss: 0.4526 | Acc: 83.92%\n",
      "Train Epoch [87/100] Batch [138/782] Loss: 0.3714 | Acc: 83.97%\n",
      "Train Epoch [87/100] Batch [139/782] Loss: 0.2456 | Acc: 84.03%\n",
      "Train Epoch [87/100] Batch [140/782] Loss: 0.4519 | Acc: 84.04%\n",
      "Train Epoch [87/100] Batch [141/782] Loss: 0.6708 | Acc: 84.02%\n",
      "Train Epoch [87/100] Batch [142/782] Loss: 0.4299 | Acc: 84.02%\n",
      "Train Epoch [87/100] Batch [143/782] Loss: 0.3698 | Acc: 84.01%\n",
      "Train Epoch [87/100] Batch [144/782] Loss: 0.2414 | Acc: 84.05%\n",
      "Train Epoch [87/100] Batch [145/782] Loss: 0.2624 | Acc: 84.09%\n",
      "Train Epoch [87/100] Batch [146/782] Loss: 0.2440 | Acc: 84.14%\n",
      "Train Epoch [87/100] Batch [147/782] Loss: 0.6054 | Acc: 84.10%\n",
      "Train Epoch [87/100] Batch [148/782] Loss: 0.3502 | Acc: 84.13%\n",
      "Train Epoch [87/100] Batch [149/782] Loss: 0.5319 | Acc: 84.10%\n",
      "Train Epoch [87/100] Batch [150/782] Loss: 0.5751 | Acc: 84.05%\n",
      "Train Epoch [87/100] Batch [151/782] Loss: 0.3406 | Acc: 84.09%\n",
      "Train Epoch [87/100] Batch [152/782] Loss: 0.3255 | Acc: 84.12%\n",
      "Train Epoch [87/100] Batch [153/782] Loss: 0.4050 | Acc: 84.09%\n",
      "Train Epoch [87/100] Batch [154/782] Loss: 0.4955 | Acc: 84.08%\n",
      "Train Epoch [87/100] Batch [155/782] Loss: 0.4599 | Acc: 84.05%\n",
      "Train Epoch [87/100] Batch [156/782] Loss: 0.3283 | Acc: 84.07%\n",
      "Train Epoch [87/100] Batch [157/782] Loss: 0.3773 | Acc: 84.09%\n",
      "Train Epoch [87/100] Batch [158/782] Loss: 0.4970 | Acc: 84.10%\n",
      "Train Epoch [87/100] Batch [159/782] Loss: 0.3727 | Acc: 84.13%\n",
      "Train Epoch [87/100] Batch [160/782] Loss: 0.3184 | Acc: 84.16%\n",
      "Train Epoch [87/100] Batch [161/782] Loss: 0.3135 | Acc: 84.18%\n",
      "Train Epoch [87/100] Batch [162/782] Loss: 0.3115 | Acc: 84.21%\n",
      "Train Epoch [87/100] Batch [163/782] Loss: 0.2581 | Acc: 84.26%\n",
      "Train Epoch [87/100] Batch [164/782] Loss: 0.2470 | Acc: 84.31%\n",
      "Train Epoch [87/100] Batch [165/782] Loss: 0.3679 | Acc: 84.34%\n",
      "Train Epoch [87/100] Batch [166/782] Loss: 0.5947 | Acc: 84.32%\n",
      "Train Epoch [87/100] Batch [167/782] Loss: 0.5114 | Acc: 84.31%\n",
      "Train Epoch [87/100] Batch [168/782] Loss: 0.2821 | Acc: 84.34%\n",
      "Train Epoch [87/100] Batch [169/782] Loss: 0.3714 | Acc: 84.35%\n",
      "Train Epoch [87/100] Batch [170/782] Loss: 0.3230 | Acc: 84.37%\n",
      "Train Epoch [87/100] Batch [171/782] Loss: 0.3189 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [172/782] Loss: 0.4747 | Acc: 84.36%\n",
      "Train Epoch [87/100] Batch [173/782] Loss: 0.3844 | Acc: 84.36%\n",
      "Train Epoch [87/100] Batch [174/782] Loss: 0.3971 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [175/782] Loss: 0.5089 | Acc: 84.36%\n",
      "Train Epoch [87/100] Batch [176/782] Loss: 0.4772 | Acc: 84.35%\n",
      "Train Epoch [87/100] Batch [177/782] Loss: 0.4263 | Acc: 84.33%\n",
      "Train Epoch [87/100] Batch [178/782] Loss: 0.4414 | Acc: 84.31%\n",
      "Train Epoch [87/100] Batch [179/782] Loss: 0.2219 | Acc: 84.36%\n",
      "Train Epoch [87/100] Batch [180/782] Loss: 0.4272 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [181/782] Loss: 0.3121 | Acc: 84.41%\n",
      "Train Epoch [87/100] Batch [182/782] Loss: 0.4293 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [183/782] Loss: 0.5387 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [184/782] Loss: 0.4027 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [185/782] Loss: 0.4298 | Acc: 84.40%\n",
      "Train Epoch [87/100] Batch [186/782] Loss: 0.3689 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [187/782] Loss: 0.4707 | Acc: 84.41%\n",
      "Train Epoch [87/100] Batch [188/782] Loss: 0.3224 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [189/782] Loss: 0.5026 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [190/782] Loss: 0.5314 | Acc: 84.39%\n",
      "Train Epoch [87/100] Batch [191/782] Loss: 0.3899 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [192/782] Loss: 0.4790 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [193/782] Loss: 0.4934 | Acc: 84.35%\n",
      "Train Epoch [87/100] Batch [194/782] Loss: 0.4367 | Acc: 84.33%\n",
      "Train Epoch [87/100] Batch [195/782] Loss: 0.4932 | Acc: 84.31%\n",
      "Train Epoch [87/100] Batch [196/782] Loss: 0.4548 | Acc: 84.30%\n",
      "Train Epoch [87/100] Batch [197/782] Loss: 0.3535 | Acc: 84.30%\n",
      "Train Epoch [87/100] Batch [198/782] Loss: 0.3294 | Acc: 84.33%\n",
      "Train Epoch [87/100] Batch [199/782] Loss: 0.2760 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [200/782] Loss: 0.3922 | Acc: 84.37%\n",
      "Train Epoch [87/100] Batch [201/782] Loss: 0.4235 | Acc: 84.37%\n",
      "Train Epoch [87/100] Batch [202/782] Loss: 0.4409 | Acc: 84.37%\n",
      "Train Epoch [87/100] Batch [203/782] Loss: 0.3791 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [204/782] Loss: 0.4640 | Acc: 84.37%\n",
      "Train Epoch [87/100] Batch [205/782] Loss: 0.2731 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [206/782] Loss: 0.5534 | Acc: 84.36%\n",
      "Train Epoch [87/100] Batch [207/782] Loss: 0.2833 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [208/782] Loss: 0.3784 | Acc: 84.38%\n",
      "Train Epoch [87/100] Batch [209/782] Loss: 0.3047 | Acc: 84.40%\n",
      "Train Epoch [87/100] Batch [210/782] Loss: 0.3767 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [211/782] Loss: 0.5015 | Acc: 84.40%\n",
      "Train Epoch [87/100] Batch [212/782] Loss: 0.2878 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [213/782] Loss: 0.3917 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [214/782] Loss: 0.5234 | Acc: 84.45%\n",
      "Train Epoch [87/100] Batch [215/782] Loss: 0.4099 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [216/782] Loss: 0.3440 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [217/782] Loss: 0.3454 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [218/782] Loss: 0.3206 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [219/782] Loss: 0.3571 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [220/782] Loss: 0.3577 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [221/782] Loss: 0.4347 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [222/782] Loss: 0.3038 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [223/782] Loss: 0.4029 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [224/782] Loss: 0.5203 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [225/782] Loss: 0.4420 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [226/782] Loss: 0.3813 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [227/782] Loss: 0.3753 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [228/782] Loss: 0.3662 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [229/782] Loss: 0.4079 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [230/782] Loss: 0.6447 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [231/782] Loss: 0.4271 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [232/782] Loss: 0.5184 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [233/782] Loss: 0.5926 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [234/782] Loss: 0.3433 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [235/782] Loss: 0.4504 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [236/782] Loss: 0.4929 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [237/782] Loss: 0.3505 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [238/782] Loss: 0.5467 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [239/782] Loss: 0.5411 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [240/782] Loss: 0.5028 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [241/782] Loss: 0.5327 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [242/782] Loss: 0.6290 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [243/782] Loss: 0.3028 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [244/782] Loss: 0.3335 | Acc: 84.45%\n",
      "Train Epoch [87/100] Batch [245/782] Loss: 0.2999 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [246/782] Loss: 0.4555 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [247/782] Loss: 0.5036 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [248/782] Loss: 0.5322 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [249/782] Loss: 0.3776 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [250/782] Loss: 0.4022 | Acc: 84.41%\n",
      "Train Epoch [87/100] Batch [251/782] Loss: 0.4389 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [252/782] Loss: 0.6114 | Acc: 84.41%\n",
      "Train Epoch [87/100] Batch [253/782] Loss: 0.3409 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [254/782] Loss: 0.5527 | Acc: 84.42%\n",
      "Train Epoch [87/100] Batch [255/782] Loss: 0.3846 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [256/782] Loss: 0.3667 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [257/782] Loss: 0.4505 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [258/782] Loss: 0.4027 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [259/782] Loss: 0.3546 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [260/782] Loss: 0.3074 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [261/782] Loss: 0.3784 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [262/782] Loss: 0.4805 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [263/782] Loss: 0.3432 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [264/782] Loss: 0.2202 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [265/782] Loss: 0.3834 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [266/782] Loss: 0.3328 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [267/782] Loss: 0.3456 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [268/782] Loss: 0.2221 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [269/782] Loss: 0.5618 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [270/782] Loss: 0.3948 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [271/782] Loss: 0.4672 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [272/782] Loss: 0.6032 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [273/782] Loss: 0.4560 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [274/782] Loss: 0.3749 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [275/782] Loss: 0.6221 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [276/782] Loss: 0.4070 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [277/782] Loss: 0.3889 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [278/782] Loss: 0.5405 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [279/782] Loss: 0.3141 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [280/782] Loss: 0.4334 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [281/782] Loss: 0.4887 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [282/782] Loss: 0.3875 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [283/782] Loss: 0.6968 | Acc: 84.45%\n",
      "Train Epoch [87/100] Batch [284/782] Loss: 0.6166 | Acc: 84.43%\n",
      "Train Epoch [87/100] Batch [285/782] Loss: 0.3356 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [286/782] Loss: 0.4166 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [287/782] Loss: 0.2523 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [288/782] Loss: 0.4152 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [289/782] Loss: 0.4185 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [290/782] Loss: 0.6005 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [291/782] Loss: 0.2723 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [292/782] Loss: 0.3582 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [293/782] Loss: 0.5402 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [294/782] Loss: 0.5912 | Acc: 84.44%\n",
      "Train Epoch [87/100] Batch [295/782] Loss: 0.3056 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [296/782] Loss: 0.3213 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [297/782] Loss: 0.5181 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [298/782] Loss: 0.2994 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [299/782] Loss: 0.4020 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [300/782] Loss: 0.5035 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [301/782] Loss: 0.3785 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [302/782] Loss: 0.2767 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [303/782] Loss: 0.2817 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [304/782] Loss: 0.1543 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [305/782] Loss: 0.4042 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [306/782] Loss: 0.4232 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [307/782] Loss: 0.3480 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [308/782] Loss: 0.3649 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [309/782] Loss: 0.4444 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [310/782] Loss: 0.4176 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [311/782] Loss: 0.2807 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [312/782] Loss: 0.6630 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [313/782] Loss: 0.4284 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [314/782] Loss: 0.2949 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [315/782] Loss: 0.5829 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [316/782] Loss: 0.4397 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [317/782] Loss: 0.5838 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [318/782] Loss: 0.3544 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [319/782] Loss: 0.3466 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [320/782] Loss: 0.5154 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [321/782] Loss: 0.5032 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [322/782] Loss: 0.4098 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [323/782] Loss: 0.2293 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [324/782] Loss: 0.3144 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [325/782] Loss: 0.3115 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [326/782] Loss: 0.4503 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [327/782] Loss: 0.5430 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [328/782] Loss: 0.4176 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [329/782] Loss: 0.4558 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [330/782] Loss: 0.5188 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [331/782] Loss: 0.2810 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [332/782] Loss: 0.5051 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [333/782] Loss: 0.5699 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [334/782] Loss: 0.5015 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [335/782] Loss: 0.2267 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [336/782] Loss: 0.5442 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [337/782] Loss: 0.3996 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [338/782] Loss: 0.1897 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [339/782] Loss: 0.4637 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [340/782] Loss: 0.4906 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [341/782] Loss: 0.4019 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [342/782] Loss: 0.4574 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [343/782] Loss: 0.4174 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [344/782] Loss: 0.2735 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [345/782] Loss: 0.4603 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [346/782] Loss: 0.3777 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [347/782] Loss: 0.1563 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [348/782] Loss: 0.3762 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [349/782] Loss: 0.3855 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [350/782] Loss: 0.5041 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [351/782] Loss: 0.6499 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [352/782] Loss: 0.3826 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [353/782] Loss: 0.4451 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [354/782] Loss: 0.3683 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [355/782] Loss: 0.5564 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [356/782] Loss: 0.3485 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [357/782] Loss: 0.5469 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [358/782] Loss: 0.4626 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [359/782] Loss: 0.4134 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [360/782] Loss: 0.4017 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [361/782] Loss: 0.5619 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [362/782] Loss: 0.4330 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [363/782] Loss: 0.4325 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [364/782] Loss: 0.4808 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [365/782] Loss: 0.2131 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [366/782] Loss: 0.5221 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [367/782] Loss: 0.4884 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [368/782] Loss: 0.3892 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [369/782] Loss: 0.3897 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [370/782] Loss: 0.4069 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [371/782] Loss: 0.3271 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [372/782] Loss: 0.4394 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [373/782] Loss: 0.2483 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [374/782] Loss: 0.5789 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [375/782] Loss: 0.3734 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [376/782] Loss: 0.4883 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [377/782] Loss: 0.5645 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [378/782] Loss: 0.3834 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [379/782] Loss: 0.4917 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [380/782] Loss: 0.3354 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [381/782] Loss: 0.4285 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [382/782] Loss: 0.3280 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [383/782] Loss: 0.2415 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [384/782] Loss: 0.3351 | Acc: 84.66%\n",
      "Train Epoch [87/100] Batch [385/782] Loss: 0.2438 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [386/782] Loss: 0.5497 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [387/782] Loss: 0.3821 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [388/782] Loss: 0.3801 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [389/782] Loss: 0.4468 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [390/782] Loss: 0.4611 | Acc: 84.66%\n",
      "Train Epoch [87/100] Batch [391/782] Loss: 0.2577 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [392/782] Loss: 0.5251 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [393/782] Loss: 0.3906 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [394/782] Loss: 0.3274 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [395/782] Loss: 0.3315 | Acc: 84.68%\n",
      "Train Epoch [87/100] Batch [396/782] Loss: 0.3123 | Acc: 84.70%\n",
      "Train Epoch [87/100] Batch [397/782] Loss: 0.3578 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [398/782] Loss: 0.3496 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [399/782] Loss: 0.3924 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [400/782] Loss: 0.3109 | Acc: 84.72%\n",
      "Train Epoch [87/100] Batch [401/782] Loss: 0.4849 | Acc: 84.71%\n",
      "Train Epoch [87/100] Batch [402/782] Loss: 0.6847 | Acc: 84.67%\n",
      "Train Epoch [87/100] Batch [403/782] Loss: 0.5690 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [404/782] Loss: 0.4913 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [405/782] Loss: 0.4400 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [406/782] Loss: 0.4219 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [407/782] Loss: 0.2980 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [408/782] Loss: 0.4202 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [409/782] Loss: 0.4190 | Acc: 84.65%\n",
      "Train Epoch [87/100] Batch [410/782] Loss: 0.6239 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [411/782] Loss: 0.4434 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [412/782] Loss: 0.5406 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [413/782] Loss: 0.6427 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [414/782] Loss: 0.5075 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [415/782] Loss: 0.4817 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [416/782] Loss: 0.5071 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [417/782] Loss: 0.5213 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [418/782] Loss: 0.4597 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [419/782] Loss: 0.3536 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [420/782] Loss: 0.4931 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [421/782] Loss: 0.5088 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [422/782] Loss: 0.4552 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [423/782] Loss: 0.4678 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [424/782] Loss: 0.4118 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [425/782] Loss: 0.3729 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [426/782] Loss: 0.4303 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [427/782] Loss: 0.6127 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [428/782] Loss: 0.5494 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [429/782] Loss: 0.5491 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [430/782] Loss: 0.3117 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [431/782] Loss: 0.5757 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [432/782] Loss: 0.5005 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [433/782] Loss: 0.4388 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [434/782] Loss: 0.4910 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [435/782] Loss: 0.4142 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [436/782] Loss: 0.3356 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [437/782] Loss: 0.3952 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [438/782] Loss: 0.3241 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [439/782] Loss: 0.3813 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [440/782] Loss: 0.5491 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [441/782] Loss: 0.4484 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [442/782] Loss: 0.3852 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [443/782] Loss: 0.6539 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [444/782] Loss: 0.3774 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [445/782] Loss: 0.3223 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [446/782] Loss: 0.4033 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [447/782] Loss: 0.6155 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [448/782] Loss: 0.4213 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [449/782] Loss: 0.3877 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [450/782] Loss: 0.5451 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [451/782] Loss: 0.1968 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [452/782] Loss: 0.6194 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [453/782] Loss: 0.5000 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [454/782] Loss: 0.4748 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [455/782] Loss: 0.3875 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [456/782] Loss: 0.3303 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [457/782] Loss: 0.2282 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [458/782] Loss: 0.3198 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [459/782] Loss: 0.5003 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [460/782] Loss: 0.3641 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [461/782] Loss: 0.2847 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [462/782] Loss: 0.6219 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [463/782] Loss: 0.4479 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [464/782] Loss: 0.5043 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [465/782] Loss: 0.6020 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [466/782] Loss: 0.3772 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [467/782] Loss: 0.3874 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [468/782] Loss: 0.6312 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [469/782] Loss: 0.2997 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [470/782] Loss: 0.4535 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [471/782] Loss: 0.4878 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [472/782] Loss: 0.3803 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [473/782] Loss: 0.4005 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [474/782] Loss: 0.5329 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [475/782] Loss: 0.3521 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [476/782] Loss: 0.3098 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [477/782] Loss: 0.4548 | Acc: 84.57%\n",
      "Train Epoch [87/100] Batch [478/782] Loss: 0.3126 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [479/782] Loss: 0.5743 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [480/782] Loss: 0.4891 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [481/782] Loss: 0.2171 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [482/782] Loss: 0.4565 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [483/782] Loss: 0.4722 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [484/782] Loss: 0.3139 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [485/782] Loss: 0.3092 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [486/782] Loss: 0.5251 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [487/782] Loss: 0.3625 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [488/782] Loss: 0.3284 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [489/782] Loss: 0.4638 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [490/782] Loss: 0.2827 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [491/782] Loss: 0.3029 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [492/782] Loss: 0.3358 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [493/782] Loss: 0.3792 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [494/782] Loss: 0.4289 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [495/782] Loss: 0.2644 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [496/782] Loss: 0.2495 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [497/782] Loss: 0.3379 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [498/782] Loss: 0.5434 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [499/782] Loss: 0.4635 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [500/782] Loss: 0.4210 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [501/782] Loss: 0.3060 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [502/782] Loss: 0.5362 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [503/782] Loss: 0.2371 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [504/782] Loss: 0.4328 | Acc: 84.64%\n",
      "Train Epoch [87/100] Batch [505/782] Loss: 0.3871 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [506/782] Loss: 0.3472 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [507/782] Loss: 0.6356 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [508/782] Loss: 0.3024 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [509/782] Loss: 0.3741 | Acc: 84.63%\n",
      "Train Epoch [87/100] Batch [510/782] Loss: 0.5496 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [511/782] Loss: 0.3681 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [512/782] Loss: 0.2429 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [513/782] Loss: 0.4309 | Acc: 84.62%\n",
      "Train Epoch [87/100] Batch [514/782] Loss: 0.5774 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [515/782] Loss: 0.3738 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [516/782] Loss: 0.5333 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [517/782] Loss: 0.4023 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [518/782] Loss: 0.4311 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [519/782] Loss: 0.5577 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [520/782] Loss: 0.5160 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [521/782] Loss: 0.3584 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [522/782] Loss: 0.3365 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [523/782] Loss: 0.4258 | Acc: 84.61%\n",
      "Train Epoch [87/100] Batch [524/782] Loss: 0.3675 | Acc: 84.60%\n",
      "Train Epoch [87/100] Batch [525/782] Loss: 0.6221 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [526/782] Loss: 0.4387 | Acc: 84.59%\n",
      "Train Epoch [87/100] Batch [527/782] Loss: 0.4935 | Acc: 84.58%\n",
      "Train Epoch [87/100] Batch [528/782] Loss: 0.4934 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [529/782] Loss: 0.4066 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [530/782] Loss: 0.5513 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [531/782] Loss: 0.3722 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [532/782] Loss: 0.5056 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [533/782] Loss: 0.3297 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [534/782] Loss: 0.4408 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [535/782] Loss: 0.4485 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [536/782] Loss: 0.4977 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [537/782] Loss: 0.3899 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [538/782] Loss: 0.4345 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [539/782] Loss: 0.3865 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [540/782] Loss: 0.3548 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [541/782] Loss: 0.6059 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [542/782] Loss: 0.4211 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [543/782] Loss: 0.4210 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [544/782] Loss: 0.3957 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [545/782] Loss: 0.2986 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [546/782] Loss: 0.3982 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [547/782] Loss: 0.4988 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [548/782] Loss: 0.4325 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [549/782] Loss: 0.3234 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [550/782] Loss: 0.6435 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [551/782] Loss: 0.3181 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [552/782] Loss: 0.4564 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [553/782] Loss: 0.3396 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [554/782] Loss: 0.2796 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [555/782] Loss: 0.4619 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [556/782] Loss: 0.5482 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [557/782] Loss: 0.7325 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [558/782] Loss: 0.4467 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [559/782] Loss: 0.4364 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [560/782] Loss: 0.3590 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [561/782] Loss: 0.5379 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [562/782] Loss: 0.5620 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [563/782] Loss: 0.3673 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [564/782] Loss: 0.4443 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [565/782] Loss: 0.3656 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [566/782] Loss: 0.4311 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [567/782] Loss: 0.4759 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [568/782] Loss: 0.3916 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [569/782] Loss: 0.4774 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [570/782] Loss: 0.6225 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [571/782] Loss: 0.3298 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [572/782] Loss: 0.3862 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [573/782] Loss: 0.5022 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [574/782] Loss: 0.4449 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [575/782] Loss: 0.5837 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [576/782] Loss: 0.4695 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [577/782] Loss: 0.3118 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [578/782] Loss: 0.3519 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [579/782] Loss: 0.2870 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [580/782] Loss: 0.4210 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [581/782] Loss: 0.5220 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [582/782] Loss: 0.3765 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [583/782] Loss: 0.3746 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [584/782] Loss: 0.5084 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [585/782] Loss: 0.4599 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [586/782] Loss: 0.2169 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [587/782] Loss: 0.3166 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [588/782] Loss: 0.4039 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [589/782] Loss: 0.5681 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [590/782] Loss: 0.3933 | Acc: 84.56%\n",
      "Train Epoch [87/100] Batch [591/782] Loss: 0.7767 | Acc: 84.55%\n",
      "Train Epoch [87/100] Batch [592/782] Loss: 0.4341 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [593/782] Loss: 0.4486 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [594/782] Loss: 0.5114 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [595/782] Loss: 0.2207 | Acc: 84.54%\n",
      "Train Epoch [87/100] Batch [596/782] Loss: 0.5160 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [597/782] Loss: 0.4629 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [598/782] Loss: 0.4757 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [599/782] Loss: 0.3837 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [600/782] Loss: 0.5407 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [601/782] Loss: 0.4192 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [602/782] Loss: 0.2658 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [603/782] Loss: 0.5523 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [604/782] Loss: 0.4166 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [605/782] Loss: 0.3012 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [606/782] Loss: 0.6440 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [607/782] Loss: 0.4889 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [608/782] Loss: 0.5356 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [609/782] Loss: 0.5238 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [610/782] Loss: 0.4069 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [611/782] Loss: 0.4515 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [612/782] Loss: 0.3872 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [613/782] Loss: 0.4899 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [614/782] Loss: 0.4054 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [615/782] Loss: 0.4145 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [616/782] Loss: 0.5513 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [617/782] Loss: 0.5809 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [618/782] Loss: 0.5500 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [619/782] Loss: 0.4532 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [620/782] Loss: 0.4569 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [621/782] Loss: 0.4415 | Acc: 84.46%\n",
      "Train Epoch [87/100] Batch [622/782] Loss: 0.2970 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [623/782] Loss: 0.4008 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [624/782] Loss: 0.4125 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [625/782] Loss: 0.2496 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [626/782] Loss: 0.2595 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [627/782] Loss: 0.2726 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [628/782] Loss: 0.4215 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [629/782] Loss: 0.4589 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [630/782] Loss: 0.2358 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [631/782] Loss: 0.3733 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [632/782] Loss: 0.5374 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [633/782] Loss: 0.5267 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [634/782] Loss: 0.4541 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [635/782] Loss: 0.4381 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [636/782] Loss: 0.3850 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [637/782] Loss: 0.4231 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [638/782] Loss: 0.7817 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [639/782] Loss: 0.4793 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [640/782] Loss: 0.2910 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [641/782] Loss: 0.4740 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [642/782] Loss: 0.4878 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [643/782] Loss: 0.6993 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [644/782] Loss: 0.4454 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [645/782] Loss: 0.5773 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [646/782] Loss: 0.3902 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [647/782] Loss: 0.4403 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [648/782] Loss: 0.5167 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [649/782] Loss: 0.4926 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [650/782] Loss: 0.3355 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [651/782] Loss: 0.4950 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [652/782] Loss: 0.3512 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [653/782] Loss: 0.4446 | Acc: 84.47%\n",
      "Train Epoch [87/100] Batch [654/782] Loss: 0.3182 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [655/782] Loss: 0.3954 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [656/782] Loss: 0.3617 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [657/782] Loss: 0.4123 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [658/782] Loss: 0.3392 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [659/782] Loss: 0.4356 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [660/782] Loss: 0.3419 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [661/782] Loss: 0.3637 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [662/782] Loss: 0.3833 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [663/782] Loss: 0.4267 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [664/782] Loss: 0.2088 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [665/782] Loss: 0.3616 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [666/782] Loss: 0.7133 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [667/782] Loss: 0.3657 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [668/782] Loss: 0.3415 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [669/782] Loss: 0.3485 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [670/782] Loss: 0.2704 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [671/782] Loss: 0.3905 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [672/782] Loss: 0.4381 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [673/782] Loss: 0.4309 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [674/782] Loss: 0.3162 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [675/782] Loss: 0.3738 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [676/782] Loss: 0.3940 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [677/782] Loss: 0.4535 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [678/782] Loss: 0.3751 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [679/782] Loss: 0.4004 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [680/782] Loss: 0.4477 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [681/782] Loss: 0.6063 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [682/782] Loss: 0.2741 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [683/782] Loss: 0.3959 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [684/782] Loss: 0.5105 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [685/782] Loss: 0.6166 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [686/782] Loss: 0.3586 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [687/782] Loss: 0.3379 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [688/782] Loss: 0.3915 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [689/782] Loss: 0.3497 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [690/782] Loss: 0.2711 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [691/782] Loss: 0.3679 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [692/782] Loss: 0.2501 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [693/782] Loss: 0.4095 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [694/782] Loss: 0.5083 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [695/782] Loss: 0.3924 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [696/782] Loss: 0.4365 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [697/782] Loss: 0.4180 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [698/782] Loss: 0.3363 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [699/782] Loss: 0.4439 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [700/782] Loss: 0.4496 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [701/782] Loss: 0.3909 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [702/782] Loss: 0.4703 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [703/782] Loss: 0.4403 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [704/782] Loss: 0.3851 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [705/782] Loss: 0.5749 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [706/782] Loss: 0.5366 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [707/782] Loss: 0.4541 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [708/782] Loss: 0.4560 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [709/782] Loss: 0.6573 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [710/782] Loss: 0.5546 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [711/782] Loss: 0.5372 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [712/782] Loss: 0.5762 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [713/782] Loss: 0.3235 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [714/782] Loss: 0.4737 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [715/782] Loss: 0.3383 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [716/782] Loss: 0.3003 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [717/782] Loss: 0.3975 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [718/782] Loss: 0.4080 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [719/782] Loss: 0.3016 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [720/782] Loss: 0.3150 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [721/782] Loss: 0.4406 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [722/782] Loss: 0.4442 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [723/782] Loss: 0.3676 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [724/782] Loss: 0.3474 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [725/782] Loss: 0.4845 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [726/782] Loss: 0.4797 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [727/782] Loss: 0.2489 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [728/782] Loss: 0.3792 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [729/782] Loss: 0.4255 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [730/782] Loss: 0.4964 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [731/782] Loss: 0.3241 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [732/782] Loss: 0.4194 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [733/782] Loss: 0.4145 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [734/782] Loss: 0.4797 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [735/782] Loss: 0.2898 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [736/782] Loss: 0.4627 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [737/782] Loss: 0.4577 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [738/782] Loss: 0.4894 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [739/782] Loss: 0.3081 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [740/782] Loss: 0.5136 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [741/782] Loss: 0.4249 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [742/782] Loss: 0.4299 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [743/782] Loss: 0.3609 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [744/782] Loss: 0.3803 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [745/782] Loss: 0.3718 | Acc: 84.53%\n",
      "Train Epoch [87/100] Batch [746/782] Loss: 0.5856 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [747/782] Loss: 0.2713 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [748/782] Loss: 0.5803 | Acc: 84.52%\n",
      "Train Epoch [87/100] Batch [749/782] Loss: 0.5722 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [750/782] Loss: 0.5274 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [751/782] Loss: 0.4864 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [752/782] Loss: 0.4113 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [753/782] Loss: 0.3750 | Acc: 84.51%\n",
      "Train Epoch [87/100] Batch [754/782] Loss: 0.6292 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [755/782] Loss: 0.4531 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [756/782] Loss: 0.4207 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [757/782] Loss: 0.3695 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [758/782] Loss: 0.5190 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [759/782] Loss: 0.5562 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [760/782] Loss: 0.4776 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [761/782] Loss: 0.4389 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [762/782] Loss: 0.4745 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [763/782] Loss: 0.5051 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [764/782] Loss: 0.3549 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [765/782] Loss: 0.4659 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [766/782] Loss: 0.4838 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [767/782] Loss: 0.3173 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [768/782] Loss: 0.6211 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [769/782] Loss: 0.3380 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [770/782] Loss: 0.4654 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [771/782] Loss: 0.3688 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [772/782] Loss: 0.4138 | Acc: 84.48%\n",
      "Train Epoch [87/100] Batch [773/782] Loss: 0.3460 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [774/782] Loss: 0.2749 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [775/782] Loss: 0.4383 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [776/782] Loss: 0.4275 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [777/782] Loss: 0.3303 | Acc: 84.49%\n",
      "Train Epoch [87/100] Batch [778/782] Loss: 0.2539 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [779/782] Loss: 0.4038 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [780/782] Loss: 0.4162 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [781/782] Loss: 0.3252 | Acc: 84.50%\n",
      "Train Epoch [87/100] Batch [782/782] Loss: 0.5669 | Acc: 84.49%\n",
      "Epoch 87 completed in 30.80s.\n",
      "Test Epoch [87/100] Loss: 0.9937 | Acc: 72.49% | Inference Time: 8.62s\n",
      "Epoch 87 results saved to CSV.\n",
      "Epoch 88/100\n",
      "Train Epoch [88/100] Batch [1/782] Loss: 0.4509 | Acc: 84.38%\n",
      "Train Epoch [88/100] Batch [2/782] Loss: 0.4459 | Acc: 83.59%\n",
      "Train Epoch [88/100] Batch [3/782] Loss: 0.3198 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [4/782] Loss: 0.5517 | Acc: 83.59%\n",
      "Train Epoch [88/100] Batch [5/782] Loss: 0.4571 | Acc: 82.81%\n",
      "Train Epoch [88/100] Batch [6/782] Loss: 0.4390 | Acc: 82.81%\n",
      "Train Epoch [88/100] Batch [7/782] Loss: 0.3770 | Acc: 82.81%\n",
      "Train Epoch [88/100] Batch [8/782] Loss: 0.5589 | Acc: 83.20%\n",
      "Train Epoch [88/100] Batch [9/782] Loss: 0.2957 | Acc: 83.85%\n",
      "Train Epoch [88/100] Batch [10/782] Loss: 0.2933 | Acc: 84.38%\n",
      "Train Epoch [88/100] Batch [11/782] Loss: 0.3643 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [12/782] Loss: 0.4559 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [13/782] Loss: 0.4898 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [14/782] Loss: 0.6177 | Acc: 84.60%\n",
      "Train Epoch [88/100] Batch [15/782] Loss: 0.3460 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [16/782] Loss: 0.5198 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [17/782] Loss: 0.4164 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [18/782] Loss: 0.3145 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [19/782] Loss: 0.3363 | Acc: 85.03%\n",
      "Train Epoch [88/100] Batch [20/782] Loss: 0.4754 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [21/782] Loss: 0.5082 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [22/782] Loss: 0.4246 | Acc: 84.38%\n",
      "Train Epoch [88/100] Batch [23/782] Loss: 0.4989 | Acc: 84.17%\n",
      "Train Epoch [88/100] Batch [24/782] Loss: 0.5028 | Acc: 84.05%\n",
      "Train Epoch [88/100] Batch [25/782] Loss: 0.2716 | Acc: 84.31%\n",
      "Train Epoch [88/100] Batch [26/782] Loss: 0.3826 | Acc: 84.50%\n",
      "Train Epoch [88/100] Batch [27/782] Loss: 0.4838 | Acc: 84.49%\n",
      "Train Epoch [88/100] Batch [28/782] Loss: 0.4159 | Acc: 84.43%\n",
      "Train Epoch [88/100] Batch [29/782] Loss: 0.3086 | Acc: 84.54%\n",
      "Train Epoch [88/100] Batch [30/782] Loss: 0.5913 | Acc: 84.38%\n",
      "Train Epoch [88/100] Batch [31/782] Loss: 0.4795 | Acc: 84.32%\n",
      "Train Epoch [88/100] Batch [32/782] Loss: 0.2807 | Acc: 84.47%\n",
      "Train Epoch [88/100] Batch [33/782] Loss: 0.4267 | Acc: 84.52%\n",
      "Train Epoch [88/100] Batch [34/782] Loss: 0.3012 | Acc: 84.60%\n",
      "Train Epoch [88/100] Batch [35/782] Loss: 0.4941 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [36/782] Loss: 0.5076 | Acc: 84.46%\n",
      "Train Epoch [88/100] Batch [37/782] Loss: 0.3381 | Acc: 84.59%\n",
      "Train Epoch [88/100] Batch [38/782] Loss: 0.4702 | Acc: 84.54%\n",
      "Train Epoch [88/100] Batch [39/782] Loss: 0.2571 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [40/782] Loss: 0.2557 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [41/782] Loss: 0.3213 | Acc: 85.02%\n",
      "Train Epoch [88/100] Batch [42/782] Loss: 0.2999 | Acc: 85.12%\n",
      "Train Epoch [88/100] Batch [43/782] Loss: 0.4243 | Acc: 85.14%\n",
      "Train Epoch [88/100] Batch [44/782] Loss: 0.4910 | Acc: 85.09%\n",
      "Train Epoch [88/100] Batch [45/782] Loss: 0.5351 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [46/782] Loss: 0.3166 | Acc: 84.99%\n",
      "Train Epoch [88/100] Batch [47/782] Loss: 0.5431 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [48/782] Loss: 0.3918 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [49/782] Loss: 0.2664 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [50/782] Loss: 0.5311 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [51/782] Loss: 0.5360 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [52/782] Loss: 0.5878 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [53/782] Loss: 0.5566 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [54/782] Loss: 0.4085 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [55/782] Loss: 0.4815 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [56/782] Loss: 0.5146 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [57/782] Loss: 0.3928 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [58/782] Loss: 0.3963 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [59/782] Loss: 0.3962 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [60/782] Loss: 0.5392 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [61/782] Loss: 0.4895 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [62/782] Loss: 0.4257 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [63/782] Loss: 0.3534 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [64/782] Loss: 0.4630 | Acc: 84.62%\n",
      "Train Epoch [88/100] Batch [65/782] Loss: 0.5409 | Acc: 84.57%\n",
      "Train Epoch [88/100] Batch [66/782] Loss: 0.4456 | Acc: 84.56%\n",
      "Train Epoch [88/100] Batch [67/782] Loss: 0.3541 | Acc: 84.58%\n",
      "Train Epoch [88/100] Batch [68/782] Loss: 0.3597 | Acc: 84.56%\n",
      "Train Epoch [88/100] Batch [69/782] Loss: 0.3051 | Acc: 84.58%\n",
      "Train Epoch [88/100] Batch [70/782] Loss: 0.4123 | Acc: 84.60%\n",
      "Train Epoch [88/100] Batch [71/782] Loss: 0.4163 | Acc: 84.62%\n",
      "Train Epoch [88/100] Batch [72/782] Loss: 0.2138 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [73/782] Loss: 0.4089 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [74/782] Loss: 0.2435 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [75/782] Loss: 0.6621 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [76/782] Loss: 0.4137 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [77/782] Loss: 0.4232 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [78/782] Loss: 0.4271 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [79/782] Loss: 0.4720 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [80/782] Loss: 0.3165 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [81/782] Loss: 0.3928 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [82/782] Loss: 0.4461 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [83/782] Loss: 0.3600 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [84/782] Loss: 0.5371 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [85/782] Loss: 0.5455 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [86/782] Loss: 0.3862 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [87/782] Loss: 0.5025 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [88/782] Loss: 0.3627 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [89/782] Loss: 0.4090 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [90/782] Loss: 0.3575 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [91/782] Loss: 0.6146 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [92/782] Loss: 0.2745 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [93/782] Loss: 0.3938 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [94/782] Loss: 0.5510 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [95/782] Loss: 0.4401 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [96/782] Loss: 0.5543 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [97/782] Loss: 0.3062 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [98/782] Loss: 0.3301 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [99/782] Loss: 0.3915 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [100/782] Loss: 0.4223 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [101/782] Loss: 0.4149 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [102/782] Loss: 0.3045 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [103/782] Loss: 0.3085 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [104/782] Loss: 0.5358 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [105/782] Loss: 0.3147 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [106/782] Loss: 0.4802 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [107/782] Loss: 0.2367 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [108/782] Loss: 0.5551 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [109/782] Loss: 0.5160 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [110/782] Loss: 0.4279 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [111/782] Loss: 0.4008 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [112/782] Loss: 0.5429 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [113/782] Loss: 0.4287 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [114/782] Loss: 0.4596 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [115/782] Loss: 0.3670 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [116/782] Loss: 0.4140 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [117/782] Loss: 0.3622 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [118/782] Loss: 0.4606 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [119/782] Loss: 0.3809 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [120/782] Loss: 0.4170 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [121/782] Loss: 0.6361 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [122/782] Loss: 0.3791 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [123/782] Loss: 0.2857 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [124/782] Loss: 0.4232 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [125/782] Loss: 0.3466 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [126/782] Loss: 0.3899 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [127/782] Loss: 0.4964 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [128/782] Loss: 0.4687 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [129/782] Loss: 0.4381 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [130/782] Loss: 0.3212 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [131/782] Loss: 0.4226 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [132/782] Loss: 0.3841 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [133/782] Loss: 0.5775 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [134/782] Loss: 0.2397 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [135/782] Loss: 0.5810 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [136/782] Loss: 0.4349 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [137/782] Loss: 0.3479 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [138/782] Loss: 0.2724 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [139/782] Loss: 0.5459 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [140/782] Loss: 0.3919 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [141/782] Loss: 0.4239 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [142/782] Loss: 0.6186 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [143/782] Loss: 0.5254 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [144/782] Loss: 0.2349 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [145/782] Loss: 0.3495 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [146/782] Loss: 0.2759 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [147/782] Loss: 0.3975 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [148/782] Loss: 0.3675 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [149/782] Loss: 0.4215 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [150/782] Loss: 0.3310 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [151/782] Loss: 0.3508 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [152/782] Loss: 0.4578 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [153/782] Loss: 0.3014 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [154/782] Loss: 0.4064 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [155/782] Loss: 0.3589 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [156/782] Loss: 0.3242 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [157/782] Loss: 0.3653 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [158/782] Loss: 0.3972 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [159/782] Loss: 0.5337 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [160/782] Loss: 0.5799 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [161/782] Loss: 0.3694 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [162/782] Loss: 0.4587 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [163/782] Loss: 0.4156 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [164/782] Loss: 0.4995 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [165/782] Loss: 0.4706 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [166/782] Loss: 0.4127 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [167/782] Loss: 0.4756 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [168/782] Loss: 0.3821 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [169/782] Loss: 0.3370 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [170/782] Loss: 0.3116 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [171/782] Loss: 0.5009 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [172/782] Loss: 0.3676 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [173/782] Loss: 0.2935 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [174/782] Loss: 0.3617 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [175/782] Loss: 0.5772 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [176/782] Loss: 0.5076 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [177/782] Loss: 0.5514 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [178/782] Loss: 0.4234 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [179/782] Loss: 0.3363 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [180/782] Loss: 0.6039 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [181/782] Loss: 0.5372 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [182/782] Loss: 0.4718 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [183/782] Loss: 0.3085 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [184/782] Loss: 0.3532 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [185/782] Loss: 0.4543 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [186/782] Loss: 0.5494 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [187/782] Loss: 0.3710 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [188/782] Loss: 0.4903 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [189/782] Loss: 0.3058 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [190/782] Loss: 0.2155 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [191/782] Loss: 0.3657 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [192/782] Loss: 0.5092 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [193/782] Loss: 0.3448 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [194/782] Loss: 0.4366 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [195/782] Loss: 0.3205 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [196/782] Loss: 0.3551 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [197/782] Loss: 0.4284 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [198/782] Loss: 0.5676 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [199/782] Loss: 0.4158 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [200/782] Loss: 0.4981 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [201/782] Loss: 0.3859 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [202/782] Loss: 0.3489 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [203/782] Loss: 0.4417 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [204/782] Loss: 0.4950 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [205/782] Loss: 0.4009 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [206/782] Loss: 0.5784 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [207/782] Loss: 0.4581 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [208/782] Loss: 0.2219 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [209/782] Loss: 0.3933 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [210/782] Loss: 0.5217 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [211/782] Loss: 0.3739 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [212/782] Loss: 0.3583 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [213/782] Loss: 0.3496 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [214/782] Loss: 0.4526 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [215/782] Loss: 0.3242 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [216/782] Loss: 0.4946 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [217/782] Loss: 0.4233 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [218/782] Loss: 0.5000 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [219/782] Loss: 0.5557 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [220/782] Loss: 0.5125 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [221/782] Loss: 0.2771 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [222/782] Loss: 0.4763 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [223/782] Loss: 0.5078 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [224/782] Loss: 0.5343 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [225/782] Loss: 0.2683 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [226/782] Loss: 0.3917 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [227/782] Loss: 0.2994 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [228/782] Loss: 0.3719 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [229/782] Loss: 0.2991 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [230/782] Loss: 0.5511 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [231/782] Loss: 0.2745 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [232/782] Loss: 0.3507 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [233/782] Loss: 0.4037 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [234/782] Loss: 0.3515 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [235/782] Loss: 0.4186 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [236/782] Loss: 0.4880 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [237/782] Loss: 0.5985 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [238/782] Loss: 0.5974 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [239/782] Loss: 0.4805 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [240/782] Loss: 0.3190 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [241/782] Loss: 0.4321 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [242/782] Loss: 0.2607 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [243/782] Loss: 0.3082 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [244/782] Loss: 0.4669 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [245/782] Loss: 0.3375 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [246/782] Loss: 0.4794 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [247/782] Loss: 0.4210 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [248/782] Loss: 0.3307 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [249/782] Loss: 0.4251 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [250/782] Loss: 0.5419 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [251/782] Loss: 0.4603 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [252/782] Loss: 0.4165 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [253/782] Loss: 0.5053 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [254/782] Loss: 0.2877 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [255/782] Loss: 0.5603 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [256/782] Loss: 0.3979 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [257/782] Loss: 0.3872 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [258/782] Loss: 0.2917 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [259/782] Loss: 0.5321 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [260/782] Loss: 0.3356 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [261/782] Loss: 0.3332 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [262/782] Loss: 0.3449 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [263/782] Loss: 0.5573 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [264/782] Loss: 0.5863 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [265/782] Loss: 0.3727 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [266/782] Loss: 0.3620 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [267/782] Loss: 0.4936 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [268/782] Loss: 0.3234 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [269/782] Loss: 0.3964 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [270/782] Loss: 0.4930 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [271/782] Loss: 0.3262 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [272/782] Loss: 0.3092 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [273/782] Loss: 0.3987 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [274/782] Loss: 0.5414 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [275/782] Loss: 0.6001 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [276/782] Loss: 0.4718 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [277/782] Loss: 0.3222 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [278/782] Loss: 0.4726 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [279/782] Loss: 0.5163 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [280/782] Loss: 0.3873 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [281/782] Loss: 0.3303 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [282/782] Loss: 0.2827 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [283/782] Loss: 0.5725 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [284/782] Loss: 0.4338 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [285/782] Loss: 0.6911 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [286/782] Loss: 0.4441 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [287/782] Loss: 0.5464 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [288/782] Loss: 0.5702 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [289/782] Loss: 0.3641 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [290/782] Loss: 0.4248 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [291/782] Loss: 0.5913 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [292/782] Loss: 0.3486 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [293/782] Loss: 0.2748 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [294/782] Loss: 0.3955 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [295/782] Loss: 0.2992 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [296/782] Loss: 0.7404 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [297/782] Loss: 0.3857 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [298/782] Loss: 0.4893 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [299/782] Loss: 0.5070 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [300/782] Loss: 0.5555 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [301/782] Loss: 0.4416 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [302/782] Loss: 0.5010 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [303/782] Loss: 0.2727 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [304/782] Loss: 0.3784 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [305/782] Loss: 0.2910 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [306/782] Loss: 0.3690 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [307/782] Loss: 0.4290 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [308/782] Loss: 0.3880 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [309/782] Loss: 0.4254 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [310/782] Loss: 0.3989 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [311/782] Loss: 0.4519 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [312/782] Loss: 0.4728 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [313/782] Loss: 0.5861 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [314/782] Loss: 0.4910 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [315/782] Loss: 0.4786 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [316/782] Loss: 0.3620 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [317/782] Loss: 0.5190 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [318/782] Loss: 0.2259 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [319/782] Loss: 0.3388 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [320/782] Loss: 0.3131 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [321/782] Loss: 0.5121 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [322/782] Loss: 0.5148 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [323/782] Loss: 0.3527 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [324/782] Loss: 0.4031 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [325/782] Loss: 0.3287 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [326/782] Loss: 0.3505 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [327/782] Loss: 0.4307 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [328/782] Loss: 0.2549 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [329/782] Loss: 0.3713 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [330/782] Loss: 0.2951 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [331/782] Loss: 0.5425 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [332/782] Loss: 0.4806 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [333/782] Loss: 0.4418 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [334/782] Loss: 0.6583 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [335/782] Loss: 0.4583 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [336/782] Loss: 0.4337 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [337/782] Loss: 0.3171 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [338/782] Loss: 0.3888 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [339/782] Loss: 0.5126 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [340/782] Loss: 0.2527 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [341/782] Loss: 0.3809 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [342/782] Loss: 0.4122 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [343/782] Loss: 0.3026 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [344/782] Loss: 0.3556 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [345/782] Loss: 0.6769 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [346/782] Loss: 0.2733 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [347/782] Loss: 0.5850 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [348/782] Loss: 0.3277 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [349/782] Loss: 0.4720 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [350/782] Loss: 0.7068 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [351/782] Loss: 0.3732 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [352/782] Loss: 0.4365 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [353/782] Loss: 0.3670 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [354/782] Loss: 0.4552 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [355/782] Loss: 0.3591 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [356/782] Loss: 0.4533 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [357/782] Loss: 0.2901 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [358/782] Loss: 0.3144 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [359/782] Loss: 0.5239 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [360/782] Loss: 0.3469 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [361/782] Loss: 0.2850 | Acc: 84.98%\n",
      "Train Epoch [88/100] Batch [362/782] Loss: 0.4425 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [363/782] Loss: 0.3489 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [364/782] Loss: 0.4502 | Acc: 84.97%\n",
      "Train Epoch [88/100] Batch [365/782] Loss: 0.5467 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [366/782] Loss: 0.2495 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [367/782] Loss: 0.3337 | Acc: 84.96%\n",
      "Train Epoch [88/100] Batch [368/782] Loss: 0.7412 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [369/782] Loss: 0.5809 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [370/782] Loss: 0.3624 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [371/782] Loss: 0.3284 | Acc: 84.91%\n",
      "Train Epoch [88/100] Batch [372/782] Loss: 0.4880 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [373/782] Loss: 0.3886 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [374/782] Loss: 0.4287 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [375/782] Loss: 0.3724 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [376/782] Loss: 0.2967 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [377/782] Loss: 0.3852 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [378/782] Loss: 0.3496 | Acc: 84.94%\n",
      "Train Epoch [88/100] Batch [379/782] Loss: 0.2968 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [380/782] Loss: 0.4776 | Acc: 84.95%\n",
      "Train Epoch [88/100] Batch [381/782] Loss: 0.6900 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [382/782] Loss: 0.2710 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [383/782] Loss: 0.5105 | Acc: 84.92%\n",
      "Train Epoch [88/100] Batch [384/782] Loss: 0.3699 | Acc: 84.93%\n",
      "Train Epoch [88/100] Batch [385/782] Loss: 0.6364 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [386/782] Loss: 0.4395 | Acc: 84.90%\n",
      "Train Epoch [88/100] Batch [387/782] Loss: 0.4994 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [388/782] Loss: 0.4809 | Acc: 84.88%\n",
      "Train Epoch [88/100] Batch [389/782] Loss: 0.5432 | Acc: 84.89%\n",
      "Train Epoch [88/100] Batch [390/782] Loss: 0.6632 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [391/782] Loss: 0.5086 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [392/782] Loss: 0.3768 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [393/782] Loss: 0.4773 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [394/782] Loss: 0.5386 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [395/782] Loss: 0.5151 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [396/782] Loss: 0.3295 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [397/782] Loss: 0.3700 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [398/782] Loss: 0.5484 | Acc: 84.87%\n",
      "Train Epoch [88/100] Batch [399/782] Loss: 0.6199 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [400/782] Loss: 0.4385 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [401/782] Loss: 0.6561 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [402/782] Loss: 0.6109 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [403/782] Loss: 0.5010 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [404/782] Loss: 0.4962 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [405/782] Loss: 0.4682 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [406/782] Loss: 0.4313 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [407/782] Loss: 0.4496 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [408/782] Loss: 0.3713 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [409/782] Loss: 0.4314 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [410/782] Loss: 0.2771 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [411/782] Loss: 0.3406 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [412/782] Loss: 0.4844 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [413/782] Loss: 0.5062 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [414/782] Loss: 0.4362 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [415/782] Loss: 0.4888 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [416/782] Loss: 0.4581 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [417/782] Loss: 0.4572 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [418/782] Loss: 0.2486 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [419/782] Loss: 0.4511 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [420/782] Loss: 0.4262 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [421/782] Loss: 0.4145 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [422/782] Loss: 0.3665 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [423/782] Loss: 0.4220 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [424/782] Loss: 0.3496 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [425/782] Loss: 0.4669 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [426/782] Loss: 0.5292 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [427/782] Loss: 0.4292 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [428/782] Loss: 0.5139 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [429/782] Loss: 0.4100 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [430/782] Loss: 0.3972 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [431/782] Loss: 0.4155 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [432/782] Loss: 0.3309 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [433/782] Loss: 0.3793 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [434/782] Loss: 0.2020 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [435/782] Loss: 0.4432 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [436/782] Loss: 0.4026 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [437/782] Loss: 0.3791 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [438/782] Loss: 0.5873 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [439/782] Loss: 0.4757 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [440/782] Loss: 0.4413 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [441/782] Loss: 0.2540 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [442/782] Loss: 0.5037 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [443/782] Loss: 0.3332 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [444/782] Loss: 0.5507 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [445/782] Loss: 0.5679 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [446/782] Loss: 0.3963 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [447/782] Loss: 0.2318 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [448/782] Loss: 0.2764 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [449/782] Loss: 0.3781 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [450/782] Loss: 0.3104 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [451/782] Loss: 0.4722 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [452/782] Loss: 0.3019 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [453/782] Loss: 0.4657 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [454/782] Loss: 0.3966 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [455/782] Loss: 0.7008 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [456/782] Loss: 0.4439 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [457/782] Loss: 0.4882 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [458/782] Loss: 0.4789 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [459/782] Loss: 0.5078 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [460/782] Loss: 0.4187 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [461/782] Loss: 0.4221 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [462/782] Loss: 0.2977 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [463/782] Loss: 0.4647 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [464/782] Loss: 0.5035 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [465/782] Loss: 0.4632 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [466/782] Loss: 0.4945 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [467/782] Loss: 0.2106 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [468/782] Loss: 0.3437 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [469/782] Loss: 0.4505 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [470/782] Loss: 0.3599 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [471/782] Loss: 0.4109 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [472/782] Loss: 0.3950 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [473/782] Loss: 0.4518 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [474/782] Loss: 0.4764 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [475/782] Loss: 0.4888 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [476/782] Loss: 0.4872 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [477/782] Loss: 0.3189 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [478/782] Loss: 0.3234 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [479/782] Loss: 0.2653 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [480/782] Loss: 0.3742 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [481/782] Loss: 0.5455 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [482/782] Loss: 0.3287 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [483/782] Loss: 0.4397 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [484/782] Loss: 0.5227 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [485/782] Loss: 0.4918 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [486/782] Loss: 0.3001 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [487/782] Loss: 0.3780 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [488/782] Loss: 0.7319 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [489/782] Loss: 0.4312 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [490/782] Loss: 0.3771 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [491/782] Loss: 0.4975 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [492/782] Loss: 0.3828 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [493/782] Loss: 0.4981 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [494/782] Loss: 0.5147 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [495/782] Loss: 0.2562 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [496/782] Loss: 0.5059 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [497/782] Loss: 0.3933 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [498/782] Loss: 0.3627 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [499/782] Loss: 0.3843 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [500/782] Loss: 0.3820 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [501/782] Loss: 0.3770 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [502/782] Loss: 0.4342 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [503/782] Loss: 0.3887 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [504/782] Loss: 0.1943 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [505/782] Loss: 0.4406 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [506/782] Loss: 0.3204 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [507/782] Loss: 0.2680 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [508/782] Loss: 0.4926 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [509/782] Loss: 0.5945 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [510/782] Loss: 0.4664 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [511/782] Loss: 0.3490 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [512/782] Loss: 0.3763 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [513/782] Loss: 0.3834 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [514/782] Loss: 0.3956 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [515/782] Loss: 0.4276 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [516/782] Loss: 0.2648 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [517/782] Loss: 0.4267 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [518/782] Loss: 0.6336 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [519/782] Loss: 0.3351 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [520/782] Loss: 0.2997 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [521/782] Loss: 0.3933 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [522/782] Loss: 0.3376 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [523/782] Loss: 0.2954 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [524/782] Loss: 0.3252 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [525/782] Loss: 0.4111 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [526/782] Loss: 0.6117 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [527/782] Loss: 0.5691 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [528/782] Loss: 0.4826 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [529/782] Loss: 0.4073 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [530/782] Loss: 0.4956 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [531/782] Loss: 0.2550 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [532/782] Loss: 0.2353 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [533/782] Loss: 0.3907 | Acc: 84.86%\n",
      "Train Epoch [88/100] Batch [534/782] Loss: 0.4816 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [535/782] Loss: 0.5153 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [536/782] Loss: 0.4857 | Acc: 84.84%\n",
      "Train Epoch [88/100] Batch [537/782] Loss: 0.5324 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [538/782] Loss: 0.4931 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [539/782] Loss: 0.4089 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [540/782] Loss: 0.4497 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [541/782] Loss: 0.2751 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [542/782] Loss: 0.5353 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [543/782] Loss: 0.2066 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [544/782] Loss: 0.3509 | Acc: 84.85%\n",
      "Train Epoch [88/100] Batch [545/782] Loss: 0.5756 | Acc: 84.83%\n",
      "Train Epoch [88/100] Batch [546/782] Loss: 0.5390 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [547/782] Loss: 0.5433 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [548/782] Loss: 0.6724 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [549/782] Loss: 0.3725 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [550/782] Loss: 0.5261 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [551/782] Loss: 0.5939 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [552/782] Loss: 0.4340 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [553/782] Loss: 0.3842 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [554/782] Loss: 0.3965 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [555/782] Loss: 0.3818 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [556/782] Loss: 0.3906 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [557/782] Loss: 0.5754 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [558/782] Loss: 0.2468 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [559/782] Loss: 0.6009 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [560/782] Loss: 0.3704 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [561/782] Loss: 0.4187 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [562/782] Loss: 0.4808 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [563/782] Loss: 0.3459 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [564/782] Loss: 0.4133 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [565/782] Loss: 0.3992 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [566/782] Loss: 0.2503 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [567/782] Loss: 0.4112 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [568/782] Loss: 0.5236 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [569/782] Loss: 0.3062 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [570/782] Loss: 0.6028 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [571/782] Loss: 0.3374 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [572/782] Loss: 0.4745 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [573/782] Loss: 0.2787 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [574/782] Loss: 0.3664 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [575/782] Loss: 0.3614 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [576/782] Loss: 0.5003 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [577/782] Loss: 0.3320 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [578/782] Loss: 0.3765 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [579/782] Loss: 0.4210 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [580/782] Loss: 0.4286 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [581/782] Loss: 0.4422 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [582/782] Loss: 0.5544 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [583/782] Loss: 0.6278 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [584/782] Loss: 0.3757 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [585/782] Loss: 0.3526 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [586/782] Loss: 0.3217 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [587/782] Loss: 0.4384 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [588/782] Loss: 0.6547 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [589/782] Loss: 0.4387 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [590/782] Loss: 0.3506 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [591/782] Loss: 0.5485 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [592/782] Loss: 0.6098 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [593/782] Loss: 0.5811 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [594/782] Loss: 0.2905 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [595/782] Loss: 0.4837 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [596/782] Loss: 0.6518 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [597/782] Loss: 0.4070 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [598/782] Loss: 0.5866 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [599/782] Loss: 0.4864 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [600/782] Loss: 0.4525 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [601/782] Loss: 0.4910 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [602/782] Loss: 0.6171 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [603/782] Loss: 0.3740 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [604/782] Loss: 0.1991 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [605/782] Loss: 0.3142 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [606/782] Loss: 0.2763 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [607/782] Loss: 0.4582 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [608/782] Loss: 0.4885 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [609/782] Loss: 0.5283 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [610/782] Loss: 0.5977 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [611/782] Loss: 0.4793 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [612/782] Loss: 0.3616 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [613/782] Loss: 0.3290 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [614/782] Loss: 0.2792 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [615/782] Loss: 0.4216 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [616/782] Loss: 0.6622 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [617/782] Loss: 0.4301 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [618/782] Loss: 0.6146 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [619/782] Loss: 0.2967 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [620/782] Loss: 0.4159 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [621/782] Loss: 0.4460 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [622/782] Loss: 0.5409 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [623/782] Loss: 0.7252 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [624/782] Loss: 0.4255 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [625/782] Loss: 0.3733 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [626/782] Loss: 0.4664 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [627/782] Loss: 0.3423 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [628/782] Loss: 0.4181 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [629/782] Loss: 0.4662 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [630/782] Loss: 0.4082 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [631/782] Loss: 0.5135 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [632/782] Loss: 0.4920 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [633/782] Loss: 0.4035 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [634/782] Loss: 0.5588 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [635/782] Loss: 0.6194 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [636/782] Loss: 0.5029 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [637/782] Loss: 0.3104 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [638/782] Loss: 0.4836 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [639/782] Loss: 0.6117 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [640/782] Loss: 0.4292 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [641/782] Loss: 0.4355 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [642/782] Loss: 0.4456 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [643/782] Loss: 0.3700 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [644/782] Loss: 0.3881 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [645/782] Loss: 0.4401 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [646/782] Loss: 0.3546 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [647/782] Loss: 0.3764 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [648/782] Loss: 0.4399 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [649/782] Loss: 0.3644 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [650/782] Loss: 0.4836 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [651/782] Loss: 0.2936 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [652/782] Loss: 0.6640 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [653/782] Loss: 0.4763 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [654/782] Loss: 0.4994 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [655/782] Loss: 0.2563 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [656/782] Loss: 0.3989 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [657/782] Loss: 0.3954 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [658/782] Loss: 0.4543 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [659/782] Loss: 0.4963 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [660/782] Loss: 0.5127 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [661/782] Loss: 0.2497 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [662/782] Loss: 0.5107 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [663/782] Loss: 0.3801 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [664/782] Loss: 0.4405 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [665/782] Loss: 0.3093 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [666/782] Loss: 0.6103 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [667/782] Loss: 0.4032 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [668/782] Loss: 0.2714 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [669/782] Loss: 0.3476 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [670/782] Loss: 0.4695 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [671/782] Loss: 0.3667 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [672/782] Loss: 0.3592 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [673/782] Loss: 0.2869 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [674/782] Loss: 0.3065 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [675/782] Loss: 0.4704 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [676/782] Loss: 0.3514 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [677/782] Loss: 0.4599 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [678/782] Loss: 0.3632 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [679/782] Loss: 0.7099 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [680/782] Loss: 0.4595 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [681/782] Loss: 0.5705 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [682/782] Loss: 0.5225 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [683/782] Loss: 0.3028 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [684/782] Loss: 0.4891 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [685/782] Loss: 0.6320 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [686/782] Loss: 0.4168 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [687/782] Loss: 0.2936 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [688/782] Loss: 0.4040 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [689/782] Loss: 0.2797 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [690/782] Loss: 0.5332 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [691/782] Loss: 0.5791 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [692/782] Loss: 0.4810 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [693/782] Loss: 0.6686 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [694/782] Loss: 0.4532 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [695/782] Loss: 0.5274 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [696/782] Loss: 0.3914 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [697/782] Loss: 0.4918 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [698/782] Loss: 0.4891 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [699/782] Loss: 0.5837 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [700/782] Loss: 0.4140 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [701/782] Loss: 0.3914 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [702/782] Loss: 0.4496 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [703/782] Loss: 0.3977 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [704/782] Loss: 0.4775 | Acc: 84.63%\n",
      "Train Epoch [88/100] Batch [705/782] Loss: 0.2857 | Acc: 84.64%\n",
      "Train Epoch [88/100] Batch [706/782] Loss: 0.2709 | Acc: 84.65%\n",
      "Train Epoch [88/100] Batch [707/782] Loss: 0.3008 | Acc: 84.66%\n",
      "Train Epoch [88/100] Batch [708/782] Loss: 0.2427 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [709/782] Loss: 0.5216 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [710/782] Loss: 0.4430 | Acc: 84.67%\n",
      "Train Epoch [88/100] Batch [711/782] Loss: 0.2631 | Acc: 84.68%\n",
      "Train Epoch [88/100] Batch [712/782] Loss: 0.2920 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [713/782] Loss: 0.4689 | Acc: 84.69%\n",
      "Train Epoch [88/100] Batch [714/782] Loss: 0.4360 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [715/782] Loss: 0.5746 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [716/782] Loss: 0.2689 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [717/782] Loss: 0.3633 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [718/782] Loss: 0.3828 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [719/782] Loss: 0.4560 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [720/782] Loss: 0.3010 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [721/782] Loss: 0.4295 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [722/782] Loss: 0.4797 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [723/782] Loss: 0.5084 | Acc: 84.70%\n",
      "Train Epoch [88/100] Batch [724/782] Loss: 0.3310 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [725/782] Loss: 0.5017 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [726/782] Loss: 0.3608 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [727/782] Loss: 0.3018 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [728/782] Loss: 0.4603 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [729/782] Loss: 0.3300 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [730/782] Loss: 0.5477 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [731/782] Loss: 0.3979 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [732/782] Loss: 0.4033 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [733/782] Loss: 0.4003 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [734/782] Loss: 0.3408 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [735/782] Loss: 0.5535 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [736/782] Loss: 0.4470 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [737/782] Loss: 0.4119 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [738/782] Loss: 0.2997 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [739/782] Loss: 0.4256 | Acc: 84.72%\n",
      "Train Epoch [88/100] Batch [740/782] Loss: 0.5248 | Acc: 84.71%\n",
      "Train Epoch [88/100] Batch [741/782] Loss: 0.2136 | Acc: 84.73%\n",
      "Train Epoch [88/100] Batch [742/782] Loss: 0.2716 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [743/782] Loss: 0.3250 | Acc: 84.74%\n",
      "Train Epoch [88/100] Batch [744/782] Loss: 0.3219 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [745/782] Loss: 0.4194 | Acc: 84.75%\n",
      "Train Epoch [88/100] Batch [746/782] Loss: 0.3689 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [747/782] Loss: 0.3874 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [748/782] Loss: 0.3396 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [749/782] Loss: 0.4920 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [750/782] Loss: 0.4481 | Acc: 84.76%\n",
      "Train Epoch [88/100] Batch [751/782] Loss: 0.3972 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [752/782] Loss: 0.4085 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [753/782] Loss: 0.3986 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [754/782] Loss: 0.4444 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [755/782] Loss: 0.3323 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [756/782] Loss: 0.2957 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [757/782] Loss: 0.3607 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [758/782] Loss: 0.3630 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [759/782] Loss: 0.4967 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [760/782] Loss: 0.4532 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [761/782] Loss: 0.6468 | Acc: 84.77%\n",
      "Train Epoch [88/100] Batch [762/782] Loss: 0.2256 | Acc: 84.78%\n",
      "Train Epoch [88/100] Batch [763/782] Loss: 0.4263 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [764/782] Loss: 0.3325 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [765/782] Loss: 0.5730 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [766/782] Loss: 0.3849 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [767/782] Loss: 0.2833 | Acc: 84.79%\n",
      "Train Epoch [88/100] Batch [768/782] Loss: 0.4479 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [769/782] Loss: 0.3950 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [770/782] Loss: 0.4667 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [771/782] Loss: 0.3775 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [772/782] Loss: 0.3197 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [773/782] Loss: 0.3635 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [774/782] Loss: 0.2937 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [775/782] Loss: 0.4433 | Acc: 84.80%\n",
      "Train Epoch [88/100] Batch [776/782] Loss: 0.2704 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [777/782] Loss: 0.5649 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [778/782] Loss: 0.3455 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [779/782] Loss: 0.5630 | Acc: 84.81%\n",
      "Train Epoch [88/100] Batch [780/782] Loss: 0.3529 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [781/782] Loss: 0.4586 | Acc: 84.82%\n",
      "Train Epoch [88/100] Batch [782/782] Loss: 0.1455 | Acc: 84.82%\n",
      "Epoch 88 completed in 31.05s.\n",
      "Test Epoch [88/100] Loss: 1.0118 | Acc: 72.14% | Inference Time: 8.72s\n",
      "Epoch 88 results saved to CSV.\n",
      "Epoch 89/100\n",
      "Train Epoch [89/100] Batch [1/782] Loss: 0.4749 | Acc: 81.25%\n",
      "Train Epoch [89/100] Batch [2/782] Loss: 0.4920 | Acc: 79.69%\n",
      "Train Epoch [89/100] Batch [3/782] Loss: 0.3592 | Acc: 81.77%\n",
      "Train Epoch [89/100] Batch [4/782] Loss: 0.4110 | Acc: 82.81%\n",
      "Train Epoch [89/100] Batch [5/782] Loss: 0.5378 | Acc: 83.12%\n",
      "Train Epoch [89/100] Batch [6/782] Loss: 0.3946 | Acc: 83.33%\n",
      "Train Epoch [89/100] Batch [7/782] Loss: 0.2805 | Acc: 84.38%\n",
      "Train Epoch [89/100] Batch [8/782] Loss: 0.6360 | Acc: 83.20%\n",
      "Train Epoch [89/100] Batch [9/782] Loss: 0.3858 | Acc: 84.03%\n",
      "Train Epoch [89/100] Batch [10/782] Loss: 0.6135 | Acc: 82.97%\n",
      "Train Epoch [89/100] Batch [11/782] Loss: 0.4814 | Acc: 83.10%\n",
      "Train Epoch [89/100] Batch [12/782] Loss: 0.3399 | Acc: 83.33%\n",
      "Train Epoch [89/100] Batch [13/782] Loss: 0.3057 | Acc: 83.89%\n",
      "Train Epoch [89/100] Batch [14/782] Loss: 0.3900 | Acc: 84.04%\n",
      "Train Epoch [89/100] Batch [15/782] Loss: 0.4802 | Acc: 84.17%\n",
      "Train Epoch [89/100] Batch [16/782] Loss: 0.3425 | Acc: 84.57%\n",
      "Train Epoch [89/100] Batch [17/782] Loss: 0.3357 | Acc: 84.83%\n",
      "Train Epoch [89/100] Batch [18/782] Loss: 0.3544 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [19/782] Loss: 0.5518 | Acc: 84.54%\n",
      "Train Epoch [89/100] Batch [20/782] Loss: 0.3775 | Acc: 84.77%\n",
      "Train Epoch [89/100] Batch [21/782] Loss: 0.3107 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [22/782] Loss: 0.3617 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [23/782] Loss: 0.5151 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [24/782] Loss: 0.3321 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [25/782] Loss: 0.6036 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [26/782] Loss: 0.5812 | Acc: 84.68%\n",
      "Train Epoch [89/100] Batch [27/782] Loss: 0.4194 | Acc: 84.55%\n",
      "Train Epoch [89/100] Batch [28/782] Loss: 0.4910 | Acc: 84.65%\n",
      "Train Epoch [89/100] Batch [29/782] Loss: 0.5281 | Acc: 84.43%\n",
      "Train Epoch [89/100] Batch [30/782] Loss: 0.3419 | Acc: 84.64%\n",
      "Train Epoch [89/100] Batch [31/782] Loss: 0.2596 | Acc: 84.83%\n",
      "Train Epoch [89/100] Batch [32/782] Loss: 0.3568 | Acc: 84.81%\n",
      "Train Epoch [89/100] Batch [33/782] Loss: 0.3692 | Acc: 84.85%\n",
      "Train Epoch [89/100] Batch [34/782] Loss: 0.3471 | Acc: 84.88%\n",
      "Train Epoch [89/100] Batch [35/782] Loss: 0.3025 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [36/782] Loss: 0.5268 | Acc: 84.90%\n",
      "Train Epoch [89/100] Batch [37/782] Loss: 0.3248 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [38/782] Loss: 0.3796 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [39/782] Loss: 0.3283 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [40/782] Loss: 0.4401 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [41/782] Loss: 0.3843 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [42/782] Loss: 0.3793 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [43/782] Loss: 0.4001 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [44/782] Loss: 0.3293 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [45/782] Loss: 0.4635 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [46/782] Loss: 0.2538 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [47/782] Loss: 0.2983 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [48/782] Loss: 0.3941 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [49/782] Loss: 0.5238 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [50/782] Loss: 0.3914 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [51/782] Loss: 0.3242 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [52/782] Loss: 0.3774 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [53/782] Loss: 0.3906 | Acc: 85.35%\n",
      "Train Epoch [89/100] Batch [54/782] Loss: 0.2920 | Acc: 85.47%\n",
      "Train Epoch [89/100] Batch [55/782] Loss: 0.2850 | Acc: 85.60%\n",
      "Train Epoch [89/100] Batch [56/782] Loss: 0.4127 | Acc: 85.63%\n",
      "Train Epoch [89/100] Batch [57/782] Loss: 0.6021 | Acc: 85.53%\n",
      "Train Epoch [89/100] Batch [58/782] Loss: 0.5494 | Acc: 85.51%\n",
      "Train Epoch [89/100] Batch [59/782] Loss: 0.4963 | Acc: 85.41%\n",
      "Train Epoch [89/100] Batch [60/782] Loss: 0.3263 | Acc: 85.47%\n",
      "Train Epoch [89/100] Batch [61/782] Loss: 0.4095 | Acc: 85.43%\n",
      "Train Epoch [89/100] Batch [62/782] Loss: 0.4085 | Acc: 85.36%\n",
      "Train Epoch [89/100] Batch [63/782] Loss: 0.6123 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [64/782] Loss: 0.2778 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [65/782] Loss: 0.4003 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [66/782] Loss: 0.3794 | Acc: 85.39%\n",
      "Train Epoch [89/100] Batch [67/782] Loss: 0.4626 | Acc: 85.38%\n",
      "Train Epoch [89/100] Batch [68/782] Loss: 0.4899 | Acc: 85.39%\n",
      "Train Epoch [89/100] Batch [69/782] Loss: 0.4096 | Acc: 85.44%\n",
      "Train Epoch [89/100] Batch [70/782] Loss: 0.3828 | Acc: 85.47%\n",
      "Train Epoch [89/100] Batch [71/782] Loss: 0.5293 | Acc: 85.39%\n",
      "Train Epoch [89/100] Batch [72/782] Loss: 0.4838 | Acc: 85.33%\n",
      "Train Epoch [89/100] Batch [73/782] Loss: 0.4867 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [74/782] Loss: 0.4173 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [75/782] Loss: 0.2285 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [76/782] Loss: 0.4100 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [77/782] Loss: 0.6364 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [78/782] Loss: 0.3230 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [79/782] Loss: 0.5006 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [80/782] Loss: 0.4620 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [81/782] Loss: 0.3760 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [82/782] Loss: 0.6028 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [83/782] Loss: 0.4399 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [84/782] Loss: 0.4601 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [85/782] Loss: 0.5150 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [86/782] Loss: 0.3759 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [87/782] Loss: 0.3639 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [88/782] Loss: 0.3332 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [89/782] Loss: 0.3715 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [90/782] Loss: 0.4754 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [91/782] Loss: 0.5663 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [92/782] Loss: 0.4361 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [93/782] Loss: 0.5342 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [94/782] Loss: 0.3653 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [95/782] Loss: 0.1759 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [96/782] Loss: 0.3494 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [97/782] Loss: 0.3069 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [98/782] Loss: 0.3999 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [99/782] Loss: 0.4458 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [100/782] Loss: 0.5095 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [101/782] Loss: 0.3787 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [102/782] Loss: 0.5071 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [103/782] Loss: 0.3693 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [104/782] Loss: 0.2872 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [105/782] Loss: 0.4695 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [106/782] Loss: 0.3960 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [107/782] Loss: 0.6850 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [108/782] Loss: 0.5014 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [109/782] Loss: 0.5320 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [110/782] Loss: 0.3918 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [111/782] Loss: 0.4228 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [112/782] Loss: 0.4302 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [113/782] Loss: 0.4720 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [114/782] Loss: 0.4563 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [115/782] Loss: 0.3372 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [116/782] Loss: 0.4274 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [117/782] Loss: 0.3654 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [118/782] Loss: 0.4354 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [119/782] Loss: 0.3259 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [120/782] Loss: 0.4953 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [121/782] Loss: 0.3291 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [122/782] Loss: 0.4491 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [123/782] Loss: 0.3090 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [124/782] Loss: 0.5197 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [125/782] Loss: 0.4648 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [126/782] Loss: 0.4384 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [127/782] Loss: 0.3032 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [128/782] Loss: 0.3026 | Acc: 85.33%\n",
      "Train Epoch [89/100] Batch [129/782] Loss: 0.4134 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [130/782] Loss: 0.3669 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [131/782] Loss: 0.5092 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [132/782] Loss: 0.3575 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [133/782] Loss: 0.4862 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [134/782] Loss: 0.3751 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [135/782] Loss: 0.3898 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [136/782] Loss: 0.4560 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [137/782] Loss: 0.4508 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [138/782] Loss: 0.3046 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [139/782] Loss: 0.3747 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [140/782] Loss: 0.5690 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [141/782] Loss: 0.3151 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [142/782] Loss: 0.5700 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [143/782] Loss: 0.6580 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [144/782] Loss: 0.4712 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [145/782] Loss: 0.2789 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [146/782] Loss: 0.5314 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [147/782] Loss: 0.2533 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [148/782] Loss: 0.4029 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [149/782] Loss: 0.5124 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [150/782] Loss: 0.2786 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [151/782] Loss: 0.4504 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [152/782] Loss: 0.3552 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [153/782] Loss: 0.4285 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [154/782] Loss: 0.3988 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [155/782] Loss: 0.4245 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [156/782] Loss: 0.3417 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [157/782] Loss: 0.3721 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [158/782] Loss: 0.6769 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [159/782] Loss: 0.4434 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [160/782] Loss: 0.3430 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [161/782] Loss: 0.4801 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [162/782] Loss: 0.4329 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [163/782] Loss: 0.5381 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [164/782] Loss: 0.3397 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [165/782] Loss: 0.3857 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [166/782] Loss: 0.3092 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [167/782] Loss: 0.5427 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [168/782] Loss: 0.3551 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [169/782] Loss: 0.4648 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [170/782] Loss: 0.3644 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [171/782] Loss: 0.4347 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [172/782] Loss: 0.5346 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [173/782] Loss: 0.4567 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [174/782] Loss: 0.3783 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [175/782] Loss: 0.3212 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [176/782] Loss: 0.3954 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [177/782] Loss: 0.3387 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [178/782] Loss: 0.4920 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [179/782] Loss: 0.3187 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [180/782] Loss: 0.3337 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [181/782] Loss: 0.4471 | Acc: 85.33%\n",
      "Train Epoch [89/100] Batch [182/782] Loss: 0.2626 | Acc: 85.36%\n",
      "Train Epoch [89/100] Batch [183/782] Loss: 0.6335 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [184/782] Loss: 0.5607 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [185/782] Loss: 0.4237 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [186/782] Loss: 0.3327 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [187/782] Loss: 0.3338 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [188/782] Loss: 0.3089 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [189/782] Loss: 0.2662 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [190/782] Loss: 0.4631 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [191/782] Loss: 0.3598 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [192/782] Loss: 0.3847 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [193/782] Loss: 0.3489 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [194/782] Loss: 0.4009 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [195/782] Loss: 0.5008 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [196/782] Loss: 0.3841 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [197/782] Loss: 0.3851 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [198/782] Loss: 0.4303 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [199/782] Loss: 0.5148 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [200/782] Loss: 0.5673 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [201/782] Loss: 0.5031 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [202/782] Loss: 0.4407 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [203/782] Loss: 0.2903 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [204/782] Loss: 0.2849 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [205/782] Loss: 0.4699 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [206/782] Loss: 0.3937 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [207/782] Loss: 0.4975 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [208/782] Loss: 0.4272 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [209/782] Loss: 0.2805 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [210/782] Loss: 0.4985 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [211/782] Loss: 0.6748 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [212/782] Loss: 0.2176 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [213/782] Loss: 0.1724 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [214/782] Loss: 0.3066 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [215/782] Loss: 0.6093 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [216/782] Loss: 0.4034 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [217/782] Loss: 0.4082 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [218/782] Loss: 0.4566 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [219/782] Loss: 0.4233 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [220/782] Loss: 0.4353 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [221/782] Loss: 0.4937 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [222/782] Loss: 0.4738 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [223/782] Loss: 0.1480 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [224/782] Loss: 0.3569 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [225/782] Loss: 0.2232 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [226/782] Loss: 0.4278 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [227/782] Loss: 0.3107 | Acc: 85.33%\n",
      "Train Epoch [89/100] Batch [228/782] Loss: 0.3311 | Acc: 85.35%\n",
      "Train Epoch [89/100] Batch [229/782] Loss: 0.6508 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [230/782] Loss: 0.4477 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [231/782] Loss: 0.6071 | Acc: 85.27%\n",
      "Train Epoch [89/100] Batch [232/782] Loss: 0.4543 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [233/782] Loss: 0.5876 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [234/782] Loss: 0.6938 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [235/782] Loss: 0.3074 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [236/782] Loss: 0.2938 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [237/782] Loss: 0.3058 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [238/782] Loss: 0.5609 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [239/782] Loss: 0.3107 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [240/782] Loss: 0.4022 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [241/782] Loss: 0.5162 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [242/782] Loss: 0.3522 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [243/782] Loss: 0.4738 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [244/782] Loss: 0.2871 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [245/782] Loss: 0.3026 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [246/782] Loss: 0.3563 | Acc: 85.28%\n",
      "Train Epoch [89/100] Batch [247/782] Loss: 0.4708 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [248/782] Loss: 0.2904 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [249/782] Loss: 0.3390 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [250/782] Loss: 0.4516 | Acc: 85.32%\n",
      "Train Epoch [89/100] Batch [251/782] Loss: 0.4722 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [252/782] Loss: 0.3017 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [253/782] Loss: 0.3154 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [254/782] Loss: 0.5465 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [255/782] Loss: 0.4318 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [256/782] Loss: 0.4101 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [257/782] Loss: 0.3044 | Acc: 85.33%\n",
      "Train Epoch [89/100] Batch [258/782] Loss: 0.3823 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [259/782] Loss: 0.4755 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [260/782] Loss: 0.4446 | Acc: 85.34%\n",
      "Train Epoch [89/100] Batch [261/782] Loss: 0.3866 | Acc: 85.35%\n",
      "Train Epoch [89/100] Batch [262/782] Loss: 0.4217 | Acc: 85.36%\n",
      "Train Epoch [89/100] Batch [263/782] Loss: 0.2857 | Acc: 85.38%\n",
      "Train Epoch [89/100] Batch [264/782] Loss: 0.3392 | Acc: 85.39%\n",
      "Train Epoch [89/100] Batch [265/782] Loss: 0.3647 | Acc: 85.41%\n",
      "Train Epoch [89/100] Batch [266/782] Loss: 0.4411 | Acc: 85.40%\n",
      "Train Epoch [89/100] Batch [267/782] Loss: 0.3799 | Acc: 85.38%\n",
      "Train Epoch [89/100] Batch [268/782] Loss: 0.3327 | Acc: 85.40%\n",
      "Train Epoch [89/100] Batch [269/782] Loss: 0.3824 | Acc: 85.40%\n",
      "Train Epoch [89/100] Batch [270/782] Loss: 0.6271 | Acc: 85.36%\n",
      "Train Epoch [89/100] Batch [271/782] Loss: 0.6179 | Acc: 85.31%\n",
      "Train Epoch [89/100] Batch [272/782] Loss: 0.5876 | Acc: 85.29%\n",
      "Train Epoch [89/100] Batch [273/782] Loss: 0.3396 | Acc: 85.30%\n",
      "Train Epoch [89/100] Batch [274/782] Loss: 0.6685 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [275/782] Loss: 0.4061 | Acc: 85.26%\n",
      "Train Epoch [89/100] Batch [276/782] Loss: 0.5322 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [277/782] Loss: 0.4580 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [278/782] Loss: 0.4379 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [279/782] Loss: 0.3775 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [280/782] Loss: 0.3046 | Acc: 85.25%\n",
      "Train Epoch [89/100] Batch [281/782] Loss: 0.3928 | Acc: 85.24%\n",
      "Train Epoch [89/100] Batch [282/782] Loss: 0.3887 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [283/782] Loss: 0.3846 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [284/782] Loss: 0.5111 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [285/782] Loss: 0.6065 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [286/782] Loss: 0.4577 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [287/782] Loss: 0.4686 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [288/782] Loss: 0.4750 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [289/782] Loss: 0.3825 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [290/782] Loss: 0.4572 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [291/782] Loss: 0.4301 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [292/782] Loss: 0.3471 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [293/782] Loss: 0.3489 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [294/782] Loss: 0.4179 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [295/782] Loss: 0.4357 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [296/782] Loss: 0.4812 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [297/782] Loss: 0.5906 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [298/782] Loss: 0.3752 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [299/782] Loss: 0.2960 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [300/782] Loss: 0.3006 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [301/782] Loss: 0.5595 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [302/782] Loss: 0.2773 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [303/782] Loss: 0.2891 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [304/782] Loss: 0.2023 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [305/782] Loss: 0.3595 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [306/782] Loss: 0.5216 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [307/782] Loss: 0.5312 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [308/782] Loss: 0.3172 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [309/782] Loss: 0.4565 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [310/782] Loss: 0.3626 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [311/782] Loss: 0.4084 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [312/782] Loss: 0.4209 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [313/782] Loss: 0.4574 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [314/782] Loss: 0.3552 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [315/782] Loss: 0.4051 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [316/782] Loss: 0.4577 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [317/782] Loss: 0.4123 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [318/782] Loss: 0.5788 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [319/782] Loss: 0.2464 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [320/782] Loss: 0.4438 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [321/782] Loss: 0.2595 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [322/782] Loss: 0.4005 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [323/782] Loss: 0.3275 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [324/782] Loss: 0.3624 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [325/782] Loss: 0.4259 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [326/782] Loss: 0.4682 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [327/782] Loss: 0.3383 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [328/782] Loss: 0.6851 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [329/782] Loss: 0.5397 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [330/782] Loss: 0.4160 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [331/782] Loss: 0.4702 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [332/782] Loss: 0.4469 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [333/782] Loss: 0.2868 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [334/782] Loss: 0.3176 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [335/782] Loss: 0.3409 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [336/782] Loss: 0.5319 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [337/782] Loss: 0.4312 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [338/782] Loss: 0.3354 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [339/782] Loss: 0.4656 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [340/782] Loss: 0.3555 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [341/782] Loss: 0.3995 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [342/782] Loss: 0.2724 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [343/782] Loss: 0.4933 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [344/782] Loss: 0.3634 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [345/782] Loss: 0.3561 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [346/782] Loss: 0.2797 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [347/782] Loss: 0.4689 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [348/782] Loss: 0.3267 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [349/782] Loss: 0.4780 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [350/782] Loss: 0.4058 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [351/782] Loss: 0.4814 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [352/782] Loss: 0.6652 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [353/782] Loss: 0.4254 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [354/782] Loss: 0.4179 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [355/782] Loss: 0.3563 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [356/782] Loss: 0.4022 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [357/782] Loss: 0.5284 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [358/782] Loss: 0.4255 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [359/782] Loss: 0.2304 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [360/782] Loss: 0.4055 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [361/782] Loss: 0.7234 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [362/782] Loss: 0.3620 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [363/782] Loss: 0.3780 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [364/782] Loss: 0.4129 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [365/782] Loss: 0.4586 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [366/782] Loss: 0.3142 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [367/782] Loss: 0.2337 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [368/782] Loss: 0.4461 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [369/782] Loss: 0.4430 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [370/782] Loss: 0.2818 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [371/782] Loss: 0.4928 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [372/782] Loss: 0.4151 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [373/782] Loss: 0.3908 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [374/782] Loss: 0.3480 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [375/782] Loss: 0.3800 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [376/782] Loss: 0.3284 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [377/782] Loss: 0.4637 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [378/782] Loss: 0.3431 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [379/782] Loss: 0.4807 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [380/782] Loss: 0.4217 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [381/782] Loss: 0.3545 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [382/782] Loss: 0.5282 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [383/782] Loss: 0.4359 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [384/782] Loss: 0.6012 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [385/782] Loss: 0.4395 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [386/782] Loss: 0.5595 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [387/782] Loss: 0.3786 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [388/782] Loss: 0.5523 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [389/782] Loss: 0.6649 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [390/782] Loss: 0.4513 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [391/782] Loss: 0.3581 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [392/782] Loss: 0.3877 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [393/782] Loss: 0.3581 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [394/782] Loss: 0.3107 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [395/782] Loss: 0.3288 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [396/782] Loss: 0.2278 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [397/782] Loss: 0.4366 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [398/782] Loss: 0.5382 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [399/782] Loss: 0.4333 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [400/782] Loss: 0.2544 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [401/782] Loss: 0.5433 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [402/782] Loss: 0.4595 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [403/782] Loss: 0.2596 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [404/782] Loss: 0.6026 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [405/782] Loss: 0.2620 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [406/782] Loss: 0.5364 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [407/782] Loss: 0.3587 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [408/782] Loss: 0.5286 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [409/782] Loss: 0.4871 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [410/782] Loss: 0.5453 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [411/782] Loss: 0.2501 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [412/782] Loss: 0.3063 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [413/782] Loss: 0.4229 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [414/782] Loss: 0.2956 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [415/782] Loss: 0.3034 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [416/782] Loss: 0.3179 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [417/782] Loss: 0.4495 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [418/782] Loss: 0.4044 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [419/782] Loss: 0.3657 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [420/782] Loss: 0.3308 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [421/782] Loss: 0.7480 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [422/782] Loss: 0.4084 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [423/782] Loss: 0.3010 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [424/782] Loss: 0.2865 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [425/782] Loss: 0.2450 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [426/782] Loss: 0.4927 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [427/782] Loss: 0.4970 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [428/782] Loss: 0.2315 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [429/782] Loss: 0.3771 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [430/782] Loss: 0.4168 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [431/782] Loss: 0.4209 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [432/782] Loss: 0.5704 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [433/782] Loss: 0.4717 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [434/782] Loss: 0.6307 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [435/782] Loss: 0.4313 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [436/782] Loss: 0.3653 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [437/782] Loss: 0.4507 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [438/782] Loss: 0.3784 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [439/782] Loss: 0.4225 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [440/782] Loss: 0.2720 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [441/782] Loss: 0.3513 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [442/782] Loss: 0.4478 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [443/782] Loss: 0.3709 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [444/782] Loss: 0.4365 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [445/782] Loss: 0.2495 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [446/782] Loss: 0.6079 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [447/782] Loss: 0.1818 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [448/782] Loss: 0.2890 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [449/782] Loss: 0.5323 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [450/782] Loss: 0.6083 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [451/782] Loss: 0.4729 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [452/782] Loss: 0.3182 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [453/782] Loss: 0.3316 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [454/782] Loss: 0.4420 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [455/782] Loss: 0.2551 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [456/782] Loss: 0.4637 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [457/782] Loss: 0.3859 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [458/782] Loss: 0.3678 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [459/782] Loss: 0.3018 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [460/782] Loss: 0.2632 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [461/782] Loss: 0.4918 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [462/782] Loss: 0.3434 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [463/782] Loss: 0.3650 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [464/782] Loss: 0.2742 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [465/782] Loss: 0.4342 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [466/782] Loss: 0.3579 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [467/782] Loss: 0.3447 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [468/782] Loss: 0.5391 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [469/782] Loss: 0.4531 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [470/782] Loss: 0.4315 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [471/782] Loss: 0.4142 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [472/782] Loss: 0.4264 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [473/782] Loss: 0.3689 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [474/782] Loss: 0.4476 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [475/782] Loss: 0.4637 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [476/782] Loss: 0.3113 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [477/782] Loss: 0.4139 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [478/782] Loss: 0.4852 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [479/782] Loss: 0.2744 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [480/782] Loss: 0.5262 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [481/782] Loss: 0.3154 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [482/782] Loss: 0.3425 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [483/782] Loss: 0.4058 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [484/782] Loss: 0.5024 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [485/782] Loss: 0.4591 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [486/782] Loss: 0.3928 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [487/782] Loss: 0.3306 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [488/782] Loss: 0.5468 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [489/782] Loss: 0.2747 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [490/782] Loss: 0.4396 | Acc: 85.23%\n",
      "Train Epoch [89/100] Batch [491/782] Loss: 0.3737 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [492/782] Loss: 0.4728 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [493/782] Loss: 0.4894 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [494/782] Loss: 0.2918 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [495/782] Loss: 0.4487 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [496/782] Loss: 0.6200 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [497/782] Loss: 0.3303 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [498/782] Loss: 0.4405 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [499/782] Loss: 0.3102 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [500/782] Loss: 0.4180 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [501/782] Loss: 0.5275 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [502/782] Loss: 0.4738 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [503/782] Loss: 0.4600 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [504/782] Loss: 0.4007 | Acc: 85.21%\n",
      "Train Epoch [89/100] Batch [505/782] Loss: 0.2755 | Acc: 85.22%\n",
      "Train Epoch [89/100] Batch [506/782] Loss: 0.6424 | Acc: 85.20%\n",
      "Train Epoch [89/100] Batch [507/782] Loss: 0.5161 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [508/782] Loss: 0.5439 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [509/782] Loss: 0.4280 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [510/782] Loss: 0.4294 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [511/782] Loss: 0.5352 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [512/782] Loss: 0.2685 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [513/782] Loss: 0.3779 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [514/782] Loss: 0.3866 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [515/782] Loss: 0.3844 | Acc: 85.18%\n",
      "Train Epoch [89/100] Batch [516/782] Loss: 0.3308 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [517/782] Loss: 0.4149 | Acc: 85.19%\n",
      "Train Epoch [89/100] Batch [518/782] Loss: 0.6352 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [519/782] Loss: 0.4014 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [520/782] Loss: 0.5056 | Acc: 85.16%\n",
      "Train Epoch [89/100] Batch [521/782] Loss: 0.2994 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [522/782] Loss: 0.3659 | Acc: 85.17%\n",
      "Train Epoch [89/100] Batch [523/782] Loss: 0.6017 | Acc: 85.15%\n",
      "Train Epoch [89/100] Batch [524/782] Loss: 0.5833 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [525/782] Loss: 0.4828 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [526/782] Loss: 0.6227 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [527/782] Loss: 0.6226 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [528/782] Loss: 0.2658 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [529/782] Loss: 0.3671 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [530/782] Loss: 0.3307 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [531/782] Loss: 0.2743 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [532/782] Loss: 0.4667 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [533/782] Loss: 0.3517 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [534/782] Loss: 0.3904 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [535/782] Loss: 0.3087 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [536/782] Loss: 0.5124 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [537/782] Loss: 0.3946 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [538/782] Loss: 0.2978 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [539/782] Loss: 0.5587 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [540/782] Loss: 0.3973 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [541/782] Loss: 0.3379 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [542/782] Loss: 0.5288 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [543/782] Loss: 0.6398 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [544/782] Loss: 0.3797 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [545/782] Loss: 0.3771 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [546/782] Loss: 0.5185 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [547/782] Loss: 0.4006 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [548/782] Loss: 0.5707 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [549/782] Loss: 0.5826 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [550/782] Loss: 0.4662 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [551/782] Loss: 0.2668 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [552/782] Loss: 0.2920 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [553/782] Loss: 0.3374 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [554/782] Loss: 0.2339 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [555/782] Loss: 0.2909 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [556/782] Loss: 0.3728 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [557/782] Loss: 0.2241 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [558/782] Loss: 0.4804 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [559/782] Loss: 0.5687 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [560/782] Loss: 0.3808 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [561/782] Loss: 0.5177 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [562/782] Loss: 0.2938 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [563/782] Loss: 0.3824 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [564/782] Loss: 0.3951 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [565/782] Loss: 0.3388 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [566/782] Loss: 0.3068 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [567/782] Loss: 0.3947 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [568/782] Loss: 0.2945 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [569/782] Loss: 0.3982 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [570/782] Loss: 0.3630 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [571/782] Loss: 0.3700 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [572/782] Loss: 0.6734 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [573/782] Loss: 0.4293 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [574/782] Loss: 0.3781 | Acc: 85.14%\n",
      "Train Epoch [89/100] Batch [575/782] Loss: 0.5303 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [576/782] Loss: 0.4290 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [577/782] Loss: 0.4434 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [578/782] Loss: 0.4960 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [579/782] Loss: 0.4788 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [580/782] Loss: 0.3001 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [581/782] Loss: 0.4317 | Acc: 85.13%\n",
      "Train Epoch [89/100] Batch [582/782] Loss: 0.6454 | Acc: 85.12%\n",
      "Train Epoch [89/100] Batch [583/782] Loss: 0.3365 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [584/782] Loss: 0.3698 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [585/782] Loss: 0.5927 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [586/782] Loss: 0.4851 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [587/782] Loss: 0.4717 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [588/782] Loss: 0.3187 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [589/782] Loss: 0.5521 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [590/782] Loss: 0.3712 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [591/782] Loss: 0.3012 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [592/782] Loss: 0.3447 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [593/782] Loss: 0.6089 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [594/782] Loss: 0.4153 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [595/782] Loss: 0.3566 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [596/782] Loss: 0.4807 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [597/782] Loss: 0.3345 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [598/782] Loss: 0.4785 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [599/782] Loss: 0.4504 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [600/782] Loss: 0.6297 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [601/782] Loss: 0.3787 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [602/782] Loss: 0.3243 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [603/782] Loss: 0.3207 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [604/782] Loss: 0.4383 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [605/782] Loss: 0.5269 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [606/782] Loss: 0.3345 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [607/782] Loss: 0.2960 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [608/782] Loss: 0.4405 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [609/782] Loss: 0.2576 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [610/782] Loss: 0.2510 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [611/782] Loss: 0.3480 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [612/782] Loss: 0.3195 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [613/782] Loss: 0.4236 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [614/782] Loss: 0.5482 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [615/782] Loss: 0.4975 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [616/782] Loss: 0.4023 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [617/782] Loss: 0.3821 | Acc: 85.11%\n",
      "Train Epoch [89/100] Batch [618/782] Loss: 0.4743 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [619/782] Loss: 0.4944 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [620/782] Loss: 0.3688 | Acc: 85.10%\n",
      "Train Epoch [89/100] Batch [621/782] Loss: 0.5357 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [622/782] Loss: 0.6132 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [623/782] Loss: 0.4199 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [624/782] Loss: 0.3597 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [625/782] Loss: 0.3034 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [626/782] Loss: 0.4764 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [627/782] Loss: 0.5721 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [628/782] Loss: 0.4204 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [629/782] Loss: 0.4737 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [630/782] Loss: 0.3529 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [631/782] Loss: 0.4676 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [632/782] Loss: 0.4483 | Acc: 85.09%\n",
      "Train Epoch [89/100] Batch [633/782] Loss: 0.4135 | Acc: 85.08%\n",
      "Train Epoch [89/100] Batch [634/782] Loss: 0.4771 | Acc: 85.07%\n",
      "Train Epoch [89/100] Batch [635/782] Loss: 0.5278 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [636/782] Loss: 0.5077 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [637/782] Loss: 0.3203 | Acc: 85.06%\n",
      "Train Epoch [89/100] Batch [638/782] Loss: 0.6467 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [639/782] Loss: 0.5707 | Acc: 85.04%\n",
      "Train Epoch [89/100] Batch [640/782] Loss: 0.4630 | Acc: 85.04%\n",
      "Train Epoch [89/100] Batch [641/782] Loss: 0.2787 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [642/782] Loss: 0.2843 | Acc: 85.05%\n",
      "Train Epoch [89/100] Batch [643/782] Loss: 0.5924 | Acc: 85.04%\n",
      "Train Epoch [89/100] Batch [644/782] Loss: 0.4028 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [645/782] Loss: 0.4602 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [646/782] Loss: 0.4411 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [647/782] Loss: 0.5149 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [648/782] Loss: 0.4133 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [649/782] Loss: 0.6067 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [650/782] Loss: 0.4354 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [651/782] Loss: 0.4363 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [652/782] Loss: 0.4108 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [653/782] Loss: 0.5960 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [654/782] Loss: 0.4670 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [655/782] Loss: 0.5098 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [656/782] Loss: 0.3375 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [657/782] Loss: 0.5685 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [658/782] Loss: 0.3839 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [659/782] Loss: 0.4397 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [660/782] Loss: 0.3176 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [661/782] Loss: 0.5642 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [662/782] Loss: 0.2836 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [663/782] Loss: 0.2674 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [664/782] Loss: 0.6216 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [665/782] Loss: 0.4148 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [666/782] Loss: 0.2821 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [667/782] Loss: 0.5785 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [668/782] Loss: 0.2484 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [669/782] Loss: 0.5043 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [670/782] Loss: 0.4120 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [671/782] Loss: 0.4291 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [672/782] Loss: 0.4674 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [673/782] Loss: 0.4155 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [674/782] Loss: 0.2669 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [675/782] Loss: 0.3595 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [676/782] Loss: 0.5908 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [677/782] Loss: 0.5802 | Acc: 84.95%\n",
      "Train Epoch [89/100] Batch [678/782] Loss: 0.1982 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [679/782] Loss: 0.3854 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [680/782] Loss: 0.3711 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [681/782] Loss: 0.4139 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [682/782] Loss: 0.5096 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [683/782] Loss: 0.4852 | Acc: 84.95%\n",
      "Train Epoch [89/100] Batch [684/782] Loss: 0.6085 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [685/782] Loss: 0.2712 | Acc: 84.95%\n",
      "Train Epoch [89/100] Batch [686/782] Loss: 0.4737 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [687/782] Loss: 0.4815 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [688/782] Loss: 0.3506 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [689/782] Loss: 0.3388 | Acc: 84.94%\n",
      "Train Epoch [89/100] Batch [690/782] Loss: 0.3523 | Acc: 84.95%\n",
      "Train Epoch [89/100] Batch [691/782] Loss: 0.2517 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [692/782] Loss: 0.3478 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [693/782] Loss: 0.2830 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [694/782] Loss: 0.3437 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [695/782] Loss: 0.4679 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [696/782] Loss: 0.4043 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [697/782] Loss: 0.4364 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [698/782] Loss: 0.5569 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [699/782] Loss: 0.4462 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [700/782] Loss: 0.3176 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [701/782] Loss: 0.4287 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [702/782] Loss: 0.4939 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [703/782] Loss: 0.2826 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [704/782] Loss: 0.3138 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [705/782] Loss: 0.6297 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [706/782] Loss: 0.3615 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [707/782] Loss: 0.4096 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [708/782] Loss: 0.4748 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [709/782] Loss: 0.4735 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [710/782] Loss: 0.3167 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [711/782] Loss: 0.3255 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [712/782] Loss: 0.4125 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [713/782] Loss: 0.2753 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [714/782] Loss: 0.3997 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [715/782] Loss: 0.4083 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [716/782] Loss: 0.6603 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [717/782] Loss: 0.4554 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [718/782] Loss: 0.4578 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [719/782] Loss: 0.2650 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [720/782] Loss: 0.3445 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [721/782] Loss: 0.3523 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [722/782] Loss: 0.4085 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [723/782] Loss: 0.4194 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [724/782] Loss: 0.4605 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [725/782] Loss: 0.3136 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [726/782] Loss: 0.4660 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [727/782] Loss: 0.3673 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [728/782] Loss: 0.4870 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [729/782] Loss: 0.4354 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [730/782] Loss: 0.5184 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [731/782] Loss: 0.3427 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [732/782] Loss: 0.3822 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [733/782] Loss: 0.3717 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [734/782] Loss: 0.3940 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [735/782] Loss: 0.4216 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [736/782] Loss: 0.4660 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [737/782] Loss: 0.3321 | Acc: 84.96%\n",
      "Train Epoch [89/100] Batch [738/782] Loss: 0.3605 | Acc: 84.97%\n",
      "Train Epoch [89/100] Batch [739/782] Loss: 0.4882 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [740/782] Loss: 0.3075 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [741/782] Loss: 0.3721 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [742/782] Loss: 0.3688 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [743/782] Loss: 0.2722 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [744/782] Loss: 0.4087 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [745/782] Loss: 0.3164 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [746/782] Loss: 0.5623 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [747/782] Loss: 0.6310 | Acc: 84.98%\n",
      "Train Epoch [89/100] Batch [748/782] Loss: 0.1926 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [749/782] Loss: 0.2935 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [750/782] Loss: 0.3168 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [751/782] Loss: 0.4092 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [752/782] Loss: 0.3893 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [753/782] Loss: 0.4499 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [754/782] Loss: 0.6580 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [755/782] Loss: 0.4402 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [756/782] Loss: 0.3608 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [757/782] Loss: 0.5463 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [758/782] Loss: 0.4188 | Acc: 84.99%\n",
      "Train Epoch [89/100] Batch [759/782] Loss: 0.2593 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [760/782] Loss: 0.5005 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [761/782] Loss: 0.3846 | Acc: 85.00%\n",
      "Train Epoch [89/100] Batch [762/782] Loss: 0.3697 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [763/782] Loss: 0.2682 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [764/782] Loss: 0.4454 | Acc: 85.01%\n",
      "Train Epoch [89/100] Batch [765/782] Loss: 0.2979 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [766/782] Loss: 0.5215 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [767/782] Loss: 0.3484 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [768/782] Loss: 0.3520 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [769/782] Loss: 0.4080 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [770/782] Loss: 0.3418 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [771/782] Loss: 0.2757 | Acc: 85.04%\n",
      "Train Epoch [89/100] Batch [772/782] Loss: 0.5216 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [773/782] Loss: 0.5076 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [774/782] Loss: 0.6429 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [775/782] Loss: 0.2694 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [776/782] Loss: 0.4070 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [777/782] Loss: 0.4618 | Acc: 85.02%\n",
      "Train Epoch [89/100] Batch [778/782] Loss: 0.3915 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [779/782] Loss: 0.3637 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [780/782] Loss: 0.4962 | Acc: 85.03%\n",
      "Train Epoch [89/100] Batch [781/782] Loss: 0.3538 | Acc: 85.04%\n",
      "Train Epoch [89/100] Batch [782/782] Loss: 0.5331 | Acc: 85.03%\n",
      "Epoch 89 completed in 30.77s.\n",
      "Test Epoch [89/100] Loss: 1.0178 | Acc: 71.93% | Inference Time: 8.61s\n",
      "Epoch 89 results saved to CSV.\n",
      "Epoch 90/100\n",
      "Train Epoch [90/100] Batch [1/782] Loss: 0.2816 | Acc: 87.50%\n",
      "Train Epoch [90/100] Batch [2/782] Loss: 0.3429 | Acc: 88.28%\n",
      "Train Epoch [90/100] Batch [3/782] Loss: 0.4565 | Acc: 85.42%\n",
      "Train Epoch [90/100] Batch [4/782] Loss: 0.3835 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [5/782] Loss: 0.4317 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [6/782] Loss: 0.3841 | Acc: 86.46%\n",
      "Train Epoch [90/100] Batch [7/782] Loss: 0.5601 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [8/782] Loss: 0.3884 | Acc: 86.13%\n",
      "Train Epoch [90/100] Batch [9/782] Loss: 0.3678 | Acc: 86.81%\n",
      "Train Epoch [90/100] Batch [10/782] Loss: 0.4583 | Acc: 85.78%\n",
      "Train Epoch [90/100] Batch [11/782] Loss: 0.3759 | Acc: 86.36%\n",
      "Train Epoch [90/100] Batch [12/782] Loss: 0.2614 | Acc: 86.59%\n",
      "Train Epoch [90/100] Batch [13/782] Loss: 0.2663 | Acc: 86.66%\n",
      "Train Epoch [90/100] Batch [14/782] Loss: 0.4310 | Acc: 86.94%\n",
      "Train Epoch [90/100] Batch [15/782] Loss: 0.3947 | Acc: 86.88%\n",
      "Train Epoch [90/100] Batch [16/782] Loss: 0.3640 | Acc: 87.21%\n",
      "Train Epoch [90/100] Batch [17/782] Loss: 0.5714 | Acc: 86.58%\n",
      "Train Epoch [90/100] Batch [18/782] Loss: 0.3910 | Acc: 86.63%\n",
      "Train Epoch [90/100] Batch [19/782] Loss: 0.3336 | Acc: 86.68%\n",
      "Train Epoch [90/100] Batch [20/782] Loss: 0.4507 | Acc: 86.48%\n",
      "Train Epoch [90/100] Batch [21/782] Loss: 0.2768 | Acc: 86.53%\n",
      "Train Epoch [90/100] Batch [22/782] Loss: 0.4659 | Acc: 86.51%\n",
      "Train Epoch [90/100] Batch [23/782] Loss: 0.3560 | Acc: 86.55%\n",
      "Train Epoch [90/100] Batch [24/782] Loss: 0.3344 | Acc: 86.52%\n",
      "Train Epoch [90/100] Batch [25/782] Loss: 0.4550 | Acc: 86.56%\n",
      "Train Epoch [90/100] Batch [26/782] Loss: 0.4526 | Acc: 86.66%\n",
      "Train Epoch [90/100] Batch [27/782] Loss: 0.5479 | Acc: 86.57%\n",
      "Train Epoch [90/100] Batch [28/782] Loss: 0.2917 | Acc: 86.61%\n",
      "Train Epoch [90/100] Batch [29/782] Loss: 0.2581 | Acc: 86.69%\n",
      "Train Epoch [90/100] Batch [30/782] Loss: 0.2568 | Acc: 86.82%\n",
      "Train Epoch [90/100] Batch [31/782] Loss: 0.4822 | Acc: 86.69%\n",
      "Train Epoch [90/100] Batch [32/782] Loss: 0.5445 | Acc: 86.52%\n",
      "Train Epoch [90/100] Batch [33/782] Loss: 0.5407 | Acc: 86.27%\n",
      "Train Epoch [90/100] Batch [34/782] Loss: 0.2815 | Acc: 86.40%\n",
      "Train Epoch [90/100] Batch [35/782] Loss: 0.6277 | Acc: 86.16%\n",
      "Train Epoch [90/100] Batch [36/782] Loss: 0.5490 | Acc: 86.11%\n",
      "Train Epoch [90/100] Batch [37/782] Loss: 0.4144 | Acc: 86.11%\n",
      "Train Epoch [90/100] Batch [38/782] Loss: 0.4290 | Acc: 86.06%\n",
      "Train Epoch [90/100] Batch [39/782] Loss: 0.4586 | Acc: 86.02%\n",
      "Train Epoch [90/100] Batch [40/782] Loss: 0.2457 | Acc: 86.05%\n",
      "Train Epoch [90/100] Batch [41/782] Loss: 0.4697 | Acc: 85.98%\n",
      "Train Epoch [90/100] Batch [42/782] Loss: 0.3794 | Acc: 86.05%\n",
      "Train Epoch [90/100] Batch [43/782] Loss: 0.5531 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [44/782] Loss: 0.4189 | Acc: 85.87%\n",
      "Train Epoch [90/100] Batch [45/782] Loss: 0.3682 | Acc: 85.87%\n",
      "Train Epoch [90/100] Batch [46/782] Loss: 0.3835 | Acc: 85.80%\n",
      "Train Epoch [90/100] Batch [47/782] Loss: 0.3790 | Acc: 85.80%\n",
      "Train Epoch [90/100] Batch [48/782] Loss: 0.2757 | Acc: 86.00%\n",
      "Train Epoch [90/100] Batch [49/782] Loss: 0.3338 | Acc: 86.10%\n",
      "Train Epoch [90/100] Batch [50/782] Loss: 0.2506 | Acc: 86.22%\n",
      "Train Epoch [90/100] Batch [51/782] Loss: 0.2898 | Acc: 86.31%\n",
      "Train Epoch [90/100] Batch [52/782] Loss: 0.3872 | Acc: 86.30%\n",
      "Train Epoch [90/100] Batch [53/782] Loss: 0.3949 | Acc: 86.35%\n",
      "Train Epoch [90/100] Batch [54/782] Loss: 0.2686 | Acc: 86.40%\n",
      "Train Epoch [90/100] Batch [55/782] Loss: 0.4301 | Acc: 86.34%\n",
      "Train Epoch [90/100] Batch [56/782] Loss: 0.5045 | Acc: 86.19%\n",
      "Train Epoch [90/100] Batch [57/782] Loss: 0.4297 | Acc: 86.16%\n",
      "Train Epoch [90/100] Batch [58/782] Loss: 0.3080 | Acc: 86.26%\n",
      "Train Epoch [90/100] Batch [59/782] Loss: 0.3636 | Acc: 86.20%\n",
      "Train Epoch [90/100] Batch [60/782] Loss: 0.5081 | Acc: 86.09%\n",
      "Train Epoch [90/100] Batch [61/782] Loss: 0.3079 | Acc: 86.14%\n",
      "Train Epoch [90/100] Batch [62/782] Loss: 0.2279 | Acc: 86.24%\n",
      "Train Epoch [90/100] Batch [63/782] Loss: 0.4262 | Acc: 86.24%\n",
      "Train Epoch [90/100] Batch [64/782] Loss: 0.4808 | Acc: 86.23%\n",
      "Train Epoch [90/100] Batch [65/782] Loss: 0.3853 | Acc: 86.18%\n",
      "Train Epoch [90/100] Batch [66/782] Loss: 0.2768 | Acc: 86.17%\n",
      "Train Epoch [90/100] Batch [67/782] Loss: 0.3579 | Acc: 86.10%\n",
      "Train Epoch [90/100] Batch [68/782] Loss: 0.6674 | Acc: 85.98%\n",
      "Train Epoch [90/100] Batch [69/782] Loss: 0.4192 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [70/782] Loss: 0.3560 | Acc: 86.00%\n",
      "Train Epoch [90/100] Batch [71/782] Loss: 0.3099 | Acc: 86.07%\n",
      "Train Epoch [90/100] Batch [72/782] Loss: 0.5682 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [73/782] Loss: 0.5304 | Acc: 85.89%\n",
      "Train Epoch [90/100] Batch [74/782] Loss: 0.3982 | Acc: 85.85%\n",
      "Train Epoch [90/100] Batch [75/782] Loss: 0.3141 | Acc: 85.88%\n",
      "Train Epoch [90/100] Batch [76/782] Loss: 0.3197 | Acc: 85.92%\n",
      "Train Epoch [90/100] Batch [77/782] Loss: 0.4854 | Acc: 85.90%\n",
      "Train Epoch [90/100] Batch [78/782] Loss: 0.2795 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [79/782] Loss: 0.4601 | Acc: 85.92%\n",
      "Train Epoch [90/100] Batch [80/782] Loss: 0.3978 | Acc: 85.88%\n",
      "Train Epoch [90/100] Batch [81/782] Loss: 0.4122 | Acc: 85.86%\n",
      "Train Epoch [90/100] Batch [82/782] Loss: 0.4029 | Acc: 85.82%\n",
      "Train Epoch [90/100] Batch [83/782] Loss: 0.5531 | Acc: 85.79%\n",
      "Train Epoch [90/100] Batch [84/782] Loss: 0.5041 | Acc: 85.77%\n",
      "Train Epoch [90/100] Batch [85/782] Loss: 0.4808 | Acc: 85.72%\n",
      "Train Epoch [90/100] Batch [86/782] Loss: 0.4702 | Acc: 85.70%\n",
      "Train Epoch [90/100] Batch [87/782] Loss: 0.1753 | Acc: 85.83%\n",
      "Train Epoch [90/100] Batch [88/782] Loss: 0.2298 | Acc: 85.92%\n",
      "Train Epoch [90/100] Batch [89/782] Loss: 0.3356 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [90/782] Loss: 0.7075 | Acc: 85.89%\n",
      "Train Epoch [90/100] Batch [91/782] Loss: 0.3744 | Acc: 85.85%\n",
      "Train Epoch [90/100] Batch [92/782] Loss: 0.4537 | Acc: 85.78%\n",
      "Train Epoch [90/100] Batch [93/782] Loss: 0.3700 | Acc: 85.84%\n",
      "Train Epoch [90/100] Batch [94/782] Loss: 0.3561 | Acc: 85.89%\n",
      "Train Epoch [90/100] Batch [95/782] Loss: 0.3233 | Acc: 85.92%\n",
      "Train Epoch [90/100] Batch [96/782] Loss: 0.3462 | Acc: 85.95%\n",
      "Train Epoch [90/100] Batch [97/782] Loss: 0.5161 | Acc: 85.92%\n",
      "Train Epoch [90/100] Batch [98/782] Loss: 0.2685 | Acc: 85.99%\n",
      "Train Epoch [90/100] Batch [99/782] Loss: 0.4536 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [100/782] Loss: 0.4544 | Acc: 85.95%\n",
      "Train Epoch [90/100] Batch [101/782] Loss: 0.2577 | Acc: 86.00%\n",
      "Train Epoch [90/100] Batch [102/782] Loss: 0.3747 | Acc: 86.03%\n",
      "Train Epoch [90/100] Batch [103/782] Loss: 0.5370 | Acc: 85.95%\n",
      "Train Epoch [90/100] Batch [104/782] Loss: 0.3908 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [105/782] Loss: 0.3787 | Acc: 85.94%\n",
      "Train Epoch [90/100] Batch [106/782] Loss: 0.5299 | Acc: 85.88%\n",
      "Train Epoch [90/100] Batch [107/782] Loss: 0.5738 | Acc: 85.86%\n",
      "Train Epoch [90/100] Batch [108/782] Loss: 0.4262 | Acc: 85.81%\n",
      "Train Epoch [90/100] Batch [109/782] Loss: 0.3121 | Acc: 85.84%\n",
      "Train Epoch [90/100] Batch [110/782] Loss: 0.3917 | Acc: 85.89%\n",
      "Train Epoch [90/100] Batch [111/782] Loss: 0.4539 | Acc: 85.90%\n",
      "Train Epoch [90/100] Batch [112/782] Loss: 0.6441 | Acc: 85.80%\n",
      "Train Epoch [90/100] Batch [113/782] Loss: 0.6637 | Acc: 85.73%\n",
      "Train Epoch [90/100] Batch [114/782] Loss: 0.3150 | Acc: 85.79%\n",
      "Train Epoch [90/100] Batch [115/782] Loss: 0.4645 | Acc: 85.80%\n",
      "Train Epoch [90/100] Batch [116/782] Loss: 0.5876 | Acc: 85.71%\n",
      "Train Epoch [90/100] Batch [117/782] Loss: 0.4956 | Acc: 85.63%\n",
      "Train Epoch [90/100] Batch [118/782] Loss: 0.3667 | Acc: 85.62%\n",
      "Train Epoch [90/100] Batch [119/782] Loss: 0.3440 | Acc: 85.60%\n",
      "Train Epoch [90/100] Batch [120/782] Loss: 0.2414 | Acc: 85.65%\n",
      "Train Epoch [90/100] Batch [121/782] Loss: 0.3240 | Acc: 85.67%\n",
      "Train Epoch [90/100] Batch [122/782] Loss: 0.4603 | Acc: 85.59%\n",
      "Train Epoch [90/100] Batch [123/782] Loss: 0.5089 | Acc: 85.57%\n",
      "Train Epoch [90/100] Batch [124/782] Loss: 0.3614 | Acc: 85.58%\n",
      "Train Epoch [90/100] Batch [125/782] Loss: 0.4705 | Acc: 85.56%\n",
      "Train Epoch [90/100] Batch [126/782] Loss: 0.3074 | Acc: 85.60%\n",
      "Train Epoch [90/100] Batch [127/782] Loss: 0.6905 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [128/782] Loss: 0.3395 | Acc: 85.58%\n",
      "Train Epoch [90/100] Batch [129/782] Loss: 0.4243 | Acc: 85.57%\n",
      "Train Epoch [90/100] Batch [130/782] Loss: 0.1863 | Acc: 85.65%\n",
      "Train Epoch [90/100] Batch [131/782] Loss: 0.6192 | Acc: 85.60%\n",
      "Train Epoch [90/100] Batch [132/782] Loss: 0.4143 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [133/782] Loss: 0.6107 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [134/782] Loss: 0.2933 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [135/782] Loss: 0.4950 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [136/782] Loss: 0.4000 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [137/782] Loss: 0.4406 | Acc: 85.53%\n",
      "Train Epoch [90/100] Batch [138/782] Loss: 0.3237 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [139/782] Loss: 0.3341 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [140/782] Loss: 0.3155 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [141/782] Loss: 0.3889 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [142/782] Loss: 0.3276 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [143/782] Loss: 0.6007 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [144/782] Loss: 0.4366 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [145/782] Loss: 0.3818 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [146/782] Loss: 0.3200 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [147/782] Loss: 0.2693 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [148/782] Loss: 0.5091 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [149/782] Loss: 0.4105 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [150/782] Loss: 0.5860 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [151/782] Loss: 0.4718 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [152/782] Loss: 0.4832 | Acc: 85.45%\n",
      "Train Epoch [90/100] Batch [153/782] Loss: 0.3444 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [154/782] Loss: 0.2714 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [155/782] Loss: 0.3421 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [156/782] Loss: 0.3316 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [157/782] Loss: 0.2868 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [158/782] Loss: 0.4692 | Acc: 85.53%\n",
      "Train Epoch [90/100] Batch [159/782] Loss: 0.5578 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [160/782] Loss: 0.2993 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [161/782] Loss: 0.4052 | Acc: 85.58%\n",
      "Train Epoch [90/100] Batch [162/782] Loss: 0.3875 | Acc: 85.61%\n",
      "Train Epoch [90/100] Batch [163/782] Loss: 0.5005 | Acc: 85.63%\n",
      "Train Epoch [90/100] Batch [164/782] Loss: 0.4759 | Acc: 85.60%\n",
      "Train Epoch [90/100] Batch [165/782] Loss: 0.3643 | Acc: 85.60%\n",
      "Train Epoch [90/100] Batch [166/782] Loss: 0.4951 | Acc: 85.56%\n",
      "Train Epoch [90/100] Batch [167/782] Loss: 0.3660 | Acc: 85.56%\n",
      "Train Epoch [90/100] Batch [168/782] Loss: 0.2601 | Acc: 85.58%\n",
      "Train Epoch [90/100] Batch [169/782] Loss: 0.3483 | Acc: 85.58%\n",
      "Train Epoch [90/100] Batch [170/782] Loss: 0.4259 | Acc: 85.57%\n",
      "Train Epoch [90/100] Batch [171/782] Loss: 0.5760 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [172/782] Loss: 0.6260 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [173/782] Loss: 0.6803 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [174/782] Loss: 0.3800 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [175/782] Loss: 0.3817 | Acc: 85.50%\n",
      "Train Epoch [90/100] Batch [176/782] Loss: 0.5685 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [177/782] Loss: 0.6516 | Acc: 85.43%\n",
      "Train Epoch [90/100] Batch [178/782] Loss: 0.3305 | Acc: 85.45%\n",
      "Train Epoch [90/100] Batch [179/782] Loss: 0.4635 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [180/782] Loss: 0.4042 | Acc: 85.47%\n",
      "Train Epoch [90/100] Batch [181/782] Loss: 0.4038 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [182/782] Loss: 0.4720 | Acc: 85.47%\n",
      "Train Epoch [90/100] Batch [183/782] Loss: 0.1949 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [184/782] Loss: 0.3560 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [185/782] Loss: 0.4439 | Acc: 85.53%\n",
      "Train Epoch [90/100] Batch [186/782] Loss: 0.3361 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [187/782] Loss: 0.3205 | Acc: 85.55%\n",
      "Train Epoch [90/100] Batch [188/782] Loss: 0.5791 | Acc: 85.53%\n",
      "Train Epoch [90/100] Batch [189/782] Loss: 0.7164 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [190/782] Loss: 0.4230 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [191/782] Loss: 0.3934 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [192/782] Loss: 0.4381 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [193/782] Loss: 0.3273 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [194/782] Loss: 0.4030 | Acc: 85.48%\n",
      "Train Epoch [90/100] Batch [195/782] Loss: 0.5820 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [196/782] Loss: 0.4588 | Acc: 85.44%\n",
      "Train Epoch [90/100] Batch [197/782] Loss: 0.3076 | Acc: 85.45%\n",
      "Train Epoch [90/100] Batch [198/782] Loss: 0.3731 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [199/782] Loss: 0.5846 | Acc: 85.41%\n",
      "Train Epoch [90/100] Batch [200/782] Loss: 0.3969 | Acc: 85.41%\n",
      "Train Epoch [90/100] Batch [201/782] Loss: 0.1874 | Acc: 85.45%\n",
      "Train Epoch [90/100] Batch [202/782] Loss: 0.3182 | Acc: 85.47%\n",
      "Train Epoch [90/100] Batch [203/782] Loss: 0.3652 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [204/782] Loss: 0.2918 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [205/782] Loss: 0.4592 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [206/782] Loss: 0.3679 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [207/782] Loss: 0.3175 | Acc: 85.54%\n",
      "Train Epoch [90/100] Batch [208/782] Loss: 0.4614 | Acc: 85.52%\n",
      "Train Epoch [90/100] Batch [209/782] Loss: 0.4026 | Acc: 85.53%\n",
      "Train Epoch [90/100] Batch [210/782] Loss: 0.4323 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [211/782] Loss: 0.3518 | Acc: 85.51%\n",
      "Train Epoch [90/100] Batch [212/782] Loss: 0.6005 | Acc: 85.47%\n",
      "Train Epoch [90/100] Batch [213/782] Loss: 0.3121 | Acc: 85.49%\n",
      "Train Epoch [90/100] Batch [214/782] Loss: 0.4799 | Acc: 85.46%\n",
      "Train Epoch [90/100] Batch [215/782] Loss: 0.5638 | Acc: 85.45%\n",
      "Train Epoch [90/100] Batch [216/782] Loss: 0.3361 | Acc: 85.47%\n",
      "Train Epoch [90/100] Batch [217/782] Loss: 0.5055 | Acc: 85.43%\n",
      "Train Epoch [90/100] Batch [218/782] Loss: 0.3555 | Acc: 85.44%\n",
      "Train Epoch [90/100] Batch [219/782] Loss: 0.5586 | Acc: 85.39%\n",
      "Train Epoch [90/100] Batch [220/782] Loss: 0.5133 | Acc: 85.35%\n",
      "Train Epoch [90/100] Batch [221/782] Loss: 0.4145 | Acc: 85.35%\n",
      "Train Epoch [90/100] Batch [222/782] Loss: 0.4110 | Acc: 85.35%\n",
      "Train Epoch [90/100] Batch [223/782] Loss: 0.4679 | Acc: 85.34%\n",
      "Train Epoch [90/100] Batch [224/782] Loss: 0.4562 | Acc: 85.30%\n",
      "Train Epoch [90/100] Batch [225/782] Loss: 0.6276 | Acc: 85.26%\n",
      "Train Epoch [90/100] Batch [226/782] Loss: 0.3740 | Acc: 85.28%\n",
      "Train Epoch [90/100] Batch [227/782] Loss: 0.5445 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [228/782] Loss: 0.3598 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [229/782] Loss: 0.3831 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [230/782] Loss: 0.4893 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [231/782] Loss: 0.4375 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [232/782] Loss: 0.4932 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [233/782] Loss: 0.5901 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [234/782] Loss: 0.3539 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [235/782] Loss: 0.5874 | Acc: 85.12%\n",
      "Train Epoch [90/100] Batch [236/782] Loss: 0.6317 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [237/782] Loss: 0.3901 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [238/782] Loss: 0.4513 | Acc: 85.07%\n",
      "Train Epoch [90/100] Batch [239/782] Loss: 0.3823 | Acc: 85.06%\n",
      "Train Epoch [90/100] Batch [240/782] Loss: 0.4351 | Acc: 85.05%\n",
      "Train Epoch [90/100] Batch [241/782] Loss: 0.2099 | Acc: 85.08%\n",
      "Train Epoch [90/100] Batch [242/782] Loss: 0.3447 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [243/782] Loss: 0.5415 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [244/782] Loss: 0.2366 | Acc: 85.12%\n",
      "Train Epoch [90/100] Batch [245/782] Loss: 0.3577 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [246/782] Loss: 0.3167 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [247/782] Loss: 0.2428 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [248/782] Loss: 0.3940 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [249/782] Loss: 0.4761 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [250/782] Loss: 0.5698 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [251/782] Loss: 0.7451 | Acc: 85.10%\n",
      "Train Epoch [90/100] Batch [252/782] Loss: 0.5797 | Acc: 85.06%\n",
      "Train Epoch [90/100] Batch [253/782] Loss: 0.2146 | Acc: 85.10%\n",
      "Train Epoch [90/100] Batch [254/782] Loss: 0.4460 | Acc: 85.12%\n",
      "Train Epoch [90/100] Batch [255/782] Loss: 0.3848 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [256/782] Loss: 0.3956 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [257/782] Loss: 0.3640 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [258/782] Loss: 0.2778 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [259/782] Loss: 0.3764 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [260/782] Loss: 0.5081 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [261/782] Loss: 0.2537 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [262/782] Loss: 0.3983 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [263/782] Loss: 0.5317 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [264/782] Loss: 0.4322 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [265/782] Loss: 0.3869 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [266/782] Loss: 0.4974 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [267/782] Loss: 0.3509 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [268/782] Loss: 0.4027 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [269/782] Loss: 0.3634 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [270/782] Loss: 0.2453 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [271/782] Loss: 0.4261 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [272/782] Loss: 0.2473 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [273/782] Loss: 0.3616 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [274/782] Loss: 0.5378 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [275/782] Loss: 0.4037 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [276/782] Loss: 0.3894 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [277/782] Loss: 0.4195 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [278/782] Loss: 0.3537 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [279/782] Loss: 0.3484 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [280/782] Loss: 0.5064 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [281/782] Loss: 0.2921 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [282/782] Loss: 0.4990 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [283/782] Loss: 0.3834 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [284/782] Loss: 0.5600 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [285/782] Loss: 0.3836 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [286/782] Loss: 0.4488 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [287/782] Loss: 0.3975 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [288/782] Loss: 0.4831 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [289/782] Loss: 0.5105 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [290/782] Loss: 0.6450 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [291/782] Loss: 0.5723 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [292/782] Loss: 0.5360 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [293/782] Loss: 0.3193 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [294/782] Loss: 0.3467 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [295/782] Loss: 0.3706 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [296/782] Loss: 0.4068 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [297/782] Loss: 0.4061 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [298/782] Loss: 0.4154 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [299/782] Loss: 0.5144 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [300/782] Loss: 0.4038 | Acc: 85.15%\n",
      "Train Epoch [90/100] Batch [301/782] Loss: 0.4113 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [302/782] Loss: 0.2909 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [303/782] Loss: 0.3033 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [304/782] Loss: 0.4956 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [305/782] Loss: 0.2909 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [306/782] Loss: 0.4154 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [307/782] Loss: 0.3986 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [308/782] Loss: 0.3840 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [309/782] Loss: 0.5034 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [310/782] Loss: 0.4583 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [311/782] Loss: 0.5847 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [312/782] Loss: 0.3466 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [313/782] Loss: 0.3127 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [314/782] Loss: 0.1937 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [315/782] Loss: 0.3584 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [316/782] Loss: 0.2943 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [317/782] Loss: 0.5343 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [318/782] Loss: 0.5426 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [319/782] Loss: 0.3711 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [320/782] Loss: 0.5001 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [321/782] Loss: 0.3290 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [322/782] Loss: 0.3293 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [323/782] Loss: 0.5027 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [324/782] Loss: 0.3391 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [325/782] Loss: 0.3583 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [326/782] Loss: 0.3635 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [327/782] Loss: 0.4165 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [328/782] Loss: 0.4347 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [329/782] Loss: 0.5173 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [330/782] Loss: 0.3113 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [331/782] Loss: 0.4659 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [332/782] Loss: 0.3271 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [333/782] Loss: 0.2706 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [334/782] Loss: 0.4641 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [335/782] Loss: 0.5311 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [336/782] Loss: 0.3826 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [337/782] Loss: 0.3941 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [338/782] Loss: 0.3500 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [339/782] Loss: 0.3900 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [340/782] Loss: 0.2392 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [341/782] Loss: 0.2867 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [342/782] Loss: 0.3494 | Acc: 85.24%\n",
      "Train Epoch [90/100] Batch [343/782] Loss: 0.5560 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [344/782] Loss: 0.3388 | Acc: 85.24%\n",
      "Train Epoch [90/100] Batch [345/782] Loss: 0.5325 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [346/782] Loss: 0.4164 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [347/782] Loss: 0.3678 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [348/782] Loss: 0.3972 | Acc: 85.23%\n",
      "Train Epoch [90/100] Batch [349/782] Loss: 0.4207 | Acc: 85.22%\n",
      "Train Epoch [90/100] Batch [350/782] Loss: 0.4854 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [351/782] Loss: 0.4923 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [352/782] Loss: 0.4848 | Acc: 85.21%\n",
      "Train Epoch [90/100] Batch [353/782] Loss: 0.4553 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [354/782] Loss: 0.4802 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [355/782] Loss: 0.4895 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [356/782] Loss: 0.3306 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [357/782] Loss: 0.3496 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [358/782] Loss: 0.3558 | Acc: 85.19%\n",
      "Train Epoch [90/100] Batch [359/782] Loss: 0.4467 | Acc: 85.20%\n",
      "Train Epoch [90/100] Batch [360/782] Loss: 0.5786 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [361/782] Loss: 0.3982 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [362/782] Loss: 0.5591 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [363/782] Loss: 0.4177 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [364/782] Loss: 0.4411 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [365/782] Loss: 0.1951 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [366/782] Loss: 0.3545 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [367/782] Loss: 0.4382 | Acc: 85.18%\n",
      "Train Epoch [90/100] Batch [368/782] Loss: 0.4661 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [369/782] Loss: 0.4657 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [370/782] Loss: 0.4418 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [371/782] Loss: 0.4813 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [372/782] Loss: 0.2324 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [373/782] Loss: 0.2978 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [374/782] Loss: 0.4620 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [375/782] Loss: 0.3411 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [376/782] Loss: 0.4611 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [377/782] Loss: 0.4271 | Acc: 85.17%\n",
      "Train Epoch [90/100] Batch [378/782] Loss: 0.3995 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [379/782] Loss: 0.3072 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [380/782] Loss: 0.2987 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [381/782] Loss: 0.4221 | Acc: 85.16%\n",
      "Train Epoch [90/100] Batch [382/782] Loss: 0.4474 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [383/782] Loss: 0.4343 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [384/782] Loss: 0.5117 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [385/782] Loss: 0.3226 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [386/782] Loss: 0.4310 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [387/782] Loss: 0.3551 | Acc: 85.13%\n",
      "Train Epoch [90/100] Batch [388/782] Loss: 0.3001 | Acc: 85.14%\n",
      "Train Epoch [90/100] Batch [389/782] Loss: 0.5605 | Acc: 85.11%\n",
      "Train Epoch [90/100] Batch [390/782] Loss: 0.5706 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [391/782] Loss: 0.4440 | Acc: 85.09%\n",
      "Train Epoch [90/100] Batch [392/782] Loss: 0.6466 | Acc: 85.06%\n",
      "Train Epoch [90/100] Batch [393/782] Loss: 0.5685 | Acc: 85.05%\n",
      "Train Epoch [90/100] Batch [394/782] Loss: 0.6434 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [395/782] Loss: 0.6403 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [396/782] Loss: 0.3046 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [397/782] Loss: 0.3460 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [398/782] Loss: 0.4152 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [399/782] Loss: 0.3604 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [400/782] Loss: 0.3210 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [401/782] Loss: 0.4138 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [402/782] Loss: 0.4129 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [403/782] Loss: 0.3402 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [404/782] Loss: 0.4770 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [405/782] Loss: 0.5330 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [406/782] Loss: 0.3185 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [407/782] Loss: 0.2711 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [408/782] Loss: 0.4032 | Acc: 85.05%\n",
      "Train Epoch [90/100] Batch [409/782] Loss: 0.6010 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [410/782] Loss: 0.3319 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [411/782] Loss: 0.3724 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [412/782] Loss: 0.3718 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [413/782] Loss: 0.4980 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [414/782] Loss: 0.5302 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [415/782] Loss: 0.4038 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [416/782] Loss: 0.3997 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [417/782] Loss: 0.5092 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [418/782] Loss: 0.4401 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [419/782] Loss: 0.5832 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [420/782] Loss: 0.4845 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [421/782] Loss: 0.5715 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [422/782] Loss: 0.3416 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [423/782] Loss: 0.4438 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [424/782] Loss: 0.3816 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [425/782] Loss: 0.4976 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [426/782] Loss: 0.4109 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [427/782] Loss: 0.6374 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [428/782] Loss: 0.5731 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [429/782] Loss: 0.3453 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [430/782] Loss: 0.3040 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [431/782] Loss: 0.4189 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [432/782] Loss: 0.3990 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [433/782] Loss: 0.3814 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [434/782] Loss: 0.4396 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [435/782] Loss: 0.4241 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [436/782] Loss: 0.3679 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [437/782] Loss: 0.2470 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [438/782] Loss: 0.4450 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [439/782] Loss: 0.3418 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [440/782] Loss: 0.1804 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [441/782] Loss: 0.4701 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [442/782] Loss: 0.5294 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [443/782] Loss: 0.4810 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [444/782] Loss: 0.3461 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [445/782] Loss: 0.4269 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [446/782] Loss: 0.2973 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [447/782] Loss: 0.4264 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [448/782] Loss: 0.4568 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [449/782] Loss: 0.4711 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [450/782] Loss: 0.5863 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [451/782] Loss: 0.6132 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [452/782] Loss: 0.6148 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [453/782] Loss: 0.4142 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [454/782] Loss: 0.3847 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [455/782] Loss: 0.6726 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [456/782] Loss: 0.3928 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [457/782] Loss: 0.4367 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [458/782] Loss: 0.4759 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [459/782] Loss: 0.8528 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [460/782] Loss: 0.3842 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [461/782] Loss: 0.4448 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [462/782] Loss: 0.4247 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [463/782] Loss: 0.4792 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [464/782] Loss: 0.3181 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [465/782] Loss: 0.3749 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [466/782] Loss: 0.4795 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [467/782] Loss: 0.3233 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [468/782] Loss: 0.4157 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [469/782] Loss: 0.4005 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [470/782] Loss: 0.3441 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [471/782] Loss: 0.4651 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [472/782] Loss: 0.3129 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [473/782] Loss: 0.3284 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [474/782] Loss: 0.3356 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [475/782] Loss: 0.3889 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [476/782] Loss: 0.6017 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [477/782] Loss: 0.3992 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [478/782] Loss: 0.5635 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [479/782] Loss: 0.2615 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [480/782] Loss: 0.4811 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [481/782] Loss: 0.4058 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [482/782] Loss: 0.4006 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [483/782] Loss: 0.2605 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [484/782] Loss: 0.5703 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [485/782] Loss: 0.3804 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [486/782] Loss: 0.4371 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [487/782] Loss: 0.4232 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [488/782] Loss: 0.3309 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [489/782] Loss: 0.5798 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [490/782] Loss: 0.3865 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [491/782] Loss: 0.4670 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [492/782] Loss: 0.5066 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [493/782] Loss: 0.4526 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [494/782] Loss: 0.5170 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [495/782] Loss: 0.3658 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [496/782] Loss: 0.4577 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [497/782] Loss: 0.3130 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [498/782] Loss: 0.3730 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [499/782] Loss: 0.4221 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [500/782] Loss: 0.4240 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [501/782] Loss: 0.5149 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [502/782] Loss: 0.3404 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [503/782] Loss: 0.4692 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [504/782] Loss: 0.4733 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [505/782] Loss: 0.4579 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [506/782] Loss: 0.4024 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [507/782] Loss: 0.4041 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [508/782] Loss: 0.4553 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [509/782] Loss: 0.5527 | Acc: 84.89%\n",
      "Train Epoch [90/100] Batch [510/782] Loss: 0.4378 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [511/782] Loss: 0.2734 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [512/782] Loss: 0.4745 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [513/782] Loss: 0.4230 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [514/782] Loss: 0.4567 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [515/782] Loss: 0.3020 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [516/782] Loss: 0.4130 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [517/782] Loss: 0.4765 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [518/782] Loss: 0.2169 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [519/782] Loss: 0.5567 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [520/782] Loss: 0.3510 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [521/782] Loss: 0.3105 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [522/782] Loss: 0.6381 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [523/782] Loss: 0.3892 | Acc: 84.90%\n",
      "Train Epoch [90/100] Batch [524/782] Loss: 0.2647 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [525/782] Loss: 0.3869 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [526/782] Loss: 0.3108 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [527/782] Loss: 0.3948 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [528/782] Loss: 0.3358 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [529/782] Loss: 0.4956 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [530/782] Loss: 0.3865 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [531/782] Loss: 0.4204 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [532/782] Loss: 0.4525 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [533/782] Loss: 0.4859 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [534/782] Loss: 0.4426 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [535/782] Loss: 0.6042 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [536/782] Loss: 0.3178 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [537/782] Loss: 0.3467 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [538/782] Loss: 0.4468 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [539/782] Loss: 0.3042 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [540/782] Loss: 0.5405 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [541/782] Loss: 0.3035 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [542/782] Loss: 0.3007 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [543/782] Loss: 0.4113 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [544/782] Loss: 0.3349 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [545/782] Loss: 0.5340 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [546/782] Loss: 0.6805 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [547/782] Loss: 0.7424 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [548/782] Loss: 0.3867 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [549/782] Loss: 0.5617 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [550/782] Loss: 0.3975 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [551/782] Loss: 0.3971 | Acc: 84.91%\n",
      "Train Epoch [90/100] Batch [552/782] Loss: 0.3527 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [553/782] Loss: 0.4359 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [554/782] Loss: 0.4009 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [555/782] Loss: 0.4989 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [556/782] Loss: 0.3587 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [557/782] Loss: 0.4042 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [558/782] Loss: 0.5062 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [559/782] Loss: 0.3098 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [560/782] Loss: 0.3766 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [561/782] Loss: 0.3516 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [562/782] Loss: 0.3805 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [563/782] Loss: 0.4123 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [564/782] Loss: 0.3382 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [565/782] Loss: 0.4501 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [566/782] Loss: 0.4429 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [567/782] Loss: 0.2749 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [568/782] Loss: 0.3292 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [569/782] Loss: 0.3645 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [570/782] Loss: 0.3894 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [571/782] Loss: 0.2931 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [572/782] Loss: 0.3267 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [573/782] Loss: 0.5284 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [574/782] Loss: 0.4732 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [575/782] Loss: 0.3870 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [576/782] Loss: 0.4722 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [577/782] Loss: 0.3989 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [578/782] Loss: 0.3067 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [579/782] Loss: 0.4247 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [580/782] Loss: 0.3979 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [581/782] Loss: 0.3475 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [582/782] Loss: 0.5174 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [583/782] Loss: 0.2998 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [584/782] Loss: 0.4856 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [585/782] Loss: 0.3877 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [586/782] Loss: 0.3886 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [587/782] Loss: 0.5646 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [588/782] Loss: 0.4683 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [589/782] Loss: 0.3571 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [590/782] Loss: 0.5603 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [591/782] Loss: 0.4384 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [592/782] Loss: 0.6463 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [593/782] Loss: 0.5095 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [594/782] Loss: 0.5104 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [595/782] Loss: 0.5361 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [596/782] Loss: 0.3194 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [597/782] Loss: 0.5484 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [598/782] Loss: 0.5293 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [599/782] Loss: 0.6002 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [600/782] Loss: 0.3842 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [601/782] Loss: 0.4779 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [602/782] Loss: 0.4123 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [603/782] Loss: 0.5394 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [604/782] Loss: 0.4890 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [605/782] Loss: 0.5456 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [606/782] Loss: 0.4032 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [607/782] Loss: 0.2600 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [608/782] Loss: 0.4187 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [609/782] Loss: 0.4779 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [610/782] Loss: 0.3745 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [611/782] Loss: 0.4667 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [612/782] Loss: 0.5604 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [613/782] Loss: 0.3472 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [614/782] Loss: 0.1596 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [615/782] Loss: 0.4930 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [616/782] Loss: 0.4204 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [617/782] Loss: 0.3564 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [618/782] Loss: 0.4377 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [619/782] Loss: 0.3687 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [620/782] Loss: 0.3808 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [621/782] Loss: 0.4114 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [622/782] Loss: 0.4411 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [623/782] Loss: 0.4548 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [624/782] Loss: 0.4156 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [625/782] Loss: 0.4153 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [626/782] Loss: 0.3919 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [627/782] Loss: 0.3124 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [628/782] Loss: 0.5160 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [629/782] Loss: 0.2380 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [630/782] Loss: 0.5431 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [631/782] Loss: 0.4689 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [632/782] Loss: 0.2977 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [633/782] Loss: 0.5101 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [634/782] Loss: 0.3215 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [635/782] Loss: 0.3829 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [636/782] Loss: 0.2992 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [637/782] Loss: 0.5462 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [638/782] Loss: 0.5054 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [639/782] Loss: 0.4211 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [640/782] Loss: 0.4093 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [641/782] Loss: 0.3019 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [642/782] Loss: 0.5514 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [643/782] Loss: 0.5719 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [644/782] Loss: 0.3724 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [645/782] Loss: 0.4704 | Acc: 84.92%\n",
      "Train Epoch [90/100] Batch [646/782] Loss: 0.3037 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [647/782] Loss: 0.2847 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [648/782] Loss: 0.4090 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [649/782] Loss: 0.1884 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [650/782] Loss: 0.6281 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [651/782] Loss: 0.5004 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [652/782] Loss: 0.2815 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [653/782] Loss: 0.2539 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [654/782] Loss: 0.3240 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [655/782] Loss: 0.3648 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [656/782] Loss: 0.2597 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [657/782] Loss: 0.4867 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [658/782] Loss: 0.4131 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [659/782] Loss: 0.4220 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [660/782] Loss: 0.5696 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [661/782] Loss: 0.5847 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [662/782] Loss: 0.4270 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [663/782] Loss: 0.4743 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [664/782] Loss: 0.4059 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [665/782] Loss: 0.3568 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [666/782] Loss: 0.5098 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [667/782] Loss: 0.3879 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [668/782] Loss: 0.4426 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [669/782] Loss: 0.3797 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [670/782] Loss: 0.3315 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [671/782] Loss: 0.5072 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [672/782] Loss: 0.3610 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [673/782] Loss: 0.4547 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [674/782] Loss: 0.5060 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [675/782] Loss: 0.4434 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [676/782] Loss: 0.5582 | Acc: 84.93%\n",
      "Train Epoch [90/100] Batch [677/782] Loss: 0.3068 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [678/782] Loss: 0.3279 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [679/782] Loss: 0.3661 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [680/782] Loss: 0.2497 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [681/782] Loss: 0.3094 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [682/782] Loss: 0.6087 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [683/782] Loss: 0.4638 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [684/782] Loss: 0.4848 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [685/782] Loss: 0.4847 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [686/782] Loss: 0.5168 | Acc: 84.94%\n",
      "Train Epoch [90/100] Batch [687/782] Loss: 0.2758 | Acc: 84.95%\n",
      "Train Epoch [90/100] Batch [688/782] Loss: 0.3843 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [689/782] Loss: 0.4295 | Acc: 84.96%\n",
      "Train Epoch [90/100] Batch [690/782] Loss: 0.2444 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [691/782] Loss: 0.2946 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [692/782] Loss: 0.2815 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [693/782] Loss: 0.4448 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [694/782] Loss: 0.3882 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [695/782] Loss: 0.4083 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [696/782] Loss: 0.3426 | Acc: 84.97%\n",
      "Train Epoch [90/100] Batch [697/782] Loss: 0.3945 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [698/782] Loss: 0.3974 | Acc: 84.98%\n",
      "Train Epoch [90/100] Batch [699/782] Loss: 0.3230 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [700/782] Loss: 0.3481 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [701/782] Loss: 0.5614 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [702/782] Loss: 0.2215 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [703/782] Loss: 0.4610 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [704/782] Loss: 0.5010 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [705/782] Loss: 0.3743 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [706/782] Loss: 0.3133 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [707/782] Loss: 0.3028 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [708/782] Loss: 0.6444 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [709/782] Loss: 0.3907 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [710/782] Loss: 0.5776 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [711/782] Loss: 0.4249 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [712/782] Loss: 0.3948 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [713/782] Loss: 0.4707 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [714/782] Loss: 0.5170 | Acc: 84.99%\n",
      "Train Epoch [90/100] Batch [715/782] Loss: 0.2982 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [716/782] Loss: 0.2649 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [717/782] Loss: 0.5947 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [718/782] Loss: 0.4081 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [719/782] Loss: 0.4713 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [720/782] Loss: 0.3963 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [721/782] Loss: 0.4554 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [722/782] Loss: 0.3819 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [723/782] Loss: 0.4358 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [724/782] Loss: 0.3169 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [725/782] Loss: 0.5271 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [726/782] Loss: 0.4596 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [727/782] Loss: 0.4193 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [728/782] Loss: 0.3172 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [729/782] Loss: 0.3248 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [730/782] Loss: 0.5157 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [731/782] Loss: 0.3819 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [732/782] Loss: 0.3198 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [733/782] Loss: 0.4181 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [734/782] Loss: 0.5297 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [735/782] Loss: 0.4696 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [736/782] Loss: 0.4048 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [737/782] Loss: 0.3598 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [738/782] Loss: 0.2944 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [739/782] Loss: 0.4519 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [740/782] Loss: 0.3869 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [741/782] Loss: 0.4155 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [742/782] Loss: 0.4691 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [743/782] Loss: 0.6775 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [744/782] Loss: 0.2704 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [745/782] Loss: 0.6982 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [746/782] Loss: 0.5029 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [747/782] Loss: 0.4774 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [748/782] Loss: 0.3537 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [749/782] Loss: 0.4141 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [750/782] Loss: 0.5395 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [751/782] Loss: 0.4008 | Acc: 85.00%\n",
      "Train Epoch [90/100] Batch [752/782] Loss: 0.2217 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [753/782] Loss: 0.3880 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [754/782] Loss: 0.2726 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [755/782] Loss: 0.4961 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [756/782] Loss: 0.5079 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [757/782] Loss: 0.4131 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [758/782] Loss: 0.4153 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [759/782] Loss: 0.3826 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [760/782] Loss: 0.3077 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [761/782] Loss: 0.2425 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [762/782] Loss: 0.4045 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [763/782] Loss: 0.2888 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [764/782] Loss: 0.4554 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [765/782] Loss: 0.5427 | Acc: 85.04%\n",
      "Train Epoch [90/100] Batch [766/782] Loss: 0.4268 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [767/782] Loss: 0.4756 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [768/782] Loss: 0.4839 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [769/782] Loss: 0.4198 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [770/782] Loss: 0.4528 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [771/782] Loss: 0.4171 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [772/782] Loss: 0.4391 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [773/782] Loss: 0.5622 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [774/782] Loss: 0.6381 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [775/782] Loss: 0.3538 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [776/782] Loss: 0.4414 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [777/782] Loss: 0.4487 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [778/782] Loss: 0.2736 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [779/782] Loss: 0.5569 | Acc: 85.01%\n",
      "Train Epoch [90/100] Batch [780/782] Loss: 0.2534 | Acc: 85.03%\n",
      "Train Epoch [90/100] Batch [781/782] Loss: 0.5139 | Acc: 85.02%\n",
      "Train Epoch [90/100] Batch [782/782] Loss: 0.1949 | Acc: 85.02%\n",
      "Epoch 90 completed in 30.78s.\n",
      "Test Epoch [90/100] Loss: 1.0155 | Acc: 72.08% | Inference Time: 8.58s\n",
      "Epoch 90 results saved to CSV.\n",
      "Epoch 91/100\n",
      "Train Epoch [91/100] Batch [1/782] Loss: 0.3689 | Acc: 81.25%\n",
      "Train Epoch [91/100] Batch [2/782] Loss: 0.3670 | Acc: 85.16%\n",
      "Train Epoch [91/100] Batch [3/782] Loss: 0.3831 | Acc: 86.98%\n",
      "Train Epoch [91/100] Batch [4/782] Loss: 0.3415 | Acc: 86.33%\n",
      "Train Epoch [91/100] Batch [5/782] Loss: 0.3073 | Acc: 86.25%\n",
      "Train Epoch [91/100] Batch [6/782] Loss: 0.3496 | Acc: 86.46%\n",
      "Train Epoch [91/100] Batch [7/782] Loss: 0.5583 | Acc: 85.04%\n",
      "Train Epoch [91/100] Batch [8/782] Loss: 0.5227 | Acc: 84.77%\n",
      "Train Epoch [91/100] Batch [9/782] Loss: 0.4144 | Acc: 84.55%\n",
      "Train Epoch [91/100] Batch [10/782] Loss: 0.2617 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [11/782] Loss: 0.3971 | Acc: 85.80%\n",
      "Train Epoch [91/100] Batch [12/782] Loss: 0.4642 | Acc: 85.42%\n",
      "Train Epoch [91/100] Batch [13/782] Loss: 0.5628 | Acc: 85.10%\n",
      "Train Epoch [91/100] Batch [14/782] Loss: 0.3248 | Acc: 85.49%\n",
      "Train Epoch [91/100] Batch [15/782] Loss: 0.4285 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [16/782] Loss: 0.2606 | Acc: 85.84%\n",
      "Train Epoch [91/100] Batch [17/782] Loss: 0.6401 | Acc: 85.57%\n",
      "Train Epoch [91/100] Batch [18/782] Loss: 0.3335 | Acc: 85.94%\n",
      "Train Epoch [91/100] Batch [19/782] Loss: 0.5959 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [20/782] Loss: 0.3601 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [21/782] Loss: 0.3703 | Acc: 85.57%\n",
      "Train Epoch [91/100] Batch [22/782] Loss: 0.3334 | Acc: 85.44%\n",
      "Train Epoch [91/100] Batch [23/782] Loss: 0.2410 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [24/782] Loss: 0.3320 | Acc: 85.81%\n",
      "Train Epoch [91/100] Batch [25/782] Loss: 0.2608 | Acc: 85.94%\n",
      "Train Epoch [91/100] Batch [26/782] Loss: 0.2637 | Acc: 86.06%\n",
      "Train Epoch [91/100] Batch [27/782] Loss: 0.3348 | Acc: 86.05%\n",
      "Train Epoch [91/100] Batch [28/782] Loss: 0.4581 | Acc: 85.94%\n",
      "Train Epoch [91/100] Batch [29/782] Loss: 0.3933 | Acc: 85.94%\n",
      "Train Epoch [91/100] Batch [30/782] Loss: 0.3685 | Acc: 85.99%\n",
      "Train Epoch [91/100] Batch [31/782] Loss: 0.3367 | Acc: 86.04%\n",
      "Train Epoch [91/100] Batch [32/782] Loss: 0.2809 | Acc: 86.18%\n",
      "Train Epoch [91/100] Batch [33/782] Loss: 0.4749 | Acc: 86.13%\n",
      "Train Epoch [91/100] Batch [34/782] Loss: 0.5125 | Acc: 85.98%\n",
      "Train Epoch [91/100] Batch [35/782] Loss: 0.3813 | Acc: 85.98%\n",
      "Train Epoch [91/100] Batch [36/782] Loss: 0.3208 | Acc: 86.02%\n",
      "Train Epoch [91/100] Batch [37/782] Loss: 0.4208 | Acc: 85.85%\n",
      "Train Epoch [91/100] Batch [38/782] Loss: 0.2498 | Acc: 86.02%\n",
      "Train Epoch [91/100] Batch [39/782] Loss: 0.4577 | Acc: 86.02%\n",
      "Train Epoch [91/100] Batch [40/782] Loss: 0.4030 | Acc: 86.09%\n",
      "Train Epoch [91/100] Batch [41/782] Loss: 0.5129 | Acc: 86.01%\n",
      "Train Epoch [91/100] Batch [42/782] Loss: 0.3574 | Acc: 86.12%\n",
      "Train Epoch [91/100] Batch [43/782] Loss: 0.3389 | Acc: 86.19%\n",
      "Train Epoch [91/100] Batch [44/782] Loss: 0.3039 | Acc: 86.26%\n",
      "Train Epoch [91/100] Batch [45/782] Loss: 0.4571 | Acc: 86.32%\n",
      "Train Epoch [91/100] Batch [46/782] Loss: 0.4658 | Acc: 86.35%\n",
      "Train Epoch [91/100] Batch [47/782] Loss: 0.2150 | Acc: 86.47%\n",
      "Train Epoch [91/100] Batch [48/782] Loss: 0.3943 | Acc: 86.49%\n",
      "Train Epoch [91/100] Batch [49/782] Loss: 0.4186 | Acc: 86.51%\n",
      "Train Epoch [91/100] Batch [50/782] Loss: 0.4802 | Acc: 86.38%\n",
      "Train Epoch [91/100] Batch [51/782] Loss: 0.4092 | Acc: 86.34%\n",
      "Train Epoch [91/100] Batch [52/782] Loss: 0.4270 | Acc: 86.27%\n",
      "Train Epoch [91/100] Batch [53/782] Loss: 0.4399 | Acc: 86.29%\n",
      "Train Epoch [91/100] Batch [54/782] Loss: 0.4392 | Acc: 86.26%\n",
      "Train Epoch [91/100] Batch [55/782] Loss: 0.3880 | Acc: 86.25%\n",
      "Train Epoch [91/100] Batch [56/782] Loss: 0.3005 | Acc: 86.27%\n",
      "Train Epoch [91/100] Batch [57/782] Loss: 0.5442 | Acc: 86.18%\n",
      "Train Epoch [91/100] Batch [58/782] Loss: 0.3139 | Acc: 86.26%\n",
      "Train Epoch [91/100] Batch [59/782] Loss: 0.3453 | Acc: 86.31%\n",
      "Train Epoch [91/100] Batch [60/782] Loss: 0.3521 | Acc: 86.33%\n",
      "Train Epoch [91/100] Batch [61/782] Loss: 0.4137 | Acc: 86.32%\n",
      "Train Epoch [91/100] Batch [62/782] Loss: 0.3695 | Acc: 86.32%\n",
      "Train Epoch [91/100] Batch [63/782] Loss: 0.2596 | Acc: 86.46%\n",
      "Train Epoch [91/100] Batch [64/782] Loss: 0.8814 | Acc: 86.18%\n",
      "Train Epoch [91/100] Batch [65/782] Loss: 0.3706 | Acc: 86.13%\n",
      "Train Epoch [91/100] Batch [66/782] Loss: 0.3482 | Acc: 86.20%\n",
      "Train Epoch [91/100] Batch [67/782] Loss: 0.4827 | Acc: 86.22%\n",
      "Train Epoch [91/100] Batch [68/782] Loss: 0.4515 | Acc: 86.17%\n",
      "Train Epoch [91/100] Batch [69/782] Loss: 0.4361 | Acc: 86.19%\n",
      "Train Epoch [91/100] Batch [70/782] Loss: 0.3258 | Acc: 86.27%\n",
      "Train Epoch [91/100] Batch [71/782] Loss: 0.4793 | Acc: 86.22%\n",
      "Train Epoch [91/100] Batch [72/782] Loss: 0.5870 | Acc: 86.11%\n",
      "Train Epoch [91/100] Batch [73/782] Loss: 0.4084 | Acc: 86.09%\n",
      "Train Epoch [91/100] Batch [74/782] Loss: 0.4922 | Acc: 85.98%\n",
      "Train Epoch [91/100] Batch [75/782] Loss: 0.4724 | Acc: 85.94%\n",
      "Train Epoch [91/100] Batch [76/782] Loss: 0.2859 | Acc: 86.02%\n",
      "Train Epoch [91/100] Batch [77/782] Loss: 0.3354 | Acc: 86.04%\n",
      "Train Epoch [91/100] Batch [78/782] Loss: 0.2739 | Acc: 86.08%\n",
      "Train Epoch [91/100] Batch [79/782] Loss: 0.4120 | Acc: 86.04%\n",
      "Train Epoch [91/100] Batch [80/782] Loss: 0.3085 | Acc: 86.09%\n",
      "Train Epoch [91/100] Batch [81/782] Loss: 0.4542 | Acc: 86.07%\n",
      "Train Epoch [91/100] Batch [82/782] Loss: 0.5094 | Acc: 86.05%\n",
      "Train Epoch [91/100] Batch [83/782] Loss: 0.4951 | Acc: 85.96%\n",
      "Train Epoch [91/100] Batch [84/782] Loss: 0.4725 | Acc: 85.92%\n",
      "Train Epoch [91/100] Batch [85/782] Loss: 0.4881 | Acc: 85.92%\n",
      "Train Epoch [91/100] Batch [86/782] Loss: 0.3474 | Acc: 85.96%\n",
      "Train Epoch [91/100] Batch [87/782] Loss: 0.2976 | Acc: 85.96%\n",
      "Train Epoch [91/100] Batch [88/782] Loss: 0.5737 | Acc: 85.88%\n",
      "Train Epoch [91/100] Batch [89/782] Loss: 0.3711 | Acc: 85.85%\n",
      "Train Epoch [91/100] Batch [90/782] Loss: 0.3880 | Acc: 85.89%\n",
      "Train Epoch [91/100] Batch [91/782] Loss: 0.5502 | Acc: 85.78%\n",
      "Train Epoch [91/100] Batch [92/782] Loss: 0.4201 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [93/782] Loss: 0.3477 | Acc: 85.74%\n",
      "Train Epoch [91/100] Batch [94/782] Loss: 0.2571 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [95/782] Loss: 0.3903 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [96/782] Loss: 0.4398 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [97/782] Loss: 0.4802 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [98/782] Loss: 0.2686 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [99/782] Loss: 0.5603 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [100/782] Loss: 0.4555 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [101/782] Loss: 0.2101 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [102/782] Loss: 0.3949 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [103/782] Loss: 0.2589 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [104/782] Loss: 0.2931 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [105/782] Loss: 0.5632 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [106/782] Loss: 0.3653 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [107/782] Loss: 0.3563 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [108/782] Loss: 0.4230 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [109/782] Loss: 0.6109 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [110/782] Loss: 0.3986 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [111/782] Loss: 0.3563 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [112/782] Loss: 0.4182 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [113/782] Loss: 0.5655 | Acc: 85.63%\n",
      "Train Epoch [91/100] Batch [114/782] Loss: 0.4337 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [115/782] Loss: 0.4624 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [116/782] Loss: 0.4493 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [117/782] Loss: 0.3329 | Acc: 85.63%\n",
      "Train Epoch [91/100] Batch [118/782] Loss: 0.3403 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [119/782] Loss: 0.5437 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [120/782] Loss: 0.5137 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [121/782] Loss: 0.4809 | Acc: 85.61%\n",
      "Train Epoch [91/100] Batch [122/782] Loss: 0.3969 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [123/782] Loss: 0.3017 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [124/782] Loss: 0.3667 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [125/782] Loss: 0.3986 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [126/782] Loss: 0.3760 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [127/782] Loss: 0.3851 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [128/782] Loss: 0.2483 | Acc: 85.74%\n",
      "Train Epoch [91/100] Batch [129/782] Loss: 0.2258 | Acc: 85.83%\n",
      "Train Epoch [91/100] Batch [130/782] Loss: 0.4777 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [131/782] Loss: 0.3745 | Acc: 85.81%\n",
      "Train Epoch [91/100] Batch [132/782] Loss: 0.3520 | Acc: 85.83%\n",
      "Train Epoch [91/100] Batch [133/782] Loss: 0.2811 | Acc: 85.87%\n",
      "Train Epoch [91/100] Batch [134/782] Loss: 0.4425 | Acc: 85.86%\n",
      "Train Epoch [91/100] Batch [135/782] Loss: 0.6009 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [136/782] Loss: 0.5111 | Acc: 85.78%\n",
      "Train Epoch [91/100] Batch [137/782] Loss: 0.3358 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [138/782] Loss: 0.4372 | Acc: 85.78%\n",
      "Train Epoch [91/100] Batch [139/782] Loss: 0.4487 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [140/782] Loss: 0.2283 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [141/782] Loss: 0.3902 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [142/782] Loss: 0.4899 | Acc: 85.82%\n",
      "Train Epoch [91/100] Batch [143/782] Loss: 0.3585 | Acc: 85.81%\n",
      "Train Epoch [91/100] Batch [144/782] Loss: 0.3021 | Acc: 85.83%\n",
      "Train Epoch [91/100] Batch [145/782] Loss: 0.4243 | Acc: 85.82%\n",
      "Train Epoch [91/100] Batch [146/782] Loss: 0.3982 | Acc: 85.81%\n",
      "Train Epoch [91/100] Batch [147/782] Loss: 0.4753 | Acc: 85.80%\n",
      "Train Epoch [91/100] Batch [148/782] Loss: 0.4761 | Acc: 85.76%\n",
      "Train Epoch [91/100] Batch [149/782] Loss: 0.3590 | Acc: 85.76%\n",
      "Train Epoch [91/100] Batch [150/782] Loss: 0.5082 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [151/782] Loss: 0.4256 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [152/782] Loss: 0.5373 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [153/782] Loss: 0.4425 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [154/782] Loss: 0.3403 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [155/782] Loss: 0.2767 | Acc: 85.75%\n",
      "Train Epoch [91/100] Batch [156/782] Loss: 0.3571 | Acc: 85.76%\n",
      "Train Epoch [91/100] Batch [157/782] Loss: 0.3644 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [158/782] Loss: 0.3884 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [159/782] Loss: 0.4218 | Acc: 85.76%\n",
      "Train Epoch [91/100] Batch [160/782] Loss: 0.2855 | Acc: 85.79%\n",
      "Train Epoch [91/100] Batch [161/782] Loss: 0.4462 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [162/782] Loss: 0.4879 | Acc: 85.75%\n",
      "Train Epoch [91/100] Batch [163/782] Loss: 0.3786 | Acc: 85.78%\n",
      "Train Epoch [91/100] Batch [164/782] Loss: 0.4701 | Acc: 85.76%\n",
      "Train Epoch [91/100] Batch [165/782] Loss: 0.5108 | Acc: 85.74%\n",
      "Train Epoch [91/100] Batch [166/782] Loss: 0.3671 | Acc: 85.75%\n",
      "Train Epoch [91/100] Batch [167/782] Loss: 0.3354 | Acc: 85.75%\n",
      "Train Epoch [91/100] Batch [168/782] Loss: 0.4919 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [169/782] Loss: 0.3961 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [170/782] Loss: 0.5262 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [171/782] Loss: 0.4708 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [172/782] Loss: 0.2507 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [173/782] Loss: 0.3897 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [174/782] Loss: 0.4417 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [175/782] Loss: 0.3875 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [176/782] Loss: 0.3600 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [177/782] Loss: 0.2461 | Acc: 85.75%\n",
      "Train Epoch [91/100] Batch [178/782] Loss: 0.4119 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [179/782] Loss: 0.4482 | Acc: 85.77%\n",
      "Train Epoch [91/100] Batch [180/782] Loss: 0.6072 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [181/782] Loss: 0.5643 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [182/782] Loss: 0.4567 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [183/782] Loss: 0.3334 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [184/782] Loss: 0.4013 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [185/782] Loss: 0.3624 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [186/782] Loss: 0.4419 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [187/782] Loss: 0.2324 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [188/782] Loss: 0.6167 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [189/782] Loss: 0.3454 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [190/782] Loss: 0.4915 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [191/782] Loss: 0.5693 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [192/782] Loss: 0.5215 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [193/782] Loss: 0.4353 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [194/782] Loss: 0.3454 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [195/782] Loss: 0.5102 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [196/782] Loss: 0.4450 | Acc: 85.56%\n",
      "Train Epoch [91/100] Batch [197/782] Loss: 0.4486 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [198/782] Loss: 0.4308 | Acc: 85.57%\n",
      "Train Epoch [91/100] Batch [199/782] Loss: 0.3729 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [200/782] Loss: 0.2818 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [201/782] Loss: 0.4295 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [202/782] Loss: 0.4249 | Acc: 85.57%\n",
      "Train Epoch [91/100] Batch [203/782] Loss: 0.3217 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [204/782] Loss: 0.3900 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [205/782] Loss: 0.2361 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [206/782] Loss: 0.2812 | Acc: 85.63%\n",
      "Train Epoch [91/100] Batch [207/782] Loss: 0.4602 | Acc: 85.63%\n",
      "Train Epoch [91/100] Batch [208/782] Loss: 0.3371 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [209/782] Loss: 0.2767 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [210/782] Loss: 0.3666 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [211/782] Loss: 0.3126 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [212/782] Loss: 0.2731 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [213/782] Loss: 0.4970 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [214/782] Loss: 0.5188 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [215/782] Loss: 0.3107 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [216/782] Loss: 0.3457 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [217/782] Loss: 0.3318 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [218/782] Loss: 0.4044 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [219/782] Loss: 0.6095 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [220/782] Loss: 0.4865 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [221/782] Loss: 0.3878 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [222/782] Loss: 0.3012 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [223/782] Loss: 0.5524 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [224/782] Loss: 0.4431 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [225/782] Loss: 0.5102 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [226/782] Loss: 0.6251 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [227/782] Loss: 0.3888 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [228/782] Loss: 0.3060 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [229/782] Loss: 0.4289 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [230/782] Loss: 0.3147 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [231/782] Loss: 0.2833 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [232/782] Loss: 0.3981 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [233/782] Loss: 0.5147 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [234/782] Loss: 0.3739 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [235/782] Loss: 0.4480 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [236/782] Loss: 0.3916 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [237/782] Loss: 0.3750 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [238/782] Loss: 0.5980 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [239/782] Loss: 0.4907 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [240/782] Loss: 0.4339 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [241/782] Loss: 0.3686 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [242/782] Loss: 0.3859 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [243/782] Loss: 0.3069 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [244/782] Loss: 0.3603 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [245/782] Loss: 0.3201 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [246/782] Loss: 0.4822 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [247/782] Loss: 0.5024 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [248/782] Loss: 0.3730 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [249/782] Loss: 0.3780 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [250/782] Loss: 0.4034 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [251/782] Loss: 0.4380 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [252/782] Loss: 0.4174 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [253/782] Loss: 0.6146 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [254/782] Loss: 0.5495 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [255/782] Loss: 0.5270 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [256/782] Loss: 0.5606 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [257/782] Loss: 0.4629 | Acc: 85.56%\n",
      "Train Epoch [91/100] Batch [258/782] Loss: 0.2027 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [259/782] Loss: 0.3970 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [260/782] Loss: 0.3569 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [261/782] Loss: 0.6507 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [262/782] Loss: 0.4425 | Acc: 85.57%\n",
      "Train Epoch [91/100] Batch [263/782] Loss: 0.3372 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [264/782] Loss: 0.3443 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [265/782] Loss: 0.3126 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [266/782] Loss: 0.2911 | Acc: 85.61%\n",
      "Train Epoch [91/100] Batch [267/782] Loss: 0.3395 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [268/782] Loss: 0.3429 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [269/782] Loss: 0.3427 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [270/782] Loss: 0.3619 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [271/782] Loss: 0.5140 | Acc: 85.65%\n",
      "Train Epoch [91/100] Batch [272/782] Loss: 0.3130 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [273/782] Loss: 0.4621 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [274/782] Loss: 0.2246 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [275/782] Loss: 0.6541 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [276/782] Loss: 0.3213 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [277/782] Loss: 0.2389 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [278/782] Loss: 0.3728 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [279/782] Loss: 0.3529 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [280/782] Loss: 0.5018 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [281/782] Loss: 0.3832 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [282/782] Loss: 0.4183 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [283/782] Loss: 0.3609 | Acc: 85.72%\n",
      "Train Epoch [91/100] Batch [284/782] Loss: 0.5083 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [285/782] Loss: 0.5421 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [286/782] Loss: 0.4387 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [287/782] Loss: 0.2394 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [288/782] Loss: 0.4572 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [289/782] Loss: 0.4245 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [290/782] Loss: 0.3719 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [291/782] Loss: 0.3058 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [292/782] Loss: 0.6030 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [293/782] Loss: 0.4536 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [294/782] Loss: 0.3546 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [295/782] Loss: 0.4223 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [296/782] Loss: 0.4426 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [297/782] Loss: 0.3672 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [298/782] Loss: 0.1509 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [299/782] Loss: 0.2992 | Acc: 85.74%\n",
      "Train Epoch [91/100] Batch [300/782] Loss: 0.4607 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [301/782] Loss: 0.4713 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [302/782] Loss: 0.5547 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [303/782] Loss: 0.3824 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [304/782] Loss: 0.5695 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [305/782] Loss: 0.4635 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [306/782] Loss: 0.4874 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [307/782] Loss: 0.4633 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [308/782] Loss: 0.3869 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [309/782] Loss: 0.2305 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [310/782] Loss: 0.4368 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [311/782] Loss: 0.2909 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [312/782] Loss: 0.3025 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [313/782] Loss: 0.5208 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [314/782] Loss: 0.2023 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [315/782] Loss: 0.2944 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [316/782] Loss: 0.3922 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [317/782] Loss: 0.3008 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [318/782] Loss: 0.3916 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [319/782] Loss: 0.3573 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [320/782] Loss: 0.4953 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [321/782] Loss: 0.3167 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [322/782] Loss: 0.3396 | Acc: 85.67%\n",
      "Train Epoch [91/100] Batch [323/782] Loss: 0.3439 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [324/782] Loss: 0.3006 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [325/782] Loss: 0.4117 | Acc: 85.68%\n",
      "Train Epoch [91/100] Batch [326/782] Loss: 0.2430 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [327/782] Loss: 0.3568 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [328/782] Loss: 0.3677 | Acc: 85.71%\n",
      "Train Epoch [91/100] Batch [329/782] Loss: 0.3337 | Acc: 85.73%\n",
      "Train Epoch [91/100] Batch [330/782] Loss: 0.5651 | Acc: 85.70%\n",
      "Train Epoch [91/100] Batch [331/782] Loss: 0.6103 | Acc: 85.69%\n",
      "Train Epoch [91/100] Batch [332/782] Loss: 0.4900 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [333/782] Loss: 0.4223 | Acc: 85.66%\n",
      "Train Epoch [91/100] Batch [334/782] Loss: 0.5558 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [335/782] Loss: 0.4252 | Acc: 85.64%\n",
      "Train Epoch [91/100] Batch [336/782] Loss: 0.5404 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [337/782] Loss: 0.3792 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [338/782] Loss: 0.3761 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [339/782] Loss: 0.4112 | Acc: 85.61%\n",
      "Train Epoch [91/100] Batch [340/782] Loss: 0.2287 | Acc: 85.62%\n",
      "Train Epoch [91/100] Batch [341/782] Loss: 0.4383 | Acc: 85.61%\n",
      "Train Epoch [91/100] Batch [342/782] Loss: 0.3817 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [343/782] Loss: 0.5106 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [344/782] Loss: 0.3675 | Acc: 85.61%\n",
      "Train Epoch [91/100] Batch [345/782] Loss: 0.4446 | Acc: 85.60%\n",
      "Train Epoch [91/100] Batch [346/782] Loss: 0.3796 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [347/782] Loss: 0.5023 | Acc: 85.59%\n",
      "Train Epoch [91/100] Batch [348/782] Loss: 0.5507 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [349/782] Loss: 0.4045 | Acc: 85.58%\n",
      "Train Epoch [91/100] Batch [350/782] Loss: 0.4013 | Acc: 85.56%\n",
      "Train Epoch [91/100] Batch [351/782] Loss: 0.3575 | Acc: 85.56%\n",
      "Train Epoch [91/100] Batch [352/782] Loss: 0.3223 | Acc: 85.56%\n",
      "Train Epoch [91/100] Batch [353/782] Loss: 0.6638 | Acc: 85.55%\n",
      "Train Epoch [91/100] Batch [354/782] Loss: 0.3990 | Acc: 85.54%\n",
      "Train Epoch [91/100] Batch [355/782] Loss: 0.5906 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [356/782] Loss: 0.4538 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [357/782] Loss: 0.3480 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [358/782] Loss: 0.3378 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [359/782] Loss: 0.5033 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [360/782] Loss: 0.4063 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [361/782] Loss: 0.3159 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [362/782] Loss: 0.3570 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [363/782] Loss: 0.3722 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [364/782] Loss: 0.4050 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [365/782] Loss: 0.3300 | Acc: 85.54%\n",
      "Train Epoch [91/100] Batch [366/782] Loss: 0.4470 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [367/782] Loss: 0.6242 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [368/782] Loss: 0.4057 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [369/782] Loss: 0.3835 | Acc: 85.53%\n",
      "Train Epoch [91/100] Batch [370/782] Loss: 0.4363 | Acc: 85.52%\n",
      "Train Epoch [91/100] Batch [371/782] Loss: 0.4416 | Acc: 85.51%\n",
      "Train Epoch [91/100] Batch [372/782] Loss: 0.3206 | Acc: 85.50%\n",
      "Train Epoch [91/100] Batch [373/782] Loss: 0.3652 | Acc: 85.51%\n",
      "Train Epoch [91/100] Batch [374/782] Loss: 0.4782 | Acc: 85.50%\n",
      "Train Epoch [91/100] Batch [375/782] Loss: 0.4777 | Acc: 85.49%\n",
      "Train Epoch [91/100] Batch [376/782] Loss: 0.4969 | Acc: 85.48%\n",
      "Train Epoch [91/100] Batch [377/782] Loss: 0.3496 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [378/782] Loss: 0.4439 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [379/782] Loss: 0.4263 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [380/782] Loss: 0.4757 | Acc: 85.47%\n",
      "Train Epoch [91/100] Batch [381/782] Loss: 0.5293 | Acc: 85.46%\n",
      "Train Epoch [91/100] Batch [382/782] Loss: 0.4248 | Acc: 85.44%\n",
      "Train Epoch [91/100] Batch [383/782] Loss: 0.4759 | Acc: 85.44%\n",
      "Train Epoch [91/100] Batch [384/782] Loss: 0.3593 | Acc: 85.43%\n",
      "Train Epoch [91/100] Batch [385/782] Loss: 0.4002 | Acc: 85.42%\n",
      "Train Epoch [91/100] Batch [386/782] Loss: 0.6711 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [387/782] Loss: 0.3137 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [388/782] Loss: 0.4737 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [389/782] Loss: 0.3498 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [390/782] Loss: 0.3586 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [391/782] Loss: 0.6909 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [392/782] Loss: 0.6184 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [393/782] Loss: 0.1540 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [394/782] Loss: 0.4944 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [395/782] Loss: 0.4670 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [396/782] Loss: 0.3735 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [397/782] Loss: 0.2845 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [398/782] Loss: 0.2651 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [399/782] Loss: 0.3625 | Acc: 85.43%\n",
      "Train Epoch [91/100] Batch [400/782] Loss: 0.4831 | Acc: 85.42%\n",
      "Train Epoch [91/100] Batch [401/782] Loss: 0.4737 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [402/782] Loss: 0.3333 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [403/782] Loss: 0.4448 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [404/782] Loss: 0.5255 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [405/782] Loss: 0.3717 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [406/782] Loss: 0.3908 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [407/782] Loss: 0.3314 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [408/782] Loss: 0.5263 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [409/782] Loss: 0.4572 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [410/782] Loss: 0.3448 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [411/782] Loss: 0.4554 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [412/782] Loss: 0.4649 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [413/782] Loss: 0.6087 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [414/782] Loss: 0.3349 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [415/782] Loss: 0.4205 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [416/782] Loss: 0.4253 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [417/782] Loss: 0.4249 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [418/782] Loss: 0.5570 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [419/782] Loss: 0.5490 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [420/782] Loss: 0.3203 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [421/782] Loss: 0.5492 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [422/782] Loss: 0.4463 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [423/782] Loss: 0.4873 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [424/782] Loss: 0.3201 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [425/782] Loss: 0.3443 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [426/782] Loss: 0.3502 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [427/782] Loss: 0.4099 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [428/782] Loss: 0.4493 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [429/782] Loss: 0.3766 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [430/782] Loss: 0.3351 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [431/782] Loss: 0.4167 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [432/782] Loss: 0.3608 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [433/782] Loss: 0.3634 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [434/782] Loss: 0.4141 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [435/782] Loss: 0.4734 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [436/782] Loss: 0.3972 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [437/782] Loss: 0.3160 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [438/782] Loss: 0.4204 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [439/782] Loss: 0.3971 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [440/782] Loss: 0.4391 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [441/782] Loss: 0.3821 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [442/782] Loss: 0.4392 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [443/782] Loss: 0.4404 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [444/782] Loss: 0.4023 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [445/782] Loss: 0.6361 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [446/782] Loss: 0.4402 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [447/782] Loss: 0.1993 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [448/782] Loss: 0.2706 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [449/782] Loss: 0.4864 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [450/782] Loss: 0.3536 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [451/782] Loss: 0.5233 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [452/782] Loss: 0.6120 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [453/782] Loss: 0.4648 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [454/782] Loss: 0.3981 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [455/782] Loss: 0.3889 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [456/782] Loss: 0.4046 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [457/782] Loss: 0.4922 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [458/782] Loss: 0.3584 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [459/782] Loss: 0.4451 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [460/782] Loss: 0.3813 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [461/782] Loss: 0.4394 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [462/782] Loss: 0.3060 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [463/782] Loss: 0.4276 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [464/782] Loss: 0.3966 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [465/782] Loss: 0.3503 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [466/782] Loss: 0.5326 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [467/782] Loss: 0.5398 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [468/782] Loss: 0.5416 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [469/782] Loss: 0.6093 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [470/782] Loss: 0.5921 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [471/782] Loss: 0.4575 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [472/782] Loss: 0.5155 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [473/782] Loss: 0.4655 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [474/782] Loss: 0.4333 | Acc: 85.29%\n",
      "Train Epoch [91/100] Batch [475/782] Loss: 0.4468 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [476/782] Loss: 0.2633 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [477/782] Loss: 0.2792 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [478/782] Loss: 0.4337 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [479/782] Loss: 0.3135 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [480/782] Loss: 0.4023 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [481/782] Loss: 0.5463 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [482/782] Loss: 0.3812 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [483/782] Loss: 0.3680 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [484/782] Loss: 0.3607 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [485/782] Loss: 0.4096 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [486/782] Loss: 0.3877 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [487/782] Loss: 0.4091 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [488/782] Loss: 0.3630 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [489/782] Loss: 0.2555 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [490/782] Loss: 0.4406 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [491/782] Loss: 0.5172 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [492/782] Loss: 0.3715 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [493/782] Loss: 0.2706 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [494/782] Loss: 0.3290 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [495/782] Loss: 0.5377 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [496/782] Loss: 0.4209 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [497/782] Loss: 0.4044 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [498/782] Loss: 0.4499 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [499/782] Loss: 0.4542 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [500/782] Loss: 0.4420 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [501/782] Loss: 0.3920 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [502/782] Loss: 0.6528 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [503/782] Loss: 0.5457 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [504/782] Loss: 0.2896 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [505/782] Loss: 0.2841 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [506/782] Loss: 0.3660 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [507/782] Loss: 0.3542 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [508/782] Loss: 0.3616 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [509/782] Loss: 0.2843 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [510/782] Loss: 0.3933 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [511/782] Loss: 0.3505 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [512/782] Loss: 0.5643 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [513/782] Loss: 0.2706 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [514/782] Loss: 0.3736 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [515/782] Loss: 0.3431 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [516/782] Loss: 0.4389 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [517/782] Loss: 0.3979 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [518/782] Loss: 0.3669 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [519/782] Loss: 0.1794 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [520/782] Loss: 0.4263 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [521/782] Loss: 0.3706 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [522/782] Loss: 0.4568 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [523/782] Loss: 0.3154 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [524/782] Loss: 0.3243 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [525/782] Loss: 0.3459 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [526/782] Loss: 0.2692 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [527/782] Loss: 0.4437 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [528/782] Loss: 0.3798 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [529/782] Loss: 0.3975 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [530/782] Loss: 0.4407 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [531/782] Loss: 0.5747 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [532/782] Loss: 0.4641 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [533/782] Loss: 0.3198 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [534/782] Loss: 0.3012 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [535/782] Loss: 0.5812 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [536/782] Loss: 0.4033 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [537/782] Loss: 0.2014 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [538/782] Loss: 0.5198 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [539/782] Loss: 0.3575 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [540/782] Loss: 0.4180 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [541/782] Loss: 0.3303 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [542/782] Loss: 0.4406 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [543/782] Loss: 0.2989 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [544/782] Loss: 0.1792 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [545/782] Loss: 0.3888 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [546/782] Loss: 0.3659 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [547/782] Loss: 0.4307 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [548/782] Loss: 0.4795 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [549/782] Loss: 0.3057 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [550/782] Loss: 0.4386 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [551/782] Loss: 0.3666 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [552/782] Loss: 0.5295 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [553/782] Loss: 0.2945 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [554/782] Loss: 0.3525 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [555/782] Loss: 0.3420 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [556/782] Loss: 0.2947 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [557/782] Loss: 0.2989 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [558/782] Loss: 0.3974 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [559/782] Loss: 0.3973 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [560/782] Loss: 0.5086 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [561/782] Loss: 0.4436 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [562/782] Loss: 0.5158 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [563/782] Loss: 0.3929 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [564/782] Loss: 0.4694 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [565/782] Loss: 0.6530 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [566/782] Loss: 0.6724 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [567/782] Loss: 0.5367 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [568/782] Loss: 0.3759 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [569/782] Loss: 0.2620 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [570/782] Loss: 0.6356 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [571/782] Loss: 0.4378 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [572/782] Loss: 0.4054 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [573/782] Loss: 0.3993 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [574/782] Loss: 0.2570 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [575/782] Loss: 0.5087 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [576/782] Loss: 0.4108 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [577/782] Loss: 0.5483 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [578/782] Loss: 0.4429 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [579/782] Loss: 0.4180 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [580/782] Loss: 0.5026 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [581/782] Loss: 0.3325 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [582/782] Loss: 0.5341 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [583/782] Loss: 0.3498 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [584/782] Loss: 0.4560 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [585/782] Loss: 0.3282 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [586/782] Loss: 0.3433 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [587/782] Loss: 0.4379 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [588/782] Loss: 0.3827 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [589/782] Loss: 0.4184 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [590/782] Loss: 0.5626 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [591/782] Loss: 0.3941 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [592/782] Loss: 0.3255 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [593/782] Loss: 0.3021 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [594/782] Loss: 0.5703 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [595/782] Loss: 0.2841 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [596/782] Loss: 0.4996 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [597/782] Loss: 0.3620 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [598/782] Loss: 0.2907 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [599/782] Loss: 0.3792 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [600/782] Loss: 0.4663 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [601/782] Loss: 0.3217 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [602/782] Loss: 0.5845 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [603/782] Loss: 0.3446 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [604/782] Loss: 0.3330 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [605/782] Loss: 0.4263 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [606/782] Loss: 0.4720 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [607/782] Loss: 0.3299 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [608/782] Loss: 0.5709 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [609/782] Loss: 0.3879 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [610/782] Loss: 0.3851 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [611/782] Loss: 0.2479 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [612/782] Loss: 0.4400 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [613/782] Loss: 0.5414 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [614/782] Loss: 0.4555 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [615/782] Loss: 0.2969 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [616/782] Loss: 0.2956 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [617/782] Loss: 0.3504 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [618/782] Loss: 0.5305 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [619/782] Loss: 0.2414 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [620/782] Loss: 0.6480 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [621/782] Loss: 0.5185 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [622/782] Loss: 0.2525 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [623/782] Loss: 0.2592 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [624/782] Loss: 0.3489 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [625/782] Loss: 0.4166 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [626/782] Loss: 0.6511 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [627/782] Loss: 0.3988 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [628/782] Loss: 0.4453 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [629/782] Loss: 0.3149 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [630/782] Loss: 0.4631 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [631/782] Loss: 0.4473 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [632/782] Loss: 0.1942 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [633/782] Loss: 0.4620 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [634/782] Loss: 0.4107 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [635/782] Loss: 0.2789 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [636/782] Loss: 0.5132 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [637/782] Loss: 0.3122 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [638/782] Loss: 0.3154 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [639/782] Loss: 0.2457 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [640/782] Loss: 0.6471 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [641/782] Loss: 0.3983 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [642/782] Loss: 0.4022 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [643/782] Loss: 0.4842 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [644/782] Loss: 0.4741 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [645/782] Loss: 0.4400 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [646/782] Loss: 0.2649 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [647/782] Loss: 0.3977 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [648/782] Loss: 0.4383 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [649/782] Loss: 0.5065 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [650/782] Loss: 0.3625 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [651/782] Loss: 0.3068 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [652/782] Loss: 0.4146 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [653/782] Loss: 0.3302 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [654/782] Loss: 0.3984 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [655/782] Loss: 0.3832 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [656/782] Loss: 0.3487 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [657/782] Loss: 0.3311 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [658/782] Loss: 0.3809 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [659/782] Loss: 0.3852 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [660/782] Loss: 0.6170 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [661/782] Loss: 0.2927 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [662/782] Loss: 0.3062 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [663/782] Loss: 0.3724 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [664/782] Loss: 0.3202 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [665/782] Loss: 0.4103 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [666/782] Loss: 0.4087 | Acc: 85.41%\n",
      "Train Epoch [91/100] Batch [667/782] Loss: 0.6684 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [668/782] Loss: 0.3962 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [669/782] Loss: 0.4042 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [670/782] Loss: 0.5273 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [671/782] Loss: 0.3264 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [672/782] Loss: 0.2251 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [673/782] Loss: 0.5398 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [674/782] Loss: 0.4536 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [675/782] Loss: 0.3518 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [676/782] Loss: 0.3406 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [677/782] Loss: 0.3143 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [678/782] Loss: 0.3091 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [679/782] Loss: 0.4510 | Acc: 85.40%\n",
      "Train Epoch [91/100] Batch [680/782] Loss: 0.5038 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [681/782] Loss: 0.4088 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [682/782] Loss: 0.6385 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [683/782] Loss: 0.2454 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [684/782] Loss: 0.4756 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [685/782] Loss: 0.3399 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [686/782] Loss: 0.4227 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [687/782] Loss: 0.6147 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [688/782] Loss: 0.4066 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [689/782] Loss: 0.3111 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [690/782] Loss: 0.3525 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [691/782] Loss: 0.6321 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [692/782] Loss: 0.3469 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [693/782] Loss: 0.3198 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [694/782] Loss: 0.4066 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [695/782] Loss: 0.3647 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [696/782] Loss: 0.3547 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [697/782] Loss: 0.4906 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [698/782] Loss: 0.2872 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [699/782] Loss: 0.2557 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [700/782] Loss: 0.4952 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [701/782] Loss: 0.4195 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [702/782] Loss: 0.4024 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [703/782] Loss: 0.3595 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [704/782] Loss: 0.4938 | Acc: 85.39%\n",
      "Train Epoch [91/100] Batch [705/782] Loss: 0.5888 | Acc: 85.38%\n",
      "Train Epoch [91/100] Batch [706/782] Loss: 0.5082 | Acc: 85.37%\n",
      "Train Epoch [91/100] Batch [707/782] Loss: 0.5632 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [708/782] Loss: 0.3700 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [709/782] Loss: 0.4934 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [710/782] Loss: 0.4905 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [711/782] Loss: 0.4176 | Acc: 85.36%\n",
      "Train Epoch [91/100] Batch [712/782] Loss: 0.4962 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [713/782] Loss: 0.5754 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [714/782] Loss: 0.4096 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [715/782] Loss: 0.5309 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [716/782] Loss: 0.5034 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [717/782] Loss: 0.4145 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [718/782] Loss: 0.3880 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [719/782] Loss: 0.2230 | Acc: 85.34%\n",
      "Train Epoch [91/100] Batch [720/782] Loss: 0.3657 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [721/782] Loss: 0.3380 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [722/782] Loss: 0.3590 | Acc: 85.35%\n",
      "Train Epoch [91/100] Batch [723/782] Loss: 0.6418 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [724/782] Loss: 0.4922 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [725/782] Loss: 0.3678 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [726/782] Loss: 0.4546 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [727/782] Loss: 0.6613 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [728/782] Loss: 0.3625 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [729/782] Loss: 0.3625 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [730/782] Loss: 0.5157 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [731/782] Loss: 0.3581 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [732/782] Loss: 0.3775 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [733/782] Loss: 0.5166 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [734/782] Loss: 0.2586 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [735/782] Loss: 0.3298 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [736/782] Loss: 0.3710 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [737/782] Loss: 0.3847 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [738/782] Loss: 0.3085 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [739/782] Loss: 0.5829 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [740/782] Loss: 0.3407 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [741/782] Loss: 0.3404 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [742/782] Loss: 0.3893 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [743/782] Loss: 0.3839 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [744/782] Loss: 0.3004 | Acc: 85.33%\n",
      "Train Epoch [91/100] Batch [745/782] Loss: 0.5384 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [746/782] Loss: 0.5961 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [747/782] Loss: 0.3861 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [748/782] Loss: 0.3550 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [749/782] Loss: 0.3874 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [750/782] Loss: 0.4729 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [751/782] Loss: 0.2987 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [752/782] Loss: 0.3543 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [753/782] Loss: 0.4206 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [754/782] Loss: 0.2876 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [755/782] Loss: 0.3516 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [756/782] Loss: 0.3146 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [757/782] Loss: 0.2292 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [758/782] Loss: 0.4918 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [759/782] Loss: 0.2380 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [760/782] Loss: 0.3045 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [761/782] Loss: 0.4389 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [762/782] Loss: 0.3637 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [763/782] Loss: 0.4573 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [764/782] Loss: 0.2934 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [765/782] Loss: 0.5949 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [766/782] Loss: 0.4639 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [767/782] Loss: 0.4927 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [768/782] Loss: 0.3340 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [769/782] Loss: 0.5792 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [770/782] Loss: 0.2642 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [771/782] Loss: 0.4111 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [772/782] Loss: 0.3761 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [773/782] Loss: 0.3240 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [774/782] Loss: 0.3694 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [775/782] Loss: 0.3913 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [776/782] Loss: 0.3320 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [777/782] Loss: 0.5642 | Acc: 85.32%\n",
      "Train Epoch [91/100] Batch [778/782] Loss: 0.5340 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [779/782] Loss: 0.4704 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [780/782] Loss: 0.4393 | Acc: 85.31%\n",
      "Train Epoch [91/100] Batch [781/782] Loss: 0.5706 | Acc: 85.30%\n",
      "Train Epoch [91/100] Batch [782/782] Loss: 0.4447 | Acc: 85.30%\n",
      "Epoch 91 completed in 29.71s.\n",
      "Test Epoch [91/100] Loss: 1.0189 | Acc: 72.09% | Inference Time: 8.04s\n",
      "Epoch 91 results saved to CSV.\n",
      "Epoch 92/100\n",
      "Train Epoch [92/100] Batch [1/782] Loss: 0.5737 | Acc: 71.88%\n",
      "Train Epoch [92/100] Batch [2/782] Loss: 0.2713 | Acc: 79.69%\n",
      "Train Epoch [92/100] Batch [3/782] Loss: 0.3361 | Acc: 82.81%\n",
      "Train Epoch [92/100] Batch [4/782] Loss: 0.4021 | Acc: 82.81%\n",
      "Train Epoch [92/100] Batch [5/782] Loss: 0.2842 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [6/782] Loss: 0.4126 | Acc: 83.85%\n",
      "Train Epoch [92/100] Batch [7/782] Loss: 0.4649 | Acc: 84.15%\n",
      "Train Epoch [92/100] Batch [8/782] Loss: 0.4351 | Acc: 84.18%\n",
      "Train Epoch [92/100] Batch [9/782] Loss: 0.5221 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [10/782] Loss: 0.4020 | Acc: 84.22%\n",
      "Train Epoch [92/100] Batch [11/782] Loss: 0.3100 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [12/782] Loss: 0.4061 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [13/782] Loss: 0.3160 | Acc: 84.62%\n",
      "Train Epoch [92/100] Batch [14/782] Loss: 0.4355 | Acc: 84.49%\n",
      "Train Epoch [92/100] Batch [15/782] Loss: 0.5778 | Acc: 83.96%\n",
      "Train Epoch [92/100] Batch [16/782] Loss: 0.3973 | Acc: 83.59%\n",
      "Train Epoch [92/100] Batch [17/782] Loss: 0.3612 | Acc: 83.46%\n",
      "Train Epoch [92/100] Batch [18/782] Loss: 0.3065 | Acc: 83.77%\n",
      "Train Epoch [92/100] Batch [19/782] Loss: 0.7763 | Acc: 83.31%\n",
      "Train Epoch [92/100] Batch [20/782] Loss: 0.4810 | Acc: 83.12%\n",
      "Train Epoch [92/100] Batch [21/782] Loss: 0.3181 | Acc: 83.41%\n",
      "Train Epoch [92/100] Batch [22/782] Loss: 0.4344 | Acc: 83.52%\n",
      "Train Epoch [92/100] Batch [23/782] Loss: 0.5554 | Acc: 83.42%\n",
      "Train Epoch [92/100] Batch [24/782] Loss: 0.4188 | Acc: 83.59%\n",
      "Train Epoch [92/100] Batch [25/782] Loss: 0.6236 | Acc: 83.44%\n",
      "Train Epoch [92/100] Batch [26/782] Loss: 0.4881 | Acc: 83.41%\n",
      "Train Epoch [92/100] Batch [27/782] Loss: 0.3882 | Acc: 83.56%\n",
      "Train Epoch [92/100] Batch [28/782] Loss: 0.4771 | Acc: 83.48%\n",
      "Train Epoch [92/100] Batch [29/782] Loss: 0.4400 | Acc: 83.57%\n",
      "Train Epoch [92/100] Batch [30/782] Loss: 0.4437 | Acc: 83.75%\n",
      "Train Epoch [92/100] Batch [31/782] Loss: 0.4241 | Acc: 83.77%\n",
      "Train Epoch [92/100] Batch [32/782] Loss: 0.3558 | Acc: 83.89%\n",
      "Train Epoch [92/100] Batch [33/782] Loss: 0.3419 | Acc: 83.95%\n",
      "Train Epoch [92/100] Batch [34/782] Loss: 0.4692 | Acc: 83.78%\n",
      "Train Epoch [92/100] Batch [35/782] Loss: 0.4111 | Acc: 83.79%\n",
      "Train Epoch [92/100] Batch [36/782] Loss: 0.4334 | Acc: 83.81%\n",
      "Train Epoch [92/100] Batch [37/782] Loss: 0.4904 | Acc: 83.78%\n",
      "Train Epoch [92/100] Batch [38/782] Loss: 0.6033 | Acc: 83.84%\n",
      "Train Epoch [92/100] Batch [39/782] Loss: 0.3711 | Acc: 83.77%\n",
      "Train Epoch [92/100] Batch [40/782] Loss: 0.4694 | Acc: 83.87%\n",
      "Train Epoch [92/100] Batch [41/782] Loss: 0.3196 | Acc: 84.07%\n",
      "Train Epoch [92/100] Batch [42/782] Loss: 0.3467 | Acc: 84.19%\n",
      "Train Epoch [92/100] Batch [43/782] Loss: 0.4491 | Acc: 84.23%\n",
      "Train Epoch [92/100] Batch [44/782] Loss: 0.4313 | Acc: 84.23%\n",
      "Train Epoch [92/100] Batch [45/782] Loss: 0.4941 | Acc: 84.10%\n",
      "Train Epoch [92/100] Batch [46/782] Loss: 0.4848 | Acc: 84.10%\n",
      "Train Epoch [92/100] Batch [47/782] Loss: 0.4682 | Acc: 84.08%\n",
      "Train Epoch [92/100] Batch [48/782] Loss: 0.5530 | Acc: 84.02%\n",
      "Train Epoch [92/100] Batch [49/782] Loss: 0.3240 | Acc: 84.12%\n",
      "Train Epoch [92/100] Batch [50/782] Loss: 0.2642 | Acc: 84.25%\n",
      "Train Epoch [92/100] Batch [51/782] Loss: 0.4225 | Acc: 84.22%\n",
      "Train Epoch [92/100] Batch [52/782] Loss: 0.3681 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [53/782] Loss: 0.3892 | Acc: 84.38%\n",
      "Train Epoch [92/100] Batch [54/782] Loss: 0.3364 | Acc: 84.43%\n",
      "Train Epoch [92/100] Batch [55/782] Loss: 0.3340 | Acc: 84.46%\n",
      "Train Epoch [92/100] Batch [56/782] Loss: 0.4066 | Acc: 84.51%\n",
      "Train Epoch [92/100] Batch [57/782] Loss: 0.3880 | Acc: 84.57%\n",
      "Train Epoch [92/100] Batch [58/782] Loss: 0.4426 | Acc: 84.54%\n",
      "Train Epoch [92/100] Batch [59/782] Loss: 0.3550 | Acc: 84.59%\n",
      "Train Epoch [92/100] Batch [60/782] Loss: 0.4228 | Acc: 84.56%\n",
      "Train Epoch [92/100] Batch [61/782] Loss: 0.3562 | Acc: 84.66%\n",
      "Train Epoch [92/100] Batch [62/782] Loss: 0.5487 | Acc: 84.58%\n",
      "Train Epoch [92/100] Batch [63/782] Loss: 0.4059 | Acc: 84.60%\n",
      "Train Epoch [92/100] Batch [64/782] Loss: 0.3575 | Acc: 84.59%\n",
      "Train Epoch [92/100] Batch [65/782] Loss: 0.3116 | Acc: 84.69%\n",
      "Train Epoch [92/100] Batch [66/782] Loss: 0.3820 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [67/782] Loss: 0.3887 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [68/782] Loss: 0.2811 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [69/782] Loss: 0.4120 | Acc: 84.85%\n",
      "Train Epoch [92/100] Batch [70/782] Loss: 0.5699 | Acc: 84.78%\n",
      "Train Epoch [92/100] Batch [71/782] Loss: 0.4902 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [72/782] Loss: 0.4090 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [73/782] Loss: 0.3880 | Acc: 84.74%\n",
      "Train Epoch [92/100] Batch [74/782] Loss: 0.4330 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [75/782] Loss: 0.4706 | Acc: 84.69%\n",
      "Train Epoch [92/100] Batch [76/782] Loss: 0.4485 | Acc: 84.64%\n",
      "Train Epoch [92/100] Batch [77/782] Loss: 0.5076 | Acc: 84.58%\n",
      "Train Epoch [92/100] Batch [78/782] Loss: 0.1942 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [79/782] Loss: 0.2674 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [80/782] Loss: 0.3410 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [81/782] Loss: 0.2500 | Acc: 84.86%\n",
      "Train Epoch [92/100] Batch [82/782] Loss: 0.3250 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [83/782] Loss: 0.3297 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [84/782] Loss: 0.4423 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [85/782] Loss: 0.2903 | Acc: 84.94%\n",
      "Train Epoch [92/100] Batch [86/782] Loss: 0.4274 | Acc: 84.97%\n",
      "Train Epoch [92/100] Batch [87/782] Loss: 0.3570 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [88/782] Loss: 0.4120 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [89/782] Loss: 0.6527 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [90/782] Loss: 0.2849 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [91/782] Loss: 0.4763 | Acc: 84.99%\n",
      "Train Epoch [92/100] Batch [92/782] Loss: 0.3214 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [93/782] Loss: 0.3699 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [94/782] Loss: 0.3731 | Acc: 85.04%\n",
      "Train Epoch [92/100] Batch [95/782] Loss: 0.4157 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [96/782] Loss: 0.5296 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [97/782] Loss: 0.5320 | Acc: 84.87%\n",
      "Train Epoch [92/100] Batch [98/782] Loss: 0.6091 | Acc: 84.73%\n",
      "Train Epoch [92/100] Batch [99/782] Loss: 0.3887 | Acc: 84.74%\n",
      "Train Epoch [92/100] Batch [100/782] Loss: 0.3369 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [101/782] Loss: 0.5452 | Acc: 84.70%\n",
      "Train Epoch [92/100] Batch [102/782] Loss: 0.4170 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [103/782] Loss: 0.3559 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [104/782] Loss: 0.5052 | Acc: 84.66%\n",
      "Train Epoch [92/100] Batch [105/782] Loss: 0.3636 | Acc: 84.67%\n",
      "Train Epoch [92/100] Batch [106/782] Loss: 0.3147 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [107/782] Loss: 0.4850 | Acc: 84.65%\n",
      "Train Epoch [92/100] Batch [108/782] Loss: 0.3641 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [109/782] Loss: 0.6765 | Acc: 84.62%\n",
      "Train Epoch [92/100] Batch [110/782] Loss: 0.4087 | Acc: 84.63%\n",
      "Train Epoch [92/100] Batch [111/782] Loss: 0.4011 | Acc: 84.60%\n",
      "Train Epoch [92/100] Batch [112/782] Loss: 0.2632 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [113/782] Loss: 0.4853 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [114/782] Loss: 0.3356 | Acc: 84.70%\n",
      "Train Epoch [92/100] Batch [115/782] Loss: 0.5067 | Acc: 84.70%\n",
      "Train Epoch [92/100] Batch [116/782] Loss: 0.4706 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [117/782] Loss: 0.5306 | Acc: 84.71%\n",
      "Train Epoch [92/100] Batch [118/782] Loss: 0.5606 | Acc: 84.68%\n",
      "Train Epoch [92/100] Batch [119/782] Loss: 0.2490 | Acc: 84.74%\n",
      "Train Epoch [92/100] Batch [120/782] Loss: 0.4089 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [121/782] Loss: 0.4112 | Acc: 84.76%\n",
      "Train Epoch [92/100] Batch [122/782] Loss: 0.4627 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [123/782] Loss: 0.3507 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [124/782] Loss: 0.2857 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [125/782] Loss: 0.4455 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [126/782] Loss: 0.4913 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [127/782] Loss: 0.2895 | Acc: 84.87%\n",
      "Train Epoch [92/100] Batch [128/782] Loss: 0.2653 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [129/782] Loss: 0.5457 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [130/782] Loss: 0.5302 | Acc: 84.88%\n",
      "Train Epoch [92/100] Batch [131/782] Loss: 0.3303 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [132/782] Loss: 0.4169 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [133/782] Loss: 0.4927 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [134/782] Loss: 0.3479 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [135/782] Loss: 0.2545 | Acc: 84.99%\n",
      "Train Epoch [92/100] Batch [136/782] Loss: 0.4040 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [137/782] Loss: 0.5553 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [138/782] Loss: 0.3723 | Acc: 84.96%\n",
      "Train Epoch [92/100] Batch [139/782] Loss: 0.4584 | Acc: 84.96%\n",
      "Train Epoch [92/100] Batch [140/782] Loss: 0.2951 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [141/782] Loss: 0.6689 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [142/782] Loss: 0.3916 | Acc: 84.98%\n",
      "Train Epoch [92/100] Batch [143/782] Loss: 0.3639 | Acc: 84.98%\n",
      "Train Epoch [92/100] Batch [144/782] Loss: 0.2342 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [145/782] Loss: 0.6291 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [146/782] Loss: 0.4426 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [147/782] Loss: 0.3668 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [148/782] Loss: 0.5327 | Acc: 84.86%\n",
      "Train Epoch [92/100] Batch [149/782] Loss: 0.2916 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [150/782] Loss: 0.4286 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [151/782] Loss: 0.3584 | Acc: 84.94%\n",
      "Train Epoch [92/100] Batch [152/782] Loss: 0.4357 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [153/782] Loss: 0.4328 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [154/782] Loss: 0.3456 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [155/782] Loss: 0.6140 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [156/782] Loss: 0.4984 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [157/782] Loss: 0.4228 | Acc: 84.89%\n",
      "Train Epoch [92/100] Batch [158/782] Loss: 0.3135 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [159/782] Loss: 0.5105 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [160/782] Loss: 0.4286 | Acc: 84.90%\n",
      "Train Epoch [92/100] Batch [161/782] Loss: 0.3579 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [162/782] Loss: 0.2567 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [163/782] Loss: 0.3281 | Acc: 84.97%\n",
      "Train Epoch [92/100] Batch [164/782] Loss: 0.4634 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [165/782] Loss: 0.3326 | Acc: 84.96%\n",
      "Train Epoch [92/100] Batch [166/782] Loss: 0.4725 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [167/782] Loss: 0.5824 | Acc: 84.88%\n",
      "Train Epoch [92/100] Batch [168/782] Loss: 0.3678 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [169/782] Loss: 0.5276 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [170/782] Loss: 0.6877 | Acc: 84.86%\n",
      "Train Epoch [92/100] Batch [171/782] Loss: 0.3046 | Acc: 84.89%\n",
      "Train Epoch [92/100] Batch [172/782] Loss: 0.4299 | Acc: 84.88%\n",
      "Train Epoch [92/100] Batch [173/782] Loss: 0.6041 | Acc: 84.82%\n",
      "Train Epoch [92/100] Batch [174/782] Loss: 0.4579 | Acc: 84.82%\n",
      "Train Epoch [92/100] Batch [175/782] Loss: 0.3973 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [176/782] Loss: 0.4721 | Acc: 84.78%\n",
      "Train Epoch [92/100] Batch [177/782] Loss: 0.3292 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [178/782] Loss: 0.4894 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [179/782] Loss: 0.4361 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [180/782] Loss: 0.3907 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [181/782] Loss: 0.4367 | Acc: 84.82%\n",
      "Train Epoch [92/100] Batch [182/782] Loss: 0.3059 | Acc: 84.86%\n",
      "Train Epoch [92/100] Batch [183/782] Loss: 0.4101 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [184/782] Loss: 0.4653 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [185/782] Loss: 0.4395 | Acc: 84.82%\n",
      "Train Epoch [92/100] Batch [186/782] Loss: 0.4311 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [187/782] Loss: 0.4647 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [188/782] Loss: 0.5013 | Acc: 84.79%\n",
      "Train Epoch [92/100] Batch [189/782] Loss: 0.3734 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [190/782] Loss: 0.5055 | Acc: 84.77%\n",
      "Train Epoch [92/100] Batch [191/782] Loss: 0.4148 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [192/782] Loss: 0.2137 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [193/782] Loss: 0.4440 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [194/782] Loss: 0.4158 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [195/782] Loss: 0.5303 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [196/782] Loss: 0.3921 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [197/782] Loss: 0.2583 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [198/782] Loss: 0.4299 | Acc: 84.82%\n",
      "Train Epoch [92/100] Batch [199/782] Loss: 0.4957 | Acc: 84.81%\n",
      "Train Epoch [92/100] Batch [200/782] Loss: 0.4812 | Acc: 84.78%\n",
      "Train Epoch [92/100] Batch [201/782] Loss: 0.3018 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [202/782] Loss: 0.5443 | Acc: 84.78%\n",
      "Train Epoch [92/100] Batch [203/782] Loss: 0.4627 | Acc: 84.78%\n",
      "Train Epoch [92/100] Batch [204/782] Loss: 0.3059 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [205/782] Loss: 0.3983 | Acc: 84.79%\n",
      "Train Epoch [92/100] Batch [206/782] Loss: 0.5220 | Acc: 84.76%\n",
      "Train Epoch [92/100] Batch [207/782] Loss: 0.4435 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [208/782] Loss: 0.3750 | Acc: 84.75%\n",
      "Train Epoch [92/100] Batch [209/782] Loss: 0.3641 | Acc: 84.79%\n",
      "Train Epoch [92/100] Batch [210/782] Loss: 0.4532 | Acc: 84.79%\n",
      "Train Epoch [92/100] Batch [211/782] Loss: 0.3777 | Acc: 84.80%\n",
      "Train Epoch [92/100] Batch [212/782] Loss: 0.2534 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [213/782] Loss: 0.4255 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [214/782] Loss: 0.4085 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [215/782] Loss: 0.4561 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [216/782] Loss: 0.3941 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [217/782] Loss: 0.4688 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [218/782] Loss: 0.4710 | Acc: 84.83%\n",
      "Train Epoch [92/100] Batch [219/782] Loss: 0.4071 | Acc: 84.85%\n",
      "Train Epoch [92/100] Batch [220/782] Loss: 0.3962 | Acc: 84.84%\n",
      "Train Epoch [92/100] Batch [221/782] Loss: 0.2910 | Acc: 84.87%\n",
      "Train Epoch [92/100] Batch [222/782] Loss: 0.3535 | Acc: 84.88%\n",
      "Train Epoch [92/100] Batch [223/782] Loss: 0.3352 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [224/782] Loss: 0.3934 | Acc: 84.91%\n",
      "Train Epoch [92/100] Batch [225/782] Loss: 0.4013 | Acc: 84.92%\n",
      "Train Epoch [92/100] Batch [226/782] Loss: 0.3648 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [227/782] Loss: 0.3928 | Acc: 84.93%\n",
      "Train Epoch [92/100] Batch [228/782] Loss: 0.3674 | Acc: 84.94%\n",
      "Train Epoch [92/100] Batch [229/782] Loss: 0.4822 | Acc: 84.94%\n",
      "Train Epoch [92/100] Batch [230/782] Loss: 0.3826 | Acc: 84.95%\n",
      "Train Epoch [92/100] Batch [231/782] Loss: 0.3988 | Acc: 84.96%\n",
      "Train Epoch [92/100] Batch [232/782] Loss: 0.1843 | Acc: 85.01%\n",
      "Train Epoch [92/100] Batch [233/782] Loss: 0.3611 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [234/782] Loss: 0.5031 | Acc: 85.01%\n",
      "Train Epoch [92/100] Batch [235/782] Loss: 0.2946 | Acc: 85.04%\n",
      "Train Epoch [92/100] Batch [236/782] Loss: 0.5949 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [237/782] Loss: 0.2997 | Acc: 85.01%\n",
      "Train Epoch [92/100] Batch [238/782] Loss: 0.3805 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [239/782] Loss: 0.5213 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [240/782] Loss: 0.4413 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [241/782] Loss: 0.3508 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [242/782] Loss: 0.6171 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [243/782] Loss: 0.4709 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [244/782] Loss: 0.4138 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [245/782] Loss: 0.4599 | Acc: 85.01%\n",
      "Train Epoch [92/100] Batch [246/782] Loss: 0.5352 | Acc: 85.01%\n",
      "Train Epoch [92/100] Batch [247/782] Loss: 0.4602 | Acc: 85.00%\n",
      "Train Epoch [92/100] Batch [248/782] Loss: 0.2753 | Acc: 85.04%\n",
      "Train Epoch [92/100] Batch [249/782] Loss: 0.5371 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [250/782] Loss: 0.4830 | Acc: 85.02%\n",
      "Train Epoch [92/100] Batch [251/782] Loss: 0.3650 | Acc: 85.03%\n",
      "Train Epoch [92/100] Batch [252/782] Loss: 0.3167 | Acc: 85.04%\n",
      "Train Epoch [92/100] Batch [253/782] Loss: 0.5022 | Acc: 85.05%\n",
      "Train Epoch [92/100] Batch [254/782] Loss: 0.4796 | Acc: 85.05%\n",
      "Train Epoch [92/100] Batch [255/782] Loss: 0.4091 | Acc: 85.06%\n",
      "Train Epoch [92/100] Batch [256/782] Loss: 0.3538 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [257/782] Loss: 0.2984 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [258/782] Loss: 0.4728 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [259/782] Loss: 0.4809 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [260/782] Loss: 0.2380 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [261/782] Loss: 0.4654 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [262/782] Loss: 0.4676 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [263/782] Loss: 0.3154 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [264/782] Loss: 0.5050 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [265/782] Loss: 0.3680 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [266/782] Loss: 0.4328 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [267/782] Loss: 0.4150 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [268/782] Loss: 0.5746 | Acc: 85.07%\n",
      "Train Epoch [92/100] Batch [269/782] Loss: 0.4780 | Acc: 85.07%\n",
      "Train Epoch [92/100] Batch [270/782] Loss: 0.4032 | Acc: 85.07%\n",
      "Train Epoch [92/100] Batch [271/782] Loss: 0.3986 | Acc: 85.07%\n",
      "Train Epoch [92/100] Batch [272/782] Loss: 0.3980 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [273/782] Loss: 0.4434 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [274/782] Loss: 0.2880 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [275/782] Loss: 0.1963 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [276/782] Loss: 0.4360 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [277/782] Loss: 0.3473 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [278/782] Loss: 0.6271 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [279/782] Loss: 0.5086 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [280/782] Loss: 0.3290 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [281/782] Loss: 0.5181 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [282/782] Loss: 0.4598 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [283/782] Loss: 0.3512 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [284/782] Loss: 0.4679 | Acc: 85.08%\n",
      "Train Epoch [92/100] Batch [285/782] Loss: 0.3722 | Acc: 85.09%\n",
      "Train Epoch [92/100] Batch [286/782] Loss: 0.2544 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [287/782] Loss: 0.3088 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [288/782] Loss: 0.4555 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [289/782] Loss: 0.3538 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [290/782] Loss: 0.3790 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [291/782] Loss: 0.3603 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [292/782] Loss: 0.3585 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [293/782] Loss: 0.3392 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [294/782] Loss: 0.2809 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [295/782] Loss: 0.4547 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [296/782] Loss: 0.2818 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [297/782] Loss: 0.2854 | Acc: 85.15%\n",
      "Train Epoch [92/100] Batch [298/782] Loss: 0.3316 | Acc: 85.16%\n",
      "Train Epoch [92/100] Batch [299/782] Loss: 0.3812 | Acc: 85.15%\n",
      "Train Epoch [92/100] Batch [300/782] Loss: 0.4020 | Acc: 85.16%\n",
      "Train Epoch [92/100] Batch [301/782] Loss: 0.6120 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [302/782] Loss: 0.4278 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [303/782] Loss: 0.4775 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [304/782] Loss: 0.3698 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [305/782] Loss: 0.4153 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [306/782] Loss: 0.2624 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [307/782] Loss: 0.4334 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [308/782] Loss: 0.4039 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [309/782] Loss: 0.4514 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [310/782] Loss: 0.3766 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [311/782] Loss: 0.2337 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [312/782] Loss: 0.3820 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [313/782] Loss: 0.3913 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [314/782] Loss: 0.4128 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [315/782] Loss: 0.3921 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [316/782] Loss: 0.3954 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [317/782] Loss: 0.3305 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [318/782] Loss: 0.4559 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [319/782] Loss: 0.3217 | Acc: 85.15%\n",
      "Train Epoch [92/100] Batch [320/782] Loss: 0.6511 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [321/782] Loss: 0.4053 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [322/782] Loss: 0.6531 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [323/782] Loss: 0.3837 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [324/782] Loss: 0.3973 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [325/782] Loss: 0.3388 | Acc: 85.13%\n",
      "Train Epoch [92/100] Batch [326/782] Loss: 0.4943 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [327/782] Loss: 0.5099 | Acc: 85.10%\n",
      "Train Epoch [92/100] Batch [328/782] Loss: 0.2591 | Acc: 85.11%\n",
      "Train Epoch [92/100] Batch [329/782] Loss: 0.3748 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [330/782] Loss: 0.3782 | Acc: 85.12%\n",
      "Train Epoch [92/100] Batch [331/782] Loss: 0.3307 | Acc: 85.14%\n",
      "Train Epoch [92/100] Batch [332/782] Loss: 0.2654 | Acc: 85.16%\n",
      "Train Epoch [92/100] Batch [333/782] Loss: 0.2326 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [334/782] Loss: 0.5947 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [335/782] Loss: 0.5711 | Acc: 85.17%\n",
      "Train Epoch [92/100] Batch [336/782] Loss: 0.4306 | Acc: 85.17%\n",
      "Train Epoch [92/100] Batch [337/782] Loss: 0.3710 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [338/782] Loss: 0.4313 | Acc: 85.17%\n",
      "Train Epoch [92/100] Batch [339/782] Loss: 0.3646 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [340/782] Loss: 0.3013 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [341/782] Loss: 0.4078 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [342/782] Loss: 0.5485 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [343/782] Loss: 0.3281 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [344/782] Loss: 0.4324 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [345/782] Loss: 0.4613 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [346/782] Loss: 0.2453 | Acc: 85.21%\n",
      "Train Epoch [92/100] Batch [347/782] Loss: 0.3487 | Acc: 85.21%\n",
      "Train Epoch [92/100] Batch [348/782] Loss: 0.4603 | Acc: 85.21%\n",
      "Train Epoch [92/100] Batch [349/782] Loss: 0.5720 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [350/782] Loss: 0.4946 | Acc: 85.17%\n",
      "Train Epoch [92/100] Batch [351/782] Loss: 0.3067 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [352/782] Loss: 0.2725 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [353/782] Loss: 0.4962 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [354/782] Loss: 0.2962 | Acc: 85.21%\n",
      "Train Epoch [92/100] Batch [355/782] Loss: 0.3079 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [356/782] Loss: 0.3752 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [357/782] Loss: 0.4204 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [358/782] Loss: 0.5019 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [359/782] Loss: 0.2798 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [360/782] Loss: 0.3800 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [361/782] Loss: 0.3304 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [362/782] Loss: 0.5396 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [363/782] Loss: 0.2530 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [364/782] Loss: 0.3685 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [365/782] Loss: 0.3158 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [366/782] Loss: 0.4422 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [367/782] Loss: 0.4623 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [368/782] Loss: 0.3255 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [369/782] Loss: 0.4152 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [370/782] Loss: 0.4479 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [371/782] Loss: 0.4496 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [372/782] Loss: 0.4631 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [373/782] Loss: 0.3159 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [374/782] Loss: 0.4886 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [375/782] Loss: 0.5074 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [376/782] Loss: 0.5197 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [377/782] Loss: 0.4880 | Acc: 85.18%\n",
      "Train Epoch [92/100] Batch [378/782] Loss: 0.3646 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [379/782] Loss: 0.3798 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [380/782] Loss: 0.3369 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [381/782] Loss: 0.3183 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [382/782] Loss: 0.4187 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [383/782] Loss: 0.4159 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [384/782] Loss: 0.4294 | Acc: 85.20%\n",
      "Train Epoch [92/100] Batch [385/782] Loss: 0.5020 | Acc: 85.19%\n",
      "Train Epoch [92/100] Batch [386/782] Loss: 0.3130 | Acc: 85.21%\n",
      "Train Epoch [92/100] Batch [387/782] Loss: 0.3057 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [388/782] Loss: 0.2994 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [389/782] Loss: 0.3141 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [390/782] Loss: 0.3593 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [391/782] Loss: 0.2291 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [392/782] Loss: 0.4841 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [393/782] Loss: 0.6397 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [394/782] Loss: 0.4062 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [395/782] Loss: 0.4316 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [396/782] Loss: 0.3245 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [397/782] Loss: 0.2663 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [398/782] Loss: 0.5076 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [399/782] Loss: 0.3946 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [400/782] Loss: 0.4325 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [401/782] Loss: 0.3176 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [402/782] Loss: 0.3657 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [403/782] Loss: 0.3874 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [404/782] Loss: 0.5775 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [405/782] Loss: 0.4116 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [406/782] Loss: 0.3652 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [407/782] Loss: 0.4110 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [408/782] Loss: 0.5505 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [409/782] Loss: 0.3182 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [410/782] Loss: 0.5603 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [411/782] Loss: 0.3273 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [412/782] Loss: 0.4153 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [413/782] Loss: 0.5326 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [414/782] Loss: 0.2738 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [415/782] Loss: 0.4778 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [416/782] Loss: 0.3716 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [417/782] Loss: 0.4619 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [418/782] Loss: 0.4074 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [419/782] Loss: 0.5314 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [420/782] Loss: 0.4925 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [421/782] Loss: 0.4110 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [422/782] Loss: 0.4760 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [423/782] Loss: 0.5223 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [424/782] Loss: 0.4838 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [425/782] Loss: 0.5332 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [426/782] Loss: 0.2963 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [427/782] Loss: 0.4144 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [428/782] Loss: 0.5530 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [429/782] Loss: 0.4642 | Acc: 85.22%\n",
      "Train Epoch [92/100] Batch [430/782] Loss: 0.2767 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [431/782] Loss: 0.4115 | Acc: 85.23%\n",
      "Train Epoch [92/100] Batch [432/782] Loss: 0.2187 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [433/782] Loss: 0.2820 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [434/782] Loss: 0.4152 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [435/782] Loss: 0.2364 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [436/782] Loss: 0.7075 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [437/782] Loss: 0.4351 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [438/782] Loss: 0.4786 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [439/782] Loss: 0.4130 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [440/782] Loss: 0.2209 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [441/782] Loss: 0.3703 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [442/782] Loss: 0.6126 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [443/782] Loss: 0.3966 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [444/782] Loss: 0.3809 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [445/782] Loss: 0.4942 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [446/782] Loss: 0.3961 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [447/782] Loss: 0.3364 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [448/782] Loss: 0.3215 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [449/782] Loss: 0.5019 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [450/782] Loss: 0.4107 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [451/782] Loss: 0.6775 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [452/782] Loss: 0.5693 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [453/782] Loss: 0.3906 | Acc: 85.24%\n",
      "Train Epoch [92/100] Batch [454/782] Loss: 0.3828 | Acc: 85.25%\n",
      "Train Epoch [92/100] Batch [455/782] Loss: 0.2371 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [456/782] Loss: 0.3607 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [457/782] Loss: 0.2696 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [458/782] Loss: 0.2970 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [459/782] Loss: 0.2556 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [460/782] Loss: 0.4378 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [461/782] Loss: 0.3199 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [462/782] Loss: 0.3406 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [463/782] Loss: 0.3921 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [464/782] Loss: 0.4500 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [465/782] Loss: 0.5068 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [466/782] Loss: 0.4743 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [467/782] Loss: 0.3200 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [468/782] Loss: 0.5110 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [469/782] Loss: 0.3883 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [470/782] Loss: 0.3660 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [471/782] Loss: 0.4493 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [472/782] Loss: 0.5405 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [473/782] Loss: 0.3491 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [474/782] Loss: 0.4734 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [475/782] Loss: 0.3850 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [476/782] Loss: 0.3993 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [477/782] Loss: 0.3217 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [478/782] Loss: 0.3892 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [479/782] Loss: 0.2908 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [480/782] Loss: 0.4661 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [481/782] Loss: 0.5012 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [482/782] Loss: 0.4114 | Acc: 85.26%\n",
      "Train Epoch [92/100] Batch [483/782] Loss: 0.2748 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [484/782] Loss: 0.2462 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [485/782] Loss: 0.3044 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [486/782] Loss: 0.3899 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [487/782] Loss: 0.3770 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [488/782] Loss: 0.3077 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [489/782] Loss: 0.2806 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [490/782] Loss: 0.4983 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [491/782] Loss: 0.3383 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [492/782] Loss: 0.4517 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [493/782] Loss: 0.2707 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [494/782] Loss: 0.4497 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [495/782] Loss: 0.3528 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [496/782] Loss: 0.3581 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [497/782] Loss: 0.3991 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [498/782] Loss: 0.2848 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [499/782] Loss: 0.6157 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [500/782] Loss: 0.4231 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [501/782] Loss: 0.4276 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [502/782] Loss: 0.3049 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [503/782] Loss: 0.4634 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [504/782] Loss: 0.2298 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [505/782] Loss: 0.4273 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [506/782] Loss: 0.3005 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [507/782] Loss: 0.4335 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [508/782] Loss: 0.4556 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [509/782] Loss: 0.4583 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [510/782] Loss: 0.3101 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [511/782] Loss: 0.2994 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [512/782] Loss: 0.3355 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [513/782] Loss: 0.2961 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [514/782] Loss: 0.4452 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [515/782] Loss: 0.6184 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [516/782] Loss: 0.4430 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [517/782] Loss: 0.4781 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [518/782] Loss: 0.3346 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [519/782] Loss: 0.3427 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [520/782] Loss: 0.3619 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [521/782] Loss: 0.3221 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [522/782] Loss: 0.3055 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [523/782] Loss: 0.4860 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [524/782] Loss: 0.5104 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [525/782] Loss: 0.4132 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [526/782] Loss: 0.5420 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [527/782] Loss: 0.4850 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [528/782] Loss: 0.3736 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [529/782] Loss: 0.3564 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [530/782] Loss: 0.4906 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [531/782] Loss: 0.3828 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [532/782] Loss: 0.2945 | Acc: 85.42%\n",
      "Train Epoch [92/100] Batch [533/782] Loss: 0.5230 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [534/782] Loss: 0.3429 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [535/782] Loss: 0.5124 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [536/782] Loss: 0.2455 | Acc: 85.42%\n",
      "Train Epoch [92/100] Batch [537/782] Loss: 0.3437 | Acc: 85.43%\n",
      "Train Epoch [92/100] Batch [538/782] Loss: 0.2460 | Acc: 85.44%\n",
      "Train Epoch [92/100] Batch [539/782] Loss: 0.6485 | Acc: 85.43%\n",
      "Train Epoch [92/100] Batch [540/782] Loss: 0.4274 | Acc: 85.43%\n",
      "Train Epoch [92/100] Batch [541/782] Loss: 0.5398 | Acc: 85.41%\n",
      "Train Epoch [92/100] Batch [542/782] Loss: 0.5922 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [543/782] Loss: 0.5860 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [544/782] Loss: 0.4054 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [545/782] Loss: 0.3104 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [546/782] Loss: 0.2976 | Acc: 85.40%\n",
      "Train Epoch [92/100] Batch [547/782] Loss: 0.7228 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [548/782] Loss: 0.2592 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [549/782] Loss: 0.4409 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [550/782] Loss: 0.3725 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [551/782] Loss: 0.4587 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [552/782] Loss: 0.4102 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [553/782] Loss: 0.4762 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [554/782] Loss: 0.4520 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [555/782] Loss: 0.3054 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [556/782] Loss: 0.2448 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [557/782] Loss: 0.4373 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [558/782] Loss: 0.3978 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [559/782] Loss: 0.4980 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [560/782] Loss: 0.3799 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [561/782] Loss: 0.4674 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [562/782] Loss: 0.4867 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [563/782] Loss: 0.2848 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [564/782] Loss: 0.3342 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [565/782] Loss: 0.2132 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [566/782] Loss: 0.5691 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [567/782] Loss: 0.2870 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [568/782] Loss: 0.4414 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [569/782] Loss: 0.3911 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [570/782] Loss: 0.3550 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [571/782] Loss: 0.3685 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [572/782] Loss: 0.6725 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [573/782] Loss: 0.4302 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [574/782] Loss: 0.3884 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [575/782] Loss: 0.2800 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [576/782] Loss: 0.3984 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [577/782] Loss: 0.2832 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [578/782] Loss: 0.4114 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [579/782] Loss: 0.4644 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [580/782] Loss: 0.4763 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [581/782] Loss: 0.2597 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [582/782] Loss: 0.3616 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [583/782] Loss: 0.5296 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [584/782] Loss: 0.5889 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [585/782] Loss: 0.3482 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [586/782] Loss: 0.6221 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [587/782] Loss: 0.3277 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [588/782] Loss: 0.3738 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [589/782] Loss: 0.2178 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [590/782] Loss: 0.3577 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [591/782] Loss: 0.4624 | Acc: 85.39%\n",
      "Train Epoch [92/100] Batch [592/782] Loss: 0.4685 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [593/782] Loss: 0.5298 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [594/782] Loss: 0.5429 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [595/782] Loss: 0.4435 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [596/782] Loss: 0.5258 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [597/782] Loss: 0.3938 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [598/782] Loss: 0.5160 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [599/782] Loss: 0.3904 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [600/782] Loss: 0.2962 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [601/782] Loss: 0.4759 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [602/782] Loss: 0.4332 | Acc: 85.38%\n",
      "Train Epoch [92/100] Batch [603/782] Loss: 0.4699 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [604/782] Loss: 0.3166 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [605/782] Loss: 0.4951 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [606/782] Loss: 0.3089 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [607/782] Loss: 0.4418 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [608/782] Loss: 0.5809 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [609/782] Loss: 0.3529 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [610/782] Loss: 0.3016 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [611/782] Loss: 0.5473 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [612/782] Loss: 0.4743 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [613/782] Loss: 0.3553 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [614/782] Loss: 0.3507 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [615/782] Loss: 0.4276 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [616/782] Loss: 0.4130 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [617/782] Loss: 0.4238 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [618/782] Loss: 0.4539 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [619/782] Loss: 0.4372 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [620/782] Loss: 0.5083 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [621/782] Loss: 0.3678 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [622/782] Loss: 0.5036 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [623/782] Loss: 0.2665 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [624/782] Loss: 0.4833 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [625/782] Loss: 0.3098 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [626/782] Loss: 0.3787 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [627/782] Loss: 0.3829 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [628/782] Loss: 0.4538 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [629/782] Loss: 0.6841 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [630/782] Loss: 0.6392 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [631/782] Loss: 0.4478 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [632/782] Loss: 0.5738 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [633/782] Loss: 0.4241 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [634/782] Loss: 0.4477 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [635/782] Loss: 0.4453 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [636/782] Loss: 0.3535 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [637/782] Loss: 0.6026 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [638/782] Loss: 0.3024 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [639/782] Loss: 0.4312 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [640/782] Loss: 0.2791 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [641/782] Loss: 0.4159 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [642/782] Loss: 0.3200 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [643/782] Loss: 0.4662 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [644/782] Loss: 0.3287 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [645/782] Loss: 0.4189 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [646/782] Loss: 0.2911 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [647/782] Loss: 0.4342 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [648/782] Loss: 0.3613 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [649/782] Loss: 0.2750 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [650/782] Loss: 0.4339 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [651/782] Loss: 0.2870 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [652/782] Loss: 0.4503 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [653/782] Loss: 0.6517 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [654/782] Loss: 0.3946 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [655/782] Loss: 0.4116 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [656/782] Loss: 0.3422 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [657/782] Loss: 0.2714 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [658/782] Loss: 0.6120 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [659/782] Loss: 0.4114 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [660/782] Loss: 0.5798 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [661/782] Loss: 0.5214 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [662/782] Loss: 0.3938 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [663/782] Loss: 0.3314 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [664/782] Loss: 0.4704 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [665/782] Loss: 0.5684 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [666/782] Loss: 0.4246 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [667/782] Loss: 0.3274 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [668/782] Loss: 0.5302 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [669/782] Loss: 0.4434 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [670/782] Loss: 0.3679 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [671/782] Loss: 0.4156 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [672/782] Loss: 0.4659 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [673/782] Loss: 0.5567 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [674/782] Loss: 0.4242 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [675/782] Loss: 0.3257 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [676/782] Loss: 0.2831 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [677/782] Loss: 0.3153 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [678/782] Loss: 0.4700 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [679/782] Loss: 0.4904 | Acc: 85.27%\n",
      "Train Epoch [92/100] Batch [680/782] Loss: 0.3269 | Acc: 85.28%\n",
      "Train Epoch [92/100] Batch [681/782] Loss: 0.2600 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [682/782] Loss: 0.4356 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [683/782] Loss: 0.4394 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [684/782] Loss: 0.4011 | Acc: 85.29%\n",
      "Train Epoch [92/100] Batch [685/782] Loss: 0.3796 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [686/782] Loss: 0.4004 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [687/782] Loss: 0.4169 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [688/782] Loss: 0.4944 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [689/782] Loss: 0.4768 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [690/782] Loss: 0.4678 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [691/782] Loss: 0.2556 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [692/782] Loss: 0.5666 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [693/782] Loss: 0.2406 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [694/782] Loss: 0.4362 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [695/782] Loss: 0.3310 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [696/782] Loss: 0.3493 | Acc: 85.30%\n",
      "Train Epoch [92/100] Batch [697/782] Loss: 0.3952 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [698/782] Loss: 0.5150 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [699/782] Loss: 0.2466 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [700/782] Loss: 0.5995 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [701/782] Loss: 0.3968 | Acc: 85.31%\n",
      "Train Epoch [92/100] Batch [702/782] Loss: 0.2280 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [703/782] Loss: 0.4506 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [704/782] Loss: 0.3997 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [705/782] Loss: 0.4148 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [706/782] Loss: 0.5303 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [707/782] Loss: 0.3642 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [708/782] Loss: 0.4532 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [709/782] Loss: 0.5308 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [710/782] Loss: 0.3585 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [711/782] Loss: 0.3118 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [712/782] Loss: 0.4364 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [713/782] Loss: 0.4369 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [714/782] Loss: 0.4877 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [715/782] Loss: 0.3485 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [716/782] Loss: 0.4494 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [717/782] Loss: 0.4131 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [718/782] Loss: 0.3843 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [719/782] Loss: 0.4076 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [720/782] Loss: 0.3210 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [721/782] Loss: 0.3938 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [722/782] Loss: 0.3089 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [723/782] Loss: 0.3068 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [724/782] Loss: 0.5092 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [725/782] Loss: 0.4544 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [726/782] Loss: 0.3064 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [727/782] Loss: 0.5898 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [728/782] Loss: 0.2850 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [729/782] Loss: 0.2956 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [730/782] Loss: 0.3780 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [731/782] Loss: 0.3841 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [732/782] Loss: 0.3967 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [733/782] Loss: 0.4540 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [734/782] Loss: 0.3810 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [735/782] Loss: 0.3072 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [736/782] Loss: 0.5162 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [737/782] Loss: 0.7106 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [738/782] Loss: 0.3638 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [739/782] Loss: 0.4033 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [740/782] Loss: 0.3363 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [741/782] Loss: 0.6487 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [742/782] Loss: 0.3957 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [743/782] Loss: 0.2455 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [744/782] Loss: 0.5667 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [745/782] Loss: 0.3830 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [746/782] Loss: 0.4431 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [747/782] Loss: 0.4994 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [748/782] Loss: 0.3356 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [749/782] Loss: 0.5627 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [750/782] Loss: 0.3002 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [751/782] Loss: 0.3915 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [752/782] Loss: 0.4183 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [753/782] Loss: 0.3027 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [754/782] Loss: 0.2835 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [755/782] Loss: 0.4623 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [756/782] Loss: 0.2783 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [757/782] Loss: 0.5167 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [758/782] Loss: 0.4591 | Acc: 85.36%\n",
      "Train Epoch [92/100] Batch [759/782] Loss: 0.3257 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [760/782] Loss: 0.4040 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [761/782] Loss: 0.5583 | Acc: 85.37%\n",
      "Train Epoch [92/100] Batch [762/782] Loss: 0.6061 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [763/782] Loss: 0.4618 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [764/782] Loss: 0.4182 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [765/782] Loss: 0.4382 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [766/782] Loss: 0.4756 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [767/782] Loss: 0.3933 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [768/782] Loss: 0.5145 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [769/782] Loss: 0.4597 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [770/782] Loss: 0.6012 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [771/782] Loss: 0.4309 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [772/782] Loss: 0.3164 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [773/782] Loss: 0.5183 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [774/782] Loss: 0.5344 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [775/782] Loss: 0.3753 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [776/782] Loss: 0.3717 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [777/782] Loss: 0.4105 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [778/782] Loss: 0.4471 | Acc: 85.35%\n",
      "Train Epoch [92/100] Batch [779/782] Loss: 0.5351 | Acc: 85.34%\n",
      "Train Epoch [92/100] Batch [780/782] Loss: 0.9753 | Acc: 85.32%\n",
      "Train Epoch [92/100] Batch [781/782] Loss: 0.3889 | Acc: 85.33%\n",
      "Train Epoch [92/100] Batch [782/782] Loss: 0.4921 | Acc: 85.32%\n",
      "Epoch 92 completed in 29.53s.\n",
      "Test Epoch [92/100] Loss: 1.0203 | Acc: 72.12% | Inference Time: 8.27s\n",
      "Epoch 92 results saved to CSV.\n",
      "Epoch 93/100\n",
      "Train Epoch [93/100] Batch [1/782] Loss: 0.4010 | Acc: 92.19%\n",
      "Train Epoch [93/100] Batch [2/782] Loss: 0.4753 | Acc: 88.28%\n",
      "Train Epoch [93/100] Batch [3/782] Loss: 0.3560 | Acc: 87.50%\n",
      "Train Epoch [93/100] Batch [4/782] Loss: 0.4561 | Acc: 86.33%\n",
      "Train Epoch [93/100] Batch [5/782] Loss: 0.3965 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [6/782] Loss: 0.3336 | Acc: 86.20%\n",
      "Train Epoch [93/100] Batch [7/782] Loss: 0.4489 | Acc: 85.27%\n",
      "Train Epoch [93/100] Batch [8/782] Loss: 0.3873 | Acc: 85.16%\n",
      "Train Epoch [93/100] Batch [9/782] Loss: 0.2060 | Acc: 86.46%\n",
      "Train Epoch [93/100] Batch [10/782] Loss: 0.2336 | Acc: 87.34%\n",
      "Train Epoch [93/100] Batch [11/782] Loss: 0.4748 | Acc: 86.65%\n",
      "Train Epoch [93/100] Batch [12/782] Loss: 0.5186 | Acc: 86.20%\n",
      "Train Epoch [93/100] Batch [13/782] Loss: 0.2823 | Acc: 86.42%\n",
      "Train Epoch [93/100] Batch [14/782] Loss: 0.2474 | Acc: 86.72%\n",
      "Train Epoch [93/100] Batch [15/782] Loss: 0.2715 | Acc: 86.98%\n",
      "Train Epoch [93/100] Batch [16/782] Loss: 0.4439 | Acc: 86.91%\n",
      "Train Epoch [93/100] Batch [17/782] Loss: 0.3083 | Acc: 86.86%\n",
      "Train Epoch [93/100] Batch [18/782] Loss: 0.3972 | Acc: 87.07%\n",
      "Train Epoch [93/100] Batch [19/782] Loss: 0.5213 | Acc: 87.01%\n",
      "Train Epoch [93/100] Batch [20/782] Loss: 0.3550 | Acc: 86.95%\n",
      "Train Epoch [93/100] Batch [21/782] Loss: 0.2446 | Acc: 87.20%\n",
      "Train Epoch [93/100] Batch [22/782] Loss: 0.2964 | Acc: 87.29%\n",
      "Train Epoch [93/100] Batch [23/782] Loss: 0.4883 | Acc: 87.09%\n",
      "Train Epoch [93/100] Batch [24/782] Loss: 0.4530 | Acc: 86.91%\n",
      "Train Epoch [93/100] Batch [25/782] Loss: 0.4812 | Acc: 86.75%\n",
      "Train Epoch [93/100] Batch [26/782] Loss: 0.4920 | Acc: 86.60%\n",
      "Train Epoch [93/100] Batch [27/782] Loss: 0.4228 | Acc: 86.40%\n",
      "Train Epoch [93/100] Batch [28/782] Loss: 0.3406 | Acc: 86.27%\n",
      "Train Epoch [93/100] Batch [29/782] Loss: 0.8228 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [30/782] Loss: 0.3038 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [31/782] Loss: 0.3881 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [32/782] Loss: 0.5140 | Acc: 85.50%\n",
      "Train Epoch [93/100] Batch [33/782] Loss: 0.4850 | Acc: 85.37%\n",
      "Train Epoch [93/100] Batch [34/782] Loss: 0.4870 | Acc: 85.48%\n",
      "Train Epoch [93/100] Batch [35/782] Loss: 0.3760 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [36/782] Loss: 0.2395 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [37/782] Loss: 0.3275 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [38/782] Loss: 0.3846 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [39/782] Loss: 0.4502 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [40/782] Loss: 0.3534 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [41/782] Loss: 0.3929 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [42/782] Loss: 0.4512 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [43/782] Loss: 0.3461 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [44/782] Loss: 0.3604 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [45/782] Loss: 0.5387 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [46/782] Loss: 0.5388 | Acc: 85.39%\n",
      "Train Epoch [93/100] Batch [47/782] Loss: 0.2590 | Acc: 85.54%\n",
      "Train Epoch [93/100] Batch [48/782] Loss: 0.4704 | Acc: 85.51%\n",
      "Train Epoch [93/100] Batch [49/782] Loss: 0.4643 | Acc: 85.55%\n",
      "Train Epoch [93/100] Batch [50/782] Loss: 0.3409 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [51/782] Loss: 0.3959 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [52/782] Loss: 0.4070 | Acc: 85.55%\n",
      "Train Epoch [93/100] Batch [53/782] Loss: 0.4458 | Acc: 85.52%\n",
      "Train Epoch [93/100] Batch [54/782] Loss: 0.3530 | Acc: 85.50%\n",
      "Train Epoch [93/100] Batch [55/782] Loss: 0.5405 | Acc: 85.40%\n",
      "Train Epoch [93/100] Batch [56/782] Loss: 0.2172 | Acc: 85.52%\n",
      "Train Epoch [93/100] Batch [57/782] Loss: 0.3376 | Acc: 85.55%\n",
      "Train Epoch [93/100] Batch [58/782] Loss: 0.3938 | Acc: 85.53%\n",
      "Train Epoch [93/100] Batch [59/782] Loss: 0.3662 | Acc: 85.51%\n",
      "Train Epoch [93/100] Batch [60/782] Loss: 0.2486 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [61/782] Loss: 0.3470 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [62/782] Loss: 0.3727 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [63/782] Loss: 0.2986 | Acc: 85.84%\n",
      "Train Epoch [93/100] Batch [64/782] Loss: 0.2875 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [65/782] Loss: 0.4504 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [66/782] Loss: 0.4680 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [67/782] Loss: 0.1998 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [68/782] Loss: 0.4320 | Acc: 85.98%\n",
      "Train Epoch [93/100] Batch [69/782] Loss: 0.3997 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [70/782] Loss: 0.3814 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [71/782] Loss: 0.3244 | Acc: 85.98%\n",
      "Train Epoch [93/100] Batch [72/782] Loss: 0.4257 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [73/782] Loss: 0.5032 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [74/782] Loss: 0.3404 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [75/782] Loss: 0.3882 | Acc: 85.98%\n",
      "Train Epoch [93/100] Batch [76/782] Loss: 0.4451 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [77/782] Loss: 0.3563 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [78/782] Loss: 0.4118 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [79/782] Loss: 0.4397 | Acc: 85.88%\n",
      "Train Epoch [93/100] Batch [80/782] Loss: 0.5176 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [81/782] Loss: 0.4550 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [82/782] Loss: 0.4728 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [83/782] Loss: 0.3395 | Acc: 85.84%\n",
      "Train Epoch [93/100] Batch [84/782] Loss: 0.3320 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [85/782] Loss: 0.3096 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [86/782] Loss: 0.4091 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [87/782] Loss: 0.4298 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [88/782] Loss: 0.3597 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [89/782] Loss: 0.4759 | Acc: 85.88%\n",
      "Train Epoch [93/100] Batch [90/782] Loss: 0.4607 | Acc: 85.85%\n",
      "Train Epoch [93/100] Batch [91/782] Loss: 0.4251 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [92/782] Loss: 0.3101 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [93/782] Loss: 0.2305 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [94/782] Loss: 0.2490 | Acc: 86.00%\n",
      "Train Epoch [93/100] Batch [95/782] Loss: 0.3241 | Acc: 85.99%\n",
      "Train Epoch [93/100] Batch [96/782] Loss: 0.4296 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [97/782] Loss: 0.3734 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [98/782] Loss: 0.3378 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [99/782] Loss: 0.3392 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [100/782] Loss: 0.4230 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [101/782] Loss: 0.2871 | Acc: 85.98%\n",
      "Train Epoch [93/100] Batch [102/782] Loss: 0.5445 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [103/782] Loss: 0.4126 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [104/782] Loss: 0.2944 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [105/782] Loss: 0.4104 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [106/782] Loss: 0.3916 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [107/782] Loss: 0.2703 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [108/782] Loss: 0.4116 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [109/782] Loss: 0.2930 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [110/782] Loss: 0.3718 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [111/782] Loss: 0.2970 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [112/782] Loss: 0.2664 | Acc: 85.99%\n",
      "Train Epoch [93/100] Batch [113/782] Loss: 0.3782 | Acc: 85.99%\n",
      "Train Epoch [93/100] Batch [114/782] Loss: 0.5216 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [115/782] Loss: 0.4234 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [116/782] Loss: 0.3103 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [117/782] Loss: 0.4447 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [118/782] Loss: 0.4812 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [119/782] Loss: 0.5616 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [120/782] Loss: 0.4121 | Acc: 85.85%\n",
      "Train Epoch [93/100] Batch [121/782] Loss: 0.2805 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [122/782] Loss: 0.6114 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [123/782] Loss: 0.2589 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [124/782] Loss: 0.2849 | Acc: 85.96%\n",
      "Train Epoch [93/100] Batch [125/782] Loss: 0.4948 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [126/782] Loss: 0.4023 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [127/782] Loss: 0.4133 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [128/782] Loss: 0.4525 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [129/782] Loss: 0.4322 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [130/782] Loss: 0.4230 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [131/782] Loss: 0.3708 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [132/782] Loss: 0.3400 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [133/782] Loss: 0.5745 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [134/782] Loss: 0.3281 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [135/782] Loss: 0.5652 | Acc: 85.88%\n",
      "Train Epoch [93/100] Batch [136/782] Loss: 0.3534 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [137/782] Loss: 0.3590 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [138/782] Loss: 0.2293 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [139/782] Loss: 0.6192 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [140/782] Loss: 0.3181 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [141/782] Loss: 0.5127 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [142/782] Loss: 0.4605 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [143/782] Loss: 0.3216 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [144/782] Loss: 0.3219 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [145/782] Loss: 0.3024 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [146/782] Loss: 0.3948 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [147/782] Loss: 0.4085 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [148/782] Loss: 0.2146 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [149/782] Loss: 0.3889 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [150/782] Loss: 0.5387 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [151/782] Loss: 0.3139 | Acc: 85.95%\n",
      "Train Epoch [93/100] Batch [152/782] Loss: 0.2849 | Acc: 85.99%\n",
      "Train Epoch [93/100] Batch [153/782] Loss: 0.5263 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [154/782] Loss: 0.2009 | Acc: 85.99%\n",
      "Train Epoch [93/100] Batch [155/782] Loss: 0.4592 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [156/782] Loss: 0.4902 | Acc: 85.91%\n",
      "Train Epoch [93/100] Batch [157/782] Loss: 0.3245 | Acc: 85.94%\n",
      "Train Epoch [93/100] Batch [158/782] Loss: 0.3528 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [159/782] Loss: 0.2707 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [160/782] Loss: 0.5115 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [161/782] Loss: 0.1921 | Acc: 86.02%\n",
      "Train Epoch [93/100] Batch [162/782] Loss: 0.4801 | Acc: 86.00%\n",
      "Train Epoch [93/100] Batch [163/782] Loss: 0.4054 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [164/782] Loss: 0.4096 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [165/782] Loss: 0.4517 | Acc: 85.98%\n",
      "Train Epoch [93/100] Batch [166/782] Loss: 0.4301 | Acc: 85.97%\n",
      "Train Epoch [93/100] Batch [167/782] Loss: 0.5310 | Acc: 85.92%\n",
      "Train Epoch [93/100] Batch [168/782] Loss: 0.4845 | Acc: 85.90%\n",
      "Train Epoch [93/100] Batch [169/782] Loss: 0.4191 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [170/782] Loss: 0.4963 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [171/782] Loss: 0.4206 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [172/782] Loss: 0.3046 | Acc: 85.89%\n",
      "Train Epoch [93/100] Batch [173/782] Loss: 0.5200 | Acc: 85.87%\n",
      "Train Epoch [93/100] Batch [174/782] Loss: 0.4037 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [175/782] Loss: 0.5946 | Acc: 85.86%\n",
      "Train Epoch [93/100] Batch [176/782] Loss: 0.5146 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [177/782] Loss: 0.3170 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [178/782] Loss: 0.5276 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [179/782] Loss: 0.5143 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [180/782] Loss: 0.2216 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [181/782] Loss: 0.5572 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [182/782] Loss: 0.3455 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [183/782] Loss: 0.4271 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [184/782] Loss: 0.3990 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [185/782] Loss: 0.7757 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [186/782] Loss: 0.5339 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [187/782] Loss: 0.4279 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [188/782] Loss: 0.4448 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [189/782] Loss: 0.3611 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [190/782] Loss: 0.3288 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [191/782] Loss: 0.3218 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [192/782] Loss: 0.3785 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [193/782] Loss: 0.3501 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [194/782] Loss: 0.3028 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [195/782] Loss: 0.6612 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [196/782] Loss: 0.3234 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [197/782] Loss: 0.5201 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [198/782] Loss: 0.3991 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [199/782] Loss: 0.3255 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [200/782] Loss: 0.4879 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [201/782] Loss: 0.3375 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [202/782] Loss: 0.4471 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [203/782] Loss: 0.4854 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [204/782] Loss: 0.3928 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [205/782] Loss: 0.4977 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [206/782] Loss: 0.6742 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [207/782] Loss: 0.2983 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [208/782] Loss: 0.4043 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [209/782] Loss: 0.4908 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [210/782] Loss: 0.4057 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [211/782] Loss: 0.2468 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [212/782] Loss: 0.2895 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [213/782] Loss: 0.3056 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [214/782] Loss: 0.3624 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [215/782] Loss: 0.4715 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [216/782] Loss: 0.2844 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [217/782] Loss: 0.4137 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [218/782] Loss: 0.4464 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [219/782] Loss: 0.2321 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [220/782] Loss: 0.4726 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [221/782] Loss: 0.4090 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [222/782] Loss: 0.5097 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [223/782] Loss: 0.6397 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [224/782] Loss: 0.5840 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [225/782] Loss: 0.4317 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [226/782] Loss: 0.3501 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [227/782] Loss: 0.5121 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [228/782] Loss: 0.3791 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [229/782] Loss: 0.5175 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [230/782] Loss: 0.2754 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [231/782] Loss: 0.3059 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [232/782] Loss: 0.5706 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [233/782] Loss: 0.3149 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [234/782] Loss: 0.4205 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [235/782] Loss: 0.4876 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [236/782] Loss: 0.3351 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [237/782] Loss: 0.4618 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [238/782] Loss: 0.3429 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [239/782] Loss: 0.2673 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [240/782] Loss: 0.4289 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [241/782] Loss: 0.3398 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [242/782] Loss: 0.2366 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [243/782] Loss: 0.4400 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [244/782] Loss: 0.3855 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [245/782] Loss: 0.3092 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [246/782] Loss: 0.4938 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [247/782] Loss: 0.3255 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [248/782] Loss: 0.4002 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [249/782] Loss: 0.2181 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [250/782] Loss: 0.4397 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [251/782] Loss: 0.2043 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [252/782] Loss: 0.4239 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [253/782] Loss: 0.5019 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [254/782] Loss: 0.2976 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [255/782] Loss: 0.2911 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [256/782] Loss: 0.4628 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [257/782] Loss: 0.3349 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [258/782] Loss: 0.4629 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [259/782] Loss: 0.3440 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [260/782] Loss: 0.4119 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [261/782] Loss: 0.3988 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [262/782] Loss: 0.3870 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [263/782] Loss: 0.4760 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [264/782] Loss: 0.3405 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [265/782] Loss: 0.3240 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [266/782] Loss: 0.4497 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [267/782] Loss: 0.5129 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [268/782] Loss: 0.2391 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [269/782] Loss: 0.4264 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [270/782] Loss: 0.5131 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [271/782] Loss: 0.4345 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [272/782] Loss: 0.3604 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [273/782] Loss: 0.3552 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [274/782] Loss: 0.3251 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [275/782] Loss: 0.2714 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [276/782] Loss: 0.6210 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [277/782] Loss: 0.3688 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [278/782] Loss: 0.2624 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [279/782] Loss: 0.3641 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [280/782] Loss: 0.2901 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [281/782] Loss: 0.1818 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [282/782] Loss: 0.4783 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [283/782] Loss: 0.3469 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [284/782] Loss: 0.2787 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [285/782] Loss: 0.4926 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [286/782] Loss: 0.4396 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [287/782] Loss: 0.5224 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [288/782] Loss: 0.6294 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [289/782] Loss: 0.2953 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [290/782] Loss: 0.3677 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [291/782] Loss: 0.4028 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [292/782] Loss: 0.4023 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [293/782] Loss: 0.4632 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [294/782] Loss: 0.5038 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [295/782] Loss: 0.3225 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [296/782] Loss: 0.6221 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [297/782] Loss: 0.3220 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [298/782] Loss: 0.3832 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [299/782] Loss: 0.2619 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [300/782] Loss: 0.5057 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [301/782] Loss: 0.5044 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [302/782] Loss: 0.2469 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [303/782] Loss: 0.3278 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [304/782] Loss: 0.3426 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [305/782] Loss: 0.3581 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [306/782] Loss: 0.4024 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [307/782] Loss: 0.4947 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [308/782] Loss: 0.5344 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [309/782] Loss: 0.3085 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [310/782] Loss: 0.4847 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [311/782] Loss: 0.4182 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [312/782] Loss: 0.4912 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [313/782] Loss: 0.4967 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [314/782] Loss: 0.3341 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [315/782] Loss: 0.3897 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [316/782] Loss: 0.4644 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [317/782] Loss: 0.3616 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [318/782] Loss: 0.4631 | Acc: 85.70%\n",
      "Train Epoch [93/100] Batch [319/782] Loss: 0.2025 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [320/782] Loss: 0.3303 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [321/782] Loss: 0.3122 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [322/782] Loss: 0.5417 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [323/782] Loss: 0.3779 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [324/782] Loss: 0.3862 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [325/782] Loss: 0.2765 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [326/782] Loss: 0.4292 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [327/782] Loss: 0.2322 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [328/782] Loss: 0.3115 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [329/782] Loss: 0.4604 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [330/782] Loss: 0.5664 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [331/782] Loss: 0.4990 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [332/782] Loss: 0.3361 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [333/782] Loss: 0.3233 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [334/782] Loss: 0.4858 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [335/782] Loss: 0.4719 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [336/782] Loss: 0.3586 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [337/782] Loss: 0.3748 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [338/782] Loss: 0.4214 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [339/782] Loss: 0.4571 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [340/782] Loss: 0.3718 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [341/782] Loss: 0.4348 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [342/782] Loss: 0.3630 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [343/782] Loss: 0.4837 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [344/782] Loss: 0.3651 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [345/782] Loss: 0.4334 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [346/782] Loss: 0.4323 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [347/782] Loss: 0.5284 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [348/782] Loss: 0.4325 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [349/782] Loss: 0.2984 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [350/782] Loss: 0.3116 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [351/782] Loss: 0.4161 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [352/782] Loss: 0.4250 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [353/782] Loss: 0.5396 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [354/782] Loss: 0.3698 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [355/782] Loss: 0.4721 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [356/782] Loss: 0.5449 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [357/782] Loss: 0.2766 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [358/782] Loss: 0.3488 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [359/782] Loss: 0.4782 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [360/782] Loss: 0.3348 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [361/782] Loss: 0.5093 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [362/782] Loss: 0.2756 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [363/782] Loss: 0.3605 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [364/782] Loss: 0.4185 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [365/782] Loss: 0.4317 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [366/782] Loss: 0.3056 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [367/782] Loss: 0.4820 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [368/782] Loss: 0.6459 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [369/782] Loss: 0.3660 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [370/782] Loss: 0.2996 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [371/782] Loss: 0.3570 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [372/782] Loss: 0.3152 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [373/782] Loss: 0.5659 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [374/782] Loss: 0.4386 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [375/782] Loss: 0.4606 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [376/782] Loss: 0.4682 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [377/782] Loss: 0.3681 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [378/782] Loss: 0.4944 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [379/782] Loss: 0.2452 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [380/782] Loss: 0.3944 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [381/782] Loss: 0.3959 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [382/782] Loss: 0.3798 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [383/782] Loss: 0.3599 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [384/782] Loss: 0.4662 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [385/782] Loss: 0.3584 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [386/782] Loss: 0.5244 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [387/782] Loss: 0.2805 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [388/782] Loss: 0.4065 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [389/782] Loss: 0.3740 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [390/782] Loss: 0.5505 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [391/782] Loss: 0.4928 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [392/782] Loss: 0.3618 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [393/782] Loss: 0.4555 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [394/782] Loss: 0.4637 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [395/782] Loss: 0.4402 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [396/782] Loss: 0.3732 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [397/782] Loss: 0.3755 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [398/782] Loss: 0.2108 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [399/782] Loss: 0.2951 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [400/782] Loss: 0.3912 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [401/782] Loss: 0.4555 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [402/782] Loss: 0.4596 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [403/782] Loss: 0.5275 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [404/782] Loss: 0.3037 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [405/782] Loss: 0.2995 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [406/782] Loss: 0.4259 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [407/782] Loss: 0.4038 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [408/782] Loss: 0.4646 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [409/782] Loss: 0.3048 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [410/782] Loss: 0.3012 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [411/782] Loss: 0.3335 | Acc: 85.79%\n",
      "Train Epoch [93/100] Batch [412/782] Loss: 0.2671 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [413/782] Loss: 0.4682 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [414/782] Loss: 0.3233 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [415/782] Loss: 0.2835 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [416/782] Loss: 0.3210 | Acc: 85.84%\n",
      "Train Epoch [93/100] Batch [417/782] Loss: 0.4244 | Acc: 85.84%\n",
      "Train Epoch [93/100] Batch [418/782] Loss: 0.5922 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [419/782] Loss: 0.3082 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [420/782] Loss: 0.4023 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [421/782] Loss: 0.3588 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [422/782] Loss: 0.4642 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [423/782] Loss: 0.4015 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [424/782] Loss: 0.4069 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [425/782] Loss: 0.4337 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [426/782] Loss: 0.5286 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [427/782] Loss: 0.3124 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [428/782] Loss: 0.2396 | Acc: 85.83%\n",
      "Train Epoch [93/100] Batch [429/782] Loss: 0.5505 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [430/782] Loss: 0.3081 | Acc: 85.82%\n",
      "Train Epoch [93/100] Batch [431/782] Loss: 0.5359 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [432/782] Loss: 0.4886 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [433/782] Loss: 0.4570 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [434/782] Loss: 0.3848 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [435/782] Loss: 0.3897 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [436/782] Loss: 0.4569 | Acc: 85.81%\n",
      "Train Epoch [93/100] Batch [437/782] Loss: 0.6826 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [438/782] Loss: 0.4601 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [439/782] Loss: 0.4557 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [440/782] Loss: 0.6388 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [441/782] Loss: 0.4907 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [442/782] Loss: 0.4777 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [443/782] Loss: 0.4999 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [444/782] Loss: 0.7645 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [445/782] Loss: 0.4464 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [446/782] Loss: 0.4397 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [447/782] Loss: 0.3877 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [448/782] Loss: 0.4268 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [449/782] Loss: 0.4557 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [450/782] Loss: 0.3494 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [451/782] Loss: 0.5027 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [452/782] Loss: 0.4882 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [453/782] Loss: 0.5342 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [454/782] Loss: 0.3475 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [455/782] Loss: 0.3246 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [456/782] Loss: 0.4896 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [457/782] Loss: 0.4161 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [458/782] Loss: 0.4391 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [459/782] Loss: 0.2378 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [460/782] Loss: 0.3934 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [461/782] Loss: 0.4522 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [462/782] Loss: 0.2635 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [463/782] Loss: 0.2861 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [464/782] Loss: 0.3471 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [465/782] Loss: 0.5139 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [466/782] Loss: 0.2465 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [467/782] Loss: 0.6447 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [468/782] Loss: 0.4160 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [469/782] Loss: 0.5212 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [470/782] Loss: 0.5517 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [471/782] Loss: 0.4283 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [472/782] Loss: 0.4816 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [473/782] Loss: 0.4298 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [474/782] Loss: 0.3778 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [475/782] Loss: 0.3278 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [476/782] Loss: 0.4155 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [477/782] Loss: 0.4301 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [478/782] Loss: 0.2930 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [479/782] Loss: 0.4924 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [480/782] Loss: 0.4249 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [481/782] Loss: 0.4999 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [482/782] Loss: 0.3639 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [483/782] Loss: 0.5007 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [484/782] Loss: 0.3107 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [485/782] Loss: 0.2974 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [486/782] Loss: 0.4021 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [487/782] Loss: 0.4136 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [488/782] Loss: 0.4060 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [489/782] Loss: 0.2514 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [490/782] Loss: 0.3095 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [491/782] Loss: 0.3646 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [492/782] Loss: 0.4966 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [493/782] Loss: 0.6261 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [494/782] Loss: 0.4902 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [495/782] Loss: 0.3716 | Acc: 85.75%\n",
      "Train Epoch [93/100] Batch [496/782] Loss: 0.3023 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [497/782] Loss: 0.3462 | Acc: 85.76%\n",
      "Train Epoch [93/100] Batch [498/782] Loss: 0.2893 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [499/782] Loss: 0.2172 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [500/782] Loss: 0.4497 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [501/782] Loss: 0.3890 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [502/782] Loss: 0.3186 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [503/782] Loss: 0.4155 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [504/782] Loss: 0.2239 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [505/782] Loss: 0.5440 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [506/782] Loss: 0.4909 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [507/782] Loss: 0.3340 | Acc: 85.80%\n",
      "Train Epoch [93/100] Batch [508/782] Loss: 0.4488 | Acc: 85.78%\n",
      "Train Epoch [93/100] Batch [509/782] Loss: 0.5056 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [510/782] Loss: 0.4187 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [511/782] Loss: 0.3217 | Acc: 85.77%\n",
      "Train Epoch [93/100] Batch [512/782] Loss: 0.6273 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [513/782] Loss: 0.3344 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [514/782] Loss: 0.5003 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [515/782] Loss: 0.3258 | Acc: 85.74%\n",
      "Train Epoch [93/100] Batch [516/782] Loss: 0.4169 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [517/782] Loss: 0.4858 | Acc: 85.73%\n",
      "Train Epoch [93/100] Batch [518/782] Loss: 0.4773 | Acc: 85.72%\n",
      "Train Epoch [93/100] Batch [519/782] Loss: 0.3978 | Acc: 85.71%\n",
      "Train Epoch [93/100] Batch [520/782] Loss: 0.6336 | Acc: 85.69%\n",
      "Train Epoch [93/100] Batch [521/782] Loss: 0.5248 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [522/782] Loss: 0.5308 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [523/782] Loss: 0.3487 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [524/782] Loss: 0.3135 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [525/782] Loss: 0.4486 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [526/782] Loss: 0.3868 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [527/782] Loss: 0.3140 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [528/782] Loss: 0.3676 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [529/782] Loss: 0.4290 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [530/782] Loss: 0.4266 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [531/782] Loss: 0.5415 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [532/782] Loss: 0.2877 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [533/782] Loss: 0.3432 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [534/782] Loss: 0.5366 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [535/782] Loss: 0.3340 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [536/782] Loss: 0.3907 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [537/782] Loss: 0.3148 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [538/782] Loss: 0.2718 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [539/782] Loss: 0.2812 | Acc: 85.68%\n",
      "Train Epoch [93/100] Batch [540/782] Loss: 0.6177 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [541/782] Loss: 0.5576 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [542/782] Loss: 0.2035 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [543/782] Loss: 0.4596 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [544/782] Loss: 0.4407 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [545/782] Loss: 0.3869 | Acc: 85.67%\n",
      "Train Epoch [93/100] Batch [546/782] Loss: 0.4543 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [547/782] Loss: 0.6028 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [548/782] Loss: 0.4263 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [549/782] Loss: 0.2419 | Acc: 85.66%\n",
      "Train Epoch [93/100] Batch [550/782] Loss: 0.5524 | Acc: 85.65%\n",
      "Train Epoch [93/100] Batch [551/782] Loss: 0.4669 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [552/782] Loss: 0.4989 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [553/782] Loss: 0.3883 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [554/782] Loss: 0.3642 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [555/782] Loss: 0.4990 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [556/782] Loss: 0.6187 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [557/782] Loss: 0.5258 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [558/782] Loss: 0.3473 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [559/782] Loss: 0.2715 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [560/782] Loss: 0.4902 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [561/782] Loss: 0.2604 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [562/782] Loss: 0.4421 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [563/782] Loss: 0.6515 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [564/782] Loss: 0.7355 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [565/782] Loss: 0.4109 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [566/782] Loss: 0.4365 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [567/782] Loss: 0.4004 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [568/782] Loss: 0.4168 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [569/782] Loss: 0.4443 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [570/782] Loss: 0.3883 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [571/782] Loss: 0.3694 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [572/782] Loss: 0.4325 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [573/782] Loss: 0.3937 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [574/782] Loss: 0.5409 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [575/782] Loss: 0.3489 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [576/782] Loss: 0.3821 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [577/782] Loss: 0.3081 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [578/782] Loss: 0.3550 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [579/782] Loss: 0.4265 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [580/782] Loss: 0.4300 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [581/782] Loss: 0.3710 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [582/782] Loss: 0.3876 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [583/782] Loss: 0.3310 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [584/782] Loss: 0.3064 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [585/782] Loss: 0.3092 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [586/782] Loss: 0.6780 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [587/782] Loss: 0.2226 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [588/782] Loss: 0.4017 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [589/782] Loss: 0.4512 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [590/782] Loss: 0.2917 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [591/782] Loss: 0.4807 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [592/782] Loss: 0.4108 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [593/782] Loss: 0.4383 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [594/782] Loss: 0.3918 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [595/782] Loss: 0.3517 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [596/782] Loss: 0.2340 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [597/782] Loss: 0.5033 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [598/782] Loss: 0.3753 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [599/782] Loss: 0.2700 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [600/782] Loss: 0.3408 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [601/782] Loss: 0.5619 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [602/782] Loss: 0.5468 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [603/782] Loss: 0.3118 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [604/782] Loss: 0.5193 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [605/782] Loss: 0.5429 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [606/782] Loss: 0.2598 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [607/782] Loss: 0.3420 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [608/782] Loss: 0.2704 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [609/782] Loss: 0.3135 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [610/782] Loss: 0.4417 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [611/782] Loss: 0.4329 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [612/782] Loss: 0.4489 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [613/782] Loss: 0.3974 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [614/782] Loss: 0.2668 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [615/782] Loss: 0.3247 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [616/782] Loss: 0.5758 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [617/782] Loss: 0.4075 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [618/782] Loss: 0.4769 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [619/782] Loss: 0.3834 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [620/782] Loss: 0.4360 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [621/782] Loss: 0.4260 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [622/782] Loss: 0.4223 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [623/782] Loss: 0.3834 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [624/782] Loss: 0.2547 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [625/782] Loss: 0.6027 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [626/782] Loss: 0.4260 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [627/782] Loss: 0.3210 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [628/782] Loss: 0.3799 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [629/782] Loss: 0.3419 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [630/782] Loss: 0.3023 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [631/782] Loss: 0.4338 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [632/782] Loss: 0.3824 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [633/782] Loss: 0.4762 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [634/782] Loss: 0.4263 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [635/782] Loss: 0.4857 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [636/782] Loss: 0.4208 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [637/782] Loss: 0.3821 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [638/782] Loss: 0.3811 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [639/782] Loss: 0.4589 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [640/782] Loss: 0.3479 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [641/782] Loss: 0.3606 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [642/782] Loss: 0.4220 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [643/782] Loss: 0.4163 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [644/782] Loss: 0.3323 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [645/782] Loss: 0.4890 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [646/782] Loss: 0.2670 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [647/782] Loss: 0.6315 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [648/782] Loss: 0.2945 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [649/782] Loss: 0.5525 | Acc: 85.55%\n",
      "Train Epoch [93/100] Batch [650/782] Loss: 0.3397 | Acc: 85.56%\n",
      "Train Epoch [93/100] Batch [651/782] Loss: 0.3149 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [652/782] Loss: 0.4398 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [653/782] Loss: 0.5176 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [654/782] Loss: 0.3557 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [655/782] Loss: 0.3728 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [656/782] Loss: 0.5508 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [657/782] Loss: 0.4470 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [658/782] Loss: 0.3653 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [659/782] Loss: 0.4367 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [660/782] Loss: 0.3311 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [661/782] Loss: 0.3987 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [662/782] Loss: 0.3312 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [663/782] Loss: 0.3407 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [664/782] Loss: 0.3373 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [665/782] Loss: 0.3504 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [666/782] Loss: 0.4350 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [667/782] Loss: 0.4517 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [668/782] Loss: 0.3802 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [669/782] Loss: 0.4399 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [670/782] Loss: 0.3836 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [671/782] Loss: 0.4065 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [672/782] Loss: 0.2952 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [673/782] Loss: 0.3099 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [674/782] Loss: 0.2907 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [675/782] Loss: 0.4134 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [676/782] Loss: 0.2531 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [677/782] Loss: 0.4742 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [678/782] Loss: 0.4063 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [679/782] Loss: 0.5794 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [680/782] Loss: 0.3861 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [681/782] Loss: 0.4922 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [682/782] Loss: 0.4870 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [683/782] Loss: 0.3196 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [684/782] Loss: 0.5136 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [685/782] Loss: 0.2758 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [686/782] Loss: 0.2936 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [687/782] Loss: 0.2752 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [688/782] Loss: 0.5886 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [689/782] Loss: 0.4236 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [690/782] Loss: 0.2536 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [691/782] Loss: 0.4297 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [692/782] Loss: 0.3500 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [693/782] Loss: 0.4925 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [694/782] Loss: 0.3715 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [695/782] Loss: 0.4495 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [696/782] Loss: 0.3855 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [697/782] Loss: 0.3960 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [698/782] Loss: 0.5224 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [699/782] Loss: 0.2809 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [700/782] Loss: 0.3586 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [701/782] Loss: 0.5670 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [702/782] Loss: 0.4701 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [703/782] Loss: 0.5008 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [704/782] Loss: 0.3553 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [705/782] Loss: 0.3426 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [706/782] Loss: 0.3030 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [707/782] Loss: 0.4609 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [708/782] Loss: 0.3112 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [709/782] Loss: 0.1793 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [710/782] Loss: 0.4135 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [711/782] Loss: 0.4532 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [712/782] Loss: 0.2921 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [713/782] Loss: 0.2968 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [714/782] Loss: 0.3271 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [715/782] Loss: 0.4231 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [716/782] Loss: 0.4450 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [717/782] Loss: 0.2671 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [718/782] Loss: 0.4736 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [719/782] Loss: 0.4199 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [720/782] Loss: 0.2885 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [721/782] Loss: 0.3690 | Acc: 85.64%\n",
      "Train Epoch [93/100] Batch [722/782] Loss: 0.4168 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [723/782] Loss: 0.4570 | Acc: 85.63%\n",
      "Train Epoch [93/100] Batch [724/782] Loss: 0.7725 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [725/782] Loss: 0.4164 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [726/782] Loss: 0.4046 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [727/782] Loss: 0.5321 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [728/782] Loss: 0.4651 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [729/782] Loss: 0.3206 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [730/782] Loss: 0.3770 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [731/782] Loss: 0.4947 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [732/782] Loss: 0.3452 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [733/782] Loss: 0.3898 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [734/782] Loss: 0.4832 | Acc: 85.58%\n",
      "Train Epoch [93/100] Batch [735/782] Loss: 0.4741 | Acc: 85.57%\n",
      "Train Epoch [93/100] Batch [736/782] Loss: 0.2230 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [737/782] Loss: 0.3345 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [738/782] Loss: 0.4441 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [739/782] Loss: 0.2943 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [740/782] Loss: 0.5379 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [741/782] Loss: 0.3542 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [742/782] Loss: 0.3382 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [743/782] Loss: 0.3855 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [744/782] Loss: 0.2525 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [745/782] Loss: 0.4629 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [746/782] Loss: 0.2997 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [747/782] Loss: 0.4534 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [748/782] Loss: 0.4344 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [749/782] Loss: 0.4797 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [750/782] Loss: 0.3168 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [751/782] Loss: 0.3486 | Acc: 85.62%\n",
      "Train Epoch [93/100] Batch [752/782] Loss: 0.6061 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [753/782] Loss: 0.4694 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [754/782] Loss: 0.4837 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [755/782] Loss: 0.5261 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [756/782] Loss: 0.3438 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [757/782] Loss: 0.2973 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [758/782] Loss: 0.4078 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [759/782] Loss: 0.4252 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [760/782] Loss: 0.4086 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [761/782] Loss: 0.4069 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [762/782] Loss: 0.3743 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [763/782] Loss: 0.3956 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [764/782] Loss: 0.4284 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [765/782] Loss: 0.4990 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [766/782] Loss: 0.5221 | Acc: 85.59%\n",
      "Train Epoch [93/100] Batch [767/782] Loss: 0.3696 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [768/782] Loss: 0.3158 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [769/782] Loss: 0.4384 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [770/782] Loss: 0.2581 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [771/782] Loss: 0.4496 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [772/782] Loss: 0.4204 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [773/782] Loss: 0.5096 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [774/782] Loss: 0.4638 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [775/782] Loss: 0.4926 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [776/782] Loss: 0.4448 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [777/782] Loss: 0.3106 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [778/782] Loss: 0.4288 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [779/782] Loss: 0.4070 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [780/782] Loss: 0.3306 | Acc: 85.60%\n",
      "Train Epoch [93/100] Batch [781/782] Loss: 0.3333 | Acc: 85.61%\n",
      "Train Epoch [93/100] Batch [782/782] Loss: 0.3009 | Acc: 85.61%\n",
      "Epoch 93 completed in 29.51s.\n",
      "Test Epoch [93/100] Loss: 1.0217 | Acc: 72.10% | Inference Time: 8.06s\n",
      "Epoch 93 results saved to CSV.\n",
      "Epoch 94/100\n",
      "Train Epoch [94/100] Batch [1/782] Loss: 0.3459 | Acc: 90.62%\n",
      "Train Epoch [94/100] Batch [2/782] Loss: 0.4733 | Acc: 86.72%\n",
      "Train Epoch [94/100] Batch [3/782] Loss: 0.2969 | Acc: 86.98%\n",
      "Train Epoch [94/100] Batch [4/782] Loss: 0.4395 | Acc: 85.94%\n",
      "Train Epoch [94/100] Batch [5/782] Loss: 0.4396 | Acc: 86.56%\n",
      "Train Epoch [94/100] Batch [6/782] Loss: 0.4507 | Acc: 86.20%\n",
      "Train Epoch [94/100] Batch [7/782] Loss: 0.3692 | Acc: 86.38%\n",
      "Train Epoch [94/100] Batch [8/782] Loss: 0.3606 | Acc: 86.52%\n",
      "Train Epoch [94/100] Batch [9/782] Loss: 0.4657 | Acc: 86.46%\n",
      "Train Epoch [94/100] Batch [10/782] Loss: 0.3006 | Acc: 87.34%\n",
      "Train Epoch [94/100] Batch [11/782] Loss: 0.4810 | Acc: 87.22%\n",
      "Train Epoch [94/100] Batch [12/782] Loss: 0.3688 | Acc: 87.76%\n",
      "Train Epoch [94/100] Batch [13/782] Loss: 0.2612 | Acc: 87.62%\n",
      "Train Epoch [94/100] Batch [14/782] Loss: 0.3102 | Acc: 87.95%\n",
      "Train Epoch [94/100] Batch [15/782] Loss: 0.3703 | Acc: 87.92%\n",
      "Train Epoch [94/100] Batch [16/782] Loss: 0.4100 | Acc: 87.79%\n",
      "Train Epoch [94/100] Batch [17/782] Loss: 0.4628 | Acc: 87.32%\n",
      "Train Epoch [94/100] Batch [18/782] Loss: 0.3894 | Acc: 87.50%\n",
      "Train Epoch [94/100] Batch [19/782] Loss: 0.6175 | Acc: 87.09%\n",
      "Train Epoch [94/100] Batch [20/782] Loss: 0.3212 | Acc: 87.19%\n",
      "Train Epoch [94/100] Batch [21/782] Loss: 0.3848 | Acc: 86.98%\n",
      "Train Epoch [94/100] Batch [22/782] Loss: 0.4857 | Acc: 86.86%\n",
      "Train Epoch [94/100] Batch [23/782] Loss: 0.5151 | Acc: 86.68%\n",
      "Train Epoch [94/100] Batch [24/782] Loss: 0.3004 | Acc: 86.78%\n",
      "Train Epoch [94/100] Batch [25/782] Loss: 0.3425 | Acc: 86.88%\n",
      "Train Epoch [94/100] Batch [26/782] Loss: 0.2706 | Acc: 86.90%\n",
      "Train Epoch [94/100] Batch [27/782] Loss: 0.4508 | Acc: 86.92%\n",
      "Train Epoch [94/100] Batch [28/782] Loss: 0.5581 | Acc: 86.83%\n",
      "Train Epoch [94/100] Batch [29/782] Loss: 0.3442 | Acc: 86.75%\n",
      "Train Epoch [94/100] Batch [30/782] Loss: 0.5912 | Acc: 86.51%\n",
      "Train Epoch [94/100] Batch [31/782] Loss: 0.4570 | Acc: 86.44%\n",
      "Train Epoch [94/100] Batch [32/782] Loss: 0.4223 | Acc: 86.38%\n",
      "Train Epoch [94/100] Batch [33/782] Loss: 0.3959 | Acc: 86.22%\n",
      "Train Epoch [94/100] Batch [34/782] Loss: 0.2718 | Acc: 86.26%\n",
      "Train Epoch [94/100] Batch [35/782] Loss: 0.3698 | Acc: 86.34%\n",
      "Train Epoch [94/100] Batch [36/782] Loss: 0.4126 | Acc: 86.20%\n",
      "Train Epoch [94/100] Batch [37/782] Loss: 0.4490 | Acc: 86.06%\n",
      "Train Epoch [94/100] Batch [38/782] Loss: 0.2337 | Acc: 86.31%\n",
      "Train Epoch [94/100] Batch [39/782] Loss: 0.5017 | Acc: 86.14%\n",
      "Train Epoch [94/100] Batch [40/782] Loss: 0.4269 | Acc: 86.13%\n",
      "Train Epoch [94/100] Batch [41/782] Loss: 0.5256 | Acc: 86.05%\n",
      "Train Epoch [94/100] Batch [42/782] Loss: 0.3783 | Acc: 86.12%\n",
      "Train Epoch [94/100] Batch [43/782] Loss: 0.4054 | Acc: 86.12%\n",
      "Train Epoch [94/100] Batch [44/782] Loss: 0.4857 | Acc: 86.04%\n",
      "Train Epoch [94/100] Batch [45/782] Loss: 0.5009 | Acc: 85.94%\n",
      "Train Epoch [94/100] Batch [46/782] Loss: 0.3885 | Acc: 85.84%\n",
      "Train Epoch [94/100] Batch [47/782] Loss: 0.3284 | Acc: 85.80%\n",
      "Train Epoch [94/100] Batch [48/782] Loss: 0.6395 | Acc: 85.68%\n",
      "Train Epoch [94/100] Batch [49/782] Loss: 0.3376 | Acc: 85.78%\n",
      "Train Epoch [94/100] Batch [50/782] Loss: 0.3218 | Acc: 85.78%\n",
      "Train Epoch [94/100] Batch [51/782] Loss: 0.3997 | Acc: 85.85%\n",
      "Train Epoch [94/100] Batch [52/782] Loss: 0.6116 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [53/782] Loss: 0.3058 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [54/782] Loss: 0.2978 | Acc: 85.76%\n",
      "Train Epoch [94/100] Batch [55/782] Loss: 0.3182 | Acc: 85.85%\n",
      "Train Epoch [94/100] Batch [56/782] Loss: 0.4580 | Acc: 85.83%\n",
      "Train Epoch [94/100] Batch [57/782] Loss: 0.3784 | Acc: 85.86%\n",
      "Train Epoch [94/100] Batch [58/782] Loss: 0.5856 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [59/782] Loss: 0.3807 | Acc: 85.75%\n",
      "Train Epoch [94/100] Batch [60/782] Loss: 0.2534 | Acc: 85.83%\n",
      "Train Epoch [94/100] Batch [61/782] Loss: 0.4417 | Acc: 85.78%\n",
      "Train Epoch [94/100] Batch [62/782] Loss: 0.5573 | Acc: 85.66%\n",
      "Train Epoch [94/100] Batch [63/782] Loss: 0.5965 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [64/782] Loss: 0.5233 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [65/782] Loss: 0.1994 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [66/782] Loss: 0.4623 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [67/782] Loss: 0.5463 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [68/782] Loss: 0.3650 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [69/782] Loss: 0.3150 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [70/782] Loss: 0.5705 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [71/782] Loss: 0.4206 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [72/782] Loss: 0.5414 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [73/782] Loss: 0.3131 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [74/782] Loss: 0.3401 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [75/782] Loss: 0.3888 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [76/782] Loss: 0.2487 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [77/782] Loss: 0.3642 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [78/782] Loss: 0.4562 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [79/782] Loss: 0.4069 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [80/782] Loss: 0.5181 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [81/782] Loss: 0.3884 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [82/782] Loss: 0.4160 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [83/782] Loss: 0.2425 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [84/782] Loss: 0.4041 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [85/782] Loss: 0.5304 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [86/782] Loss: 0.5234 | Acc: 85.36%\n",
      "Train Epoch [94/100] Batch [87/782] Loss: 0.2793 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [88/782] Loss: 0.4131 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [89/782] Loss: 0.4663 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [90/782] Loss: 0.3413 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [91/782] Loss: 0.5025 | Acc: 85.37%\n",
      "Train Epoch [94/100] Batch [92/782] Loss: 0.3030 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [93/782] Loss: 0.3136 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [94/782] Loss: 0.3185 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [95/782] Loss: 0.4244 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [96/782] Loss: 0.2504 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [97/782] Loss: 0.3350 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [98/782] Loss: 0.3623 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [99/782] Loss: 0.4882 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [100/782] Loss: 0.5044 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [101/782] Loss: 0.4457 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [102/782] Loss: 0.3547 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [103/782] Loss: 0.2022 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [104/782] Loss: 0.3838 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [105/782] Loss: 0.2473 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [106/782] Loss: 0.3333 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [107/782] Loss: 0.3198 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [108/782] Loss: 0.3156 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [109/782] Loss: 0.2486 | Acc: 85.71%\n",
      "Train Epoch [94/100] Batch [110/782] Loss: 0.2710 | Acc: 85.75%\n",
      "Train Epoch [94/100] Batch [111/782] Loss: 0.3218 | Acc: 85.75%\n",
      "Train Epoch [94/100] Batch [112/782] Loss: 0.2998 | Acc: 85.78%\n",
      "Train Epoch [94/100] Batch [113/782] Loss: 0.4737 | Acc: 85.77%\n",
      "Train Epoch [94/100] Batch [114/782] Loss: 0.4042 | Acc: 85.79%\n",
      "Train Epoch [94/100] Batch [115/782] Loss: 0.4513 | Acc: 85.77%\n",
      "Train Epoch [94/100] Batch [116/782] Loss: 0.3821 | Acc: 85.78%\n",
      "Train Epoch [94/100] Batch [117/782] Loss: 0.4811 | Acc: 85.75%\n",
      "Train Epoch [94/100] Batch [118/782] Loss: 0.5087 | Acc: 85.71%\n",
      "Train Epoch [94/100] Batch [119/782] Loss: 0.4566 | Acc: 85.70%\n",
      "Train Epoch [94/100] Batch [120/782] Loss: 0.2843 | Acc: 85.74%\n",
      "Train Epoch [94/100] Batch [121/782] Loss: 0.4282 | Acc: 85.73%\n",
      "Train Epoch [94/100] Batch [122/782] Loss: 0.4553 | Acc: 85.73%\n",
      "Train Epoch [94/100] Batch [123/782] Loss: 0.3746 | Acc: 85.71%\n",
      "Train Epoch [94/100] Batch [124/782] Loss: 0.2999 | Acc: 85.72%\n",
      "Train Epoch [94/100] Batch [125/782] Loss: 0.5018 | Acc: 85.70%\n",
      "Train Epoch [94/100] Batch [126/782] Loss: 0.4095 | Acc: 85.68%\n",
      "Train Epoch [94/100] Batch [127/782] Loss: 0.4845 | Acc: 85.65%\n",
      "Train Epoch [94/100] Batch [128/782] Loss: 0.4912 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [129/782] Loss: 0.4108 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [130/782] Loss: 0.3408 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [131/782] Loss: 0.3482 | Acc: 85.63%\n",
      "Train Epoch [94/100] Batch [132/782] Loss: 0.4443 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [133/782] Loss: 0.2784 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [134/782] Loss: 0.2722 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [135/782] Loss: 0.4615 | Acc: 85.66%\n",
      "Train Epoch [94/100] Batch [136/782] Loss: 0.3378 | Acc: 85.70%\n",
      "Train Epoch [94/100] Batch [137/782] Loss: 0.3567 | Acc: 85.69%\n",
      "Train Epoch [94/100] Batch [138/782] Loss: 0.3929 | Acc: 85.68%\n",
      "Train Epoch [94/100] Batch [139/782] Loss: 0.4983 | Acc: 85.68%\n",
      "Train Epoch [94/100] Batch [140/782] Loss: 0.4397 | Acc: 85.66%\n",
      "Train Epoch [94/100] Batch [141/782] Loss: 0.4864 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [142/782] Loss: 0.3933 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [143/782] Loss: 0.4769 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [144/782] Loss: 0.5037 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [145/782] Loss: 0.2914 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [146/782] Loss: 0.4080 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [147/782] Loss: 0.4981 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [148/782] Loss: 0.3602 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [149/782] Loss: 0.4744 | Acc: 85.60%\n",
      "Train Epoch [94/100] Batch [150/782] Loss: 0.3444 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [151/782] Loss: 0.4979 | Acc: 85.63%\n",
      "Train Epoch [94/100] Batch [152/782] Loss: 0.4711 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [153/782] Loss: 0.3022 | Acc: 85.60%\n",
      "Train Epoch [94/100] Batch [154/782] Loss: 0.4528 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [155/782] Loss: 0.4837 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [156/782] Loss: 0.2926 | Acc: 85.60%\n",
      "Train Epoch [94/100] Batch [157/782] Loss: 0.3926 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [158/782] Loss: 0.3365 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [159/782] Loss: 0.2441 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [160/782] Loss: 0.1915 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [161/782] Loss: 0.4351 | Acc: 85.65%\n",
      "Train Epoch [94/100] Batch [162/782] Loss: 0.5158 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [163/782] Loss: 0.3853 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [164/782] Loss: 0.3338 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [165/782] Loss: 0.4176 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [166/782] Loss: 0.2945 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [167/782] Loss: 0.3206 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [168/782] Loss: 0.3120 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [169/782] Loss: 0.4246 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [170/782] Loss: 0.3842 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [171/782] Loss: 0.5339 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [172/782] Loss: 0.4001 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [173/782] Loss: 0.3501 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [174/782] Loss: 0.2808 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [175/782] Loss: 0.4538 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [176/782] Loss: 0.4311 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [177/782] Loss: 0.4508 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [178/782] Loss: 0.3354 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [179/782] Loss: 0.4158 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [180/782] Loss: 0.3889 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [181/782] Loss: 0.2963 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [182/782] Loss: 0.3527 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [183/782] Loss: 0.6301 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [184/782] Loss: 0.1662 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [185/782] Loss: 0.4241 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [186/782] Loss: 0.3474 | Acc: 85.61%\n",
      "Train Epoch [94/100] Batch [187/782] Loss: 0.6839 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [188/782] Loss: 0.3847 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [189/782] Loss: 0.3141 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [190/782] Loss: 0.3125 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [191/782] Loss: 0.4091 | Acc: 85.58%\n",
      "Train Epoch [94/100] Batch [192/782] Loss: 0.5344 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [193/782] Loss: 0.4262 | Acc: 85.55%\n",
      "Train Epoch [94/100] Batch [194/782] Loss: 0.2023 | Acc: 85.59%\n",
      "Train Epoch [94/100] Batch [195/782] Loss: 0.5205 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [196/782] Loss: 0.2919 | Acc: 85.60%\n",
      "Train Epoch [94/100] Batch [197/782] Loss: 0.5866 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [198/782] Loss: 0.3716 | Acc: 85.57%\n",
      "Train Epoch [94/100] Batch [199/782] Loss: 0.4423 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [200/782] Loss: 0.4971 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [201/782] Loss: 0.3474 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [202/782] Loss: 0.3686 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [203/782] Loss: 0.2457 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [204/782] Loss: 0.4050 | Acc: 85.56%\n",
      "Train Epoch [94/100] Batch [205/782] Loss: 0.2693 | Acc: 85.60%\n",
      "Train Epoch [94/100] Batch [206/782] Loss: 0.3025 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [207/782] Loss: 0.2975 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [208/782] Loss: 0.3966 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [209/782] Loss: 0.2771 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [210/782] Loss: 0.4824 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [211/782] Loss: 0.5193 | Acc: 85.62%\n",
      "Train Epoch [94/100] Batch [212/782] Loss: 0.2754 | Acc: 85.64%\n",
      "Train Epoch [94/100] Batch [213/782] Loss: 0.4457 | Acc: 85.66%\n",
      "Train Epoch [94/100] Batch [214/782] Loss: 0.3085 | Acc: 85.67%\n",
      "Train Epoch [94/100] Batch [215/782] Loss: 0.3605 | Acc: 85.69%\n",
      "Train Epoch [94/100] Batch [216/782] Loss: 0.3590 | Acc: 85.68%\n",
      "Train Epoch [94/100] Batch [217/782] Loss: 0.5413 | Acc: 85.65%\n",
      "Train Epoch [94/100] Batch [218/782] Loss: 0.3891 | Acc: 85.63%\n",
      "Train Epoch [94/100] Batch [219/782] Loss: 0.4270 | Acc: 85.63%\n",
      "Train Epoch [94/100] Batch [220/782] Loss: 0.8652 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [221/782] Loss: 0.4165 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [222/782] Loss: 0.2192 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [223/782] Loss: 0.4684 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [224/782] Loss: 0.6016 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [225/782] Loss: 0.3852 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [226/782] Loss: 0.3419 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [227/782] Loss: 0.5989 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [228/782] Loss: 0.2809 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [229/782] Loss: 0.4299 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [230/782] Loss: 0.4646 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [231/782] Loss: 0.8157 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [232/782] Loss: 0.2919 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [233/782] Loss: 0.4458 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [234/782] Loss: 0.4659 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [235/782] Loss: 0.3492 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [236/782] Loss: 0.4670 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [237/782] Loss: 0.4291 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [238/782] Loss: 0.3555 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [239/782] Loss: 0.4314 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [240/782] Loss: 0.4389 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [241/782] Loss: 0.5120 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [242/782] Loss: 0.4905 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [243/782] Loss: 0.3463 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [244/782] Loss: 0.3593 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [245/782] Loss: 0.3807 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [246/782] Loss: 0.3600 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [247/782] Loss: 0.5324 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [248/782] Loss: 0.3254 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [249/782] Loss: 0.3857 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [250/782] Loss: 0.4095 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [251/782] Loss: 0.3539 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [252/782] Loss: 0.4556 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [253/782] Loss: 0.4476 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [254/782] Loss: 0.3354 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [255/782] Loss: 0.5857 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [256/782] Loss: 0.2671 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [257/782] Loss: 0.2777 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [258/782] Loss: 0.3407 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [259/782] Loss: 0.3520 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [260/782] Loss: 0.2071 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [261/782] Loss: 0.5644 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [262/782] Loss: 0.3975 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [263/782] Loss: 0.3261 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [264/782] Loss: 0.2574 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [265/782] Loss: 0.4827 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [266/782] Loss: 0.4909 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [267/782] Loss: 0.3688 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [268/782] Loss: 0.3839 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [269/782] Loss: 0.4485 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [270/782] Loss: 0.4990 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [271/782] Loss: 0.4165 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [272/782] Loss: 0.4932 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [273/782] Loss: 0.2748 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [274/782] Loss: 0.4808 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [275/782] Loss: 0.3554 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [276/782] Loss: 0.4581 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [277/782] Loss: 0.5987 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [278/782] Loss: 0.4336 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [279/782] Loss: 0.3324 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [280/782] Loss: 0.4443 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [281/782] Loss: 0.5272 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [282/782] Loss: 0.3468 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [283/782] Loss: 0.3503 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [284/782] Loss: 0.3292 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [285/782] Loss: 0.3162 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [286/782] Loss: 0.4969 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [287/782] Loss: 0.3475 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [288/782] Loss: 0.4390 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [289/782] Loss: 0.3207 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [290/782] Loss: 0.4147 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [291/782] Loss: 0.3613 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [292/782] Loss: 0.2473 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [293/782] Loss: 0.3267 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [294/782] Loss: 0.5400 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [295/782] Loss: 0.4001 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [296/782] Loss: 0.6343 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [297/782] Loss: 0.3969 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [298/782] Loss: 0.2724 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [299/782] Loss: 0.3756 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [300/782] Loss: 0.4365 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [301/782] Loss: 0.3541 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [302/782] Loss: 0.4238 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [303/782] Loss: 0.6629 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [304/782] Loss: 0.5396 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [305/782] Loss: 0.5630 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [306/782] Loss: 0.3991 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [307/782] Loss: 0.2955 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [308/782] Loss: 0.4152 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [309/782] Loss: 0.3657 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [310/782] Loss: 0.4520 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [311/782] Loss: 0.3312 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [312/782] Loss: 0.4422 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [313/782] Loss: 0.3567 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [314/782] Loss: 0.2707 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [315/782] Loss: 0.4179 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [316/782] Loss: 0.3813 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [317/782] Loss: 0.4858 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [318/782] Loss: 0.3696 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [319/782] Loss: 0.4941 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [320/782] Loss: 0.4858 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [321/782] Loss: 0.5348 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [322/782] Loss: 0.4581 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [323/782] Loss: 0.4651 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [324/782] Loss: 0.4408 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [325/782] Loss: 0.2931 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [326/782] Loss: 0.4363 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [327/782] Loss: 0.5469 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [328/782] Loss: 0.3315 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [329/782] Loss: 0.4218 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [330/782] Loss: 0.7144 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [331/782] Loss: 0.4615 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [332/782] Loss: 0.2048 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [333/782] Loss: 0.4378 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [334/782] Loss: 0.5094 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [335/782] Loss: 0.4941 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [336/782] Loss: 0.3510 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [337/782] Loss: 0.2989 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [338/782] Loss: 0.3269 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [339/782] Loss: 0.3700 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [340/782] Loss: 0.5100 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [341/782] Loss: 0.4241 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [342/782] Loss: 0.4816 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [343/782] Loss: 0.4245 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [344/782] Loss: 0.5674 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [345/782] Loss: 0.3687 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [346/782] Loss: 0.4415 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [347/782] Loss: 0.2709 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [348/782] Loss: 0.3774 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [349/782] Loss: 0.4233 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [350/782] Loss: 0.2799 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [351/782] Loss: 0.3049 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [352/782] Loss: 0.3455 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [353/782] Loss: 0.2782 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [354/782] Loss: 0.3716 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [355/782] Loss: 0.4575 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [356/782] Loss: 0.3599 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [357/782] Loss: 0.5943 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [358/782] Loss: 0.5765 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [359/782] Loss: 0.6895 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [360/782] Loss: 0.3760 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [361/782] Loss: 0.6540 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [362/782] Loss: 0.4516 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [363/782] Loss: 0.3128 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [364/782] Loss: 0.5875 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [365/782] Loss: 0.4213 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [366/782] Loss: 0.5546 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [367/782] Loss: 0.6316 | Acc: 85.37%\n",
      "Train Epoch [94/100] Batch [368/782] Loss: 0.4524 | Acc: 85.37%\n",
      "Train Epoch [94/100] Batch [369/782] Loss: 0.3775 | Acc: 85.37%\n",
      "Train Epoch [94/100] Batch [370/782] Loss: 0.4749 | Acc: 85.36%\n",
      "Train Epoch [94/100] Batch [371/782] Loss: 0.4017 | Acc: 85.37%\n",
      "Train Epoch [94/100] Batch [372/782] Loss: 0.3272 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [373/782] Loss: 0.5315 | Acc: 85.38%\n",
      "Train Epoch [94/100] Batch [374/782] Loss: 0.3855 | Acc: 85.38%\n",
      "Train Epoch [94/100] Batch [375/782] Loss: 0.3429 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [376/782] Loss: 0.1676 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [377/782] Loss: 0.4519 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [378/782] Loss: 0.4307 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [379/782] Loss: 0.4537 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [380/782] Loss: 0.4550 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [381/782] Loss: 0.2991 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [382/782] Loss: 0.3774 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [383/782] Loss: 0.4771 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [384/782] Loss: 0.3868 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [385/782] Loss: 0.3926 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [386/782] Loss: 0.4391 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [387/782] Loss: 0.3166 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [388/782] Loss: 0.3475 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [389/782] Loss: 0.3730 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [390/782] Loss: 0.4130 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [391/782] Loss: 0.6578 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [392/782] Loss: 0.3719 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [393/782] Loss: 0.3313 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [394/782] Loss: 0.3510 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [395/782] Loss: 0.2984 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [396/782] Loss: 0.3975 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [397/782] Loss: 0.4214 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [398/782] Loss: 0.3077 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [399/782] Loss: 0.3777 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [400/782] Loss: 0.5498 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [401/782] Loss: 0.4356 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [402/782] Loss: 0.2863 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [403/782] Loss: 0.3945 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [404/782] Loss: 0.4431 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [405/782] Loss: 0.3151 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [406/782] Loss: 0.3166 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [407/782] Loss: 0.5046 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [408/782] Loss: 0.2398 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [409/782] Loss: 0.3773 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [410/782] Loss: 0.5413 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [411/782] Loss: 0.3678 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [412/782] Loss: 0.2599 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [413/782] Loss: 0.3233 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [414/782] Loss: 0.2846 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [415/782] Loss: 0.2699 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [416/782] Loss: 0.5321 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [417/782] Loss: 0.3901 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [418/782] Loss: 0.3424 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [419/782] Loss: 0.3681 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [420/782] Loss: 0.2921 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [421/782] Loss: 0.5889 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [422/782] Loss: 0.5471 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [423/782] Loss: 0.4211 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [424/782] Loss: 0.4026 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [425/782] Loss: 0.5143 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [426/782] Loss: 0.4858 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [427/782] Loss: 0.4971 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [428/782] Loss: 0.5490 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [429/782] Loss: 0.3334 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [430/782] Loss: 0.2977 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [431/782] Loss: 0.3384 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [432/782] Loss: 0.4883 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [433/782] Loss: 0.3554 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [434/782] Loss: 0.4498 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [435/782] Loss: 0.2051 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [436/782] Loss: 0.4280 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [437/782] Loss: 0.2613 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [438/782] Loss: 0.3463 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [439/782] Loss: 0.2892 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [440/782] Loss: 0.4273 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [441/782] Loss: 0.2817 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [442/782] Loss: 0.2608 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [443/782] Loss: 0.5740 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [444/782] Loss: 0.4816 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [445/782] Loss: 0.2736 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [446/782] Loss: 0.3737 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [447/782] Loss: 0.3919 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [448/782] Loss: 0.4799 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [449/782] Loss: 0.6170 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [450/782] Loss: 0.2364 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [451/782] Loss: 0.3971 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [452/782] Loss: 0.4131 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [453/782] Loss: 0.3514 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [454/782] Loss: 0.3295 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [455/782] Loss: 0.3341 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [456/782] Loss: 0.2816 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [457/782] Loss: 0.1622 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [458/782] Loss: 0.3083 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [459/782] Loss: 0.2710 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [460/782] Loss: 0.4306 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [461/782] Loss: 0.9036 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [462/782] Loss: 0.4756 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [463/782] Loss: 0.4686 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [464/782] Loss: 0.3403 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [465/782] Loss: 0.4629 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [466/782] Loss: 0.4358 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [467/782] Loss: 0.4325 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [468/782] Loss: 0.4033 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [469/782] Loss: 0.5356 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [470/782] Loss: 0.2946 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [471/782] Loss: 0.7148 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [472/782] Loss: 0.3542 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [473/782] Loss: 0.5270 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [474/782] Loss: 0.4188 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [475/782] Loss: 0.5123 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [476/782] Loss: 0.5181 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [477/782] Loss: 0.3217 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [478/782] Loss: 0.3752 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [479/782] Loss: 0.5533 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [480/782] Loss: 0.3806 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [481/782] Loss: 0.3304 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [482/782] Loss: 0.4841 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [483/782] Loss: 0.5212 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [484/782] Loss: 0.3918 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [485/782] Loss: 0.2312 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [486/782] Loss: 0.4555 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [487/782] Loss: 0.3465 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [488/782] Loss: 0.5054 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [489/782] Loss: 0.2638 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [490/782] Loss: 0.3894 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [491/782] Loss: 0.4706 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [492/782] Loss: 0.4121 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [493/782] Loss: 0.2862 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [494/782] Loss: 0.4637 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [495/782] Loss: 0.5288 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [496/782] Loss: 0.2776 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [497/782] Loss: 0.3291 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [498/782] Loss: 0.3867 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [499/782] Loss: 0.3877 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [500/782] Loss: 0.3643 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [501/782] Loss: 0.3312 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [502/782] Loss: 0.2277 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [503/782] Loss: 0.5144 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [504/782] Loss: 0.3469 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [505/782] Loss: 0.4603 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [506/782] Loss: 0.2598 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [507/782] Loss: 0.2519 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [508/782] Loss: 0.6372 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [509/782] Loss: 0.5485 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [510/782] Loss: 0.6526 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [511/782] Loss: 0.2518 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [512/782] Loss: 0.4615 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [513/782] Loss: 0.5556 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [514/782] Loss: 0.3592 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [515/782] Loss: 0.4358 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [516/782] Loss: 0.2493 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [517/782] Loss: 0.3143 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [518/782] Loss: 0.5712 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [519/782] Loss: 0.4517 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [520/782] Loss: 0.3503 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [521/782] Loss: 0.3687 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [522/782] Loss: 0.3284 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [523/782] Loss: 0.2913 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [524/782] Loss: 0.4948 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [525/782] Loss: 0.2932 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [526/782] Loss: 0.6997 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [527/782] Loss: 0.3419 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [528/782] Loss: 0.2507 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [529/782] Loss: 0.5331 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [530/782] Loss: 0.3005 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [531/782] Loss: 0.4096 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [532/782] Loss: 0.3601 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [533/782] Loss: 0.3187 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [534/782] Loss: 0.4053 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [535/782] Loss: 0.3925 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [536/782] Loss: 0.4132 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [537/782] Loss: 0.5059 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [538/782] Loss: 0.4446 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [539/782] Loss: 0.3237 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [540/782] Loss: 0.4424 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [541/782] Loss: 0.5307 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [542/782] Loss: 0.3663 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [543/782] Loss: 0.5218 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [544/782] Loss: 0.3128 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [545/782] Loss: 0.5405 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [546/782] Loss: 0.5516 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [547/782] Loss: 0.3553 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [548/782] Loss: 0.4231 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [549/782] Loss: 0.3293 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [550/782] Loss: 0.3356 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [551/782] Loss: 0.3892 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [552/782] Loss: 0.2931 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [553/782] Loss: 0.3471 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [554/782] Loss: 0.3372 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [555/782] Loss: 0.5174 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [556/782] Loss: 0.3732 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [557/782] Loss: 0.4720 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [558/782] Loss: 0.3204 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [559/782] Loss: 0.2984 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [560/782] Loss: 0.3352 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [561/782] Loss: 0.5189 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [562/782] Loss: 0.3210 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [563/782] Loss: 0.5819 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [564/782] Loss: 0.3612 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [565/782] Loss: 0.3372 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [566/782] Loss: 0.4595 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [567/782] Loss: 0.3394 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [568/782] Loss: 0.4445 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [569/782] Loss: 0.5133 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [570/782] Loss: 0.4136 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [571/782] Loss: 0.4005 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [572/782] Loss: 0.3412 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [573/782] Loss: 0.3907 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [574/782] Loss: 0.5561 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [575/782] Loss: 0.4472 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [576/782] Loss: 0.4251 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [577/782] Loss: 0.4672 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [578/782] Loss: 0.4509 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [579/782] Loss: 0.3378 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [580/782] Loss: 0.5669 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [581/782] Loss: 0.3550 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [582/782] Loss: 0.4407 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [583/782] Loss: 0.3129 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [584/782] Loss: 0.5179 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [585/782] Loss: 0.3599 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [586/782] Loss: 0.3102 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [587/782] Loss: 0.1774 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [588/782] Loss: 0.4523 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [589/782] Loss: 0.3820 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [590/782] Loss: 0.3339 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [591/782] Loss: 0.2346 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [592/782] Loss: 0.3830 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [593/782] Loss: 0.5692 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [594/782] Loss: 0.4024 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [595/782] Loss: 0.5131 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [596/782] Loss: 0.4822 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [597/782] Loss: 0.2979 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [598/782] Loss: 0.2039 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [599/782] Loss: 0.3170 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [600/782] Loss: 0.4985 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [601/782] Loss: 0.2842 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [602/782] Loss: 0.3858 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [603/782] Loss: 0.4982 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [604/782] Loss: 0.2919 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [605/782] Loss: 0.5406 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [606/782] Loss: 0.3187 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [607/782] Loss: 0.3497 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [608/782] Loss: 0.3537 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [609/782] Loss: 0.4307 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [610/782] Loss: 0.5979 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [611/782] Loss: 0.3226 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [612/782] Loss: 0.3884 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [613/782] Loss: 0.3636 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [614/782] Loss: 0.5070 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [615/782] Loss: 0.4728 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [616/782] Loss: 0.2945 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [617/782] Loss: 0.3166 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [618/782] Loss: 0.3085 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [619/782] Loss: 0.6976 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [620/782] Loss: 0.5375 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [621/782] Loss: 0.4329 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [622/782] Loss: 0.5669 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [623/782] Loss: 0.3553 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [624/782] Loss: 0.3397 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [625/782] Loss: 0.4440 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [626/782] Loss: 0.5992 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [627/782] Loss: 0.4232 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [628/782] Loss: 0.4066 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [629/782] Loss: 0.3000 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [630/782] Loss: 0.1927 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [631/782] Loss: 0.2017 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [632/782] Loss: 0.3162 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [633/782] Loss: 0.5461 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [634/782] Loss: 0.4369 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [635/782] Loss: 0.4642 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [636/782] Loss: 0.3584 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [637/782] Loss: 0.5337 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [638/782] Loss: 0.4210 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [639/782] Loss: 0.4078 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [640/782] Loss: 0.3887 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [641/782] Loss: 0.5188 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [642/782] Loss: 0.2594 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [643/782] Loss: 0.3104 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [644/782] Loss: 0.3499 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [645/782] Loss: 0.4934 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [646/782] Loss: 0.4435 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [647/782] Loss: 0.4904 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [648/782] Loss: 0.2822 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [649/782] Loss: 0.2738 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [650/782] Loss: 0.3841 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [651/782] Loss: 0.3485 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [652/782] Loss: 0.4398 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [653/782] Loss: 0.2800 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [654/782] Loss: 0.5876 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [655/782] Loss: 0.4156 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [656/782] Loss: 0.2040 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [657/782] Loss: 0.3553 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [658/782] Loss: 0.3539 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [659/782] Loss: 0.4833 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [660/782] Loss: 0.2457 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [661/782] Loss: 0.3310 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [662/782] Loss: 0.3716 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [663/782] Loss: 0.4611 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [664/782] Loss: 0.5259 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [665/782] Loss: 0.3501 | Acc: 85.53%\n",
      "Train Epoch [94/100] Batch [666/782] Loss: 0.3042 | Acc: 85.54%\n",
      "Train Epoch [94/100] Batch [667/782] Loss: 0.5100 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [668/782] Loss: 0.4375 | Acc: 85.52%\n",
      "Train Epoch [94/100] Batch [669/782] Loss: 0.5194 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [670/782] Loss: 0.3782 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [671/782] Loss: 0.3299 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [672/782] Loss: 0.4438 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [673/782] Loss: 0.3647 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [674/782] Loss: 0.4427 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [675/782] Loss: 0.5111 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [676/782] Loss: 0.1650 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [677/782] Loss: 0.3926 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [678/782] Loss: 0.5139 | Acc: 85.51%\n",
      "Train Epoch [94/100] Batch [679/782] Loss: 0.4543 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [680/782] Loss: 0.4430 | Acc: 85.50%\n",
      "Train Epoch [94/100] Batch [681/782] Loss: 0.5394 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [682/782] Loss: 0.3960 | Acc: 85.49%\n",
      "Train Epoch [94/100] Batch [683/782] Loss: 0.4210 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [684/782] Loss: 0.3743 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [685/782] Loss: 0.3838 | Acc: 85.48%\n",
      "Train Epoch [94/100] Batch [686/782] Loss: 0.5953 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [687/782] Loss: 0.4782 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [688/782] Loss: 0.2470 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [689/782] Loss: 0.3440 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [690/782] Loss: 0.4534 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [691/782] Loss: 0.5030 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [692/782] Loss: 0.4303 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [693/782] Loss: 0.2859 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [694/782] Loss: 0.6396 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [695/782] Loss: 0.3763 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [696/782] Loss: 0.3597 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [697/782] Loss: 0.6549 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [698/782] Loss: 0.2764 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [699/782] Loss: 0.3222 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [700/782] Loss: 0.2962 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [701/782] Loss: 0.4171 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [702/782] Loss: 0.4998 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [703/782] Loss: 0.4049 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [704/782] Loss: 0.3638 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [705/782] Loss: 0.3409 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [706/782] Loss: 0.4988 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [707/782] Loss: 0.2883 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [708/782] Loss: 0.4688 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [709/782] Loss: 0.4460 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [710/782] Loss: 0.5838 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [711/782] Loss: 0.2766 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [712/782] Loss: 0.4099 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [713/782] Loss: 0.3814 | Acc: 85.47%\n",
      "Train Epoch [94/100] Batch [714/782] Loss: 0.7256 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [715/782] Loss: 0.3818 | Acc: 85.45%\n",
      "Train Epoch [94/100] Batch [716/782] Loss: 0.2469 | Acc: 85.46%\n",
      "Train Epoch [94/100] Batch [717/782] Loss: 0.4681 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [718/782] Loss: 0.6820 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [719/782] Loss: 0.5535 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [720/782] Loss: 0.4861 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [721/782] Loss: 0.4697 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [722/782] Loss: 0.4242 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [723/782] Loss: 0.2960 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [724/782] Loss: 0.3362 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [725/782] Loss: 0.4898 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [726/782] Loss: 0.5448 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [727/782] Loss: 0.3979 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [728/782] Loss: 0.4731 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [729/782] Loss: 0.2893 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [730/782] Loss: 0.4540 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [731/782] Loss: 0.4108 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [732/782] Loss: 0.4344 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [733/782] Loss: 0.4745 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [734/782] Loss: 0.2779 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [735/782] Loss: 0.4160 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [736/782] Loss: 0.4951 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [737/782] Loss: 0.4642 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [738/782] Loss: 0.3408 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [739/782] Loss: 0.3645 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [740/782] Loss: 0.4496 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [741/782] Loss: 0.2965 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [742/782] Loss: 0.4548 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [743/782] Loss: 0.4638 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [744/782] Loss: 0.3784 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [745/782] Loss: 0.3292 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [746/782] Loss: 0.4600 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [747/782] Loss: 0.3710 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [748/782] Loss: 0.3035 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [749/782] Loss: 0.3660 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [750/782] Loss: 0.4371 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [751/782] Loss: 0.3175 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [752/782] Loss: 0.4582 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [753/782] Loss: 0.6247 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [754/782] Loss: 0.3044 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [755/782] Loss: 0.2842 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [756/782] Loss: 0.5243 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [757/782] Loss: 0.3492 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [758/782] Loss: 0.5172 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [759/782] Loss: 0.4690 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [760/782] Loss: 0.2647 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [761/782] Loss: 0.3855 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [762/782] Loss: 0.3189 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [763/782] Loss: 0.4274 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [764/782] Loss: 0.3764 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [765/782] Loss: 0.5304 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [766/782] Loss: 0.3401 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [767/782] Loss: 0.5637 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [768/782] Loss: 0.4273 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [769/782] Loss: 0.2981 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [770/782] Loss: 0.3822 | Acc: 85.44%\n",
      "Train Epoch [94/100] Batch [771/782] Loss: 0.5390 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [772/782] Loss: 0.3600 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [773/782] Loss: 0.4154 | Acc: 85.43%\n",
      "Train Epoch [94/100] Batch [774/782] Loss: 0.6607 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [775/782] Loss: 0.4981 | Acc: 85.42%\n",
      "Train Epoch [94/100] Batch [776/782] Loss: 0.5473 | Acc: 85.41%\n",
      "Train Epoch [94/100] Batch [777/782] Loss: 0.6075 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [778/782] Loss: 0.3415 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [779/782] Loss: 0.5172 | Acc: 85.40%\n",
      "Train Epoch [94/100] Batch [780/782] Loss: 0.5147 | Acc: 85.39%\n",
      "Train Epoch [94/100] Batch [781/782] Loss: 0.4702 | Acc: 85.38%\n",
      "Train Epoch [94/100] Batch [782/782] Loss: 0.2583 | Acc: 85.38%\n",
      "Epoch 94 completed in 29.37s.\n",
      "Test Epoch [94/100] Loss: 1.0183 | Acc: 72.08% | Inference Time: 8.05s\n",
      "Epoch 94 results saved to CSV.\n",
      "Epoch 95/100\n",
      "Train Epoch [95/100] Batch [1/782] Loss: 0.3043 | Acc: 89.06%\n",
      "Train Epoch [95/100] Batch [2/782] Loss: 0.3191 | Acc: 89.06%\n",
      "Train Epoch [95/100] Batch [3/782] Loss: 0.3919 | Acc: 87.50%\n",
      "Train Epoch [95/100] Batch [4/782] Loss: 0.5181 | Acc: 85.94%\n",
      "Train Epoch [95/100] Batch [5/782] Loss: 0.3111 | Acc: 86.25%\n",
      "Train Epoch [95/100] Batch [6/782] Loss: 0.5862 | Acc: 85.42%\n",
      "Train Epoch [95/100] Batch [7/782] Loss: 0.5004 | Acc: 85.04%\n",
      "Train Epoch [95/100] Batch [8/782] Loss: 0.5378 | Acc: 84.57%\n",
      "Train Epoch [95/100] Batch [9/782] Loss: 0.2980 | Acc: 85.07%\n",
      "Train Epoch [95/100] Batch [10/782] Loss: 0.3525 | Acc: 85.31%\n",
      "Train Epoch [95/100] Batch [11/782] Loss: 0.5005 | Acc: 85.09%\n",
      "Train Epoch [95/100] Batch [12/782] Loss: 0.4802 | Acc: 84.64%\n",
      "Train Epoch [95/100] Batch [13/782] Loss: 0.3105 | Acc: 84.98%\n",
      "Train Epoch [95/100] Batch [14/782] Loss: 0.5835 | Acc: 84.26%\n",
      "Train Epoch [95/100] Batch [15/782] Loss: 0.4463 | Acc: 84.27%\n",
      "Train Epoch [95/100] Batch [16/782] Loss: 0.3546 | Acc: 84.28%\n",
      "Train Epoch [95/100] Batch [17/782] Loss: 0.5789 | Acc: 83.92%\n",
      "Train Epoch [95/100] Batch [18/782] Loss: 0.2936 | Acc: 84.11%\n",
      "Train Epoch [95/100] Batch [19/782] Loss: 0.5802 | Acc: 83.72%\n",
      "Train Epoch [95/100] Batch [20/782] Loss: 0.2752 | Acc: 84.06%\n",
      "Train Epoch [95/100] Batch [21/782] Loss: 0.2220 | Acc: 84.52%\n",
      "Train Epoch [95/100] Batch [22/782] Loss: 0.4782 | Acc: 84.16%\n",
      "Train Epoch [95/100] Batch [23/782] Loss: 0.4371 | Acc: 84.04%\n",
      "Train Epoch [95/100] Batch [24/782] Loss: 0.4290 | Acc: 84.05%\n",
      "Train Epoch [95/100] Batch [25/782] Loss: 0.4838 | Acc: 84.00%\n",
      "Train Epoch [95/100] Batch [26/782] Loss: 0.4338 | Acc: 84.07%\n",
      "Train Epoch [95/100] Batch [27/782] Loss: 0.4153 | Acc: 84.03%\n",
      "Train Epoch [95/100] Batch [28/782] Loss: 0.4089 | Acc: 84.10%\n",
      "Train Epoch [95/100] Batch [29/782] Loss: 0.5158 | Acc: 84.00%\n",
      "Train Epoch [95/100] Batch [30/782] Loss: 0.2517 | Acc: 84.27%\n",
      "Train Epoch [95/100] Batch [31/782] Loss: 0.5080 | Acc: 84.17%\n",
      "Train Epoch [95/100] Batch [32/782] Loss: 0.4637 | Acc: 84.08%\n",
      "Train Epoch [95/100] Batch [33/782] Loss: 0.4190 | Acc: 84.04%\n",
      "Train Epoch [95/100] Batch [34/782] Loss: 0.3959 | Acc: 84.15%\n",
      "Train Epoch [95/100] Batch [35/782] Loss: 0.3295 | Acc: 84.29%\n",
      "Train Epoch [95/100] Batch [36/782] Loss: 0.3248 | Acc: 84.38%\n",
      "Train Epoch [95/100] Batch [37/782] Loss: 0.1693 | Acc: 84.67%\n",
      "Train Epoch [95/100] Batch [38/782] Loss: 0.5110 | Acc: 84.54%\n",
      "Train Epoch [95/100] Batch [39/782] Loss: 0.3808 | Acc: 84.54%\n",
      "Train Epoch [95/100] Batch [40/782] Loss: 0.4474 | Acc: 84.57%\n",
      "Train Epoch [95/100] Batch [41/782] Loss: 0.6710 | Acc: 84.26%\n",
      "Train Epoch [95/100] Batch [42/782] Loss: 0.4674 | Acc: 84.23%\n",
      "Train Epoch [95/100] Batch [43/782] Loss: 0.4143 | Acc: 84.19%\n",
      "Train Epoch [95/100] Batch [44/782] Loss: 0.5393 | Acc: 84.02%\n",
      "Train Epoch [95/100] Batch [45/782] Loss: 0.4508 | Acc: 83.96%\n",
      "Train Epoch [95/100] Batch [46/782] Loss: 0.3764 | Acc: 84.04%\n",
      "Train Epoch [95/100] Batch [47/782] Loss: 0.4814 | Acc: 83.98%\n",
      "Train Epoch [95/100] Batch [48/782] Loss: 0.4914 | Acc: 83.98%\n",
      "Train Epoch [95/100] Batch [49/782] Loss: 0.6584 | Acc: 83.90%\n",
      "Train Epoch [95/100] Batch [50/782] Loss: 0.2263 | Acc: 84.09%\n",
      "Train Epoch [95/100] Batch [51/782] Loss: 0.5785 | Acc: 84.01%\n",
      "Train Epoch [95/100] Batch [52/782] Loss: 0.3481 | Acc: 84.01%\n",
      "Train Epoch [95/100] Batch [53/782] Loss: 0.3812 | Acc: 84.11%\n",
      "Train Epoch [95/100] Batch [54/782] Loss: 0.3360 | Acc: 84.17%\n",
      "Train Epoch [95/100] Batch [55/782] Loss: 0.4082 | Acc: 84.23%\n",
      "Train Epoch [95/100] Batch [56/782] Loss: 0.4250 | Acc: 84.18%\n",
      "Train Epoch [95/100] Batch [57/782] Loss: 0.4266 | Acc: 84.21%\n",
      "Train Epoch [95/100] Batch [58/782] Loss: 0.3748 | Acc: 84.27%\n",
      "Train Epoch [95/100] Batch [59/782] Loss: 0.3593 | Acc: 84.30%\n",
      "Train Epoch [95/100] Batch [60/782] Loss: 0.3514 | Acc: 84.30%\n",
      "Train Epoch [95/100] Batch [61/782] Loss: 0.2871 | Acc: 84.38%\n",
      "Train Epoch [95/100] Batch [62/782] Loss: 0.4168 | Acc: 84.38%\n",
      "Train Epoch [95/100] Batch [63/782] Loss: 0.3577 | Acc: 84.45%\n",
      "Train Epoch [95/100] Batch [64/782] Loss: 0.5081 | Acc: 84.52%\n",
      "Train Epoch [95/100] Batch [65/782] Loss: 0.3338 | Acc: 84.57%\n",
      "Train Epoch [95/100] Batch [66/782] Loss: 0.5005 | Acc: 84.52%\n",
      "Train Epoch [95/100] Batch [67/782] Loss: 0.5183 | Acc: 84.47%\n",
      "Train Epoch [95/100] Batch [68/782] Loss: 0.4004 | Acc: 84.54%\n",
      "Train Epoch [95/100] Batch [69/782] Loss: 0.3619 | Acc: 84.51%\n",
      "Train Epoch [95/100] Batch [70/782] Loss: 0.2301 | Acc: 84.58%\n",
      "Train Epoch [95/100] Batch [71/782] Loss: 0.2283 | Acc: 84.68%\n",
      "Train Epoch [95/100] Batch [72/782] Loss: 0.3821 | Acc: 84.72%\n",
      "Train Epoch [95/100] Batch [73/782] Loss: 0.3607 | Acc: 84.78%\n",
      "Train Epoch [95/100] Batch [74/782] Loss: 0.5056 | Acc: 84.76%\n",
      "Train Epoch [95/100] Batch [75/782] Loss: 0.3176 | Acc: 84.85%\n",
      "Train Epoch [95/100] Batch [76/782] Loss: 0.3977 | Acc: 84.89%\n",
      "Train Epoch [95/100] Batch [77/782] Loss: 0.4532 | Acc: 84.84%\n",
      "Train Epoch [95/100] Batch [78/782] Loss: 0.3019 | Acc: 84.88%\n",
      "Train Epoch [95/100] Batch [79/782] Loss: 0.2665 | Acc: 84.93%\n",
      "Train Epoch [95/100] Batch [80/782] Loss: 0.4071 | Acc: 84.98%\n",
      "Train Epoch [95/100] Batch [81/782] Loss: 0.4742 | Acc: 84.99%\n",
      "Train Epoch [95/100] Batch [82/782] Loss: 0.4231 | Acc: 84.95%\n",
      "Train Epoch [95/100] Batch [83/782] Loss: 0.4024 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [84/782] Loss: 0.4409 | Acc: 84.97%\n",
      "Train Epoch [95/100] Batch [85/782] Loss: 0.3529 | Acc: 84.94%\n",
      "Train Epoch [95/100] Batch [86/782] Loss: 0.4786 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [87/782] Loss: 0.4460 | Acc: 84.97%\n",
      "Train Epoch [95/100] Batch [88/782] Loss: 0.4662 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [89/782] Loss: 0.4797 | Acc: 84.88%\n",
      "Train Epoch [95/100] Batch [90/782] Loss: 0.2698 | Acc: 84.95%\n",
      "Train Epoch [95/100] Batch [91/782] Loss: 0.3727 | Acc: 84.98%\n",
      "Train Epoch [95/100] Batch [92/782] Loss: 0.3427 | Acc: 85.00%\n",
      "Train Epoch [95/100] Batch [93/782] Loss: 0.4926 | Acc: 84.95%\n",
      "Train Epoch [95/100] Batch [94/782] Loss: 0.4139 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [95/782] Loss: 0.3876 | Acc: 84.98%\n",
      "Train Epoch [95/100] Batch [96/782] Loss: 0.3930 | Acc: 84.99%\n",
      "Train Epoch [95/100] Batch [97/782] Loss: 0.3941 | Acc: 85.00%\n",
      "Train Epoch [95/100] Batch [98/782] Loss: 0.6083 | Acc: 84.90%\n",
      "Train Epoch [95/100] Batch [99/782] Loss: 0.4411 | Acc: 84.94%\n",
      "Train Epoch [95/100] Batch [100/782] Loss: 0.4666 | Acc: 84.92%\n",
      "Train Epoch [95/100] Batch [101/782] Loss: 0.4705 | Acc: 84.90%\n",
      "Train Epoch [95/100] Batch [102/782] Loss: 0.4348 | Acc: 84.90%\n",
      "Train Epoch [95/100] Batch [103/782] Loss: 0.3752 | Acc: 84.86%\n",
      "Train Epoch [95/100] Batch [104/782] Loss: 0.4835 | Acc: 84.83%\n",
      "Train Epoch [95/100] Batch [105/782] Loss: 0.3257 | Acc: 84.85%\n",
      "Train Epoch [95/100] Batch [106/782] Loss: 0.3561 | Acc: 84.89%\n",
      "Train Epoch [95/100] Batch [107/782] Loss: 0.4069 | Acc: 84.89%\n",
      "Train Epoch [95/100] Batch [108/782] Loss: 0.3363 | Acc: 84.92%\n",
      "Train Epoch [95/100] Batch [109/782] Loss: 0.5375 | Acc: 84.91%\n",
      "Train Epoch [95/100] Batch [110/782] Loss: 0.3101 | Acc: 84.93%\n",
      "Train Epoch [95/100] Batch [111/782] Loss: 0.4407 | Acc: 84.90%\n",
      "Train Epoch [95/100] Batch [112/782] Loss: 0.4174 | Acc: 84.89%\n",
      "Train Epoch [95/100] Batch [113/782] Loss: 0.4717 | Acc: 84.87%\n",
      "Train Epoch [95/100] Batch [114/782] Loss: 0.2813 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [115/782] Loss: 0.5975 | Acc: 84.90%\n",
      "Train Epoch [95/100] Batch [116/782] Loss: 0.3278 | Acc: 84.94%\n",
      "Train Epoch [95/100] Batch [117/782] Loss: 0.3583 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [118/782] Loss: 0.3649 | Acc: 84.96%\n",
      "Train Epoch [95/100] Batch [119/782] Loss: 0.3330 | Acc: 85.02%\n",
      "Train Epoch [95/100] Batch [120/782] Loss: 0.5458 | Acc: 84.95%\n",
      "Train Epoch [95/100] Batch [121/782] Loss: 0.4549 | Acc: 84.93%\n",
      "Train Epoch [95/100] Batch [122/782] Loss: 0.2871 | Acc: 84.95%\n",
      "Train Epoch [95/100] Batch [123/782] Loss: 0.3923 | Acc: 84.98%\n",
      "Train Epoch [95/100] Batch [124/782] Loss: 0.4338 | Acc: 84.99%\n",
      "Train Epoch [95/100] Batch [125/782] Loss: 0.4797 | Acc: 84.97%\n",
      "Train Epoch [95/100] Batch [126/782] Loss: 0.2949 | Acc: 85.02%\n",
      "Train Epoch [95/100] Batch [127/782] Loss: 0.3324 | Acc: 85.08%\n",
      "Train Epoch [95/100] Batch [128/782] Loss: 0.3518 | Acc: 85.10%\n",
      "Train Epoch [95/100] Batch [129/782] Loss: 0.3078 | Acc: 85.13%\n",
      "Train Epoch [95/100] Batch [130/782] Loss: 0.4846 | Acc: 85.14%\n",
      "Train Epoch [95/100] Batch [131/782] Loss: 0.5450 | Acc: 85.15%\n",
      "Train Epoch [95/100] Batch [132/782] Loss: 0.4471 | Acc: 85.12%\n",
      "Train Epoch [95/100] Batch [133/782] Loss: 0.3715 | Acc: 85.10%\n",
      "Train Epoch [95/100] Batch [134/782] Loss: 0.3211 | Acc: 85.14%\n",
      "Train Epoch [95/100] Batch [135/782] Loss: 0.4650 | Acc: 85.13%\n",
      "Train Epoch [95/100] Batch [136/782] Loss: 0.4132 | Acc: 85.13%\n",
      "Train Epoch [95/100] Batch [137/782] Loss: 0.4331 | Acc: 85.14%\n",
      "Train Epoch [95/100] Batch [138/782] Loss: 0.4622 | Acc: 85.11%\n",
      "Train Epoch [95/100] Batch [139/782] Loss: 0.5445 | Acc: 85.08%\n",
      "Train Epoch [95/100] Batch [140/782] Loss: 0.4011 | Acc: 85.08%\n",
      "Train Epoch [95/100] Batch [141/782] Loss: 0.3588 | Acc: 85.08%\n",
      "Train Epoch [95/100] Batch [142/782] Loss: 0.4010 | Acc: 85.07%\n",
      "Train Epoch [95/100] Batch [143/782] Loss: 0.2790 | Acc: 85.12%\n",
      "Train Epoch [95/100] Batch [144/782] Loss: 0.3231 | Acc: 85.16%\n",
      "Train Epoch [95/100] Batch [145/782] Loss: 0.5476 | Acc: 85.16%\n",
      "Train Epoch [95/100] Batch [146/782] Loss: 0.4841 | Acc: 85.13%\n",
      "Train Epoch [95/100] Batch [147/782] Loss: 0.2842 | Acc: 85.17%\n",
      "Train Epoch [95/100] Batch [148/782] Loss: 0.3149 | Acc: 85.21%\n",
      "Train Epoch [95/100] Batch [149/782] Loss: 0.4254 | Acc: 85.19%\n",
      "Train Epoch [95/100] Batch [150/782] Loss: 0.5358 | Acc: 85.15%\n",
      "Train Epoch [95/100] Batch [151/782] Loss: 0.4337 | Acc: 85.16%\n",
      "Train Epoch [95/100] Batch [152/782] Loss: 0.3385 | Acc: 85.18%\n",
      "Train Epoch [95/100] Batch [153/782] Loss: 0.4486 | Acc: 85.18%\n",
      "Train Epoch [95/100] Batch [154/782] Loss: 0.3266 | Acc: 85.22%\n",
      "Train Epoch [95/100] Batch [155/782] Loss: 0.3272 | Acc: 85.24%\n",
      "Train Epoch [95/100] Batch [156/782] Loss: 0.4002 | Acc: 85.26%\n",
      "Train Epoch [95/100] Batch [157/782] Loss: 0.4148 | Acc: 85.27%\n",
      "Train Epoch [95/100] Batch [158/782] Loss: 0.1890 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [159/782] Loss: 0.5086 | Acc: 85.31%\n",
      "Train Epoch [95/100] Batch [160/782] Loss: 0.5285 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [161/782] Loss: 0.4212 | Acc: 85.27%\n",
      "Train Epoch [95/100] Batch [162/782] Loss: 0.3845 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [163/782] Loss: 0.5038 | Acc: 85.20%\n",
      "Train Epoch [95/100] Batch [164/782] Loss: 0.4161 | Acc: 85.21%\n",
      "Train Epoch [95/100] Batch [165/782] Loss: 0.3276 | Acc: 85.20%\n",
      "Train Epoch [95/100] Batch [166/782] Loss: 0.4427 | Acc: 85.20%\n",
      "Train Epoch [95/100] Batch [167/782] Loss: 0.4159 | Acc: 85.20%\n",
      "Train Epoch [95/100] Batch [168/782] Loss: 0.4100 | Acc: 85.22%\n",
      "Train Epoch [95/100] Batch [169/782] Loss: 0.2994 | Acc: 85.24%\n",
      "Train Epoch [95/100] Batch [170/782] Loss: 0.2885 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [171/782] Loss: 0.4810 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [172/782] Loss: 0.2587 | Acc: 85.27%\n",
      "Train Epoch [95/100] Batch [173/782] Loss: 0.4785 | Acc: 85.27%\n",
      "Train Epoch [95/100] Batch [174/782] Loss: 0.5497 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [175/782] Loss: 0.4696 | Acc: 85.24%\n",
      "Train Epoch [95/100] Batch [176/782] Loss: 0.3745 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [177/782] Loss: 0.4367 | Acc: 85.24%\n",
      "Train Epoch [95/100] Batch [178/782] Loss: 0.3266 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [179/782] Loss: 0.2739 | Acc: 85.29%\n",
      "Train Epoch [95/100] Batch [180/782] Loss: 0.4733 | Acc: 85.31%\n",
      "Train Epoch [95/100] Batch [181/782] Loss: 0.3985 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [182/782] Loss: 0.3012 | Acc: 85.33%\n",
      "Train Epoch [95/100] Batch [183/782] Loss: 0.3703 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [184/782] Loss: 0.4590 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [185/782] Loss: 0.5961 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [186/782] Loss: 0.3297 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [187/782] Loss: 0.5380 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [188/782] Loss: 0.4200 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [189/782] Loss: 0.3510 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [190/782] Loss: 0.5854 | Acc: 85.25%\n",
      "Train Epoch [95/100] Batch [191/782] Loss: 0.3280 | Acc: 85.27%\n",
      "Train Epoch [95/100] Batch [192/782] Loss: 0.3629 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [193/782] Loss: 0.4705 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [194/782] Loss: 0.4872 | Acc: 85.31%\n",
      "Train Epoch [95/100] Batch [195/782] Loss: 0.4253 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [196/782] Loss: 0.2814 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [197/782] Loss: 0.5919 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [198/782] Loss: 0.3081 | Acc: 85.33%\n",
      "Train Epoch [95/100] Batch [199/782] Loss: 0.4754 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [200/782] Loss: 0.4156 | Acc: 85.33%\n",
      "Train Epoch [95/100] Batch [201/782] Loss: 0.6172 | Acc: 85.29%\n",
      "Train Epoch [95/100] Batch [202/782] Loss: 0.3501 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [203/782] Loss: 0.3793 | Acc: 85.31%\n",
      "Train Epoch [95/100] Batch [204/782] Loss: 0.4570 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [205/782] Loss: 0.4423 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [206/782] Loss: 0.3251 | Acc: 85.32%\n",
      "Train Epoch [95/100] Batch [207/782] Loss: 0.5172 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [208/782] Loss: 0.5329 | Acc: 85.28%\n",
      "Train Epoch [95/100] Batch [209/782] Loss: 0.4082 | Acc: 85.30%\n",
      "Train Epoch [95/100] Batch [210/782] Loss: 0.2332 | Acc: 85.35%\n",
      "Train Epoch [95/100] Batch [211/782] Loss: 0.3370 | Acc: 85.37%\n",
      "Train Epoch [95/100] Batch [212/782] Loss: 0.3428 | Acc: 85.38%\n",
      "Train Epoch [95/100] Batch [213/782] Loss: 0.4120 | Acc: 85.38%\n",
      "Train Epoch [95/100] Batch [214/782] Loss: 0.3117 | Acc: 85.40%\n",
      "Train Epoch [95/100] Batch [215/782] Loss: 0.3885 | Acc: 85.42%\n",
      "Train Epoch [95/100] Batch [216/782] Loss: 0.3583 | Acc: 85.42%\n",
      "Train Epoch [95/100] Batch [217/782] Loss: 0.4061 | Acc: 85.43%\n",
      "Train Epoch [95/100] Batch [218/782] Loss: 0.4403 | Acc: 85.43%\n",
      "Train Epoch [95/100] Batch [219/782] Loss: 0.2709 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [220/782] Loss: 0.4497 | Acc: 85.45%\n",
      "Train Epoch [95/100] Batch [221/782] Loss: 0.3846 | Acc: 85.44%\n",
      "Train Epoch [95/100] Batch [222/782] Loss: 0.3855 | Acc: 85.45%\n",
      "Train Epoch [95/100] Batch [223/782] Loss: 0.3249 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [224/782] Loss: 0.3588 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [225/782] Loss: 0.3639 | Acc: 85.45%\n",
      "Train Epoch [95/100] Batch [226/782] Loss: 0.2829 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [227/782] Loss: 0.4427 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [228/782] Loss: 0.4703 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [229/782] Loss: 0.4400 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [230/782] Loss: 0.4420 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [231/782] Loss: 0.4252 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [232/782] Loss: 0.3339 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [233/782] Loss: 0.3861 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [234/782] Loss: 0.4696 | Acc: 85.44%\n",
      "Train Epoch [95/100] Batch [235/782] Loss: 0.3892 | Acc: 85.45%\n",
      "Train Epoch [95/100] Batch [236/782] Loss: 0.4262 | Acc: 85.44%\n",
      "Train Epoch [95/100] Batch [237/782] Loss: 0.3283 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [238/782] Loss: 0.3999 | Acc: 85.45%\n",
      "Train Epoch [95/100] Batch [239/782] Loss: 0.3942 | Acc: 85.43%\n",
      "Train Epoch [95/100] Batch [240/782] Loss: 0.2103 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [241/782] Loss: 0.3976 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [242/782] Loss: 0.5818 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [243/782] Loss: 0.3385 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [244/782] Loss: 0.3220 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [245/782] Loss: 0.4101 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [246/782] Loss: 0.4580 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [247/782] Loss: 0.6717 | Acc: 85.44%\n",
      "Train Epoch [95/100] Batch [248/782] Loss: 0.3804 | Acc: 85.44%\n",
      "Train Epoch [95/100] Batch [249/782] Loss: 0.2076 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [250/782] Loss: 0.3294 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [251/782] Loss: 0.1565 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [252/782] Loss: 0.4573 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [253/782] Loss: 0.2502 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [254/782] Loss: 0.4603 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [255/782] Loss: 0.3527 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [256/782] Loss: 0.6326 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [257/782] Loss: 0.4860 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [258/782] Loss: 0.2600 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [259/782] Loss: 0.4103 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [260/782] Loss: 0.3935 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [261/782] Loss: 0.3559 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [262/782] Loss: 0.2828 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [263/782] Loss: 0.5626 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [264/782] Loss: 0.2586 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [265/782] Loss: 0.3499 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [266/782] Loss: 0.4464 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [267/782] Loss: 0.4253 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [268/782] Loss: 0.2797 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [269/782] Loss: 0.3777 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [270/782] Loss: 0.3856 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [271/782] Loss: 0.5858 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [272/782] Loss: 0.3491 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [273/782] Loss: 0.4972 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [274/782] Loss: 0.2259 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [275/782] Loss: 0.4865 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [276/782] Loss: 0.4751 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [277/782] Loss: 0.3936 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [278/782] Loss: 0.2236 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [279/782] Loss: 0.2762 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [280/782] Loss: 0.3453 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [281/782] Loss: 0.4055 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [282/782] Loss: 0.4864 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [283/782] Loss: 0.4260 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [284/782] Loss: 0.5827 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [285/782] Loss: 0.4731 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [286/782] Loss: 0.3362 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [287/782] Loss: 0.4907 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [288/782] Loss: 0.3736 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [289/782] Loss: 0.4750 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [290/782] Loss: 0.4364 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [291/782] Loss: 0.3701 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [292/782] Loss: 0.3696 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [293/782] Loss: 0.3042 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [294/782] Loss: 0.3854 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [295/782] Loss: 0.3494 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [296/782] Loss: 0.3008 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [297/782] Loss: 0.3142 | Acc: 85.63%\n",
      "Train Epoch [95/100] Batch [298/782] Loss: 0.5209 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [299/782] Loss: 0.5379 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [300/782] Loss: 0.4417 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [301/782] Loss: 0.4774 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [302/782] Loss: 0.5178 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [303/782] Loss: 0.4335 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [304/782] Loss: 0.2691 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [305/782] Loss: 0.4662 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [306/782] Loss: 0.3839 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [307/782] Loss: 0.4476 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [308/782] Loss: 0.3768 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [309/782] Loss: 0.2852 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [310/782] Loss: 0.4002 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [311/782] Loss: 0.3237 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [312/782] Loss: 0.5603 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [313/782] Loss: 0.3584 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [314/782] Loss: 0.4458 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [315/782] Loss: 0.3465 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [316/782] Loss: 0.3126 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [317/782] Loss: 0.5566 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [318/782] Loss: 0.2496 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [319/782] Loss: 0.4564 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [320/782] Loss: 0.2827 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [321/782] Loss: 0.4232 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [322/782] Loss: 0.4095 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [323/782] Loss: 0.4990 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [324/782] Loss: 0.4436 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [325/782] Loss: 0.4284 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [326/782] Loss: 0.4864 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [327/782] Loss: 0.4560 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [328/782] Loss: 0.2901 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [329/782] Loss: 0.4011 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [330/782] Loss: 0.2353 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [331/782] Loss: 0.3418 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [332/782] Loss: 0.2821 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [333/782] Loss: 0.2728 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [334/782] Loss: 0.3146 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [335/782] Loss: 0.3928 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [336/782] Loss: 0.4395 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [337/782] Loss: 0.4817 | Acc: 85.63%\n",
      "Train Epoch [95/100] Batch [338/782] Loss: 0.3887 | Acc: 85.64%\n",
      "Train Epoch [95/100] Batch [339/782] Loss: 0.4285 | Acc: 85.64%\n",
      "Train Epoch [95/100] Batch [340/782] Loss: 0.4323 | Acc: 85.64%\n",
      "Train Epoch [95/100] Batch [341/782] Loss: 0.4368 | Acc: 85.65%\n",
      "Train Epoch [95/100] Batch [342/782] Loss: 0.4385 | Acc: 85.64%\n",
      "Train Epoch [95/100] Batch [343/782] Loss: 0.4203 | Acc: 85.65%\n",
      "Train Epoch [95/100] Batch [344/782] Loss: 0.3353 | Acc: 85.66%\n",
      "Train Epoch [95/100] Batch [345/782] Loss: 0.4534 | Acc: 85.64%\n",
      "Train Epoch [95/100] Batch [346/782] Loss: 0.5192 | Acc: 85.63%\n",
      "Train Epoch [95/100] Batch [347/782] Loss: 0.3473 | Acc: 85.63%\n",
      "Train Epoch [95/100] Batch [348/782] Loss: 0.5037 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [349/782] Loss: 0.5897 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [350/782] Loss: 0.3348 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [351/782] Loss: 0.3182 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [352/782] Loss: 0.3382 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [353/782] Loss: 0.4069 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [354/782] Loss: 0.4232 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [355/782] Loss: 0.3016 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [356/782] Loss: 0.3637 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [357/782] Loss: 0.2636 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [358/782] Loss: 0.3620 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [359/782] Loss: 0.5454 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [360/782] Loss: 0.3486 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [361/782] Loss: 0.3603 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [362/782] Loss: 0.3419 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [363/782] Loss: 0.4083 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [364/782] Loss: 0.5127 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [365/782] Loss: 0.3617 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [366/782] Loss: 0.3279 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [367/782] Loss: 0.4452 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [368/782] Loss: 0.5274 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [369/782] Loss: 0.4714 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [370/782] Loss: 0.5065 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [371/782] Loss: 0.4701 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [372/782] Loss: 0.3864 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [373/782] Loss: 0.3638 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [374/782] Loss: 0.2232 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [375/782] Loss: 0.2790 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [376/782] Loss: 0.3220 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [377/782] Loss: 0.4302 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [378/782] Loss: 0.3340 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [379/782] Loss: 0.4032 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [380/782] Loss: 0.5526 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [381/782] Loss: 0.4412 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [382/782] Loss: 0.3726 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [383/782] Loss: 0.2706 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [384/782] Loss: 0.2500 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [385/782] Loss: 0.3936 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [386/782] Loss: 0.2405 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [387/782] Loss: 0.4163 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [388/782] Loss: 0.5333 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [389/782] Loss: 0.4979 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [390/782] Loss: 0.3058 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [391/782] Loss: 0.4713 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [392/782] Loss: 0.2788 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [393/782] Loss: 0.2938 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [394/782] Loss: 0.4885 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [395/782] Loss: 0.3253 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [396/782] Loss: 0.5470 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [397/782] Loss: 0.3234 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [398/782] Loss: 0.5798 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [399/782] Loss: 0.4901 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [400/782] Loss: 0.5725 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [401/782] Loss: 0.4824 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [402/782] Loss: 0.7044 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [403/782] Loss: 0.3448 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [404/782] Loss: 0.5006 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [405/782] Loss: 0.3291 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [406/782] Loss: 0.4618 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [407/782] Loss: 0.4217 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [408/782] Loss: 0.3293 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [409/782] Loss: 0.3467 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [410/782] Loss: 0.2930 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [411/782] Loss: 0.4698 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [412/782] Loss: 0.3084 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [413/782] Loss: 0.3511 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [414/782] Loss: 0.4147 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [415/782] Loss: 0.4244 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [416/782] Loss: 0.3845 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [417/782] Loss: 0.5828 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [418/782] Loss: 0.5876 | Acc: 85.46%\n",
      "Train Epoch [95/100] Batch [419/782] Loss: 0.3227 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [420/782] Loss: 0.4348 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [421/782] Loss: 0.3585 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [422/782] Loss: 0.2054 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [423/782] Loss: 0.3711 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [424/782] Loss: 0.3259 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [425/782] Loss: 0.2600 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [426/782] Loss: 0.4753 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [427/782] Loss: 0.4968 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [428/782] Loss: 0.3891 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [429/782] Loss: 0.3826 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [430/782] Loss: 0.2585 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [431/782] Loss: 0.7178 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [432/782] Loss: 0.3303 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [433/782] Loss: 0.3591 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [434/782] Loss: 0.4582 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [435/782] Loss: 0.4655 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [436/782] Loss: 0.3006 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [437/782] Loss: 0.3468 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [438/782] Loss: 0.3097 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [439/782] Loss: 0.2866 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [440/782] Loss: 0.3774 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [441/782] Loss: 0.3974 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [442/782] Loss: 0.5322 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [443/782] Loss: 0.3768 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [444/782] Loss: 0.4937 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [445/782] Loss: 0.3891 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [446/782] Loss: 0.5011 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [447/782] Loss: 0.3641 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [448/782] Loss: 0.4489 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [449/782] Loss: 0.3184 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [450/782] Loss: 0.2865 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [451/782] Loss: 0.3572 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [452/782] Loss: 0.4338 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [453/782] Loss: 0.2643 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [454/782] Loss: 0.4121 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [455/782] Loss: 0.4559 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [456/782] Loss: 0.4403 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [457/782] Loss: 0.2318 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [458/782] Loss: 0.2764 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [459/782] Loss: 0.2987 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [460/782] Loss: 0.2506 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [461/782] Loss: 0.4474 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [462/782] Loss: 0.4280 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [463/782] Loss: 0.3604 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [464/782] Loss: 0.4075 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [465/782] Loss: 0.3949 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [466/782] Loss: 0.3668 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [467/782] Loss: 0.4430 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [468/782] Loss: 0.3719 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [469/782] Loss: 0.3496 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [470/782] Loss: 0.3979 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [471/782] Loss: 0.3391 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [472/782] Loss: 0.3604 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [473/782] Loss: 0.6857 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [474/782] Loss: 0.5141 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [475/782] Loss: 0.3045 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [476/782] Loss: 0.3366 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [477/782] Loss: 0.2721 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [478/782] Loss: 0.3216 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [479/782] Loss: 0.4699 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [480/782] Loss: 0.5037 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [481/782] Loss: 0.4405 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [482/782] Loss: 0.3379 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [483/782] Loss: 0.4031 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [484/782] Loss: 0.3337 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [485/782] Loss: 0.5621 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [486/782] Loss: 0.3970 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [487/782] Loss: 0.5057 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [488/782] Loss: 0.3861 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [489/782] Loss: 0.4466 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [490/782] Loss: 0.4329 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [491/782] Loss: 0.4802 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [492/782] Loss: 0.2642 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [493/782] Loss: 0.4333 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [494/782] Loss: 0.4328 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [495/782] Loss: 0.3848 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [496/782] Loss: 0.4273 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [497/782] Loss: 0.4279 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [498/782] Loss: 0.5642 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [499/782] Loss: 0.4337 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [500/782] Loss: 0.3786 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [501/782] Loss: 0.2957 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [502/782] Loss: 0.4614 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [503/782] Loss: 0.3108 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [504/782] Loss: 0.4049 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [505/782] Loss: 0.5334 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [506/782] Loss: 0.5157 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [507/782] Loss: 0.4329 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [508/782] Loss: 0.4193 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [509/782] Loss: 0.3302 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [510/782] Loss: 0.4254 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [511/782] Loss: 0.3930 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [512/782] Loss: 0.4210 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [513/782] Loss: 0.4203 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [514/782] Loss: 0.5328 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [515/782] Loss: 0.2985 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [516/782] Loss: 0.2880 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [517/782] Loss: 0.6157 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [518/782] Loss: 0.3221 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [519/782] Loss: 0.3182 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [520/782] Loss: 0.4993 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [521/782] Loss: 0.4391 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [522/782] Loss: 0.3168 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [523/782] Loss: 0.3909 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [524/782] Loss: 0.3515 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [525/782] Loss: 0.4412 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [526/782] Loss: 0.5533 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [527/782] Loss: 0.2526 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [528/782] Loss: 0.4309 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [529/782] Loss: 0.3931 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [530/782] Loss: 0.2787 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [531/782] Loss: 0.3596 | Acc: 85.52%\n",
      "Train Epoch [95/100] Batch [532/782] Loss: 0.4569 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [533/782] Loss: 0.3638 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [534/782] Loss: 0.4805 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [535/782] Loss: 0.5148 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [536/782] Loss: 0.6014 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [537/782] Loss: 0.4899 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [538/782] Loss: 0.4110 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [539/782] Loss: 0.3411 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [540/782] Loss: 0.3420 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [541/782] Loss: 0.5887 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [542/782] Loss: 0.3274 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [543/782] Loss: 0.4124 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [544/782] Loss: 0.4778 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [545/782] Loss: 0.3787 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [546/782] Loss: 0.4922 | Acc: 85.47%\n",
      "Train Epoch [95/100] Batch [547/782] Loss: 0.2344 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [548/782] Loss: 0.3589 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [549/782] Loss: 0.3905 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [550/782] Loss: 0.4172 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [551/782] Loss: 0.3717 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [552/782] Loss: 0.3758 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [553/782] Loss: 0.6452 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [554/782] Loss: 0.2788 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [555/782] Loss: 0.4139 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [556/782] Loss: 0.3624 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [557/782] Loss: 0.4608 | Acc: 85.48%\n",
      "Train Epoch [95/100] Batch [558/782] Loss: 0.1845 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [559/782] Loss: 0.4877 | Acc: 85.49%\n",
      "Train Epoch [95/100] Batch [560/782] Loss: 0.3927 | Acc: 85.50%\n",
      "Train Epoch [95/100] Batch [561/782] Loss: 0.3372 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [562/782] Loss: 0.3195 | Acc: 85.51%\n",
      "Train Epoch [95/100] Batch [563/782] Loss: 0.3045 | Acc: 85.53%\n",
      "Train Epoch [95/100] Batch [564/782] Loss: 0.2585 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [565/782] Loss: 0.3212 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [566/782] Loss: 0.4733 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [567/782] Loss: 0.3142 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [568/782] Loss: 0.2895 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [569/782] Loss: 0.1962 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [570/782] Loss: 0.4612 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [571/782] Loss: 0.3422 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [572/782] Loss: 0.4148 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [573/782] Loss: 0.3650 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [574/782] Loss: 0.3284 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [575/782] Loss: 0.3577 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [576/782] Loss: 0.3959 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [577/782] Loss: 0.3275 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [578/782] Loss: 0.3958 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [579/782] Loss: 0.4467 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [580/782] Loss: 0.5611 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [581/782] Loss: 0.4966 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [582/782] Loss: 0.3612 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [583/782] Loss: 0.3219 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [584/782] Loss: 0.5676 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [585/782] Loss: 0.2610 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [586/782] Loss: 0.3540 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [587/782] Loss: 0.6046 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [588/782] Loss: 0.2984 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [589/782] Loss: 0.4601 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [590/782] Loss: 0.2956 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [591/782] Loss: 0.3106 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [592/782] Loss: 0.4305 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [593/782] Loss: 0.3801 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [594/782] Loss: 0.3913 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [595/782] Loss: 0.4311 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [596/782] Loss: 0.4881 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [597/782] Loss: 0.3709 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [598/782] Loss: 0.3821 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [599/782] Loss: 0.5172 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [600/782] Loss: 0.3032 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [601/782] Loss: 0.3736 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [602/782] Loss: 0.5057 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [603/782] Loss: 0.3534 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [604/782] Loss: 0.3795 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [605/782] Loss: 0.5604 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [606/782] Loss: 0.3699 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [607/782] Loss: 0.3211 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [608/782] Loss: 0.5237 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [609/782] Loss: 0.2719 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [610/782] Loss: 0.3647 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [611/782] Loss: 0.2952 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [612/782] Loss: 0.4078 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [613/782] Loss: 0.4180 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [614/782] Loss: 0.2870 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [615/782] Loss: 0.3076 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [616/782] Loss: 0.2845 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [617/782] Loss: 0.3538 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [618/782] Loss: 0.4442 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [619/782] Loss: 0.3978 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [620/782] Loss: 0.4485 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [621/782] Loss: 0.4043 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [622/782] Loss: 0.3728 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [623/782] Loss: 0.3767 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [624/782] Loss: 0.4605 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [625/782] Loss: 0.3355 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [626/782] Loss: 0.3742 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [627/782] Loss: 0.2991 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [628/782] Loss: 0.3775 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [629/782] Loss: 0.3865 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [630/782] Loss: 0.4884 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [631/782] Loss: 0.4660 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [632/782] Loss: 0.4166 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [633/782] Loss: 0.3897 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [634/782] Loss: 0.3713 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [635/782] Loss: 0.3311 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [636/782] Loss: 0.5208 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [637/782] Loss: 0.6162 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [638/782] Loss: 0.3558 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [639/782] Loss: 0.2881 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [640/782] Loss: 0.1682 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [641/782] Loss: 0.5659 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [642/782] Loss: 0.4378 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [643/782] Loss: 0.5290 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [644/782] Loss: 0.3693 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [645/782] Loss: 0.3849 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [646/782] Loss: 0.3343 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [647/782] Loss: 0.3345 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [648/782] Loss: 0.4084 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [649/782] Loss: 0.4416 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [650/782] Loss: 0.4265 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [651/782] Loss: 0.4390 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [652/782] Loss: 0.5954 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [653/782] Loss: 0.3948 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [654/782] Loss: 0.7047 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [655/782] Loss: 0.2364 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [656/782] Loss: 0.4023 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [657/782] Loss: 0.3365 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [658/782] Loss: 0.4358 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [659/782] Loss: 0.5245 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [660/782] Loss: 0.4087 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [661/782] Loss: 0.5639 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [662/782] Loss: 0.2754 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [663/782] Loss: 0.5519 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [664/782] Loss: 0.2927 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [665/782] Loss: 0.4145 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [666/782] Loss: 0.3796 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [667/782] Loss: 0.3998 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [668/782] Loss: 0.5247 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [669/782] Loss: 0.4580 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [670/782] Loss: 0.4552 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [671/782] Loss: 0.3986 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [672/782] Loss: 0.4884 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [673/782] Loss: 0.2846 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [674/782] Loss: 0.3179 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [675/782] Loss: 0.4276 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [676/782] Loss: 0.5843 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [677/782] Loss: 0.3866 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [678/782] Loss: 0.3033 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [679/782] Loss: 0.3739 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [680/782] Loss: 0.2410 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [681/782] Loss: 0.4568 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [682/782] Loss: 0.5296 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [683/782] Loss: 0.4461 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [684/782] Loss: 0.3122 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [685/782] Loss: 0.5390 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [686/782] Loss: 0.4415 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [687/782] Loss: 0.3459 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [688/782] Loss: 0.4365 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [689/782] Loss: 0.2829 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [690/782] Loss: 0.4437 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [691/782] Loss: 0.5163 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [692/782] Loss: 0.3256 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [693/782] Loss: 0.3596 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [694/782] Loss: 0.6526 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [695/782] Loss: 0.2686 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [696/782] Loss: 0.5015 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [697/782] Loss: 0.4875 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [698/782] Loss: 0.3769 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [699/782] Loss: 0.4823 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [700/782] Loss: 0.2986 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [701/782] Loss: 0.3548 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [702/782] Loss: 0.1783 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [703/782] Loss: 0.3893 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [704/782] Loss: 0.4098 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [705/782] Loss: 0.4511 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [706/782] Loss: 0.3963 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [707/782] Loss: 0.5639 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [708/782] Loss: 0.3877 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [709/782] Loss: 0.3970 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [710/782] Loss: 0.3761 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [711/782] Loss: 0.3020 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [712/782] Loss: 0.4404 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [713/782] Loss: 0.2924 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [714/782] Loss: 0.3189 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [715/782] Loss: 0.4135 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [716/782] Loss: 0.4415 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [717/782] Loss: 0.2494 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [718/782] Loss: 0.4399 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [719/782] Loss: 0.4225 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [720/782] Loss: 0.4456 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [721/782] Loss: 0.4679 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [722/782] Loss: 0.3982 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [723/782] Loss: 0.3738 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [724/782] Loss: 0.7189 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [725/782] Loss: 0.3383 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [726/782] Loss: 0.2745 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [727/782] Loss: 0.5241 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [728/782] Loss: 0.4407 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [729/782] Loss: 0.4091 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [730/782] Loss: 0.3476 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [731/782] Loss: 0.6346 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [732/782] Loss: 0.3647 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [733/782] Loss: 0.5616 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [734/782] Loss: 0.3329 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [735/782] Loss: 0.4702 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [736/782] Loss: 0.3701 | Acc: 85.54%\n",
      "Train Epoch [95/100] Batch [737/782] Loss: 0.3424 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [738/782] Loss: 0.3069 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [739/782] Loss: 0.5030 | Acc: 85.55%\n",
      "Train Epoch [95/100] Batch [740/782] Loss: 0.4355 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [741/782] Loss: 0.3354 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [742/782] Loss: 0.2789 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [743/782] Loss: 0.3527 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [744/782] Loss: 0.3889 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [745/782] Loss: 0.2731 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [746/782] Loss: 0.3463 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [747/782] Loss: 0.4117 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [748/782] Loss: 0.5168 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [749/782] Loss: 0.5243 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [750/782] Loss: 0.3834 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [751/782] Loss: 0.3917 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [752/782] Loss: 0.4826 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [753/782] Loss: 0.5171 | Acc: 85.56%\n",
      "Train Epoch [95/100] Batch [754/782] Loss: 0.3853 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [755/782] Loss: 0.4898 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [756/782] Loss: 0.4246 | Acc: 85.57%\n",
      "Train Epoch [95/100] Batch [757/782] Loss: 0.1839 | Acc: 85.58%\n",
      "Train Epoch [95/100] Batch [758/782] Loss: 0.2661 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [759/782] Loss: 0.4302 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [760/782] Loss: 0.3996 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [761/782] Loss: 0.3752 | Acc: 85.59%\n",
      "Train Epoch [95/100] Batch [762/782] Loss: 0.2429 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [763/782] Loss: 0.4064 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [764/782] Loss: 0.5194 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [765/782] Loss: 0.4061 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [766/782] Loss: 0.3954 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [767/782] Loss: 0.2132 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [768/782] Loss: 0.2087 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [769/782] Loss: 0.4181 | Acc: 85.62%\n",
      "Train Epoch [95/100] Batch [770/782] Loss: 0.5321 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [771/782] Loss: 0.3268 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [772/782] Loss: 0.4664 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [773/782] Loss: 0.4884 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [774/782] Loss: 0.3896 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [775/782] Loss: 0.4471 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [776/782] Loss: 0.3512 | Acc: 85.60%\n",
      "Train Epoch [95/100] Batch [777/782] Loss: 0.2378 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [778/782] Loss: 0.4887 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [779/782] Loss: 0.2403 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [780/782] Loss: 0.3949 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [781/782] Loss: 0.4767 | Acc: 85.61%\n",
      "Train Epoch [95/100] Batch [782/782] Loss: 0.5181 | Acc: 85.61%\n",
      "Epoch 95 completed in 29.67s.\n",
      "Test Epoch [95/100] Loss: 1.0247 | Acc: 72.08% | Inference Time: 8.95s\n",
      "Epoch 95 results saved to CSV.\n",
      "Epoch 96/100\n",
      "Train Epoch [96/100] Batch [1/782] Loss: 0.3210 | Acc: 85.94%\n",
      "Train Epoch [96/100] Batch [2/782] Loss: 0.4718 | Acc: 84.38%\n",
      "Train Epoch [96/100] Batch [3/782] Loss: 0.3995 | Acc: 84.90%\n",
      "Train Epoch [96/100] Batch [4/782] Loss: 0.3747 | Acc: 84.77%\n",
      "Train Epoch [96/100] Batch [5/782] Loss: 0.3492 | Acc: 85.00%\n",
      "Train Epoch [96/100] Batch [6/782] Loss: 0.5175 | Acc: 84.11%\n",
      "Train Epoch [96/100] Batch [7/782] Loss: 0.4939 | Acc: 83.93%\n",
      "Train Epoch [96/100] Batch [8/782] Loss: 0.2015 | Acc: 85.35%\n",
      "Train Epoch [96/100] Batch [9/782] Loss: 0.5404 | Acc: 85.07%\n",
      "Train Epoch [96/100] Batch [10/782] Loss: 0.4136 | Acc: 85.00%\n",
      "Train Epoch [96/100] Batch [11/782] Loss: 0.3886 | Acc: 85.09%\n",
      "Train Epoch [96/100] Batch [12/782] Loss: 0.3891 | Acc: 85.16%\n",
      "Train Epoch [96/100] Batch [13/782] Loss: 0.4442 | Acc: 84.74%\n",
      "Train Epoch [96/100] Batch [14/782] Loss: 0.4576 | Acc: 84.49%\n",
      "Train Epoch [96/100] Batch [15/782] Loss: 0.5016 | Acc: 84.17%\n",
      "Train Epoch [96/100] Batch [16/782] Loss: 0.3086 | Acc: 84.38%\n",
      "Train Epoch [96/100] Batch [17/782] Loss: 0.3442 | Acc: 84.19%\n",
      "Train Epoch [96/100] Batch [18/782] Loss: 0.3006 | Acc: 84.55%\n",
      "Train Epoch [96/100] Batch [19/782] Loss: 0.2846 | Acc: 84.87%\n",
      "Train Epoch [96/100] Batch [20/782] Loss: 0.2743 | Acc: 85.16%\n",
      "Train Epoch [96/100] Batch [21/782] Loss: 0.4303 | Acc: 85.19%\n",
      "Train Epoch [96/100] Batch [22/782] Loss: 0.3998 | Acc: 85.23%\n",
      "Train Epoch [96/100] Batch [23/782] Loss: 0.3099 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [24/782] Loss: 0.5924 | Acc: 85.29%\n",
      "Train Epoch [96/100] Batch [25/782] Loss: 0.4213 | Acc: 85.31%\n",
      "Train Epoch [96/100] Batch [26/782] Loss: 0.2212 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [27/782] Loss: 0.4145 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [28/782] Loss: 0.3257 | Acc: 85.49%\n",
      "Train Epoch [96/100] Batch [29/782] Loss: 0.4438 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [30/782] Loss: 0.4209 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [31/782] Loss: 0.3006 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [32/782] Loss: 0.3237 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [33/782] Loss: 0.3566 | Acc: 85.51%\n",
      "Train Epoch [96/100] Batch [34/782] Loss: 0.3298 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [35/782] Loss: 0.3190 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [36/782] Loss: 0.4596 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [37/782] Loss: 0.4995 | Acc: 85.52%\n",
      "Train Epoch [96/100] Batch [38/782] Loss: 0.2503 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [39/782] Loss: 0.5517 | Acc: 85.54%\n",
      "Train Epoch [96/100] Batch [40/782] Loss: 0.4958 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [41/782] Loss: 0.3713 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [42/782] Loss: 0.5713 | Acc: 85.53%\n",
      "Train Epoch [96/100] Batch [43/782] Loss: 0.4187 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [44/782] Loss: 0.3123 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [45/782] Loss: 0.4530 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [46/782] Loss: 0.4081 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [47/782] Loss: 0.5060 | Acc: 85.27%\n",
      "Train Epoch [96/100] Batch [48/782] Loss: 0.2551 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [49/782] Loss: 0.4768 | Acc: 85.33%\n",
      "Train Epoch [96/100] Batch [50/782] Loss: 0.4248 | Acc: 85.34%\n",
      "Train Epoch [96/100] Batch [51/782] Loss: 0.3393 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [52/782] Loss: 0.4415 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [53/782] Loss: 0.5484 | Acc: 85.32%\n",
      "Train Epoch [96/100] Batch [54/782] Loss: 0.3897 | Acc: 85.21%\n",
      "Train Epoch [96/100] Batch [55/782] Loss: 0.4509 | Acc: 85.23%\n",
      "Train Epoch [96/100] Batch [56/782] Loss: 0.4692 | Acc: 85.18%\n",
      "Train Epoch [96/100] Batch [57/782] Loss: 0.4516 | Acc: 85.09%\n",
      "Train Epoch [96/100] Batch [58/782] Loss: 0.4384 | Acc: 85.10%\n",
      "Train Epoch [96/100] Batch [59/782] Loss: 0.3202 | Acc: 85.17%\n",
      "Train Epoch [96/100] Batch [60/782] Loss: 0.2662 | Acc: 85.29%\n",
      "Train Epoch [96/100] Batch [61/782] Loss: 0.4022 | Acc: 85.32%\n",
      "Train Epoch [96/100] Batch [62/782] Loss: 0.2449 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [63/782] Loss: 0.3413 | Acc: 85.52%\n",
      "Train Epoch [96/100] Batch [64/782] Loss: 0.3656 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [65/782] Loss: 0.4787 | Acc: 85.48%\n",
      "Train Epoch [96/100] Batch [66/782] Loss: 0.2128 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [67/782] Loss: 0.5685 | Acc: 85.61%\n",
      "Train Epoch [96/100] Batch [68/782] Loss: 0.5624 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [69/782] Loss: 0.3292 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [70/782] Loss: 0.3600 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [71/782] Loss: 0.4570 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [72/782] Loss: 0.3364 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [73/782] Loss: 0.4556 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [74/782] Loss: 0.4226 | Acc: 85.60%\n",
      "Train Epoch [96/100] Batch [75/782] Loss: 0.4888 | Acc: 85.48%\n",
      "Train Epoch [96/100] Batch [76/782] Loss: 0.6137 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [77/782] Loss: 0.3929 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [78/782] Loss: 0.3048 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [79/782] Loss: 0.5762 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [80/782] Loss: 0.2733 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [81/782] Loss: 0.4312 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [82/782] Loss: 0.2784 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [83/782] Loss: 0.4109 | Acc: 85.52%\n",
      "Train Epoch [96/100] Batch [84/782] Loss: 0.3030 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [85/782] Loss: 0.2678 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [86/782] Loss: 0.4282 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [87/782] Loss: 0.6206 | Acc: 85.51%\n",
      "Train Epoch [96/100] Batch [88/782] Loss: 0.3680 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [89/782] Loss: 0.5679 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [90/782] Loss: 0.3425 | Acc: 85.52%\n",
      "Train Epoch [96/100] Batch [91/782] Loss: 0.2757 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [92/782] Loss: 0.3641 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [93/782] Loss: 0.3129 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [94/782] Loss: 0.4812 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [95/782] Loss: 0.3848 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [96/782] Loss: 0.3394 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [97/782] Loss: 0.4266 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [98/782] Loss: 0.5631 | Acc: 85.54%\n",
      "Train Epoch [96/100] Batch [99/782] Loss: 0.3951 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [100/782] Loss: 0.4458 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [101/782] Loss: 0.4732 | Acc: 85.54%\n",
      "Train Epoch [96/100] Batch [102/782] Loss: 0.5329 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [103/782] Loss: 0.1175 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [104/782] Loss: 0.3373 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [105/782] Loss: 0.2927 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [106/782] Loss: 0.2241 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [107/782] Loss: 0.2459 | Acc: 85.84%\n",
      "Train Epoch [96/100] Batch [108/782] Loss: 0.5834 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [109/782] Loss: 0.5230 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [110/782] Loss: 0.3751 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [111/782] Loss: 0.3484 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [112/782] Loss: 0.3882 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [113/782] Loss: 0.5367 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [114/782] Loss: 0.3020 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [115/782] Loss: 0.3472 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [116/782] Loss: 0.6314 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [117/782] Loss: 0.4173 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [118/782] Loss: 0.3247 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [119/782] Loss: 0.3457 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [120/782] Loss: 0.2237 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [121/782] Loss: 0.2432 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [122/782] Loss: 0.5018 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [123/782] Loss: 0.5827 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [124/782] Loss: 0.3594 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [125/782] Loss: 0.3287 | Acc: 85.65%\n",
      "Train Epoch [96/100] Batch [126/782] Loss: 0.4477 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [127/782] Loss: 0.3383 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [128/782] Loss: 0.4022 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [129/782] Loss: 0.2457 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [130/782] Loss: 0.2668 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [131/782] Loss: 0.2967 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [132/782] Loss: 0.2277 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [133/782] Loss: 0.2479 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [134/782] Loss: 0.3274 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [135/782] Loss: 0.6428 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [136/782] Loss: 0.4186 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [137/782] Loss: 0.4531 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [138/782] Loss: 0.4379 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [139/782] Loss: 0.3971 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [140/782] Loss: 0.5568 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [141/782] Loss: 0.3761 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [142/782] Loss: 0.2273 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [143/782] Loss: 0.4653 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [144/782] Loss: 0.3553 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [145/782] Loss: 0.2917 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [146/782] Loss: 0.4352 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [147/782] Loss: 0.3075 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [148/782] Loss: 0.3622 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [149/782] Loss: 0.6586 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [150/782] Loss: 0.4528 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [151/782] Loss: 0.3778 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [152/782] Loss: 0.2575 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [153/782] Loss: 0.3990 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [154/782] Loss: 0.4842 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [155/782] Loss: 0.3339 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [156/782] Loss: 0.3368 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [157/782] Loss: 0.3622 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [158/782] Loss: 0.3533 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [159/782] Loss: 0.4893 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [160/782] Loss: 0.5319 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [161/782] Loss: 0.3880 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [162/782] Loss: 0.3181 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [163/782] Loss: 0.5193 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [164/782] Loss: 0.3129 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [165/782] Loss: 0.4314 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [166/782] Loss: 0.3077 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [167/782] Loss: 0.4164 | Acc: 85.82%\n",
      "Train Epoch [96/100] Batch [168/782] Loss: 0.4487 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [169/782] Loss: 0.5508 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [170/782] Loss: 0.3660 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [171/782] Loss: 0.3538 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [172/782] Loss: 0.3348 | Acc: 85.84%\n",
      "Train Epoch [96/100] Batch [173/782] Loss: 0.4825 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [174/782] Loss: 0.3031 | Acc: 85.84%\n",
      "Train Epoch [96/100] Batch [175/782] Loss: 0.5554 | Acc: 85.84%\n",
      "Train Epoch [96/100] Batch [176/782] Loss: 0.4893 | Acc: 85.82%\n",
      "Train Epoch [96/100] Batch [177/782] Loss: 0.3989 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [178/782] Loss: 0.3566 | Acc: 85.86%\n",
      "Train Epoch [96/100] Batch [179/782] Loss: 0.4411 | Acc: 85.86%\n",
      "Train Epoch [96/100] Batch [180/782] Loss: 0.3595 | Acc: 85.86%\n",
      "Train Epoch [96/100] Batch [181/782] Loss: 0.3704 | Acc: 85.85%\n",
      "Train Epoch [96/100] Batch [182/782] Loss: 0.3991 | Acc: 85.86%\n",
      "Train Epoch [96/100] Batch [183/782] Loss: 0.5280 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [184/782] Loss: 0.3901 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [185/782] Loss: 0.4135 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [186/782] Loss: 0.5704 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [187/782] Loss: 0.4456 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [188/782] Loss: 0.4722 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [189/782] Loss: 0.2426 | Acc: 85.83%\n",
      "Train Epoch [96/100] Batch [190/782] Loss: 0.5661 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [191/782] Loss: 0.4198 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [192/782] Loss: 0.2904 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [193/782] Loss: 0.4892 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [194/782] Loss: 0.3496 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [195/782] Loss: 0.3283 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [196/782] Loss: 0.4164 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [197/782] Loss: 0.4776 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [198/782] Loss: 0.4025 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [199/782] Loss: 0.4668 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [200/782] Loss: 0.3467 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [201/782] Loss: 0.5348 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [202/782] Loss: 0.4293 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [203/782] Loss: 0.3004 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [204/782] Loss: 0.4497 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [205/782] Loss: 0.3482 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [206/782] Loss: 0.4876 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [207/782] Loss: 0.5283 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [208/782] Loss: 0.5816 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [209/782] Loss: 0.3339 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [210/782] Loss: 0.4739 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [211/782] Loss: 0.3150 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [212/782] Loss: 0.3565 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [213/782] Loss: 0.4016 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [214/782] Loss: 0.5909 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [215/782] Loss: 0.3903 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [216/782] Loss: 0.4730 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [217/782] Loss: 0.3936 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [218/782] Loss: 0.5348 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [219/782] Loss: 0.3831 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [220/782] Loss: 0.2496 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [221/782] Loss: 0.3034 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [222/782] Loss: 0.4136 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [223/782] Loss: 0.4761 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [224/782] Loss: 0.2596 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [225/782] Loss: 0.4922 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [226/782] Loss: 0.8342 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [227/782] Loss: 0.3788 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [228/782] Loss: 0.4019 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [229/782] Loss: 0.4760 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [230/782] Loss: 0.3124 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [231/782] Loss: 0.2180 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [232/782] Loss: 0.2780 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [233/782] Loss: 0.4151 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [234/782] Loss: 0.4787 | Acc: 85.65%\n",
      "Train Epoch [96/100] Batch [235/782] Loss: 0.6125 | Acc: 85.61%\n",
      "Train Epoch [96/100] Batch [236/782] Loss: 0.5603 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [237/782] Loss: 0.2808 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [238/782] Loss: 0.4190 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [239/782] Loss: 0.2538 | Acc: 85.65%\n",
      "Train Epoch [96/100] Batch [240/782] Loss: 0.4113 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [241/782] Loss: 0.2261 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [242/782] Loss: 0.2613 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [243/782] Loss: 0.4091 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [244/782] Loss: 0.4898 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [245/782] Loss: 0.3787 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [246/782] Loss: 0.3188 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [247/782] Loss: 0.3637 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [248/782] Loss: 0.4073 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [249/782] Loss: 0.3495 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [250/782] Loss: 0.4196 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [251/782] Loss: 0.2280 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [252/782] Loss: 0.3448 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [253/782] Loss: 0.5326 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [254/782] Loss: 0.3021 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [255/782] Loss: 0.3283 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [256/782] Loss: 0.3856 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [257/782] Loss: 0.4092 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [258/782] Loss: 0.3790 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [259/782] Loss: 0.3668 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [260/782] Loss: 0.4605 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [261/782] Loss: 0.5411 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [262/782] Loss: 0.3062 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [263/782] Loss: 0.4824 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [264/782] Loss: 0.2472 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [265/782] Loss: 0.3886 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [266/782] Loss: 0.5601 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [267/782] Loss: 0.3945 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [268/782] Loss: 0.3986 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [269/782] Loss: 0.3051 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [270/782] Loss: 0.3533 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [271/782] Loss: 0.3901 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [272/782] Loss: 0.2708 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [273/782] Loss: 0.3305 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [274/782] Loss: 0.4225 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [275/782] Loss: 0.4167 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [276/782] Loss: 0.3688 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [277/782] Loss: 0.3605 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [278/782] Loss: 0.5057 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [279/782] Loss: 0.3479 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [280/782] Loss: 0.3054 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [281/782] Loss: 0.3401 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [282/782] Loss: 0.3817 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [283/782] Loss: 0.4846 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [284/782] Loss: 0.5363 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [285/782] Loss: 0.4840 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [286/782] Loss: 0.4516 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [287/782] Loss: 0.2751 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [288/782] Loss: 0.2623 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [289/782] Loss: 0.2516 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [290/782] Loss: 0.3295 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [291/782] Loss: 0.2835 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [292/782] Loss: 0.4043 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [293/782] Loss: 0.4157 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [294/782] Loss: 0.2180 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [295/782] Loss: 0.5033 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [296/782] Loss: 0.4322 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [297/782] Loss: 0.4681 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [298/782] Loss: 0.5077 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [299/782] Loss: 0.4992 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [300/782] Loss: 0.2601 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [301/782] Loss: 0.5229 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [302/782] Loss: 0.1966 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [303/782] Loss: 0.3415 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [304/782] Loss: 0.3687 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [305/782] Loss: 0.4135 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [306/782] Loss: 0.5036 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [307/782] Loss: 0.2977 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [308/782] Loss: 0.3738 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [309/782] Loss: 0.2958 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [310/782] Loss: 0.3714 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [311/782] Loss: 0.3551 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [312/782] Loss: 0.4716 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [313/782] Loss: 0.3466 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [314/782] Loss: 0.4418 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [315/782] Loss: 0.3044 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [316/782] Loss: 0.3582 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [317/782] Loss: 0.3529 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [318/782] Loss: 0.3872 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [319/782] Loss: 0.3869 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [320/782] Loss: 0.4636 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [321/782] Loss: 0.3368 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [322/782] Loss: 0.2864 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [323/782] Loss: 0.4433 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [324/782] Loss: 0.4345 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [325/782] Loss: 0.4848 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [326/782] Loss: 0.4128 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [327/782] Loss: 0.3710 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [328/782] Loss: 0.4635 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [329/782] Loss: 0.4014 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [330/782] Loss: 0.5282 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [331/782] Loss: 0.3230 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [332/782] Loss: 0.3591 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [333/782] Loss: 0.5243 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [334/782] Loss: 0.4339 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [335/782] Loss: 0.3990 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [336/782] Loss: 0.2212 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [337/782] Loss: 0.4239 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [338/782] Loss: 0.4315 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [339/782] Loss: 0.4548 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [340/782] Loss: 0.2203 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [341/782] Loss: 0.3580 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [342/782] Loss: 0.2848 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [343/782] Loss: 0.3554 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [344/782] Loss: 0.3862 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [345/782] Loss: 0.3448 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [346/782] Loss: 0.2990 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [347/782] Loss: 0.3882 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [348/782] Loss: 0.6174 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [349/782] Loss: 0.4522 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [350/782] Loss: 0.4436 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [351/782] Loss: 0.2795 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [352/782] Loss: 0.3556 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [353/782] Loss: 0.6053 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [354/782] Loss: 0.4131 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [355/782] Loss: 0.4325 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [356/782] Loss: 0.3823 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [357/782] Loss: 0.3335 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [358/782] Loss: 0.3443 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [359/782] Loss: 0.2590 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [360/782] Loss: 0.2447 | Acc: 85.82%\n",
      "Train Epoch [96/100] Batch [361/782] Loss: 0.3635 | Acc: 85.82%\n",
      "Train Epoch [96/100] Batch [362/782] Loss: 0.5776 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [363/782] Loss: 0.4219 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [364/782] Loss: 0.3222 | Acc: 85.81%\n",
      "Train Epoch [96/100] Batch [365/782] Loss: 0.3848 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [366/782] Loss: 0.5238 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [367/782] Loss: 0.5237 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [368/782] Loss: 0.2868 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [369/782] Loss: 0.2548 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [370/782] Loss: 0.4449 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [371/782] Loss: 0.3792 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [372/782] Loss: 0.2754 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [373/782] Loss: 0.2201 | Acc: 85.82%\n",
      "Train Epoch [96/100] Batch [374/782] Loss: 0.4231 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [375/782] Loss: 0.3992 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [376/782] Loss: 0.3653 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [377/782] Loss: 0.4246 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [378/782] Loss: 0.4488 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [379/782] Loss: 0.4860 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [380/782] Loss: 0.3345 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [381/782] Loss: 0.5316 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [382/782] Loss: 0.2392 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [383/782] Loss: 0.2766 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [384/782] Loss: 0.3925 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [385/782] Loss: 0.3282 | Acc: 85.80%\n",
      "Train Epoch [96/100] Batch [386/782] Loss: 0.5486 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [387/782] Loss: 0.3492 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [388/782] Loss: 0.2701 | Acc: 85.79%\n",
      "Train Epoch [96/100] Batch [389/782] Loss: 0.2974 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [390/782] Loss: 0.3772 | Acc: 85.78%\n",
      "Train Epoch [96/100] Batch [391/782] Loss: 0.5191 | Acc: 85.77%\n",
      "Train Epoch [96/100] Batch [392/782] Loss: 0.4577 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [393/782] Loss: 0.3763 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [394/782] Loss: 0.4669 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [395/782] Loss: 0.5531 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [396/782] Loss: 0.4526 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [397/782] Loss: 0.2769 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [398/782] Loss: 0.3848 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [399/782] Loss: 0.4996 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [400/782] Loss: 0.4076 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [401/782] Loss: 0.3624 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [402/782] Loss: 0.2421 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [403/782] Loss: 0.3327 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [404/782] Loss: 0.6321 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [405/782] Loss: 0.3618 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [406/782] Loss: 0.2889 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [407/782] Loss: 0.3906 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [408/782] Loss: 0.3230 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [409/782] Loss: 0.3745 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [410/782] Loss: 0.3259 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [411/782] Loss: 0.3838 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [412/782] Loss: 0.5023 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [413/782] Loss: 0.2536 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [414/782] Loss: 0.4258 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [415/782] Loss: 0.5045 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [416/782] Loss: 0.2756 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [417/782] Loss: 0.5334 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [418/782] Loss: 0.3859 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [419/782] Loss: 0.3321 | Acc: 85.76%\n",
      "Train Epoch [96/100] Batch [420/782] Loss: 0.4488 | Acc: 85.75%\n",
      "Train Epoch [96/100] Batch [421/782] Loss: 0.6137 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [422/782] Loss: 0.3865 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [423/782] Loss: 0.6430 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [424/782] Loss: 0.3061 | Acc: 85.74%\n",
      "Train Epoch [96/100] Batch [425/782] Loss: 0.4095 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [426/782] Loss: 0.4178 | Acc: 85.72%\n",
      "Train Epoch [96/100] Batch [427/782] Loss: 0.3557 | Acc: 85.73%\n",
      "Train Epoch [96/100] Batch [428/782] Loss: 0.4583 | Acc: 85.71%\n",
      "Train Epoch [96/100] Batch [429/782] Loss: 0.5570 | Acc: 85.70%\n",
      "Train Epoch [96/100] Batch [430/782] Loss: 0.5844 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [431/782] Loss: 0.5509 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [432/782] Loss: 0.3324 | Acc: 85.68%\n",
      "Train Epoch [96/100] Batch [433/782] Loss: 0.3989 | Acc: 85.69%\n",
      "Train Epoch [96/100] Batch [434/782] Loss: 0.5431 | Acc: 85.67%\n",
      "Train Epoch [96/100] Batch [435/782] Loss: 0.3850 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [436/782] Loss: 0.3804 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [437/782] Loss: 0.3421 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [438/782] Loss: 0.2838 | Acc: 85.66%\n",
      "Train Epoch [96/100] Batch [439/782] Loss: 0.5141 | Acc: 85.65%\n",
      "Train Epoch [96/100] Batch [440/782] Loss: 0.5482 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [441/782] Loss: 0.3495 | Acc: 85.63%\n",
      "Train Epoch [96/100] Batch [442/782] Loss: 0.2890 | Acc: 85.64%\n",
      "Train Epoch [96/100] Batch [443/782] Loss: 0.5343 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [444/782] Loss: 0.5888 | Acc: 85.61%\n",
      "Train Epoch [96/100] Batch [445/782] Loss: 0.2759 | Acc: 85.61%\n",
      "Train Epoch [96/100] Batch [446/782] Loss: 0.3382 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [447/782] Loss: 0.3499 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [448/782] Loss: 0.5529 | Acc: 85.61%\n",
      "Train Epoch [96/100] Batch [449/782] Loss: 0.2670 | Acc: 85.62%\n",
      "Train Epoch [96/100] Batch [450/782] Loss: 0.5935 | Acc: 85.60%\n",
      "Train Epoch [96/100] Batch [451/782] Loss: 0.5446 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [452/782] Loss: 0.3905 | Acc: 85.59%\n",
      "Train Epoch [96/100] Batch [453/782] Loss: 0.4749 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [454/782] Loss: 0.3959 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [455/782] Loss: 0.3317 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [456/782] Loss: 0.4175 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [457/782] Loss: 0.3923 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [458/782] Loss: 0.5475 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [459/782] Loss: 0.3329 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [460/782] Loss: 0.6868 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [461/782] Loss: 0.4841 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [462/782] Loss: 0.2843 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [463/782] Loss: 0.3765 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [464/782] Loss: 0.3509 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [465/782] Loss: 0.3594 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [466/782] Loss: 0.3370 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [467/782] Loss: 0.3353 | Acc: 85.58%\n",
      "Train Epoch [96/100] Batch [468/782] Loss: 0.5508 | Acc: 85.57%\n",
      "Train Epoch [96/100] Batch [469/782] Loss: 0.4460 | Acc: 85.56%\n",
      "Train Epoch [96/100] Batch [470/782] Loss: 0.5191 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [471/782] Loss: 0.4863 | Acc: 85.54%\n",
      "Train Epoch [96/100] Batch [472/782] Loss: 0.3476 | Acc: 85.54%\n",
      "Train Epoch [96/100] Batch [473/782] Loss: 0.4375 | Acc: 85.53%\n",
      "Train Epoch [96/100] Batch [474/782] Loss: 0.2834 | Acc: 85.55%\n",
      "Train Epoch [96/100] Batch [475/782] Loss: 0.5861 | Acc: 85.53%\n",
      "Train Epoch [96/100] Batch [476/782] Loss: 0.4752 | Acc: 85.52%\n",
      "Train Epoch [96/100] Batch [477/782] Loss: 0.5424 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [478/782] Loss: 0.4271 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [479/782] Loss: 0.3658 | Acc: 85.49%\n",
      "Train Epoch [96/100] Batch [480/782] Loss: 0.4538 | Acc: 85.49%\n",
      "Train Epoch [96/100] Batch [481/782] Loss: 0.3271 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [482/782] Loss: 0.5216 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [483/782] Loss: 0.3536 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [484/782] Loss: 0.3431 | Acc: 85.51%\n",
      "Train Epoch [96/100] Batch [485/782] Loss: 0.6905 | Acc: 85.50%\n",
      "Train Epoch [96/100] Batch [486/782] Loss: 0.6904 | Acc: 85.48%\n",
      "Train Epoch [96/100] Batch [487/782] Loss: 0.4721 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [488/782] Loss: 0.4113 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [489/782] Loss: 0.4435 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [490/782] Loss: 0.4513 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [491/782] Loss: 0.4630 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [492/782] Loss: 0.3633 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [493/782] Loss: 0.3641 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [494/782] Loss: 0.3258 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [495/782] Loss: 0.4016 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [496/782] Loss: 0.3737 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [497/782] Loss: 0.4771 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [498/782] Loss: 0.3083 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [499/782] Loss: 0.3604 | Acc: 85.48%\n",
      "Train Epoch [96/100] Batch [500/782] Loss: 0.5356 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [501/782] Loss: 0.4715 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [502/782] Loss: 0.4177 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [503/782] Loss: 0.3903 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [504/782] Loss: 0.6909 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [505/782] Loss: 0.3262 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [506/782] Loss: 0.4345 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [507/782] Loss: 0.3637 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [508/782] Loss: 0.4000 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [509/782] Loss: 0.4175 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [510/782] Loss: 0.3575 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [511/782] Loss: 0.4497 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [512/782] Loss: 0.4420 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [513/782] Loss: 0.2881 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [514/782] Loss: 0.4014 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [515/782] Loss: 0.4415 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [516/782] Loss: 0.6154 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [517/782] Loss: 0.2555 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [518/782] Loss: 0.4016 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [519/782] Loss: 0.5802 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [520/782] Loss: 0.6556 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [521/782] Loss: 0.5136 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [522/782] Loss: 0.2330 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [523/782] Loss: 0.2443 | Acc: 85.47%\n",
      "Train Epoch [96/100] Batch [524/782] Loss: 0.4219 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [525/782] Loss: 0.3937 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [526/782] Loss: 0.4920 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [527/782] Loss: 0.4228 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [528/782] Loss: 0.4697 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [529/782] Loss: 0.5083 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [530/782] Loss: 0.2699 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [531/782] Loss: 0.2826 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [532/782] Loss: 0.5557 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [533/782] Loss: 0.3141 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [534/782] Loss: 0.4422 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [535/782] Loss: 0.2759 | Acc: 85.46%\n",
      "Train Epoch [96/100] Batch [536/782] Loss: 0.5178 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [537/782] Loss: 0.4413 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [538/782] Loss: 0.4799 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [539/782] Loss: 0.5248 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [540/782] Loss: 0.5891 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [541/782] Loss: 0.3353 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [542/782] Loss: 0.5061 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [543/782] Loss: 0.3009 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [544/782] Loss: 0.4331 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [545/782] Loss: 0.3065 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [546/782] Loss: 0.3580 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [547/782] Loss: 0.3309 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [548/782] Loss: 0.3619 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [549/782] Loss: 0.4509 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [550/782] Loss: 0.5266 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [551/782] Loss: 0.3629 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [552/782] Loss: 0.3823 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [553/782] Loss: 0.4245 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [554/782] Loss: 0.5922 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [555/782] Loss: 0.5433 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [556/782] Loss: 0.3714 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [557/782] Loss: 0.3691 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [558/782] Loss: 0.3407 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [559/782] Loss: 0.4472 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [560/782] Loss: 0.4431 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [561/782] Loss: 0.3216 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [562/782] Loss: 0.3374 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [563/782] Loss: 0.4745 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [564/782] Loss: 0.5662 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [565/782] Loss: 0.4619 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [566/782] Loss: 0.2758 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [567/782] Loss: 0.3109 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [568/782] Loss: 0.3311 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [569/782] Loss: 0.1857 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [570/782] Loss: 0.6027 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [571/782] Loss: 0.4382 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [572/782] Loss: 0.4949 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [573/782] Loss: 0.4266 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [574/782] Loss: 0.4661 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [575/782] Loss: 0.3040 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [576/782] Loss: 0.3284 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [577/782] Loss: 0.3631 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [578/782] Loss: 0.3285 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [579/782] Loss: 0.2952 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [580/782] Loss: 0.4606 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [581/782] Loss: 0.3906 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [582/782] Loss: 0.3346 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [583/782] Loss: 0.4875 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [584/782] Loss: 0.3938 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [585/782] Loss: 0.4468 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [586/782] Loss: 0.4093 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [587/782] Loss: 0.4797 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [588/782] Loss: 0.4321 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [589/782] Loss: 0.2610 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [590/782] Loss: 0.3734 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [591/782] Loss: 0.3782 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [592/782] Loss: 0.4159 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [593/782] Loss: 0.6336 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [594/782] Loss: 0.3897 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [595/782] Loss: 0.3791 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [596/782] Loss: 0.5382 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [597/782] Loss: 0.3333 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [598/782] Loss: 0.5019 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [599/782] Loss: 0.4819 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [600/782] Loss: 0.5059 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [601/782] Loss: 0.3665 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [602/782] Loss: 0.3527 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [603/782] Loss: 0.3615 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [604/782] Loss: 0.3380 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [605/782] Loss: 0.6337 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [606/782] Loss: 0.3021 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [607/782] Loss: 0.3009 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [608/782] Loss: 0.4938 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [609/782] Loss: 0.4287 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [610/782] Loss: 0.3853 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [611/782] Loss: 0.4245 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [612/782] Loss: 0.4105 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [613/782] Loss: 0.4220 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [614/782] Loss: 0.3063 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [615/782] Loss: 0.2563 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [616/782] Loss: 0.5171 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [617/782] Loss: 0.5621 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [618/782] Loss: 0.2592 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [619/782] Loss: 0.4493 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [620/782] Loss: 0.2547 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [621/782] Loss: 0.3752 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [622/782] Loss: 0.4283 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [623/782] Loss: 0.3947 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [624/782] Loss: 0.4919 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [625/782] Loss: 0.5757 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [626/782] Loss: 0.5285 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [627/782] Loss: 0.4856 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [628/782] Loss: 0.4173 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [629/782] Loss: 0.4845 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [630/782] Loss: 0.4739 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [631/782] Loss: 0.3213 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [632/782] Loss: 0.4398 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [633/782] Loss: 0.4560 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [634/782] Loss: 0.4034 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [635/782] Loss: 0.5175 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [636/782] Loss: 0.3202 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [637/782] Loss: 0.3761 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [638/782] Loss: 0.5550 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [639/782] Loss: 0.4599 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [640/782] Loss: 0.5501 | Acc: 85.36%\n",
      "Train Epoch [96/100] Batch [641/782] Loss: 0.4282 | Acc: 85.36%\n",
      "Train Epoch [96/100] Batch [642/782] Loss: 0.3821 | Acc: 85.36%\n",
      "Train Epoch [96/100] Batch [643/782] Loss: 0.3530 | Acc: 85.36%\n",
      "Train Epoch [96/100] Batch [644/782] Loss: 0.2963 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [645/782] Loss: 0.5052 | Acc: 85.36%\n",
      "Train Epoch [96/100] Batch [646/782] Loss: 0.2992 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [647/782] Loss: 0.3643 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [648/782] Loss: 0.3868 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [649/782] Loss: 0.3053 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [650/782] Loss: 0.3832 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [651/782] Loss: 0.3541 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [652/782] Loss: 0.4785 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [653/782] Loss: 0.5072 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [654/782] Loss: 0.5151 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [655/782] Loss: 0.3601 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [656/782] Loss: 0.2869 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [657/782] Loss: 0.5605 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [658/782] Loss: 0.2895 | Acc: 85.37%\n",
      "Train Epoch [96/100] Batch [659/782] Loss: 0.3657 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [660/782] Loss: 0.2532 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [661/782] Loss: 0.3364 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [662/782] Loss: 0.2787 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [663/782] Loss: 0.2873 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [664/782] Loss: 0.3666 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [665/782] Loss: 0.3842 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [666/782] Loss: 0.5020 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [667/782] Loss: 0.3294 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [668/782] Loss: 0.4879 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [669/782] Loss: 0.3703 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [670/782] Loss: 0.2575 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [671/782] Loss: 0.4227 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [672/782] Loss: 0.3838 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [673/782] Loss: 0.3425 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [674/782] Loss: 0.3262 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [675/782] Loss: 0.5019 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [676/782] Loss: 0.3669 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [677/782] Loss: 0.4184 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [678/782] Loss: 0.2827 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [679/782] Loss: 0.3158 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [680/782] Loss: 0.5632 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [681/782] Loss: 0.3861 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [682/782] Loss: 0.4889 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [683/782] Loss: 0.5048 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [684/782] Loss: 0.3128 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [685/782] Loss: 0.2147 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [686/782] Loss: 0.2964 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [687/782] Loss: 0.5693 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [688/782] Loss: 0.5661 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [689/782] Loss: 0.4364 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [690/782] Loss: 0.3588 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [691/782] Loss: 0.3617 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [692/782] Loss: 0.4709 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [693/782] Loss: 0.6610 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [694/782] Loss: 0.5011 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [695/782] Loss: 0.3435 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [696/782] Loss: 0.4649 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [697/782] Loss: 0.3552 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [698/782] Loss: 0.3775 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [699/782] Loss: 0.3873 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [700/782] Loss: 0.3518 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [701/782] Loss: 0.3068 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [702/782] Loss: 0.3270 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [703/782] Loss: 0.5544 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [704/782] Loss: 0.4218 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [705/782] Loss: 0.5359 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [706/782] Loss: 0.4914 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [707/782] Loss: 0.3933 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [708/782] Loss: 0.2848 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [709/782] Loss: 0.4436 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [710/782] Loss: 0.2151 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [711/782] Loss: 0.4241 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [712/782] Loss: 0.3796 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [713/782] Loss: 0.2192 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [714/782] Loss: 0.3874 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [715/782] Loss: 0.5821 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [716/782] Loss: 0.3961 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [717/782] Loss: 0.2950 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [718/782] Loss: 0.4560 | Acc: 85.45%\n",
      "Train Epoch [96/100] Batch [719/782] Loss: 0.6561 | Acc: 85.44%\n",
      "Train Epoch [96/100] Batch [720/782] Loss: 0.4564 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [721/782] Loss: 0.5013 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [722/782] Loss: 0.3920 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [723/782] Loss: 0.3649 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [724/782] Loss: 0.3790 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [725/782] Loss: 0.4956 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [726/782] Loss: 0.3696 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [727/782] Loss: 0.5331 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [728/782] Loss: 0.4662 | Acc: 85.43%\n",
      "Train Epoch [96/100] Batch [729/782] Loss: 0.4722 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [730/782] Loss: 0.3808 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [731/782] Loss: 0.6543 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [732/782] Loss: 0.6135 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [733/782] Loss: 0.3802 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [734/782] Loss: 0.5825 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [735/782] Loss: 0.3419 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [736/782] Loss: 0.5074 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [737/782] Loss: 0.4763 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [738/782] Loss: 0.4836 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [739/782] Loss: 0.3098 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [740/782] Loss: 0.5465 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [741/782] Loss: 0.4687 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [742/782] Loss: 0.2490 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [743/782] Loss: 0.2653 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [744/782] Loss: 0.4718 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [745/782] Loss: 0.3902 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [746/782] Loss: 0.4050 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [747/782] Loss: 0.3506 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [748/782] Loss: 0.4554 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [749/782] Loss: 0.4405 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [750/782] Loss: 0.4322 | Acc: 85.38%\n",
      "Train Epoch [96/100] Batch [751/782] Loss: 0.2536 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [752/782] Loss: 0.3578 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [753/782] Loss: 0.3918 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [754/782] Loss: 0.4325 | Acc: 85.39%\n",
      "Train Epoch [96/100] Batch [755/782] Loss: 0.3646 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [756/782] Loss: 0.4934 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [757/782] Loss: 0.3679 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [758/782] Loss: 0.2000 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [759/782] Loss: 0.4991 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [760/782] Loss: 0.3464 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [761/782] Loss: 0.3476 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [762/782] Loss: 0.4208 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [763/782] Loss: 0.3748 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [764/782] Loss: 0.4435 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [765/782] Loss: 0.5129 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [766/782] Loss: 0.6628 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [767/782] Loss: 0.2405 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [768/782] Loss: 0.3331 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [769/782] Loss: 0.4975 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [770/782] Loss: 0.3808 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [771/782] Loss: 0.4060 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [772/782] Loss: 0.3322 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [773/782] Loss: 0.3471 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [774/782] Loss: 0.2594 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [775/782] Loss: 0.4077 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [776/782] Loss: 0.4647 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [777/782] Loss: 0.3468 | Acc: 85.42%\n",
      "Train Epoch [96/100] Batch [778/782] Loss: 0.5436 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [779/782] Loss: 0.3534 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [780/782] Loss: 0.4694 | Acc: 85.41%\n",
      "Train Epoch [96/100] Batch [781/782] Loss: 0.4423 | Acc: 85.40%\n",
      "Train Epoch [96/100] Batch [782/782] Loss: 0.4676 | Acc: 85.40%\n",
      "Epoch 96 completed in 30.85s.\n",
      "Test Epoch [96/100] Loss: 1.0205 | Acc: 72.07% | Inference Time: 8.54s\n",
      "Epoch 96 results saved to CSV.\n",
      "Epoch 97/100\n",
      "Train Epoch [97/100] Batch [1/782] Loss: 0.2938 | Acc: 87.50%\n",
      "Train Epoch [97/100] Batch [2/782] Loss: 0.4122 | Acc: 87.50%\n",
      "Train Epoch [97/100] Batch [3/782] Loss: 0.4226 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [4/782] Loss: 0.2904 | Acc: 87.11%\n",
      "Train Epoch [97/100] Batch [5/782] Loss: 0.3590 | Acc: 87.50%\n",
      "Train Epoch [97/100] Batch [6/782] Loss: 0.2719 | Acc: 88.28%\n",
      "Train Epoch [97/100] Batch [7/782] Loss: 0.3840 | Acc: 87.50%\n",
      "Train Epoch [97/100] Batch [8/782] Loss: 0.4364 | Acc: 86.91%\n",
      "Train Epoch [97/100] Batch [9/782] Loss: 0.4740 | Acc: 86.28%\n",
      "Train Epoch [97/100] Batch [10/782] Loss: 0.5375 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [11/782] Loss: 0.5030 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [12/782] Loss: 0.4239 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [13/782] Loss: 0.3050 | Acc: 86.18%\n",
      "Train Epoch [97/100] Batch [14/782] Loss: 0.5702 | Acc: 85.49%\n",
      "Train Epoch [97/100] Batch [15/782] Loss: 0.4454 | Acc: 85.31%\n",
      "Train Epoch [97/100] Batch [16/782] Loss: 0.5676 | Acc: 84.77%\n",
      "Train Epoch [97/100] Batch [17/782] Loss: 0.3354 | Acc: 85.02%\n",
      "Train Epoch [97/100] Batch [18/782] Loss: 0.4331 | Acc: 84.81%\n",
      "Train Epoch [97/100] Batch [19/782] Loss: 0.2988 | Acc: 85.20%\n",
      "Train Epoch [97/100] Batch [20/782] Loss: 0.6493 | Acc: 84.61%\n",
      "Train Epoch [97/100] Batch [21/782] Loss: 0.3514 | Acc: 84.67%\n",
      "Train Epoch [97/100] Batch [22/782] Loss: 0.4476 | Acc: 84.80%\n",
      "Train Epoch [97/100] Batch [23/782] Loss: 0.3938 | Acc: 84.85%\n",
      "Train Epoch [97/100] Batch [24/782] Loss: 0.3905 | Acc: 84.96%\n",
      "Train Epoch [97/100] Batch [25/782] Loss: 0.4426 | Acc: 85.00%\n",
      "Train Epoch [97/100] Batch [26/782] Loss: 0.1631 | Acc: 85.34%\n",
      "Train Epoch [97/100] Batch [27/782] Loss: 0.2470 | Acc: 85.59%\n",
      "Train Epoch [97/100] Batch [28/782] Loss: 0.2313 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [29/782] Loss: 0.4259 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [30/782] Loss: 0.3250 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [31/782] Loss: 0.4450 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [32/782] Loss: 0.2720 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [33/782] Loss: 0.3512 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [34/782] Loss: 0.4009 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [35/782] Loss: 0.3729 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [36/782] Loss: 0.4915 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [37/782] Loss: 0.6116 | Acc: 85.60%\n",
      "Train Epoch [97/100] Batch [38/782] Loss: 0.4479 | Acc: 85.53%\n",
      "Train Epoch [97/100] Batch [39/782] Loss: 0.2876 | Acc: 85.62%\n",
      "Train Epoch [97/100] Batch [40/782] Loss: 0.4385 | Acc: 85.62%\n",
      "Train Epoch [97/100] Batch [41/782] Loss: 0.3585 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [42/782] Loss: 0.4225 | Acc: 85.64%\n",
      "Train Epoch [97/100] Batch [43/782] Loss: 0.5198 | Acc: 85.57%\n",
      "Train Epoch [97/100] Batch [44/782] Loss: 0.3334 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [45/782] Loss: 0.3267 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [46/782] Loss: 0.3805 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [47/782] Loss: 0.5110 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [48/782] Loss: 0.3074 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [49/782] Loss: 0.5015 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [50/782] Loss: 0.7514 | Acc: 85.41%\n",
      "Train Epoch [97/100] Batch [51/782] Loss: 0.2606 | Acc: 85.48%\n",
      "Train Epoch [97/100] Batch [52/782] Loss: 0.4790 | Acc: 85.43%\n",
      "Train Epoch [97/100] Batch [53/782] Loss: 0.3599 | Acc: 85.50%\n",
      "Train Epoch [97/100] Batch [54/782] Loss: 0.5121 | Acc: 85.36%\n",
      "Train Epoch [97/100] Batch [55/782] Loss: 0.5448 | Acc: 85.23%\n",
      "Train Epoch [97/100] Batch [56/782] Loss: 0.3579 | Acc: 85.32%\n",
      "Train Epoch [97/100] Batch [57/782] Loss: 0.3907 | Acc: 85.31%\n",
      "Train Epoch [97/100] Batch [58/782] Loss: 0.3981 | Acc: 85.32%\n",
      "Train Epoch [97/100] Batch [59/782] Loss: 0.2881 | Acc: 85.35%\n",
      "Train Epoch [97/100] Batch [60/782] Loss: 0.5826 | Acc: 85.23%\n",
      "Train Epoch [97/100] Batch [61/782] Loss: 0.3916 | Acc: 85.19%\n",
      "Train Epoch [97/100] Batch [62/782] Loss: 0.3316 | Acc: 85.28%\n",
      "Train Epoch [97/100] Batch [63/782] Loss: 0.2360 | Acc: 85.42%\n",
      "Train Epoch [97/100] Batch [64/782] Loss: 0.3254 | Acc: 85.42%\n",
      "Train Epoch [97/100] Batch [65/782] Loss: 0.4213 | Acc: 85.43%\n",
      "Train Epoch [97/100] Batch [66/782] Loss: 0.3095 | Acc: 85.51%\n",
      "Train Epoch [97/100] Batch [67/782] Loss: 0.3557 | Acc: 85.49%\n",
      "Train Epoch [97/100] Batch [68/782] Loss: 0.4322 | Acc: 85.50%\n",
      "Train Epoch [97/100] Batch [69/782] Loss: 0.4264 | Acc: 85.46%\n",
      "Train Epoch [97/100] Batch [70/782] Loss: 0.4062 | Acc: 85.47%\n",
      "Train Epoch [97/100] Batch [71/782] Loss: 0.3259 | Acc: 85.48%\n",
      "Train Epoch [97/100] Batch [72/782] Loss: 0.3113 | Acc: 85.55%\n",
      "Train Epoch [97/100] Batch [73/782] Loss: 0.3692 | Acc: 85.55%\n",
      "Train Epoch [97/100] Batch [74/782] Loss: 0.2555 | Acc: 85.64%\n",
      "Train Epoch [97/100] Batch [75/782] Loss: 0.2164 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [76/782] Loss: 0.3806 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [77/782] Loss: 0.3170 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [78/782] Loss: 0.5276 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [79/782] Loss: 0.4044 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [80/782] Loss: 0.2393 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [81/782] Loss: 0.4228 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [82/782] Loss: 0.3087 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [83/782] Loss: 0.3767 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [84/782] Loss: 0.2652 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [85/782] Loss: 0.4435 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [86/782] Loss: 0.2291 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [87/782] Loss: 0.4890 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [88/782] Loss: 0.3923 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [89/782] Loss: 0.4858 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [90/782] Loss: 0.3451 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [91/782] Loss: 0.6817 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [92/782] Loss: 0.4997 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [93/782] Loss: 0.2513 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [94/782] Loss: 0.6313 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [95/782] Loss: 0.3734 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [96/782] Loss: 0.4814 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [97/782] Loss: 0.2118 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [98/782] Loss: 0.3746 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [99/782] Loss: 0.1976 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [100/782] Loss: 0.1983 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [101/782] Loss: 0.5487 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [102/782] Loss: 0.3839 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [103/782] Loss: 0.2204 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [104/782] Loss: 0.4604 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [105/782] Loss: 0.3733 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [106/782] Loss: 0.4159 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [107/782] Loss: 0.2817 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [108/782] Loss: 0.2941 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [109/782] Loss: 0.4302 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [110/782] Loss: 0.4921 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [111/782] Loss: 0.4026 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [112/782] Loss: 0.5396 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [113/782] Loss: 0.4282 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [114/782] Loss: 0.3381 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [115/782] Loss: 0.3713 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [116/782] Loss: 0.3697 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [117/782] Loss: 0.3727 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [118/782] Loss: 0.5432 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [119/782] Loss: 0.4031 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [120/782] Loss: 0.4121 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [121/782] Loss: 0.3129 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [122/782] Loss: 0.3100 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [123/782] Loss: 0.3118 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [124/782] Loss: 0.3059 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [125/782] Loss: 0.3707 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [126/782] Loss: 0.4895 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [127/782] Loss: 0.4748 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [128/782] Loss: 0.3162 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [129/782] Loss: 0.3230 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [130/782] Loss: 0.2777 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [131/782] Loss: 0.2780 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [132/782] Loss: 0.3689 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [133/782] Loss: 0.3201 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [134/782] Loss: 0.4478 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [135/782] Loss: 0.4098 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [136/782] Loss: 0.5395 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [137/782] Loss: 0.2530 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [138/782] Loss: 0.6067 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [139/782] Loss: 0.3527 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [140/782] Loss: 0.3968 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [141/782] Loss: 0.5041 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [142/782] Loss: 0.4404 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [143/782] Loss: 0.4826 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [144/782] Loss: 0.4465 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [145/782] Loss: 0.2152 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [146/782] Loss: 0.5694 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [147/782] Loss: 0.5338 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [148/782] Loss: 0.3366 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [149/782] Loss: 0.2518 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [150/782] Loss: 0.3721 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [151/782] Loss: 0.4705 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [152/782] Loss: 0.4033 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [153/782] Loss: 0.4814 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [154/782] Loss: 0.3972 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [155/782] Loss: 0.2646 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [156/782] Loss: 0.4268 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [157/782] Loss: 0.6230 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [158/782] Loss: 0.3794 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [159/782] Loss: 0.4496 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [160/782] Loss: 0.3561 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [161/782] Loss: 0.3668 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [162/782] Loss: 0.2709 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [163/782] Loss: 0.5504 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [164/782] Loss: 0.3617 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [165/782] Loss: 0.2907 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [166/782] Loss: 0.4581 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [167/782] Loss: 0.3783 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [168/782] Loss: 0.7455 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [169/782] Loss: 0.4763 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [170/782] Loss: 0.4109 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [171/782] Loss: 0.3606 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [172/782] Loss: 0.5168 | Acc: 85.66%\n",
      "Train Epoch [97/100] Batch [173/782] Loss: 0.2754 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [174/782] Loss: 0.3807 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [175/782] Loss: 0.4063 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [176/782] Loss: 0.4092 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [177/782] Loss: 0.5787 | Acc: 85.65%\n",
      "Train Epoch [97/100] Batch [178/782] Loss: 0.4104 | Acc: 85.60%\n",
      "Train Epoch [97/100] Batch [179/782] Loss: 0.4497 | Acc: 85.59%\n",
      "Train Epoch [97/100] Batch [180/782] Loss: 0.5330 | Acc: 85.58%\n",
      "Train Epoch [97/100] Batch [181/782] Loss: 0.3750 | Acc: 85.60%\n",
      "Train Epoch [97/100] Batch [182/782] Loss: 0.5531 | Acc: 85.59%\n",
      "Train Epoch [97/100] Batch [183/782] Loss: 0.5232 | Acc: 85.56%\n",
      "Train Epoch [97/100] Batch [184/782] Loss: 0.3512 | Acc: 85.56%\n",
      "Train Epoch [97/100] Batch [185/782] Loss: 0.3362 | Acc: 85.58%\n",
      "Train Epoch [97/100] Batch [186/782] Loss: 0.3403 | Acc: 85.59%\n",
      "Train Epoch [97/100] Batch [187/782] Loss: 0.3053 | Acc: 85.59%\n",
      "Train Epoch [97/100] Batch [188/782] Loss: 0.3055 | Acc: 85.62%\n",
      "Train Epoch [97/100] Batch [189/782] Loss: 0.3330 | Acc: 85.62%\n",
      "Train Epoch [97/100] Batch [190/782] Loss: 0.2791 | Acc: 85.65%\n",
      "Train Epoch [97/100] Batch [191/782] Loss: 0.3685 | Acc: 85.66%\n",
      "Train Epoch [97/100] Batch [192/782] Loss: 0.4227 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [193/782] Loss: 0.6061 | Acc: 85.66%\n",
      "Train Epoch [97/100] Batch [194/782] Loss: 0.4178 | Acc: 85.66%\n",
      "Train Epoch [97/100] Batch [195/782] Loss: 0.3419 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [196/782] Loss: 0.3616 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [197/782] Loss: 0.3064 | Acc: 85.69%\n",
      "Train Epoch [97/100] Batch [198/782] Loss: 0.3227 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [199/782] Loss: 0.4772 | Acc: 85.68%\n",
      "Train Epoch [97/100] Batch [200/782] Loss: 0.4842 | Acc: 85.67%\n",
      "Train Epoch [97/100] Batch [201/782] Loss: 0.2955 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [202/782] Loss: 0.1434 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [203/782] Loss: 0.3264 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [204/782] Loss: 0.2060 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [205/782] Loss: 0.3405 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [206/782] Loss: 0.4495 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [207/782] Loss: 0.2780 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [208/782] Loss: 0.4054 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [209/782] Loss: 0.3612 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [210/782] Loss: 0.4357 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [211/782] Loss: 0.4401 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [212/782] Loss: 0.4161 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [213/782] Loss: 0.4258 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [214/782] Loss: 0.3305 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [215/782] Loss: 0.3818 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [216/782] Loss: 0.2902 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [217/782] Loss: 0.3003 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [218/782] Loss: 0.5163 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [219/782] Loss: 0.3185 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [220/782] Loss: 0.2775 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [221/782] Loss: 0.3909 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [222/782] Loss: 0.4607 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [223/782] Loss: 0.4122 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [224/782] Loss: 0.3355 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [225/782] Loss: 0.3005 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [226/782] Loss: 0.3259 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [227/782] Loss: 0.3163 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [228/782] Loss: 0.3566 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [229/782] Loss: 0.5165 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [230/782] Loss: 0.4328 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [231/782] Loss: 0.3714 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [232/782] Loss: 0.4571 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [233/782] Loss: 0.4252 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [234/782] Loss: 0.3619 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [235/782] Loss: 0.3149 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [236/782] Loss: 0.4407 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [237/782] Loss: 0.4418 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [238/782] Loss: 0.5168 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [239/782] Loss: 0.2941 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [240/782] Loss: 0.4600 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [241/782] Loss: 0.4209 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [242/782] Loss: 0.3126 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [243/782] Loss: 0.4626 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [244/782] Loss: 0.3474 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [245/782] Loss: 0.3077 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [246/782] Loss: 0.4720 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [247/782] Loss: 0.4273 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [248/782] Loss: 0.2575 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [249/782] Loss: 0.3940 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [250/782] Loss: 0.3527 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [251/782] Loss: 0.3311 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [252/782] Loss: 0.4372 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [253/782] Loss: 0.3256 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [254/782] Loss: 0.3620 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [255/782] Loss: 0.3176 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [256/782] Loss: 0.3244 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [257/782] Loss: 0.4917 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [258/782] Loss: 0.4137 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [259/782] Loss: 0.2615 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [260/782] Loss: 0.4848 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [261/782] Loss: 0.5165 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [262/782] Loss: 0.3733 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [263/782] Loss: 0.4080 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [264/782] Loss: 0.5147 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [265/782] Loss: 0.2004 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [266/782] Loss: 0.4367 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [267/782] Loss: 0.3030 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [268/782] Loss: 0.3135 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [269/782] Loss: 0.2922 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [270/782] Loss: 0.4442 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [271/782] Loss: 0.3761 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [272/782] Loss: 0.4705 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [273/782] Loss: 0.4716 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [274/782] Loss: 0.3281 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [275/782] Loss: 0.5532 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [276/782] Loss: 0.4968 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [277/782] Loss: 0.3472 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [278/782] Loss: 0.3342 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [279/782] Loss: 0.4962 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [280/782] Loss: 0.5697 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [281/782] Loss: 0.3314 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [282/782] Loss: 0.3609 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [283/782] Loss: 0.3894 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [284/782] Loss: 0.4176 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [285/782] Loss: 0.3662 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [286/782] Loss: 0.3291 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [287/782] Loss: 0.5314 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [288/782] Loss: 0.2827 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [289/782] Loss: 0.4021 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [290/782] Loss: 0.3790 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [291/782] Loss: 0.3979 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [292/782] Loss: 0.3815 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [293/782] Loss: 0.5229 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [294/782] Loss: 0.4015 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [295/782] Loss: 0.3958 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [296/782] Loss: 0.4881 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [297/782] Loss: 0.2588 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [298/782] Loss: 0.4202 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [299/782] Loss: 0.5449 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [300/782] Loss: 0.2948 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [301/782] Loss: 0.4105 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [302/782] Loss: 0.4660 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [303/782] Loss: 0.3933 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [304/782] Loss: 0.5238 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [305/782] Loss: 0.3133 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [306/782] Loss: 0.5001 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [307/782] Loss: 0.3864 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [308/782] Loss: 0.2799 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [309/782] Loss: 0.2899 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [310/782] Loss: 0.3109 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [311/782] Loss: 0.3770 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [312/782] Loss: 0.3227 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [313/782] Loss: 0.3282 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [314/782] Loss: 0.4037 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [315/782] Loss: 0.4083 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [316/782] Loss: 0.1714 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [317/782] Loss: 0.5775 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [318/782] Loss: 0.4978 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [319/782] Loss: 0.4045 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [320/782] Loss: 0.3789 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [321/782] Loss: 0.3982 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [322/782] Loss: 0.4312 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [323/782] Loss: 0.3367 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [324/782] Loss: 0.2979 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [325/782] Loss: 0.4072 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [326/782] Loss: 0.4222 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [327/782] Loss: 0.4950 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [328/782] Loss: 0.4838 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [329/782] Loss: 0.4396 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [330/782] Loss: 0.2530 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [331/782] Loss: 0.3121 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [332/782] Loss: 0.3535 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [333/782] Loss: 0.3883 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [334/782] Loss: 0.2901 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [335/782] Loss: 0.4113 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [336/782] Loss: 0.4894 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [337/782] Loss: 0.3843 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [338/782] Loss: 0.2784 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [339/782] Loss: 0.3268 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [340/782] Loss: 0.3688 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [341/782] Loss: 0.4152 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [342/782] Loss: 0.3283 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [343/782] Loss: 0.5326 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [344/782] Loss: 0.2531 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [345/782] Loss: 0.2649 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [346/782] Loss: 0.3820 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [347/782] Loss: 0.3540 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [348/782] Loss: 0.3202 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [349/782] Loss: 0.2645 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [350/782] Loss: 0.5041 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [351/782] Loss: 0.5423 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [352/782] Loss: 0.3604 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [353/782] Loss: 0.3507 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [354/782] Loss: 0.4035 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [355/782] Loss: 0.4363 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [356/782] Loss: 0.4740 | Acc: 85.99%\n",
      "Train Epoch [97/100] Batch [357/782] Loss: 0.2693 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [358/782] Loss: 0.4702 | Acc: 86.00%\n",
      "Train Epoch [97/100] Batch [359/782] Loss: 0.2747 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [360/782] Loss: 0.2121 | Acc: 86.04%\n",
      "Train Epoch [97/100] Batch [361/782] Loss: 0.5021 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [362/782] Loss: 0.4468 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [363/782] Loss: 0.3679 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [364/782] Loss: 0.4628 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [365/782] Loss: 0.2777 | Acc: 86.03%\n",
      "Train Epoch [97/100] Batch [366/782] Loss: 0.4529 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [367/782] Loss: 0.3148 | Acc: 86.02%\n",
      "Train Epoch [97/100] Batch [368/782] Loss: 0.3544 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [369/782] Loss: 0.4303 | Acc: 86.01%\n",
      "Train Epoch [97/100] Batch [370/782] Loss: 0.5113 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [371/782] Loss: 0.3877 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [372/782] Loss: 0.6059 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [373/782] Loss: 0.4325 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [374/782] Loss: 0.4457 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [375/782] Loss: 0.3036 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [376/782] Loss: 0.3761 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [377/782] Loss: 0.4509 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [378/782] Loss: 0.3616 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [379/782] Loss: 0.3710 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [380/782] Loss: 0.3139 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [381/782] Loss: 0.4280 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [382/782] Loss: 0.2781 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [383/782] Loss: 0.3717 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [384/782] Loss: 0.2779 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [385/782] Loss: 0.5562 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [386/782] Loss: 0.3316 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [387/782] Loss: 0.3813 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [388/782] Loss: 0.4715 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [389/782] Loss: 0.4542 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [390/782] Loss: 0.5493 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [391/782] Loss: 0.3108 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [392/782] Loss: 0.4566 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [393/782] Loss: 0.3975 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [394/782] Loss: 0.3425 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [395/782] Loss: 0.3283 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [396/782] Loss: 0.4660 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [397/782] Loss: 0.2604 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [398/782] Loss: 0.2810 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [399/782] Loss: 0.3943 | Acc: 85.98%\n",
      "Train Epoch [97/100] Batch [400/782] Loss: 0.4974 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [401/782] Loss: 0.3857 | Acc: 85.97%\n",
      "Train Epoch [97/100] Batch [402/782] Loss: 0.6569 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [403/782] Loss: 0.4710 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [404/782] Loss: 0.3494 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [405/782] Loss: 0.4000 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [406/782] Loss: 0.3613 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [407/782] Loss: 0.2911 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [408/782] Loss: 0.3250 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [409/782] Loss: 0.4469 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [410/782] Loss: 0.3660 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [411/782] Loss: 0.2735 | Acc: 85.95%\n",
      "Train Epoch [97/100] Batch [412/782] Loss: 0.4080 | Acc: 85.96%\n",
      "Train Epoch [97/100] Batch [413/782] Loss: 0.5976 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [414/782] Loss: 0.5115 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [415/782] Loss: 0.2602 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [416/782] Loss: 0.3932 | Acc: 85.94%\n",
      "Train Epoch [97/100] Batch [417/782] Loss: 0.5938 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [418/782] Loss: 0.3995 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [419/782] Loss: 0.3440 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [420/782] Loss: 0.1556 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [421/782] Loss: 0.5895 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [422/782] Loss: 0.7917 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [423/782] Loss: 0.3164 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [424/782] Loss: 0.2670 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [425/782] Loss: 0.5637 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [426/782] Loss: 0.2692 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [427/782] Loss: 0.3108 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [428/782] Loss: 0.5272 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [429/782] Loss: 0.3648 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [430/782] Loss: 0.4329 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [431/782] Loss: 0.5659 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [432/782] Loss: 0.3467 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [433/782] Loss: 0.6200 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [434/782] Loss: 0.3179 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [435/782] Loss: 0.3236 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [436/782] Loss: 0.4068 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [437/782] Loss: 0.4007 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [438/782] Loss: 0.5285 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [439/782] Loss: 0.4274 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [440/782] Loss: 0.3990 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [441/782] Loss: 0.3696 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [442/782] Loss: 0.3877 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [443/782] Loss: 0.3081 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [444/782] Loss: 0.3358 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [445/782] Loss: 0.3200 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [446/782] Loss: 0.3849 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [447/782] Loss: 0.5643 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [448/782] Loss: 0.3357 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [449/782] Loss: 0.1994 | Acc: 85.93%\n",
      "Train Epoch [97/100] Batch [450/782] Loss: 0.6492 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [451/782] Loss: 0.3506 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [452/782] Loss: 0.4323 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [453/782] Loss: 0.3783 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [454/782] Loss: 0.3593 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [455/782] Loss: 0.2161 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [456/782] Loss: 0.3791 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [457/782] Loss: 0.4515 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [458/782] Loss: 0.6739 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [459/782] Loss: 0.4282 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [460/782] Loss: 0.4650 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [461/782] Loss: 0.9233 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [462/782] Loss: 0.3130 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [463/782] Loss: 0.4555 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [464/782] Loss: 0.3772 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [465/782] Loss: 0.4827 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [466/782] Loss: 0.3485 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [467/782] Loss: 0.3257 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [468/782] Loss: 0.4237 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [469/782] Loss: 0.4518 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [470/782] Loss: 0.3562 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [471/782] Loss: 0.3777 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [472/782] Loss: 0.4221 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [473/782] Loss: 0.3062 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [474/782] Loss: 0.5037 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [475/782] Loss: 0.4775 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [476/782] Loss: 0.3739 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [477/782] Loss: 0.4620 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [478/782] Loss: 0.4387 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [479/782] Loss: 0.4556 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [480/782] Loss: 0.3606 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [481/782] Loss: 0.3188 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [482/782] Loss: 0.3655 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [483/782] Loss: 0.3683 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [484/782] Loss: 0.2325 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [485/782] Loss: 0.3645 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [486/782] Loss: 0.4447 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [487/782] Loss: 0.3426 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [488/782] Loss: 0.5405 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [489/782] Loss: 0.5081 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [490/782] Loss: 0.4469 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [491/782] Loss: 0.3014 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [492/782] Loss: 0.4429 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [493/782] Loss: 0.5072 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [494/782] Loss: 0.2712 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [495/782] Loss: 0.2962 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [496/782] Loss: 0.3519 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [497/782] Loss: 0.2945 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [498/782] Loss: 0.4742 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [499/782] Loss: 0.3176 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [500/782] Loss: 0.4843 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [501/782] Loss: 0.4090 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [502/782] Loss: 0.3149 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [503/782] Loss: 0.3908 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [504/782] Loss: 0.4028 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [505/782] Loss: 0.4025 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [506/782] Loss: 0.3463 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [507/782] Loss: 0.2076 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [508/782] Loss: 0.2954 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [509/782] Loss: 0.3755 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [510/782] Loss: 0.3379 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [511/782] Loss: 0.3248 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [512/782] Loss: 0.4096 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [513/782] Loss: 0.2918 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [514/782] Loss: 0.4125 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [515/782] Loss: 0.4859 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [516/782] Loss: 0.5211 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [517/782] Loss: 0.4362 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [518/782] Loss: 0.4507 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [519/782] Loss: 0.3841 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [520/782] Loss: 0.3650 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [521/782] Loss: 0.3253 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [522/782] Loss: 0.3569 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [523/782] Loss: 0.2959 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [524/782] Loss: 0.3243 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [525/782] Loss: 0.4457 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [526/782] Loss: 0.6238 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [527/782] Loss: 0.3678 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [528/782] Loss: 0.3819 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [529/782] Loss: 0.4308 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [530/782] Loss: 0.4502 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [531/782] Loss: 0.5072 | Acc: 85.92%\n",
      "Train Epoch [97/100] Batch [532/782] Loss: 0.3811 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [533/782] Loss: 0.7085 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [534/782] Loss: 0.3887 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [535/782] Loss: 0.3263 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [536/782] Loss: 0.3720 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [537/782] Loss: 0.4430 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [538/782] Loss: 0.4051 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [539/782] Loss: 0.5308 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [540/782] Loss: 0.3926 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [541/782] Loss: 0.2389 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [542/782] Loss: 0.3956 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [543/782] Loss: 0.6356 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [544/782] Loss: 0.2908 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [545/782] Loss: 0.2650 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [546/782] Loss: 0.4147 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [547/782] Loss: 0.4195 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [548/782] Loss: 0.2832 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [549/782] Loss: 0.5904 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [550/782] Loss: 0.3648 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [551/782] Loss: 0.3840 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [552/782] Loss: 0.5062 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [553/782] Loss: 0.2409 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [554/782] Loss: 0.4159 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [555/782] Loss: 0.5565 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [556/782] Loss: 0.3053 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [557/782] Loss: 0.3550 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [558/782] Loss: 0.4423 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [559/782] Loss: 0.4987 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [560/782] Loss: 0.4403 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [561/782] Loss: 0.3261 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [562/782] Loss: 0.2191 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [563/782] Loss: 0.3256 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [564/782] Loss: 0.2457 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [565/782] Loss: 0.5003 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [566/782] Loss: 0.3758 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [567/782] Loss: 0.2880 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [568/782] Loss: 0.4308 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [569/782] Loss: 0.2489 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [570/782] Loss: 0.2839 | Acc: 85.91%\n",
      "Train Epoch [97/100] Batch [571/782] Loss: 0.5051 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [572/782] Loss: 0.3379 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [573/782] Loss: 0.4628 | Acc: 85.90%\n",
      "Train Epoch [97/100] Batch [574/782] Loss: 0.4832 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [575/782] Loss: 0.3945 | Acc: 85.89%\n",
      "Train Epoch [97/100] Batch [576/782] Loss: 0.4324 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [577/782] Loss: 0.3882 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [578/782] Loss: 0.3360 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [579/782] Loss: 0.4680 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [580/782] Loss: 0.3517 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [581/782] Loss: 0.5888 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [582/782] Loss: 0.4784 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [583/782] Loss: 0.3537 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [584/782] Loss: 0.3510 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [585/782] Loss: 0.3534 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [586/782] Loss: 0.4480 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [587/782] Loss: 0.4227 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [588/782] Loss: 0.3044 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [589/782] Loss: 0.2201 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [590/782] Loss: 0.3646 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [591/782] Loss: 0.4069 | Acc: 85.88%\n",
      "Train Epoch [97/100] Batch [592/782] Loss: 0.5833 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [593/782] Loss: 0.4023 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [594/782] Loss: 0.4234 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [595/782] Loss: 0.3690 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [596/782] Loss: 0.3297 | Acc: 85.87%\n",
      "Train Epoch [97/100] Batch [597/782] Loss: 0.4299 | Acc: 85.86%\n",
      "Train Epoch [97/100] Batch [598/782] Loss: 0.5930 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [599/782] Loss: 0.5023 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [600/782] Loss: 0.3587 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [601/782] Loss: 0.4945 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [602/782] Loss: 0.2649 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [603/782] Loss: 0.4774 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [604/782] Loss: 0.5319 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [605/782] Loss: 0.4855 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [606/782] Loss: 0.4045 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [607/782] Loss: 0.3882 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [608/782] Loss: 0.5534 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [609/782] Loss: 0.5005 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [610/782] Loss: 0.5406 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [611/782] Loss: 0.2886 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [612/782] Loss: 0.3776 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [613/782] Loss: 0.4161 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [614/782] Loss: 0.2287 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [615/782] Loss: 0.3294 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [616/782] Loss: 0.3910 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [617/782] Loss: 0.2418 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [618/782] Loss: 0.2662 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [619/782] Loss: 0.2405 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [620/782] Loss: 0.4838 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [621/782] Loss: 0.2508 | Acc: 85.85%\n",
      "Train Epoch [97/100] Batch [622/782] Loss: 0.4811 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [623/782] Loss: 0.4916 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [624/782] Loss: 0.3509 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [625/782] Loss: 0.3345 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [626/782] Loss: 0.4424 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [627/782] Loss: 0.3638 | Acc: 85.83%\n",
      "Train Epoch [97/100] Batch [628/782] Loss: 0.3130 | Acc: 85.84%\n",
      "Train Epoch [97/100] Batch [629/782] Loss: 0.5272 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [630/782] Loss: 0.5790 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [631/782] Loss: 0.6031 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [632/782] Loss: 0.4269 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [633/782] Loss: 0.3717 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [634/782] Loss: 0.4199 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [635/782] Loss: 0.4557 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [636/782] Loss: 0.3508 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [637/782] Loss: 0.4617 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [638/782] Loss: 0.3527 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [639/782] Loss: 0.3713 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [640/782] Loss: 0.4267 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [641/782] Loss: 0.4241 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [642/782] Loss: 0.2951 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [643/782] Loss: 0.5570 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [644/782] Loss: 0.5999 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [645/782] Loss: 0.4100 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [646/782] Loss: 0.4213 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [647/782] Loss: 0.2866 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [648/782] Loss: 0.5136 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [649/782] Loss: 0.3962 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [650/782] Loss: 0.4089 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [651/782] Loss: 0.4117 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [652/782] Loss: 0.5144 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [653/782] Loss: 0.2778 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [654/782] Loss: 0.5797 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [655/782] Loss: 0.4523 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [656/782] Loss: 0.3067 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [657/782] Loss: 0.3667 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [658/782] Loss: 0.3006 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [659/782] Loss: 0.4336 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [660/782] Loss: 0.1808 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [661/782] Loss: 0.4477 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [662/782] Loss: 0.4502 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [663/782] Loss: 0.4737 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [664/782] Loss: 0.2718 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [665/782] Loss: 0.4176 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [666/782] Loss: 0.5920 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [667/782] Loss: 0.3139 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [668/782] Loss: 0.4641 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [669/782] Loss: 0.4316 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [670/782] Loss: 0.5037 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [671/782] Loss: 0.2409 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [672/782] Loss: 0.2150 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [673/782] Loss: 0.3814 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [674/782] Loss: 0.4840 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [675/782] Loss: 0.5030 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [676/782] Loss: 0.3821 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [677/782] Loss: 0.3134 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [678/782] Loss: 0.3544 | Acc: 85.82%\n",
      "Train Epoch [97/100] Batch [679/782] Loss: 0.5881 | Acc: 85.81%\n",
      "Train Epoch [97/100] Batch [680/782] Loss: 0.4658 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [681/782] Loss: 0.5565 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [682/782] Loss: 0.4094 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [683/782] Loss: 0.4134 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [684/782] Loss: 0.4699 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [685/782] Loss: 0.3015 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [686/782] Loss: 0.5459 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [687/782] Loss: 0.2005 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [688/782] Loss: 0.4052 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [689/782] Loss: 0.3998 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [690/782] Loss: 0.4243 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [691/782] Loss: 0.1913 | Acc: 85.80%\n",
      "Train Epoch [97/100] Batch [692/782] Loss: 0.4132 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [693/782] Loss: 0.6390 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [694/782] Loss: 0.5499 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [695/782] Loss: 0.3224 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [696/782] Loss: 0.2319 | Acc: 85.78%\n",
      "Train Epoch [97/100] Batch [697/782] Loss: 0.4755 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [698/782] Loss: 0.5361 | Acc: 85.79%\n",
      "Train Epoch [97/100] Batch [699/782] Loss: 0.7858 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [700/782] Loss: 0.3607 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [701/782] Loss: 0.4789 | Acc: 85.77%\n",
      "Train Epoch [97/100] Batch [702/782] Loss: 0.6175 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [703/782] Loss: 0.3317 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [704/782] Loss: 0.3913 | Acc: 85.76%\n",
      "Train Epoch [97/100] Batch [705/782] Loss: 0.5161 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [706/782] Loss: 0.5944 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [707/782] Loss: 0.3196 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [708/782] Loss: 0.4650 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [709/782] Loss: 0.2744 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [710/782] Loss: 0.5143 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [711/782] Loss: 0.6508 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [712/782] Loss: 0.3560 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [713/782] Loss: 0.4561 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [714/782] Loss: 0.4676 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [715/782] Loss: 0.3942 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [716/782] Loss: 0.4353 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [717/782] Loss: 0.4298 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [718/782] Loss: 0.2081 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [719/782] Loss: 0.4458 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [720/782] Loss: 0.3902 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [721/782] Loss: 0.4321 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [722/782] Loss: 0.3773 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [723/782] Loss: 0.4428 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [724/782] Loss: 0.4353 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [725/782] Loss: 0.3690 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [726/782] Loss: 0.5020 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [727/782] Loss: 0.3895 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [728/782] Loss: 0.3103 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [729/782] Loss: 0.4036 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [730/782] Loss: 0.3877 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [731/782] Loss: 0.2663 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [732/782] Loss: 0.5138 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [733/782] Loss: 0.5220 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [734/782] Loss: 0.3926 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [735/782] Loss: 0.3418 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [736/782] Loss: 0.5357 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [737/782] Loss: 0.3784 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [738/782] Loss: 0.3077 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [739/782] Loss: 0.4625 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [740/782] Loss: 0.4731 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [741/782] Loss: 0.5111 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [742/782] Loss: 0.4059 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [743/782] Loss: 0.2262 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [744/782] Loss: 0.3863 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [745/782] Loss: 0.5921 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [746/782] Loss: 0.3084 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [747/782] Loss: 0.5605 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [748/782] Loss: 0.4951 | Acc: 85.70%\n",
      "Train Epoch [97/100] Batch [749/782] Loss: 0.2874 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [750/782] Loss: 0.3471 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [751/782] Loss: 0.2808 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [752/782] Loss: 0.3920 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [753/782] Loss: 0.3934 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [754/782] Loss: 0.2562 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [755/782] Loss: 0.3931 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [756/782] Loss: 0.4314 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [757/782] Loss: 0.3531 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [758/782] Loss: 0.3844 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [759/782] Loss: 0.4500 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [760/782] Loss: 0.2822 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [761/782] Loss: 0.3803 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [762/782] Loss: 0.3406 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [763/782] Loss: 0.3639 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [764/782] Loss: 0.5031 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [765/782] Loss: 0.4785 | Acc: 85.71%\n",
      "Train Epoch [97/100] Batch [766/782] Loss: 0.3124 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [767/782] Loss: 0.2040 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [768/782] Loss: 0.4498 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [769/782] Loss: 0.4437 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [770/782] Loss: 0.2046 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [771/782] Loss: 0.3612 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [772/782] Loss: 0.3640 | Acc: 85.72%\n",
      "Train Epoch [97/100] Batch [773/782] Loss: 0.3413 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [774/782] Loss: 0.5194 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [775/782] Loss: 0.3650 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [776/782] Loss: 0.3587 | Acc: 85.73%\n",
      "Train Epoch [97/100] Batch [777/782] Loss: 0.3034 | Acc: 85.74%\n",
      "Train Epoch [97/100] Batch [778/782] Loss: 0.4150 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [779/782] Loss: 0.2681 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [780/782] Loss: 0.4761 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [781/782] Loss: 0.4913 | Acc: 85.75%\n",
      "Train Epoch [97/100] Batch [782/782] Loss: 0.6250 | Acc: 85.75%\n",
      "Epoch 97 completed in 30.45s.\n",
      "Test Epoch [97/100] Loss: 1.0234 | Acc: 72.13% | Inference Time: 8.34s\n",
      "Epoch 97 results saved to CSV.\n",
      "Epoch 98/100\n",
      "Train Epoch [98/100] Batch [1/782] Loss: 0.4588 | Acc: 81.25%\n",
      "Train Epoch [98/100] Batch [2/782] Loss: 0.4377 | Acc: 78.91%\n",
      "Train Epoch [98/100] Batch [3/782] Loss: 0.3749 | Acc: 82.29%\n",
      "Train Epoch [98/100] Batch [4/782] Loss: 0.2411 | Acc: 85.16%\n",
      "Train Epoch [98/100] Batch [5/782] Loss: 0.4953 | Acc: 84.69%\n",
      "Train Epoch [98/100] Batch [6/782] Loss: 0.3267 | Acc: 84.90%\n",
      "Train Epoch [98/100] Batch [7/782] Loss: 0.4483 | Acc: 84.15%\n",
      "Train Epoch [98/100] Batch [8/782] Loss: 0.3700 | Acc: 84.38%\n",
      "Train Epoch [98/100] Batch [9/782] Loss: 0.2719 | Acc: 84.90%\n",
      "Train Epoch [98/100] Batch [10/782] Loss: 0.3873 | Acc: 85.16%\n",
      "Train Epoch [98/100] Batch [11/782] Loss: 0.3984 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [12/782] Loss: 0.5372 | Acc: 84.64%\n",
      "Train Epoch [98/100] Batch [13/782] Loss: 0.3372 | Acc: 84.62%\n",
      "Train Epoch [98/100] Batch [14/782] Loss: 0.3626 | Acc: 84.60%\n",
      "Train Epoch [98/100] Batch [15/782] Loss: 0.2986 | Acc: 85.10%\n",
      "Train Epoch [98/100] Batch [16/782] Loss: 0.5867 | Acc: 84.67%\n",
      "Train Epoch [98/100] Batch [17/782] Loss: 0.3322 | Acc: 85.02%\n",
      "Train Epoch [98/100] Batch [18/782] Loss: 0.3169 | Acc: 85.16%\n",
      "Train Epoch [98/100] Batch [19/782] Loss: 0.3934 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [20/782] Loss: 0.3468 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [21/782] Loss: 0.4100 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [22/782] Loss: 0.4174 | Acc: 85.09%\n",
      "Train Epoch [98/100] Batch [23/782] Loss: 0.2783 | Acc: 85.33%\n",
      "Train Epoch [98/100] Batch [24/782] Loss: 0.3697 | Acc: 85.16%\n",
      "Train Epoch [98/100] Batch [25/782] Loss: 0.4837 | Acc: 85.06%\n",
      "Train Epoch [98/100] Batch [26/782] Loss: 0.5306 | Acc: 84.80%\n",
      "Train Epoch [98/100] Batch [27/782] Loss: 0.3055 | Acc: 84.95%\n",
      "Train Epoch [98/100] Batch [28/782] Loss: 0.4208 | Acc: 84.88%\n",
      "Train Epoch [98/100] Batch [29/782] Loss: 0.3757 | Acc: 84.97%\n",
      "Train Epoch [98/100] Batch [30/782] Loss: 0.3925 | Acc: 84.95%\n",
      "Train Epoch [98/100] Batch [31/782] Loss: 0.4614 | Acc: 84.98%\n",
      "Train Epoch [98/100] Batch [32/782] Loss: 0.3823 | Acc: 84.96%\n",
      "Train Epoch [98/100] Batch [33/782] Loss: 0.4155 | Acc: 85.04%\n",
      "Train Epoch [98/100] Batch [34/782] Loss: 0.4377 | Acc: 85.11%\n",
      "Train Epoch [98/100] Batch [35/782] Loss: 0.5347 | Acc: 84.96%\n",
      "Train Epoch [98/100] Batch [36/782] Loss: 0.4206 | Acc: 84.98%\n",
      "Train Epoch [98/100] Batch [37/782] Loss: 0.3620 | Acc: 85.09%\n",
      "Train Epoch [98/100] Batch [38/782] Loss: 0.3324 | Acc: 85.24%\n",
      "Train Epoch [98/100] Batch [39/782] Loss: 0.5662 | Acc: 85.06%\n",
      "Train Epoch [98/100] Batch [40/782] Loss: 0.2723 | Acc: 85.23%\n",
      "Train Epoch [98/100] Batch [41/782] Loss: 0.3506 | Acc: 85.25%\n",
      "Train Epoch [98/100] Batch [42/782] Loss: 0.5237 | Acc: 85.23%\n",
      "Train Epoch [98/100] Batch [43/782] Loss: 0.2348 | Acc: 85.32%\n",
      "Train Epoch [98/100] Batch [44/782] Loss: 0.3890 | Acc: 85.26%\n",
      "Train Epoch [98/100] Batch [45/782] Loss: 0.4595 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [46/782] Loss: 0.3490 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [47/782] Loss: 0.3054 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [48/782] Loss: 0.3922 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [49/782] Loss: 0.3896 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [50/782] Loss: 0.3803 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [51/782] Loss: 0.2604 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [52/782] Loss: 0.4254 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [53/782] Loss: 0.3336 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [54/782] Loss: 0.5641 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [55/782] Loss: 0.4472 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [56/782] Loss: 0.3049 | Acc: 85.57%\n",
      "Train Epoch [98/100] Batch [57/782] Loss: 0.4020 | Acc: 85.55%\n",
      "Train Epoch [98/100] Batch [58/782] Loss: 0.3895 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [59/782] Loss: 0.4863 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [60/782] Loss: 0.2548 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [61/782] Loss: 0.4770 | Acc: 85.58%\n",
      "Train Epoch [98/100] Batch [62/782] Loss: 0.3694 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [63/782] Loss: 0.3212 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [64/782] Loss: 0.2718 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [65/782] Loss: 0.2735 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [66/782] Loss: 0.4992 | Acc: 85.75%\n",
      "Train Epoch [98/100] Batch [67/782] Loss: 0.1593 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [68/782] Loss: 0.2763 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [69/782] Loss: 0.4759 | Acc: 85.91%\n",
      "Train Epoch [98/100] Batch [70/782] Loss: 0.3311 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [71/782] Loss: 0.3226 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [72/782] Loss: 0.3939 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [73/782] Loss: 0.4175 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [74/782] Loss: 0.2891 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [75/782] Loss: 0.3307 | Acc: 86.04%\n",
      "Train Epoch [98/100] Batch [76/782] Loss: 0.3647 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [77/782] Loss: 0.3559 | Acc: 86.04%\n",
      "Train Epoch [98/100] Batch [78/782] Loss: 0.4366 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [79/782] Loss: 0.4257 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [80/782] Loss: 0.2191 | Acc: 86.13%\n",
      "Train Epoch [98/100] Batch [81/782] Loss: 0.3763 | Acc: 86.11%\n",
      "Train Epoch [98/100] Batch [82/782] Loss: 0.2988 | Acc: 86.15%\n",
      "Train Epoch [98/100] Batch [83/782] Loss: 0.3817 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [84/782] Loss: 0.3969 | Acc: 86.09%\n",
      "Train Epoch [98/100] Batch [85/782] Loss: 0.2805 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [86/782] Loss: 0.3668 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [87/782] Loss: 0.2881 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [88/782] Loss: 0.4246 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [89/782] Loss: 0.4026 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [90/782] Loss: 0.5501 | Acc: 85.99%\n",
      "Train Epoch [98/100] Batch [91/782] Loss: 0.3536 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [92/782] Loss: 0.3452 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [93/782] Loss: 0.2652 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [94/782] Loss: 0.6174 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [95/782] Loss: 0.3139 | Acc: 86.07%\n",
      "Train Epoch [98/100] Batch [96/782] Loss: 0.2867 | Acc: 86.10%\n",
      "Train Epoch [98/100] Batch [97/782] Loss: 0.4879 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [98/782] Loss: 0.2570 | Acc: 86.07%\n",
      "Train Epoch [98/100] Batch [99/782] Loss: 0.4564 | Acc: 86.05%\n",
      "Train Epoch [98/100] Batch [100/782] Loss: 0.3250 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [101/782] Loss: 0.5318 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [102/782] Loss: 0.4750 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [103/782] Loss: 0.5802 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [104/782] Loss: 0.1907 | Acc: 86.03%\n",
      "Train Epoch [98/100] Batch [105/782] Loss: 0.5771 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [106/782] Loss: 0.4577 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [107/782] Loss: 0.3899 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [108/782] Loss: 0.3880 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [109/782] Loss: 0.4955 | Acc: 85.92%\n",
      "Train Epoch [98/100] Batch [110/782] Loss: 0.5840 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [111/782] Loss: 0.3539 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [112/782] Loss: 0.3830 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [113/782] Loss: 0.3055 | Acc: 85.92%\n",
      "Train Epoch [98/100] Batch [114/782] Loss: 0.2910 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [115/782] Loss: 0.4215 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [116/782] Loss: 0.3694 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [117/782] Loss: 0.2910 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [118/782] Loss: 0.3176 | Acc: 85.99%\n",
      "Train Epoch [98/100] Batch [119/782] Loss: 0.3788 | Acc: 86.03%\n",
      "Train Epoch [98/100] Batch [120/782] Loss: 0.2786 | Acc: 86.05%\n",
      "Train Epoch [98/100] Batch [121/782] Loss: 0.3958 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [122/782] Loss: 0.4319 | Acc: 86.05%\n",
      "Train Epoch [98/100] Batch [123/782] Loss: 0.5004 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [124/782] Loss: 0.4819 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [125/782] Loss: 0.2476 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [126/782] Loss: 0.5680 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [127/782] Loss: 0.4825 | Acc: 85.93%\n",
      "Train Epoch [98/100] Batch [128/782] Loss: 0.3936 | Acc: 85.89%\n",
      "Train Epoch [98/100] Batch [129/782] Loss: 0.3345 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [130/782] Loss: 0.4397 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [131/782] Loss: 0.3593 | Acc: 85.88%\n",
      "Train Epoch [98/100] Batch [132/782] Loss: 0.3231 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [133/782] Loss: 0.7375 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [134/782] Loss: 0.5186 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [135/782] Loss: 0.1898 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [136/782] Loss: 0.4160 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [137/782] Loss: 0.2724 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [138/782] Loss: 0.4727 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [139/782] Loss: 0.4193 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [140/782] Loss: 0.4174 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [141/782] Loss: 0.1857 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [142/782] Loss: 0.4728 | Acc: 85.93%\n",
      "Train Epoch [98/100] Batch [143/782] Loss: 0.5465 | Acc: 85.92%\n",
      "Train Epoch [98/100] Batch [144/782] Loss: 0.2839 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [145/782] Loss: 0.1726 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [146/782] Loss: 0.4227 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [147/782] Loss: 0.4071 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [148/782] Loss: 0.3805 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [149/782] Loss: 0.3944 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [150/782] Loss: 0.2893 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [151/782] Loss: 0.2981 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [152/782] Loss: 0.3443 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [153/782] Loss: 0.2593 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [154/782] Loss: 0.4199 | Acc: 86.05%\n",
      "Train Epoch [98/100] Batch [155/782] Loss: 0.4538 | Acc: 86.04%\n",
      "Train Epoch [98/100] Batch [156/782] Loss: 0.3097 | Acc: 86.07%\n",
      "Train Epoch [98/100] Batch [157/782] Loss: 0.2858 | Acc: 86.10%\n",
      "Train Epoch [98/100] Batch [158/782] Loss: 0.2375 | Acc: 86.13%\n",
      "Train Epoch [98/100] Batch [159/782] Loss: 0.3440 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [160/782] Loss: 0.2656 | Acc: 86.16%\n",
      "Train Epoch [98/100] Batch [161/782] Loss: 0.5107 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [162/782] Loss: 0.2562 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [163/782] Loss: 0.2901 | Acc: 86.17%\n",
      "Train Epoch [98/100] Batch [164/782] Loss: 0.3981 | Acc: 86.15%\n",
      "Train Epoch [98/100] Batch [165/782] Loss: 0.2524 | Acc: 86.17%\n",
      "Train Epoch [98/100] Batch [166/782] Loss: 0.3748 | Acc: 86.18%\n",
      "Train Epoch [98/100] Batch [167/782] Loss: 0.4373 | Acc: 86.15%\n",
      "Train Epoch [98/100] Batch [168/782] Loss: 0.3506 | Acc: 86.16%\n",
      "Train Epoch [98/100] Batch [169/782] Loss: 0.4192 | Acc: 86.13%\n",
      "Train Epoch [98/100] Batch [170/782] Loss: 0.5422 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [171/782] Loss: 0.3967 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [172/782] Loss: 0.3084 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [173/782] Loss: 0.2500 | Acc: 86.16%\n",
      "Train Epoch [98/100] Batch [174/782] Loss: 0.3415 | Acc: 86.16%\n",
      "Train Epoch [98/100] Batch [175/782] Loss: 0.4052 | Acc: 86.17%\n",
      "Train Epoch [98/100] Batch [176/782] Loss: 0.3316 | Acc: 86.17%\n",
      "Train Epoch [98/100] Batch [177/782] Loss: 0.5159 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [178/782] Loss: 0.4618 | Acc: 86.14%\n",
      "Train Epoch [98/100] Batch [179/782] Loss: 0.4671 | Acc: 86.11%\n",
      "Train Epoch [98/100] Batch [180/782] Loss: 0.4409 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [181/782] Loss: 0.5205 | Acc: 86.09%\n",
      "Train Epoch [98/100] Batch [182/782] Loss: 0.3757 | Acc: 86.10%\n",
      "Train Epoch [98/100] Batch [183/782] Loss: 0.3422 | Acc: 86.11%\n",
      "Train Epoch [98/100] Batch [184/782] Loss: 0.4283 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [185/782] Loss: 0.4111 | Acc: 86.12%\n",
      "Train Epoch [98/100] Batch [186/782] Loss: 0.4303 | Acc: 86.11%\n",
      "Train Epoch [98/100] Batch [187/782] Loss: 0.3418 | Acc: 86.10%\n",
      "Train Epoch [98/100] Batch [188/782] Loss: 0.5385 | Acc: 86.05%\n",
      "Train Epoch [98/100] Batch [189/782] Loss: 0.3389 | Acc: 86.04%\n",
      "Train Epoch [98/100] Batch [190/782] Loss: 0.4040 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [191/782] Loss: 0.2422 | Acc: 86.06%\n",
      "Train Epoch [98/100] Batch [192/782] Loss: 0.2325 | Acc: 86.09%\n",
      "Train Epoch [98/100] Batch [193/782] Loss: 0.4997 | Acc: 86.08%\n",
      "Train Epoch [98/100] Batch [194/782] Loss: 0.5697 | Acc: 86.07%\n",
      "Train Epoch [98/100] Batch [195/782] Loss: 0.4365 | Acc: 86.03%\n",
      "Train Epoch [98/100] Batch [196/782] Loss: 0.4423 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [197/782] Loss: 0.4049 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [198/782] Loss: 0.3941 | Acc: 86.02%\n",
      "Train Epoch [98/100] Batch [199/782] Loss: 0.6672 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [200/782] Loss: 0.4643 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [201/782] Loss: 0.2862 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [202/782] Loss: 0.2649 | Acc: 85.99%\n",
      "Train Epoch [98/100] Batch [203/782] Loss: 0.3516 | Acc: 85.99%\n",
      "Train Epoch [98/100] Batch [204/782] Loss: 0.4372 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [205/782] Loss: 0.3437 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [206/782] Loss: 0.4513 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [207/782] Loss: 0.3953 | Acc: 86.01%\n",
      "Train Epoch [98/100] Batch [208/782] Loss: 0.3487 | Acc: 86.04%\n",
      "Train Epoch [98/100] Batch [209/782] Loss: 0.6210 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [210/782] Loss: 0.3589 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [211/782] Loss: 0.4809 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [212/782] Loss: 0.4421 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [213/782] Loss: 0.3340 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [214/782] Loss: 0.2854 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [215/782] Loss: 0.2742 | Acc: 86.00%\n",
      "Train Epoch [98/100] Batch [216/782] Loss: 0.4596 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [217/782] Loss: 0.4111 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [218/782] Loss: 0.4170 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [219/782] Loss: 0.3959 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [220/782] Loss: 0.3466 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [221/782] Loss: 0.2862 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [222/782] Loss: 0.3962 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [223/782] Loss: 0.3229 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [224/782] Loss: 0.5993 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [225/782] Loss: 0.4156 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [226/782] Loss: 0.3973 | Acc: 85.97%\n",
      "Train Epoch [98/100] Batch [227/782] Loss: 0.4416 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [228/782] Loss: 0.3755 | Acc: 85.96%\n",
      "Train Epoch [98/100] Batch [229/782] Loss: 0.2857 | Acc: 85.98%\n",
      "Train Epoch [98/100] Batch [230/782] Loss: 0.6010 | Acc: 85.95%\n",
      "Train Epoch [98/100] Batch [231/782] Loss: 0.4981 | Acc: 85.94%\n",
      "Train Epoch [98/100] Batch [232/782] Loss: 0.5376 | Acc: 85.91%\n",
      "Train Epoch [98/100] Batch [233/782] Loss: 0.5101 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [234/782] Loss: 0.5410 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [235/782] Loss: 0.4204 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [236/782] Loss: 0.3787 | Acc: 85.89%\n",
      "Train Epoch [98/100] Batch [237/782] Loss: 0.3016 | Acc: 85.90%\n",
      "Train Epoch [98/100] Batch [238/782] Loss: 0.6064 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [239/782] Loss: 0.3582 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [240/782] Loss: 0.2953 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [241/782] Loss: 0.5699 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [242/782] Loss: 0.3597 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [243/782] Loss: 0.3138 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [244/782] Loss: 0.4404 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [245/782] Loss: 0.5102 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [246/782] Loss: 0.3143 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [247/782] Loss: 0.5451 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [248/782] Loss: 0.3982 | Acc: 85.87%\n",
      "Train Epoch [98/100] Batch [249/782] Loss: 0.5205 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [250/782] Loss: 0.3661 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [251/782] Loss: 0.3709 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [252/782] Loss: 0.4636 | Acc: 85.85%\n",
      "Train Epoch [98/100] Batch [253/782] Loss: 0.3673 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [254/782] Loss: 0.3153 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [255/782] Loss: 0.4674 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [256/782] Loss: 0.5964 | Acc: 85.80%\n",
      "Train Epoch [98/100] Batch [257/782] Loss: 0.3283 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [258/782] Loss: 0.4920 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [259/782] Loss: 0.4106 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [260/782] Loss: 0.5103 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [261/782] Loss: 0.4192 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [262/782] Loss: 0.3662 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [263/782] Loss: 0.3448 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [264/782] Loss: 0.2250 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [265/782] Loss: 0.4806 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [266/782] Loss: 0.3896 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [267/782] Loss: 0.2871 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [268/782] Loss: 0.1958 | Acc: 85.86%\n",
      "Train Epoch [98/100] Batch [269/782] Loss: 0.5367 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [270/782] Loss: 0.3167 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [271/782] Loss: 0.3275 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [272/782] Loss: 0.4063 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [273/782] Loss: 0.4231 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [274/782] Loss: 0.4467 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [275/782] Loss: 0.6359 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [276/782] Loss: 0.4430 | Acc: 85.80%\n",
      "Train Epoch [98/100] Batch [277/782] Loss: 0.4328 | Acc: 85.78%\n",
      "Train Epoch [98/100] Batch [278/782] Loss: 0.3869 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [279/782] Loss: 0.1614 | Acc: 85.80%\n",
      "Train Epoch [98/100] Batch [280/782] Loss: 0.4771 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [281/782] Loss: 0.4062 | Acc: 85.78%\n",
      "Train Epoch [98/100] Batch [282/782] Loss: 0.4686 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [283/782] Loss: 0.3081 | Acc: 85.80%\n",
      "Train Epoch [98/100] Batch [284/782] Loss: 0.2878 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [285/782] Loss: 0.4188 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [286/782] Loss: 0.2231 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [287/782] Loss: 0.4143 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [288/782] Loss: 0.7780 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [289/782] Loss: 0.3233 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [290/782] Loss: 0.3129 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [291/782] Loss: 0.3603 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [292/782] Loss: 0.2807 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [293/782] Loss: 0.4668 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [294/782] Loss: 0.3707 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [295/782] Loss: 0.2606 | Acc: 85.84%\n",
      "Train Epoch [98/100] Batch [296/782] Loss: 0.5669 | Acc: 85.83%\n",
      "Train Epoch [98/100] Batch [297/782] Loss: 0.5083 | Acc: 85.82%\n",
      "Train Epoch [98/100] Batch [298/782] Loss: 0.4905 | Acc: 85.81%\n",
      "Train Epoch [98/100] Batch [299/782] Loss: 0.5541 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [300/782] Loss: 0.5558 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [301/782] Loss: 0.2779 | Acc: 85.78%\n",
      "Train Epoch [98/100] Batch [302/782] Loss: 0.5907 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [303/782] Loss: 0.3551 | Acc: 85.76%\n",
      "Train Epoch [98/100] Batch [304/782] Loss: 0.3604 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [305/782] Loss: 0.4823 | Acc: 85.75%\n",
      "Train Epoch [98/100] Batch [306/782] Loss: 0.3412 | Acc: 85.76%\n",
      "Train Epoch [98/100] Batch [307/782] Loss: 0.5239 | Acc: 85.75%\n",
      "Train Epoch [98/100] Batch [308/782] Loss: 0.2615 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [309/782] Loss: 0.3829 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [310/782] Loss: 0.3973 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [311/782] Loss: 0.3134 | Acc: 85.80%\n",
      "Train Epoch [98/100] Batch [312/782] Loss: 0.4249 | Acc: 85.79%\n",
      "Train Epoch [98/100] Batch [313/782] Loss: 0.4949 | Acc: 85.77%\n",
      "Train Epoch [98/100] Batch [314/782] Loss: 0.6650 | Acc: 85.72%\n",
      "Train Epoch [98/100] Batch [315/782] Loss: 0.5340 | Acc: 85.70%\n",
      "Train Epoch [98/100] Batch [316/782] Loss: 0.5535 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [317/782] Loss: 0.4422 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [318/782] Loss: 0.4880 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [319/782] Loss: 0.4484 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [320/782] Loss: 0.2725 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [321/782] Loss: 0.4309 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [322/782] Loss: 0.4112 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [323/782] Loss: 0.2470 | Acc: 85.69%\n",
      "Train Epoch [98/100] Batch [324/782] Loss: 0.6870 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [325/782] Loss: 0.4291 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [326/782] Loss: 0.5321 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [327/782] Loss: 0.5045 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [328/782] Loss: 0.3624 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [329/782] Loss: 0.3396 | Acc: 85.69%\n",
      "Train Epoch [98/100] Batch [330/782] Loss: 0.3834 | Acc: 85.68%\n",
      "Train Epoch [98/100] Batch [331/782] Loss: 0.5023 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [332/782] Loss: 0.5333 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [333/782] Loss: 0.4500 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [334/782] Loss: 0.4865 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [335/782] Loss: 0.4654 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [336/782] Loss: 0.4940 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [337/782] Loss: 0.4516 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [338/782] Loss: 0.3822 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [339/782] Loss: 0.5006 | Acc: 85.63%\n",
      "Train Epoch [98/100] Batch [340/782] Loss: 0.4685 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [341/782] Loss: 0.3735 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [342/782] Loss: 0.3374 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [343/782] Loss: 0.5289 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [344/782] Loss: 0.2474 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [345/782] Loss: 0.4825 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [346/782] Loss: 0.3775 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [347/782] Loss: 0.2925 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [348/782] Loss: 0.5381 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [349/782] Loss: 0.4284 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [350/782] Loss: 0.4663 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [351/782] Loss: 0.4158 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [352/782] Loss: 0.5092 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [353/782] Loss: 0.4781 | Acc: 85.58%\n",
      "Train Epoch [98/100] Batch [354/782] Loss: 0.2516 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [355/782] Loss: 0.4858 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [356/782] Loss: 0.2780 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [357/782] Loss: 0.3452 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [358/782] Loss: 0.4683 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [359/782] Loss: 0.3659 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [360/782] Loss: 0.3621 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [361/782] Loss: 0.4551 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [362/782] Loss: 0.4814 | Acc: 85.57%\n",
      "Train Epoch [98/100] Batch [363/782] Loss: 0.4027 | Acc: 85.58%\n",
      "Train Epoch [98/100] Batch [364/782] Loss: 0.3501 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [365/782] Loss: 0.3227 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [366/782] Loss: 0.4328 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [367/782] Loss: 0.4070 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [368/782] Loss: 0.3134 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [369/782] Loss: 0.5490 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [370/782] Loss: 0.4189 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [371/782] Loss: 0.2987 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [372/782] Loss: 0.4999 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [373/782] Loss: 0.3405 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [374/782] Loss: 0.4865 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [375/782] Loss: 0.2683 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [376/782] Loss: 0.2613 | Acc: 85.63%\n",
      "Train Epoch [98/100] Batch [377/782] Loss: 0.6056 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [378/782] Loss: 0.3799 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [379/782] Loss: 0.3678 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [380/782] Loss: 0.2614 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [381/782] Loss: 0.5643 | Acc: 85.63%\n",
      "Train Epoch [98/100] Batch [382/782] Loss: 0.3651 | Acc: 85.63%\n",
      "Train Epoch [98/100] Batch [383/782] Loss: 0.4144 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [384/782] Loss: 0.1456 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [385/782] Loss: 0.2930 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [386/782] Loss: 0.3315 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [387/782] Loss: 0.3472 | Acc: 85.67%\n",
      "Train Epoch [98/100] Batch [388/782] Loss: 0.5332 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [389/782] Loss: 0.4574 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [390/782] Loss: 0.3875 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [391/782] Loss: 0.3567 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [392/782] Loss: 0.4704 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [393/782] Loss: 0.2955 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [394/782] Loss: 0.3898 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [395/782] Loss: 0.4577 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [396/782] Loss: 0.4186 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [397/782] Loss: 0.3055 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [398/782] Loss: 0.4652 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [399/782] Loss: 0.3823 | Acc: 85.64%\n",
      "Train Epoch [98/100] Batch [400/782] Loss: 0.3027 | Acc: 85.65%\n",
      "Train Epoch [98/100] Batch [401/782] Loss: 0.4101 | Acc: 85.66%\n",
      "Train Epoch [98/100] Batch [402/782] Loss: 0.5638 | Acc: 85.63%\n",
      "Train Epoch [98/100] Batch [403/782] Loss: 0.4230 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [404/782] Loss: 0.3334 | Acc: 85.62%\n",
      "Train Epoch [98/100] Batch [405/782] Loss: 0.4918 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [406/782] Loss: 0.3756 | Acc: 85.61%\n",
      "Train Epoch [98/100] Batch [407/782] Loss: 0.6169 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [408/782] Loss: 0.3215 | Acc: 85.60%\n",
      "Train Epoch [98/100] Batch [409/782] Loss: 0.4588 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [410/782] Loss: 0.4831 | Acc: 85.58%\n",
      "Train Epoch [98/100] Batch [411/782] Loss: 0.6034 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [412/782] Loss: 0.3714 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [413/782] Loss: 0.3139 | Acc: 85.57%\n",
      "Train Epoch [98/100] Batch [414/782] Loss: 0.2958 | Acc: 85.59%\n",
      "Train Epoch [98/100] Batch [415/782] Loss: 0.4405 | Acc: 85.58%\n",
      "Train Epoch [98/100] Batch [416/782] Loss: 0.5273 | Acc: 85.55%\n",
      "Train Epoch [98/100] Batch [417/782] Loss: 0.3026 | Acc: 85.56%\n",
      "Train Epoch [98/100] Batch [418/782] Loss: 0.6320 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [419/782] Loss: 0.6536 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [420/782] Loss: 0.4451 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [421/782] Loss: 0.4864 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [422/782] Loss: 0.3602 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [423/782] Loss: 0.4172 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [424/782] Loss: 0.3460 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [425/782] Loss: 0.2485 | Acc: 85.54%\n",
      "Train Epoch [98/100] Batch [426/782] Loss: 0.6000 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [427/782] Loss: 0.2346 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [428/782] Loss: 0.4348 | Acc: 85.54%\n",
      "Train Epoch [98/100] Batch [429/782] Loss: 0.4404 | Acc: 85.53%\n",
      "Train Epoch [98/100] Batch [430/782] Loss: 0.8183 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [431/782] Loss: 0.4244 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [432/782] Loss: 0.4080 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [433/782] Loss: 0.4624 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [434/782] Loss: 0.4226 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [435/782] Loss: 0.2364 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [436/782] Loss: 0.4072 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [437/782] Loss: 0.5100 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [438/782] Loss: 0.5301 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [439/782] Loss: 0.5857 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [440/782] Loss: 0.5563 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [441/782] Loss: 0.5031 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [442/782] Loss: 0.3354 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [443/782] Loss: 0.5632 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [444/782] Loss: 0.3892 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [445/782] Loss: 0.3629 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [446/782] Loss: 0.3201 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [447/782] Loss: 0.4173 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [448/782] Loss: 0.5812 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [449/782] Loss: 0.4349 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [450/782] Loss: 0.5485 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [451/782] Loss: 0.2952 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [452/782] Loss: 0.4596 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [453/782] Loss: 0.5251 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [454/782] Loss: 0.5482 | Acc: 85.40%\n",
      "Train Epoch [98/100] Batch [455/782] Loss: 0.3228 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [456/782] Loss: 0.3284 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [457/782] Loss: 0.3080 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [458/782] Loss: 0.2399 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [459/782] Loss: 0.4255 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [460/782] Loss: 0.4191 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [461/782] Loss: 0.3916 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [462/782] Loss: 0.3658 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [463/782] Loss: 0.3340 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [464/782] Loss: 0.5236 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [465/782] Loss: 0.3787 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [466/782] Loss: 0.4133 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [467/782] Loss: 0.2133 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [468/782] Loss: 0.5057 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [469/782] Loss: 0.5739 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [470/782] Loss: 0.3473 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [471/782] Loss: 0.4392 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [472/782] Loss: 0.3488 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [473/782] Loss: 0.3055 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [474/782] Loss: 0.4595 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [475/782] Loss: 0.5041 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [476/782] Loss: 0.3295 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [477/782] Loss: 0.4171 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [478/782] Loss: 0.4481 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [479/782] Loss: 0.3509 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [480/782] Loss: 0.3318 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [481/782] Loss: 0.3511 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [482/782] Loss: 0.2586 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [483/782] Loss: 0.3699 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [484/782] Loss: 0.3744 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [485/782] Loss: 0.5071 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [486/782] Loss: 0.3677 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [487/782] Loss: 0.1805 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [488/782] Loss: 0.3477 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [489/782] Loss: 0.5352 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [490/782] Loss: 0.2661 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [491/782] Loss: 0.3849 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [492/782] Loss: 0.3463 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [493/782] Loss: 0.4078 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [494/782] Loss: 0.2817 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [495/782] Loss: 0.6471 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [496/782] Loss: 0.3635 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [497/782] Loss: 0.3488 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [498/782] Loss: 0.3385 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [499/782] Loss: 0.4957 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [500/782] Loss: 0.3214 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [501/782] Loss: 0.3176 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [502/782] Loss: 0.6333 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [503/782] Loss: 0.5526 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [504/782] Loss: 0.6261 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [505/782] Loss: 0.6222 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [506/782] Loss: 0.3430 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [507/782] Loss: 0.3596 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [508/782] Loss: 0.3923 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [509/782] Loss: 0.4465 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [510/782] Loss: 0.4619 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [511/782] Loss: 0.3378 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [512/782] Loss: 0.2711 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [513/782] Loss: 0.4057 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [514/782] Loss: 0.4485 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [515/782] Loss: 0.5480 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [516/782] Loss: 0.3668 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [517/782] Loss: 0.6729 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [518/782] Loss: 0.3217 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [519/782] Loss: 0.2700 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [520/782] Loss: 0.4757 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [521/782] Loss: 0.5160 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [522/782] Loss: 0.5641 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [523/782] Loss: 0.3294 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [524/782] Loss: 0.3723 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [525/782] Loss: 0.4677 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [526/782] Loss: 0.4760 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [527/782] Loss: 0.2673 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [528/782] Loss: 0.2631 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [529/782] Loss: 0.5726 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [530/782] Loss: 0.4328 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [531/782] Loss: 0.6314 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [532/782] Loss: 0.4177 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [533/782] Loss: 0.4123 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [534/782] Loss: 0.5118 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [535/782] Loss: 0.3694 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [536/782] Loss: 0.3423 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [537/782] Loss: 0.3173 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [538/782] Loss: 0.3063 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [539/782] Loss: 0.3595 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [540/782] Loss: 0.4525 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [541/782] Loss: 0.2993 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [542/782] Loss: 0.3639 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [543/782] Loss: 0.3052 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [544/782] Loss: 0.3845 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [545/782] Loss: 0.3860 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [546/782] Loss: 0.2771 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [547/782] Loss: 0.3123 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [548/782] Loss: 0.4786 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [549/782] Loss: 0.5244 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [550/782] Loss: 0.5115 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [551/782] Loss: 0.2466 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [552/782] Loss: 0.4819 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [553/782] Loss: 0.2963 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [554/782] Loss: 0.3527 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [555/782] Loss: 0.6206 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [556/782] Loss: 0.3207 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [557/782] Loss: 0.3182 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [558/782] Loss: 0.5716 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [559/782] Loss: 0.3621 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [560/782] Loss: 0.5040 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [561/782] Loss: 0.4110 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [562/782] Loss: 0.5053 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [563/782] Loss: 0.3008 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [564/782] Loss: 0.2780 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [565/782] Loss: 0.3392 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [566/782] Loss: 0.3372 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [567/782] Loss: 0.5031 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [568/782] Loss: 0.3050 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [569/782] Loss: 0.7027 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [570/782] Loss: 0.4305 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [571/782] Loss: 0.4996 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [572/782] Loss: 0.4685 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [573/782] Loss: 0.5495 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [574/782] Loss: 0.3701 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [575/782] Loss: 0.4405 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [576/782] Loss: 0.3635 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [577/782] Loss: 0.4828 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [578/782] Loss: 0.2850 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [579/782] Loss: 0.3892 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [580/782] Loss: 0.4312 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [581/782] Loss: 0.3362 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [582/782] Loss: 0.4068 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [583/782] Loss: 0.4342 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [584/782] Loss: 0.2834 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [585/782] Loss: 0.4060 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [586/782] Loss: 0.2976 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [587/782] Loss: 0.1978 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [588/782] Loss: 0.4937 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [589/782] Loss: 0.2786 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [590/782] Loss: 0.7082 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [591/782] Loss: 0.4215 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [592/782] Loss: 0.4705 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [593/782] Loss: 0.4484 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [594/782] Loss: 0.4537 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [595/782] Loss: 0.3761 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [596/782] Loss: 0.2490 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [597/782] Loss: 0.5381 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [598/782] Loss: 0.4087 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [599/782] Loss: 0.5042 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [600/782] Loss: 0.3093 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [601/782] Loss: 0.4409 | Acc: 85.40%\n",
      "Train Epoch [98/100] Batch [602/782] Loss: 0.6299 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [603/782] Loss: 0.3488 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [604/782] Loss: 0.6550 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [605/782] Loss: 0.4688 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [606/782] Loss: 0.2459 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [607/782] Loss: 0.4831 | Acc: 85.38%\n",
      "Train Epoch [98/100] Batch [608/782] Loss: 0.3524 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [609/782] Loss: 0.2777 | Acc: 85.38%\n",
      "Train Epoch [98/100] Batch [610/782] Loss: 0.3550 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [611/782] Loss: 0.7704 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [612/782] Loss: 0.6957 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [613/782] Loss: 0.5595 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [614/782] Loss: 0.3958 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [615/782] Loss: 0.3914 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [616/782] Loss: 0.4493 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [617/782] Loss: 0.5619 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [618/782] Loss: 0.3650 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [619/782] Loss: 0.5427 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [620/782] Loss: 0.4237 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [621/782] Loss: 0.4427 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [622/782] Loss: 0.4238 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [623/782] Loss: 0.2521 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [624/782] Loss: 0.4720 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [625/782] Loss: 0.4825 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [626/782] Loss: 0.3989 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [627/782] Loss: 0.5052 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [628/782] Loss: 0.3631 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [629/782] Loss: 0.3920 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [630/782] Loss: 0.2971 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [631/782] Loss: 0.6174 | Acc: 85.34%\n",
      "Train Epoch [98/100] Batch [632/782] Loss: 0.5036 | Acc: 85.33%\n",
      "Train Epoch [98/100] Batch [633/782] Loss: 0.4410 | Acc: 85.33%\n",
      "Train Epoch [98/100] Batch [634/782] Loss: 0.3099 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [635/782] Loss: 0.3963 | Acc: 85.35%\n",
      "Train Epoch [98/100] Batch [636/782] Loss: 0.2340 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [637/782] Loss: 0.3481 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [638/782] Loss: 0.3613 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [639/782] Loss: 0.4317 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [640/782] Loss: 0.3108 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [641/782] Loss: 0.4492 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [642/782] Loss: 0.4940 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [643/782] Loss: 0.5513 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [644/782] Loss: 0.3445 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [645/782] Loss: 0.4012 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [646/782] Loss: 0.3787 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [647/782] Loss: 0.5665 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [648/782] Loss: 0.5565 | Acc: 85.36%\n",
      "Train Epoch [98/100] Batch [649/782] Loss: 0.2649 | Acc: 85.37%\n",
      "Train Epoch [98/100] Batch [650/782] Loss: 0.4435 | Acc: 85.38%\n",
      "Train Epoch [98/100] Batch [651/782] Loss: 0.4517 | Acc: 85.38%\n",
      "Train Epoch [98/100] Batch [652/782] Loss: 0.1883 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [653/782] Loss: 0.4660 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [654/782] Loss: 0.3170 | Acc: 85.40%\n",
      "Train Epoch [98/100] Batch [655/782] Loss: 0.5011 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [656/782] Loss: 0.3691 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [657/782] Loss: 0.3586 | Acc: 85.39%\n",
      "Train Epoch [98/100] Batch [658/782] Loss: 0.2214 | Acc: 85.40%\n",
      "Train Epoch [98/100] Batch [659/782] Loss: 0.3328 | Acc: 85.41%\n",
      "Train Epoch [98/100] Batch [660/782] Loss: 0.2789 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [661/782] Loss: 0.1682 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [662/782] Loss: 0.2977 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [663/782] Loss: 0.3925 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [664/782] Loss: 0.3717 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [665/782] Loss: 0.4492 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [666/782] Loss: 0.3783 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [667/782] Loss: 0.2803 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [668/782] Loss: 0.3636 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [669/782] Loss: 0.3587 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [670/782] Loss: 0.4169 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [671/782] Loss: 0.3012 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [672/782] Loss: 0.4839 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [673/782] Loss: 0.3659 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [674/782] Loss: 0.4092 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [675/782] Loss: 0.4507 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [676/782] Loss: 0.3123 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [677/782] Loss: 0.3982 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [678/782] Loss: 0.4019 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [679/782] Loss: 0.7659 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [680/782] Loss: 0.4982 | Acc: 85.42%\n",
      "Train Epoch [98/100] Batch [681/782] Loss: 0.3552 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [682/782] Loss: 0.2064 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [683/782] Loss: 0.4878 | Acc: 85.43%\n",
      "Train Epoch [98/100] Batch [684/782] Loss: 0.3775 | Acc: 85.44%\n",
      "Train Epoch [98/100] Batch [685/782] Loss: 0.2623 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [686/782] Loss: 0.3586 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [687/782] Loss: 0.3021 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [688/782] Loss: 0.6510 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [689/782] Loss: 0.5024 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [690/782] Loss: 0.4174 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [691/782] Loss: 0.4645 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [692/782] Loss: 0.4150 | Acc: 85.45%\n",
      "Train Epoch [98/100] Batch [693/782] Loss: 0.2833 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [694/782] Loss: 0.2310 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [695/782] Loss: 0.3564 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [696/782] Loss: 0.3181 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [697/782] Loss: 0.2905 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [698/782] Loss: 0.4079 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [699/782] Loss: 0.5036 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [700/782] Loss: 0.3227 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [701/782] Loss: 0.2826 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [702/782] Loss: 0.6654 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [703/782] Loss: 0.3660 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [704/782] Loss: 0.3441 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [705/782] Loss: 0.3864 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [706/782] Loss: 0.4139 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [707/782] Loss: 0.3805 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [708/782] Loss: 0.3084 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [709/782] Loss: 0.4857 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [710/782] Loss: 0.3054 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [711/782] Loss: 0.2740 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [712/782] Loss: 0.4304 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [713/782] Loss: 0.3633 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [714/782] Loss: 0.4519 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [715/782] Loss: 0.2821 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [716/782] Loss: 0.5696 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [717/782] Loss: 0.5136 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [718/782] Loss: 0.3333 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [719/782] Loss: 0.5304 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [720/782] Loss: 0.4877 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [721/782] Loss: 0.4094 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [722/782] Loss: 0.4122 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [723/782] Loss: 0.2860 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [724/782] Loss: 0.4302 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [725/782] Loss: 0.3980 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [726/782] Loss: 0.3771 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [727/782] Loss: 0.2525 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [728/782] Loss: 0.3040 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [729/782] Loss: 0.2726 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [730/782] Loss: 0.4268 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [731/782] Loss: 0.3274 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [732/782] Loss: 0.5315 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [733/782] Loss: 0.3396 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [734/782] Loss: 0.4783 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [735/782] Loss: 0.6200 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [736/782] Loss: 0.2049 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [737/782] Loss: 0.3882 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [738/782] Loss: 0.4917 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [739/782] Loss: 0.2890 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [740/782] Loss: 0.4460 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [741/782] Loss: 0.5208 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [742/782] Loss: 0.6083 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [743/782] Loss: 0.4743 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [744/782] Loss: 0.4301 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [745/782] Loss: 0.3830 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [746/782] Loss: 0.4188 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [747/782] Loss: 0.4685 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [748/782] Loss: 0.6088 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [749/782] Loss: 0.5272 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [750/782] Loss: 0.5970 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [751/782] Loss: 0.3279 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [752/782] Loss: 0.4733 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [753/782] Loss: 0.5560 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [754/782] Loss: 0.4463 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [755/782] Loss: 0.3082 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [756/782] Loss: 0.2620 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [757/782] Loss: 0.4240 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [758/782] Loss: 0.4153 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [759/782] Loss: 0.3744 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [760/782] Loss: 0.4179 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [761/782] Loss: 0.5756 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [762/782] Loss: 0.3950 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [763/782] Loss: 0.4066 | Acc: 85.46%\n",
      "Train Epoch [98/100] Batch [764/782] Loss: 0.3121 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [765/782] Loss: 0.4328 | Acc: 85.47%\n",
      "Train Epoch [98/100] Batch [766/782] Loss: 0.2927 | Acc: 85.48%\n",
      "Train Epoch [98/100] Batch [767/782] Loss: 0.3050 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [768/782] Loss: 0.3308 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [769/782] Loss: 0.2620 | Acc: 85.49%\n",
      "Train Epoch [98/100] Batch [770/782] Loss: 0.2459 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [771/782] Loss: 0.4332 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [772/782] Loss: 0.3762 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [773/782] Loss: 0.3245 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [774/782] Loss: 0.4327 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [775/782] Loss: 0.4122 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [776/782] Loss: 0.3119 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [777/782] Loss: 0.3209 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [778/782] Loss: 0.4644 | Acc: 85.50%\n",
      "Train Epoch [98/100] Batch [779/782] Loss: 0.2466 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [780/782] Loss: 0.2867 | Acc: 85.52%\n",
      "Train Epoch [98/100] Batch [781/782] Loss: 0.5984 | Acc: 85.51%\n",
      "Train Epoch [98/100] Batch [782/782] Loss: 0.1433 | Acc: 85.52%\n",
      "Epoch 98 completed in 30.69s.\n",
      "Test Epoch [98/100] Loss: 1.0228 | Acc: 72.12% | Inference Time: 8.56s\n",
      "Epoch 98 results saved to CSV.\n",
      "Epoch 99/100\n",
      "Train Epoch [99/100] Batch [1/782] Loss: 0.3672 | Acc: 87.50%\n",
      "Train Epoch [99/100] Batch [2/782] Loss: 0.5331 | Acc: 85.16%\n",
      "Train Epoch [99/100] Batch [3/782] Loss: 0.4078 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [4/782] Loss: 0.4200 | Acc: 84.38%\n",
      "Train Epoch [99/100] Batch [5/782] Loss: 0.2993 | Acc: 85.31%\n",
      "Train Epoch [99/100] Batch [6/782] Loss: 0.3629 | Acc: 85.68%\n",
      "Train Epoch [99/100] Batch [7/782] Loss: 0.3715 | Acc: 86.16%\n",
      "Train Epoch [99/100] Batch [8/782] Loss: 0.4171 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [9/782] Loss: 0.3721 | Acc: 85.59%\n",
      "Train Epoch [99/100] Batch [10/782] Loss: 0.3558 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [11/782] Loss: 0.5722 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [12/782] Loss: 0.5623 | Acc: 85.29%\n",
      "Train Epoch [99/100] Batch [13/782] Loss: 0.2772 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [14/782] Loss: 0.2556 | Acc: 86.16%\n",
      "Train Epoch [99/100] Batch [15/782] Loss: 0.3930 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [16/782] Loss: 0.3936 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [17/782] Loss: 0.4127 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [18/782] Loss: 0.3851 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [19/782] Loss: 0.2271 | Acc: 86.10%\n",
      "Train Epoch [99/100] Batch [20/782] Loss: 0.3616 | Acc: 86.02%\n",
      "Train Epoch [99/100] Batch [21/782] Loss: 0.2104 | Acc: 86.24%\n",
      "Train Epoch [99/100] Batch [22/782] Loss: 0.4847 | Acc: 86.08%\n",
      "Train Epoch [99/100] Batch [23/782] Loss: 0.3579 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [24/782] Loss: 0.4651 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [25/782] Loss: 0.4160 | Acc: 86.06%\n",
      "Train Epoch [99/100] Batch [26/782] Loss: 0.3244 | Acc: 86.18%\n",
      "Train Epoch [99/100] Batch [27/782] Loss: 0.2826 | Acc: 86.34%\n",
      "Train Epoch [99/100] Batch [28/782] Loss: 0.5734 | Acc: 86.22%\n",
      "Train Epoch [99/100] Batch [29/782] Loss: 0.7182 | Acc: 86.05%\n",
      "Train Epoch [99/100] Batch [30/782] Loss: 0.3248 | Acc: 86.30%\n",
      "Train Epoch [99/100] Batch [31/782] Loss: 0.3674 | Acc: 86.39%\n",
      "Train Epoch [99/100] Batch [32/782] Loss: 0.3218 | Acc: 86.57%\n",
      "Train Epoch [99/100] Batch [33/782] Loss: 0.1369 | Acc: 86.84%\n",
      "Train Epoch [99/100] Batch [34/782] Loss: 0.4774 | Acc: 86.76%\n",
      "Train Epoch [99/100] Batch [35/782] Loss: 0.3396 | Acc: 86.88%\n",
      "Train Epoch [99/100] Batch [36/782] Loss: 0.3968 | Acc: 86.85%\n",
      "Train Epoch [99/100] Batch [37/782] Loss: 0.4846 | Acc: 86.78%\n",
      "Train Epoch [99/100] Batch [38/782] Loss: 0.4133 | Acc: 86.72%\n",
      "Train Epoch [99/100] Batch [39/782] Loss: 0.4411 | Acc: 86.74%\n",
      "Train Epoch [99/100] Batch [40/782] Loss: 0.4956 | Acc: 86.60%\n",
      "Train Epoch [99/100] Batch [41/782] Loss: 0.3921 | Acc: 86.59%\n",
      "Train Epoch [99/100] Batch [42/782] Loss: 0.4120 | Acc: 86.57%\n",
      "Train Epoch [99/100] Batch [43/782] Loss: 0.2542 | Acc: 86.77%\n",
      "Train Epoch [99/100] Batch [44/782] Loss: 0.3007 | Acc: 86.83%\n",
      "Train Epoch [99/100] Batch [45/782] Loss: 0.3626 | Acc: 86.77%\n",
      "Train Epoch [99/100] Batch [46/782] Loss: 0.5133 | Acc: 86.68%\n",
      "Train Epoch [99/100] Batch [47/782] Loss: 0.3897 | Acc: 86.64%\n",
      "Train Epoch [99/100] Batch [48/782] Loss: 0.4793 | Acc: 86.59%\n",
      "Train Epoch [99/100] Batch [49/782] Loss: 0.4227 | Acc: 86.54%\n",
      "Train Epoch [99/100] Batch [50/782] Loss: 0.4004 | Acc: 86.53%\n",
      "Train Epoch [99/100] Batch [51/782] Loss: 0.3414 | Acc: 86.58%\n",
      "Train Epoch [99/100] Batch [52/782] Loss: 0.2698 | Acc: 86.66%\n",
      "Train Epoch [99/100] Batch [53/782] Loss: 0.3399 | Acc: 86.73%\n",
      "Train Epoch [99/100] Batch [54/782] Loss: 0.6176 | Acc: 86.63%\n",
      "Train Epoch [99/100] Batch [55/782] Loss: 0.5766 | Acc: 86.51%\n",
      "Train Epoch [99/100] Batch [56/782] Loss: 0.4815 | Acc: 86.44%\n",
      "Train Epoch [99/100] Batch [57/782] Loss: 0.3877 | Acc: 86.40%\n",
      "Train Epoch [99/100] Batch [58/782] Loss: 0.5760 | Acc: 86.23%\n",
      "Train Epoch [99/100] Batch [59/782] Loss: 0.3118 | Acc: 86.28%\n",
      "Train Epoch [99/100] Batch [60/782] Loss: 0.4306 | Acc: 86.30%\n",
      "Train Epoch [99/100] Batch [61/782] Loss: 0.6242 | Acc: 86.12%\n",
      "Train Epoch [99/100] Batch [62/782] Loss: 0.3544 | Acc: 86.14%\n",
      "Train Epoch [99/100] Batch [63/782] Loss: 0.3090 | Acc: 86.16%\n",
      "Train Epoch [99/100] Batch [64/782] Loss: 0.4985 | Acc: 86.06%\n",
      "Train Epoch [99/100] Batch [65/782] Loss: 0.4663 | Acc: 86.08%\n",
      "Train Epoch [99/100] Batch [66/782] Loss: 0.3410 | Acc: 86.13%\n",
      "Train Epoch [99/100] Batch [67/782] Loss: 0.3346 | Acc: 86.22%\n",
      "Train Epoch [99/100] Batch [68/782] Loss: 0.4791 | Acc: 86.17%\n",
      "Train Epoch [99/100] Batch [69/782] Loss: 0.4061 | Acc: 86.07%\n",
      "Train Epoch [99/100] Batch [70/782] Loss: 0.6321 | Acc: 85.89%\n",
      "Train Epoch [99/100] Batch [71/782] Loss: 0.5262 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [72/782] Loss: 0.3572 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [73/782] Loss: 0.4547 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [74/782] Loss: 0.1657 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [75/782] Loss: 0.2969 | Acc: 86.00%\n",
      "Train Epoch [99/100] Batch [76/782] Loss: 0.5611 | Acc: 85.90%\n",
      "Train Epoch [99/100] Batch [77/782] Loss: 0.3972 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [78/782] Loss: 0.4668 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [79/782] Loss: 0.4554 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [80/782] Loss: 0.3734 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [81/782] Loss: 0.4926 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [82/782] Loss: 0.5082 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [83/782] Loss: 0.3065 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [84/782] Loss: 0.5411 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [85/782] Loss: 0.3679 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [86/782] Loss: 0.3733 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [87/782] Loss: 0.3621 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [88/782] Loss: 0.5212 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [89/782] Loss: 0.3069 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [90/782] Loss: 0.2314 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [91/782] Loss: 0.2101 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [92/782] Loss: 0.4211 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [93/782] Loss: 0.4141 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [94/782] Loss: 0.5602 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [95/782] Loss: 0.3296 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [96/782] Loss: 0.4065 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [97/782] Loss: 0.3824 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [98/782] Loss: 0.4217 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [99/782] Loss: 0.3657 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [100/782] Loss: 0.4424 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [101/782] Loss: 0.2878 | Acc: 85.86%\n",
      "Train Epoch [99/100] Batch [102/782] Loss: 0.2891 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [103/782] Loss: 0.3330 | Acc: 85.92%\n",
      "Train Epoch [99/100] Batch [104/782] Loss: 0.3541 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [105/782] Loss: 0.3411 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [106/782] Loss: 0.4019 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [107/782] Loss: 0.2966 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [108/782] Loss: 0.6259 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [109/782] Loss: 0.4109 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [110/782] Loss: 0.5575 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [111/782] Loss: 0.4777 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [112/782] Loss: 0.2753 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [113/782] Loss: 0.4912 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [114/782] Loss: 0.2172 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [115/782] Loss: 0.4473 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [116/782] Loss: 0.3151 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [117/782] Loss: 0.2379 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [118/782] Loss: 0.5270 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [119/782] Loss: 0.3689 | Acc: 85.86%\n",
      "Train Epoch [99/100] Batch [120/782] Loss: 0.3727 | Acc: 85.86%\n",
      "Train Epoch [99/100] Batch [121/782] Loss: 0.3197 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [122/782] Loss: 0.3958 | Acc: 85.86%\n",
      "Train Epoch [99/100] Batch [123/782] Loss: 0.5645 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [124/782] Loss: 0.5831 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [125/782] Loss: 0.3831 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [126/782] Loss: 0.4111 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [127/782] Loss: 0.5330 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [128/782] Loss: 0.3084 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [129/782] Loss: 0.3226 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [130/782] Loss: 0.3508 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [131/782] Loss: 0.2341 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [132/782] Loss: 0.4280 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [133/782] Loss: 0.5028 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [134/782] Loss: 0.4186 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [135/782] Loss: 0.3496 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [136/782] Loss: 0.2251 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [137/782] Loss: 0.2900 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [138/782] Loss: 0.4143 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [139/782] Loss: 0.2835 | Acc: 85.89%\n",
      "Train Epoch [99/100] Batch [140/782] Loss: 0.4456 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [141/782] Loss: 0.3527 | Acc: 85.89%\n",
      "Train Epoch [99/100] Batch [142/782] Loss: 0.3479 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [143/782] Loss: 0.3161 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [144/782] Loss: 0.3735 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [145/782] Loss: 0.2203 | Acc: 85.95%\n",
      "Train Epoch [99/100] Batch [146/782] Loss: 0.3521 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [147/782] Loss: 0.3941 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [148/782] Loss: 0.3790 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [149/782] Loss: 0.3866 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [150/782] Loss: 0.3027 | Acc: 86.01%\n",
      "Train Epoch [99/100] Batch [151/782] Loss: 0.3173 | Acc: 86.05%\n",
      "Train Epoch [99/100] Batch [152/782] Loss: 0.4609 | Acc: 86.03%\n",
      "Train Epoch [99/100] Batch [153/782] Loss: 0.4710 | Acc: 85.99%\n",
      "Train Epoch [99/100] Batch [154/782] Loss: 0.2548 | Acc: 86.00%\n",
      "Train Epoch [99/100] Batch [155/782] Loss: 0.3876 | Acc: 86.00%\n",
      "Train Epoch [99/100] Batch [156/782] Loss: 0.3431 | Acc: 86.00%\n",
      "Train Epoch [99/100] Batch [157/782] Loss: 0.3633 | Acc: 85.99%\n",
      "Train Epoch [99/100] Batch [158/782] Loss: 0.3796 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [159/782] Loss: 0.5615 | Acc: 85.93%\n",
      "Train Epoch [99/100] Batch [160/782] Loss: 0.1943 | Acc: 85.99%\n",
      "Train Epoch [99/100] Batch [161/782] Loss: 0.3232 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [162/782] Loss: 0.2229 | Acc: 86.01%\n",
      "Train Epoch [99/100] Batch [163/782] Loss: 0.5076 | Acc: 86.00%\n",
      "Train Epoch [99/100] Batch [164/782] Loss: 0.3925 | Acc: 85.99%\n",
      "Train Epoch [99/100] Batch [165/782] Loss: 0.4144 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [166/782] Loss: 0.5744 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [167/782] Loss: 0.4039 | Acc: 85.96%\n",
      "Train Epoch [99/100] Batch [168/782] Loss: 0.2982 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [169/782] Loss: 0.2556 | Acc: 85.98%\n",
      "Train Epoch [99/100] Batch [170/782] Loss: 0.3399 | Acc: 85.99%\n",
      "Train Epoch [99/100] Batch [171/782] Loss: 0.4815 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [172/782] Loss: 0.2754 | Acc: 86.02%\n",
      "Train Epoch [99/100] Batch [173/782] Loss: 0.5628 | Acc: 85.97%\n",
      "Train Epoch [99/100] Batch [174/782] Loss: 0.5888 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [175/782] Loss: 0.4155 | Acc: 85.90%\n",
      "Train Epoch [99/100] Batch [176/782] Loss: 0.2788 | Acc: 85.92%\n",
      "Train Epoch [99/100] Batch [177/782] Loss: 0.3447 | Acc: 85.92%\n",
      "Train Epoch [99/100] Batch [178/782] Loss: 0.2305 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [179/782] Loss: 0.4272 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [180/782] Loss: 0.5807 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [181/782] Loss: 0.4659 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [182/782] Loss: 0.3555 | Acc: 85.95%\n",
      "Train Epoch [99/100] Batch [183/782] Loss: 0.3893 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [184/782] Loss: 0.2719 | Acc: 85.96%\n",
      "Train Epoch [99/100] Batch [185/782] Loss: 0.3076 | Acc: 85.95%\n",
      "Train Epoch [99/100] Batch [186/782] Loss: 0.4770 | Acc: 85.94%\n",
      "Train Epoch [99/100] Batch [187/782] Loss: 0.3812 | Acc: 85.92%\n",
      "Train Epoch [99/100] Batch [188/782] Loss: 0.3567 | Acc: 85.93%\n",
      "Train Epoch [99/100] Batch [189/782] Loss: 0.5160 | Acc: 85.89%\n",
      "Train Epoch [99/100] Batch [190/782] Loss: 0.2364 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [191/782] Loss: 0.2990 | Acc: 85.93%\n",
      "Train Epoch [99/100] Batch [192/782] Loss: 0.3344 | Acc: 85.93%\n",
      "Train Epoch [99/100] Batch [193/782] Loss: 0.5007 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [194/782] Loss: 0.3914 | Acc: 85.92%\n",
      "Train Epoch [99/100] Batch [195/782] Loss: 0.3390 | Acc: 85.91%\n",
      "Train Epoch [99/100] Batch [196/782] Loss: 0.4953 | Acc: 85.90%\n",
      "Train Epoch [99/100] Batch [197/782] Loss: 0.3800 | Acc: 85.90%\n",
      "Train Epoch [99/100] Batch [198/782] Loss: 0.5986 | Acc: 85.87%\n",
      "Train Epoch [99/100] Batch [199/782] Loss: 0.3458 | Acc: 85.88%\n",
      "Train Epoch [99/100] Batch [200/782] Loss: 0.5811 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [201/782] Loss: 0.5930 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [202/782] Loss: 0.2409 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [203/782] Loss: 0.4821 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [204/782] Loss: 0.3847 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [205/782] Loss: 0.2801 | Acc: 85.85%\n",
      "Train Epoch [99/100] Batch [206/782] Loss: 0.4267 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [207/782] Loss: 0.3298 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [208/782] Loss: 0.5657 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [209/782] Loss: 0.5390 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [210/782] Loss: 0.4733 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [211/782] Loss: 0.4843 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [212/782] Loss: 0.3367 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [213/782] Loss: 0.4217 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [214/782] Loss: 0.4476 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [215/782] Loss: 0.4806 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [216/782] Loss: 0.3919 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [217/782] Loss: 0.5975 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [218/782] Loss: 0.3793 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [219/782] Loss: 0.3044 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [220/782] Loss: 0.5014 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [221/782] Loss: 0.2772 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [222/782] Loss: 0.3742 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [223/782] Loss: 0.4276 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [224/782] Loss: 0.2381 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [225/782] Loss: 0.5057 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [226/782] Loss: 0.2958 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [227/782] Loss: 0.3948 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [228/782] Loss: 0.2280 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [229/782] Loss: 0.4426 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [230/782] Loss: 0.3676 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [231/782] Loss: 0.4701 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [232/782] Loss: 0.3641 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [233/782] Loss: 0.4496 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [234/782] Loss: 0.3243 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [235/782] Loss: 0.3174 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [236/782] Loss: 0.4667 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [237/782] Loss: 0.3386 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [238/782] Loss: 0.3174 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [239/782] Loss: 0.3208 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [240/782] Loss: 0.5549 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [241/782] Loss: 0.3969 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [242/782] Loss: 0.2971 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [243/782] Loss: 0.2917 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [244/782] Loss: 0.3969 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [245/782] Loss: 0.4448 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [246/782] Loss: 0.4142 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [247/782] Loss: 0.3697 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [248/782] Loss: 0.3495 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [249/782] Loss: 0.3967 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [250/782] Loss: 0.2745 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [251/782] Loss: 0.5548 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [252/782] Loss: 0.3558 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [253/782] Loss: 0.5762 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [254/782] Loss: 0.2957 | Acc: 85.81%\n",
      "Train Epoch [99/100] Batch [255/782] Loss: 0.2979 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [256/782] Loss: 0.3664 | Acc: 85.83%\n",
      "Train Epoch [99/100] Batch [257/782] Loss: 0.3975 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [258/782] Loss: 0.2758 | Acc: 85.84%\n",
      "Train Epoch [99/100] Batch [259/782] Loss: 0.4742 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [260/782] Loss: 0.3945 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [261/782] Loss: 0.4134 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [262/782] Loss: 0.5185 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [263/782] Loss: 0.6246 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [264/782] Loss: 0.4257 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [265/782] Loss: 0.3238 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [266/782] Loss: 0.4925 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [267/782] Loss: 0.5455 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [268/782] Loss: 0.2798 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [269/782] Loss: 0.3016 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [270/782] Loss: 0.3886 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [271/782] Loss: 0.4378 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [272/782] Loss: 0.3354 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [273/782] Loss: 0.2831 | Acc: 85.82%\n",
      "Train Epoch [99/100] Batch [274/782] Loss: 0.5171 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [275/782] Loss: 0.5063 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [276/782] Loss: 0.4518 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [277/782] Loss: 0.3216 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [278/782] Loss: 0.4850 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [279/782] Loss: 0.3356 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [280/782] Loss: 0.3891 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [281/782] Loss: 0.4642 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [282/782] Loss: 0.3793 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [283/782] Loss: 0.2944 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [284/782] Loss: 0.3346 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [285/782] Loss: 0.4566 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [286/782] Loss: 0.4563 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [287/782] Loss: 0.3325 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [288/782] Loss: 0.5061 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [289/782] Loss: 0.4455 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [290/782] Loss: 0.4199 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [291/782] Loss: 0.5058 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [292/782] Loss: 0.2699 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [293/782] Loss: 0.3893 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [294/782] Loss: 0.4221 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [295/782] Loss: 0.5003 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [296/782] Loss: 0.3782 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [297/782] Loss: 0.6908 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [298/782] Loss: 0.3904 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [299/782] Loss: 0.4757 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [300/782] Loss: 0.4256 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [301/782] Loss: 0.3649 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [302/782] Loss: 0.3392 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [303/782] Loss: 0.2857 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [304/782] Loss: 0.4395 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [305/782] Loss: 0.1953 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [306/782] Loss: 0.4531 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [307/782] Loss: 0.5009 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [308/782] Loss: 0.4879 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [309/782] Loss: 0.3125 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [310/782] Loss: 0.3777 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [311/782] Loss: 0.2413 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [312/782] Loss: 0.3062 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [313/782] Loss: 0.4006 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [314/782] Loss: 0.4013 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [315/782] Loss: 0.5391 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [316/782] Loss: 0.2874 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [317/782] Loss: 0.2660 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [318/782] Loss: 0.3355 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [319/782] Loss: 0.3085 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [320/782] Loss: 0.3887 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [321/782] Loss: 0.4306 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [322/782] Loss: 0.3536 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [323/782] Loss: 0.2925 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [324/782] Loss: 0.4371 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [325/782] Loss: 0.5576 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [326/782] Loss: 0.3214 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [327/782] Loss: 0.4022 | Acc: 85.80%\n",
      "Train Epoch [99/100] Batch [328/782] Loss: 0.4138 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [329/782] Loss: 0.3101 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [330/782] Loss: 0.3307 | Acc: 85.79%\n",
      "Train Epoch [99/100] Batch [331/782] Loss: 0.5870 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [332/782] Loss: 0.4188 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [333/782] Loss: 0.3155 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [334/782] Loss: 0.4214 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [335/782] Loss: 0.4247 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [336/782] Loss: 0.5067 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [337/782] Loss: 0.4645 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [338/782] Loss: 0.3985 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [339/782] Loss: 0.5372 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [340/782] Loss: 0.4836 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [341/782] Loss: 0.4190 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [342/782] Loss: 0.5425 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [343/782] Loss: 0.4785 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [344/782] Loss: 0.3086 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [345/782] Loss: 0.5059 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [346/782] Loss: 0.3571 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [347/782] Loss: 0.2427 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [348/782] Loss: 0.3877 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [349/782] Loss: 0.4797 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [350/782] Loss: 0.3697 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [351/782] Loss: 0.3165 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [352/782] Loss: 0.2792 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [353/782] Loss: 0.3383 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [354/782] Loss: 0.4284 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [355/782] Loss: 0.6012 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [356/782] Loss: 0.2924 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [357/782] Loss: 0.3694 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [358/782] Loss: 0.3347 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [359/782] Loss: 0.4160 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [360/782] Loss: 0.3198 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [361/782] Loss: 0.3885 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [362/782] Loss: 0.4894 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [363/782] Loss: 0.5017 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [364/782] Loss: 0.3085 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [365/782] Loss: 0.2392 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [366/782] Loss: 0.5404 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [367/782] Loss: 0.4051 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [368/782] Loss: 0.2459 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [369/782] Loss: 0.5239 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [370/782] Loss: 0.5260 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [371/782] Loss: 0.5840 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [372/782] Loss: 0.4347 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [373/782] Loss: 0.4017 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [374/782] Loss: 0.2087 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [375/782] Loss: 0.4125 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [376/782] Loss: 0.5481 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [377/782] Loss: 0.4784 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [378/782] Loss: 0.3849 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [379/782] Loss: 0.2794 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [380/782] Loss: 0.2655 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [381/782] Loss: 0.6333 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [382/782] Loss: 0.4061 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [383/782] Loss: 0.3434 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [384/782] Loss: 0.3083 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [385/782] Loss: 0.3217 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [386/782] Loss: 0.4549 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [387/782] Loss: 0.5620 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [388/782] Loss: 0.3009 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [389/782] Loss: 0.2408 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [390/782] Loss: 0.4627 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [391/782] Loss: 0.3060 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [392/782] Loss: 0.2948 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [393/782] Loss: 0.3555 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [394/782] Loss: 0.3944 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [395/782] Loss: 0.3417 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [396/782] Loss: 0.4532 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [397/782] Loss: 0.3522 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [398/782] Loss: 0.2620 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [399/782] Loss: 0.3424 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [400/782] Loss: 0.4458 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [401/782] Loss: 0.6370 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [402/782] Loss: 0.4788 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [403/782] Loss: 0.3458 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [404/782] Loss: 0.4513 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [405/782] Loss: 0.3254 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [406/782] Loss: 0.3683 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [407/782] Loss: 0.3648 | Acc: 85.77%\n",
      "Train Epoch [99/100] Batch [408/782] Loss: 0.3081 | Acc: 85.78%\n",
      "Train Epoch [99/100] Batch [409/782] Loss: 0.5565 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [410/782] Loss: 0.2840 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [411/782] Loss: 0.3615 | Acc: 85.76%\n",
      "Train Epoch [99/100] Batch [412/782] Loss: 0.3979 | Acc: 85.75%\n",
      "Train Epoch [99/100] Batch [413/782] Loss: 0.4549 | Acc: 85.74%\n",
      "Train Epoch [99/100] Batch [414/782] Loss: 0.5680 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [415/782] Loss: 0.2446 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [416/782] Loss: 0.4066 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [417/782] Loss: 0.5555 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [418/782] Loss: 0.2815 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [419/782] Loss: 0.2053 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [420/782] Loss: 0.3837 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [421/782] Loss: 0.4977 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [422/782] Loss: 0.3383 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [423/782] Loss: 0.4326 | Acc: 85.73%\n",
      "Train Epoch [99/100] Batch [424/782] Loss: 0.3791 | Acc: 85.72%\n",
      "Train Epoch [99/100] Batch [425/782] Loss: 0.5588 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [426/782] Loss: 0.3910 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [427/782] Loss: 0.3639 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [428/782] Loss: 0.3222 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [429/782] Loss: 0.4574 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [430/782] Loss: 0.4805 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [431/782] Loss: 0.4433 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [432/782] Loss: 0.2844 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [433/782] Loss: 0.4471 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [434/782] Loss: 0.3528 | Acc: 85.71%\n",
      "Train Epoch [99/100] Batch [435/782] Loss: 0.7116 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [436/782] Loss: 0.4093 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [437/782] Loss: 0.4303 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [438/782] Loss: 0.4135 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [439/782] Loss: 0.3812 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [440/782] Loss: 0.4729 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [441/782] Loss: 0.4904 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [442/782] Loss: 0.3477 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [443/782] Loss: 0.4472 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [444/782] Loss: 0.5352 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [445/782] Loss: 0.4609 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [446/782] Loss: 0.2983 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [447/782] Loss: 0.4473 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [448/782] Loss: 0.2172 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [449/782] Loss: 0.4089 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [450/782] Loss: 0.3914 | Acc: 85.70%\n",
      "Train Epoch [99/100] Batch [451/782] Loss: 0.4227 | Acc: 85.69%\n",
      "Train Epoch [99/100] Batch [452/782] Loss: 0.6176 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [453/782] Loss: 0.4459 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [454/782] Loss: 0.3888 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [455/782] Loss: 0.6128 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [456/782] Loss: 0.4681 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [457/782] Loss: 0.4129 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [458/782] Loss: 0.3220 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [459/782] Loss: 0.3750 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [460/782] Loss: 0.5926 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [461/782] Loss: 0.3397 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [462/782] Loss: 0.3388 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [463/782] Loss: 0.3321 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [464/782] Loss: 0.3027 | Acc: 85.67%\n",
      "Train Epoch [99/100] Batch [465/782] Loss: 0.5545 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [466/782] Loss: 0.3566 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [467/782] Loss: 0.5193 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [468/782] Loss: 0.4854 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [469/782] Loss: 0.3263 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [470/782] Loss: 0.3046 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [471/782] Loss: 0.3176 | Acc: 85.66%\n",
      "Train Epoch [99/100] Batch [472/782] Loss: 0.4568 | Acc: 85.65%\n",
      "Train Epoch [99/100] Batch [473/782] Loss: 0.5762 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [474/782] Loss: 0.3187 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [475/782] Loss: 0.4404 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [476/782] Loss: 0.2649 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [477/782] Loss: 0.5580 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [478/782] Loss: 0.3881 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [479/782] Loss: 0.5572 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [480/782] Loss: 0.3198 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [481/782] Loss: 0.3242 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [482/782] Loss: 0.2975 | Acc: 85.63%\n",
      "Train Epoch [99/100] Batch [483/782] Loss: 0.2671 | Acc: 85.64%\n",
      "Train Epoch [99/100] Batch [484/782] Loss: 0.6839 | Acc: 85.62%\n",
      "Train Epoch [99/100] Batch [485/782] Loss: 0.6698 | Acc: 85.59%\n",
      "Train Epoch [99/100] Batch [486/782] Loss: 0.4707 | Acc: 85.59%\n",
      "Train Epoch [99/100] Batch [487/782] Loss: 0.4172 | Acc: 85.59%\n",
      "Train Epoch [99/100] Batch [488/782] Loss: 0.3300 | Acc: 85.60%\n",
      "Train Epoch [99/100] Batch [489/782] Loss: 0.5253 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [490/782] Loss: 0.3952 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [491/782] Loss: 0.4722 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [492/782] Loss: 0.5186 | Acc: 85.56%\n",
      "Train Epoch [99/100] Batch [493/782] Loss: 0.3589 | Acc: 85.57%\n",
      "Train Epoch [99/100] Batch [494/782] Loss: 0.4286 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [495/782] Loss: 0.4380 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [496/782] Loss: 0.2726 | Acc: 85.56%\n",
      "Train Epoch [99/100] Batch [497/782] Loss: 0.3435 | Acc: 85.57%\n",
      "Train Epoch [99/100] Batch [498/782] Loss: 0.4076 | Acc: 85.57%\n",
      "Train Epoch [99/100] Batch [499/782] Loss: 0.3098 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [500/782] Loss: 0.2928 | Acc: 85.58%\n",
      "Train Epoch [99/100] Batch [501/782] Loss: 0.4534 | Acc: 85.57%\n",
      "Train Epoch [99/100] Batch [502/782] Loss: 0.3853 | Acc: 85.57%\n",
      "Train Epoch [99/100] Batch [503/782] Loss: 0.5345 | Acc: 85.56%\n",
      "Train Epoch [99/100] Batch [504/782] Loss: 0.3418 | Acc: 85.56%\n",
      "Train Epoch [99/100] Batch [505/782] Loss: 0.6110 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [506/782] Loss: 0.4529 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [507/782] Loss: 0.2770 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [508/782] Loss: 0.4730 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [509/782] Loss: 0.7525 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [510/782] Loss: 0.4942 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [511/782] Loss: 0.4723 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [512/782] Loss: 0.3227 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [513/782] Loss: 0.3699 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [514/782] Loss: 0.4530 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [515/782] Loss: 0.3523 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [516/782] Loss: 0.4860 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [517/782] Loss: 0.4430 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [518/782] Loss: 0.4340 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [519/782] Loss: 0.4966 | Acc: 85.47%\n",
      "Train Epoch [99/100] Batch [520/782] Loss: 0.4768 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [521/782] Loss: 0.5902 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [522/782] Loss: 0.3827 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [523/782] Loss: 0.5933 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [524/782] Loss: 0.4481 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [525/782] Loss: 0.4879 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [526/782] Loss: 0.4847 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [527/782] Loss: 0.2829 | Acc: 85.47%\n",
      "Train Epoch [99/100] Batch [528/782] Loss: 0.4520 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [529/782] Loss: 0.8196 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [530/782] Loss: 0.4033 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [531/782] Loss: 0.7135 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [532/782] Loss: 0.3819 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [533/782] Loss: 0.4471 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [534/782] Loss: 0.4401 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [535/782] Loss: 0.3636 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [536/782] Loss: 0.3097 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [537/782] Loss: 0.5721 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [538/782] Loss: 0.3532 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [539/782] Loss: 0.3877 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [540/782] Loss: 0.2243 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [541/782] Loss: 0.5844 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [542/782] Loss: 0.3828 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [543/782] Loss: 0.3771 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [544/782] Loss: 0.3365 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [545/782] Loss: 0.4354 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [546/782] Loss: 0.2228 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [547/782] Loss: 0.4108 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [548/782] Loss: 0.4094 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [549/782] Loss: 0.4315 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [550/782] Loss: 0.4199 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [551/782] Loss: 0.5511 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [552/782] Loss: 0.3972 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [553/782] Loss: 0.2784 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [554/782] Loss: 0.4578 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [555/782] Loss: 0.5271 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [556/782] Loss: 0.4089 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [557/782] Loss: 0.4316 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [558/782] Loss: 0.4048 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [559/782] Loss: 0.4082 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [560/782] Loss: 0.3992 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [561/782] Loss: 0.4474 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [562/782] Loss: 0.4454 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [563/782] Loss: 0.4446 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [564/782] Loss: 0.5821 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [565/782] Loss: 0.4968 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [566/782] Loss: 0.5488 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [567/782] Loss: 0.3875 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [568/782] Loss: 0.3384 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [569/782] Loss: 0.4054 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [570/782] Loss: 0.4269 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [571/782] Loss: 0.4899 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [572/782] Loss: 0.4672 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [573/782] Loss: 0.4041 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [574/782] Loss: 0.4278 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [575/782] Loss: 0.3073 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [576/782] Loss: 0.6319 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [577/782] Loss: 0.4287 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [578/782] Loss: 0.4082 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [579/782] Loss: 0.2841 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [580/782] Loss: 0.3975 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [581/782] Loss: 0.3520 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [582/782] Loss: 0.4036 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [583/782] Loss: 0.2936 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [584/782] Loss: 0.4470 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [585/782] Loss: 0.5180 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [586/782] Loss: 0.3364 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [587/782] Loss: 0.3331 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [588/782] Loss: 0.5991 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [589/782] Loss: 0.4126 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [590/782] Loss: 0.3873 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [591/782] Loss: 0.3455 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [592/782] Loss: 0.3803 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [593/782] Loss: 0.3650 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [594/782] Loss: 0.3290 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [595/782] Loss: 0.2551 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [596/782] Loss: 0.4049 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [597/782] Loss: 0.5652 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [598/782] Loss: 0.3167 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [599/782] Loss: 0.2894 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [600/782] Loss: 0.5770 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [601/782] Loss: 0.3243 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [602/782] Loss: 0.3149 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [603/782] Loss: 0.4926 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [604/782] Loss: 0.4773 | Acc: 85.37%\n",
      "Train Epoch [99/100] Batch [605/782] Loss: 0.2655 | Acc: 85.38%\n",
      "Train Epoch [99/100] Batch [606/782] Loss: 0.3590 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [607/782] Loss: 0.3186 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [608/782] Loss: 0.3804 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [609/782] Loss: 0.4835 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [610/782] Loss: 0.3233 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [611/782] Loss: 0.3797 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [612/782] Loss: 0.4509 | Acc: 85.39%\n",
      "Train Epoch [99/100] Batch [613/782] Loss: 0.3072 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [614/782] Loss: 0.3111 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [615/782] Loss: 0.3594 | Acc: 85.40%\n",
      "Train Epoch [99/100] Batch [616/782] Loss: 0.2499 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [617/782] Loss: 0.2975 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [618/782] Loss: 0.3236 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [619/782] Loss: 0.3297 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [620/782] Loss: 0.3119 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [621/782] Loss: 0.3868 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [622/782] Loss: 0.5809 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [623/782] Loss: 0.3011 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [624/782] Loss: 0.3897 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [625/782] Loss: 0.2164 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [626/782] Loss: 0.4917 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [627/782] Loss: 0.4488 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [628/782] Loss: 0.3734 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [629/782] Loss: 0.4681 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [630/782] Loss: 0.3233 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [631/782] Loss: 0.3768 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [632/782] Loss: 0.2786 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [633/782] Loss: 0.4151 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [634/782] Loss: 0.5780 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [635/782] Loss: 0.3576 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [636/782] Loss: 0.6263 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [637/782] Loss: 0.4127 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [638/782] Loss: 0.4085 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [639/782] Loss: 0.3149 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [640/782] Loss: 0.3344 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [641/782] Loss: 0.3744 | Acc: 85.44%\n",
      "Train Epoch [99/100] Batch [642/782] Loss: 0.4214 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [643/782] Loss: 0.5428 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [644/782] Loss: 0.4959 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [645/782] Loss: 0.3585 | Acc: 85.41%\n",
      "Train Epoch [99/100] Batch [646/782] Loss: 0.2273 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [647/782] Loss: 0.5290 | Acc: 85.42%\n",
      "Train Epoch [99/100] Batch [648/782] Loss: 0.3695 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [649/782] Loss: 0.4033 | Acc: 85.43%\n",
      "Train Epoch [99/100] Batch [650/782] Loss: 0.2822 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [651/782] Loss: 0.4453 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [652/782] Loss: 0.4527 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [653/782] Loss: 0.4641 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [654/782] Loss: 0.5452 | Acc: 85.45%\n",
      "Train Epoch [99/100] Batch [655/782] Loss: 0.1878 | Acc: 85.46%\n",
      "Train Epoch [99/100] Batch [656/782] Loss: 0.3372 | Acc: 85.47%\n",
      "Train Epoch [99/100] Batch [657/782] Loss: 0.2853 | Acc: 85.47%\n",
      "Train Epoch [99/100] Batch [658/782] Loss: 0.5790 | Acc: 85.47%\n",
      "Train Epoch [99/100] Batch [659/782] Loss: 0.3755 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [660/782] Loss: 0.3762 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [661/782] Loss: 0.3103 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [662/782] Loss: 0.4570 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [663/782] Loss: 0.2884 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [664/782] Loss: 0.4930 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [665/782] Loss: 0.3423 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [666/782] Loss: 0.3282 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [667/782] Loss: 0.3718 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [668/782] Loss: 0.4890 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [669/782] Loss: 0.3967 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [670/782] Loss: 0.2878 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [671/782] Loss: 0.3473 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [672/782] Loss: 0.4399 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [673/782] Loss: 0.2267 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [674/782] Loss: 0.5753 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [675/782] Loss: 0.4139 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [676/782] Loss: 0.2557 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [677/782] Loss: 0.3504 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [678/782] Loss: 0.5141 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [679/782] Loss: 0.4025 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [680/782] Loss: 0.3063 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [681/782] Loss: 0.3417 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [682/782] Loss: 0.4617 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [683/782] Loss: 0.2400 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [684/782] Loss: 0.4509 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [685/782] Loss: 0.5044 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [686/782] Loss: 0.4208 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [687/782] Loss: 0.3063 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [688/782] Loss: 0.3004 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [689/782] Loss: 0.4441 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [690/782] Loss: 0.4242 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [691/782] Loss: 0.4322 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [692/782] Loss: 0.5941 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [693/782] Loss: 0.2789 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [694/782] Loss: 0.3417 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [695/782] Loss: 0.5156 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [696/782] Loss: 0.2940 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [697/782] Loss: 0.3530 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [698/782] Loss: 0.3950 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [699/782] Loss: 0.4770 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [700/782] Loss: 0.4965 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [701/782] Loss: 0.6149 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [702/782] Loss: 0.3985 | Acc: 85.48%\n",
      "Train Epoch [99/100] Batch [703/782] Loss: 0.2685 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [704/782] Loss: 0.3539 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [705/782] Loss: 0.5048 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [706/782] Loss: 0.4133 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [707/782] Loss: 0.5343 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [708/782] Loss: 0.3659 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [709/782] Loss: 0.4899 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [710/782] Loss: 0.3977 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [711/782] Loss: 0.2864 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [712/782] Loss: 0.3736 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [713/782] Loss: 0.2816 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [714/782] Loss: 0.4090 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [715/782] Loss: 0.4424 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [716/782] Loss: 0.4860 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [717/782] Loss: 0.5090 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [718/782] Loss: 0.4498 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [719/782] Loss: 0.4557 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [720/782] Loss: 0.4763 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [721/782] Loss: 0.5043 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [722/782] Loss: 0.4053 | Acc: 85.49%\n",
      "Train Epoch [99/100] Batch [723/782] Loss: 0.3384 | Acc: 85.50%\n",
      "Train Epoch [99/100] Batch [724/782] Loss: 0.3041 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [725/782] Loss: 0.3089 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [726/782] Loss: 0.2815 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [727/782] Loss: 0.3602 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [728/782] Loss: 0.3931 | Acc: 85.51%\n",
      "Train Epoch [99/100] Batch [729/782] Loss: 0.3794 | Acc: 85.52%\n",
      "Train Epoch [99/100] Batch [730/782] Loss: 0.3096 | Acc: 85.52%\n",
      "Train Epoch [99/100] Batch [731/782] Loss: 0.3541 | Acc: 85.52%\n",
      "Train Epoch [99/100] Batch [732/782] Loss: 0.2727 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [733/782] Loss: 0.5004 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [734/782] Loss: 0.2877 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [735/782] Loss: 0.2836 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [736/782] Loss: 0.3035 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [737/782] Loss: 0.2641 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [738/782] Loss: 0.4386 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [739/782] Loss: 0.3203 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [740/782] Loss: 0.6775 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [741/782] Loss: 0.3674 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [742/782] Loss: 0.3909 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [743/782] Loss: 0.4621 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [744/782] Loss: 0.4193 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [745/782] Loss: 0.4414 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [746/782] Loss: 0.3550 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [747/782] Loss: 0.2327 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [748/782] Loss: 0.3673 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [749/782] Loss: 0.2936 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [750/782] Loss: 0.4227 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [751/782] Loss: 0.3764 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [752/782] Loss: 0.4731 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [753/782] Loss: 0.4487 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [754/782] Loss: 0.4862 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [755/782] Loss: 0.2326 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [756/782] Loss: 0.4679 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [757/782] Loss: 0.4573 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [758/782] Loss: 0.4237 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [759/782] Loss: 0.4140 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [760/782] Loss: 0.3942 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [761/782] Loss: 0.3389 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [762/782] Loss: 0.4589 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [763/782] Loss: 0.4002 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [764/782] Loss: 0.3275 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [765/782] Loss: 0.4500 | Acc: 85.52%\n",
      "Train Epoch [99/100] Batch [766/782] Loss: 0.4682 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [767/782] Loss: 0.5125 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [768/782] Loss: 0.4765 | Acc: 85.52%\n",
      "Train Epoch [99/100] Batch [769/782] Loss: 0.3163 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [770/782] Loss: 0.4877 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [771/782] Loss: 0.4277 | Acc: 85.53%\n",
      "Train Epoch [99/100] Batch [772/782] Loss: 0.2986 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [773/782] Loss: 0.3216 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [774/782] Loss: 0.2598 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [775/782] Loss: 0.6654 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [776/782] Loss: 0.3819 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [777/782] Loss: 0.3887 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [778/782] Loss: 0.4141 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [779/782] Loss: 0.4212 | Acc: 85.54%\n",
      "Train Epoch [99/100] Batch [780/782] Loss: 0.2563 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [781/782] Loss: 0.3745 | Acc: 85.55%\n",
      "Train Epoch [99/100] Batch [782/782] Loss: 0.2906 | Acc: 85.55%\n",
      "Epoch 99 completed in 30.45s.\n",
      "Test Epoch [99/100] Loss: 1.0234 | Acc: 72.12% | Inference Time: 8.56s\n",
      "Epoch 99 results saved to CSV.\n",
      "Epoch 100/100\n",
      "Train Epoch [100/100] Batch [1/782] Loss: 0.4303 | Acc: 85.94%\n",
      "Train Epoch [100/100] Batch [2/782] Loss: 0.4188 | Acc: 86.72%\n",
      "Train Epoch [100/100] Batch [3/782] Loss: 0.4187 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [4/782] Loss: 0.4080 | Acc: 86.33%\n",
      "Train Epoch [100/100] Batch [5/782] Loss: 0.6371 | Acc: 84.06%\n",
      "Train Epoch [100/100] Batch [6/782] Loss: 0.3372 | Acc: 85.16%\n",
      "Train Epoch [100/100] Batch [7/782] Loss: 0.3728 | Acc: 85.27%\n",
      "Train Epoch [100/100] Batch [8/782] Loss: 0.5414 | Acc: 84.57%\n",
      "Train Epoch [100/100] Batch [9/782] Loss: 0.4995 | Acc: 84.20%\n",
      "Train Epoch [100/100] Batch [10/782] Loss: 0.4157 | Acc: 84.22%\n",
      "Train Epoch [100/100] Batch [11/782] Loss: 0.4457 | Acc: 83.95%\n",
      "Train Epoch [100/100] Batch [12/782] Loss: 0.2020 | Acc: 84.64%\n",
      "Train Epoch [100/100] Batch [13/782] Loss: 0.2539 | Acc: 84.98%\n",
      "Train Epoch [100/100] Batch [14/782] Loss: 0.2770 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [15/782] Loss: 0.5134 | Acc: 85.10%\n",
      "Train Epoch [100/100] Batch [16/782] Loss: 0.3205 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [17/782] Loss: 0.3209 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [18/782] Loss: 0.3334 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [19/782] Loss: 0.3666 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [20/782] Loss: 0.2947 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [21/782] Loss: 0.4733 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [22/782] Loss: 0.4449 | Acc: 85.30%\n",
      "Train Epoch [100/100] Batch [23/782] Loss: 0.3236 | Acc: 85.39%\n",
      "Train Epoch [100/100] Batch [24/782] Loss: 0.4368 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [25/782] Loss: 0.3431 | Acc: 85.38%\n",
      "Train Epoch [100/100] Batch [26/782] Loss: 0.4142 | Acc: 85.40%\n",
      "Train Epoch [100/100] Batch [27/782] Loss: 0.4275 | Acc: 85.30%\n",
      "Train Epoch [100/100] Batch [28/782] Loss: 0.4999 | Acc: 85.21%\n",
      "Train Epoch [100/100] Batch [29/782] Loss: 0.3375 | Acc: 85.40%\n",
      "Train Epoch [100/100] Batch [30/782] Loss: 0.2677 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [31/782] Loss: 0.4737 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [32/782] Loss: 0.4346 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [33/782] Loss: 0.4224 | Acc: 85.32%\n",
      "Train Epoch [100/100] Batch [34/782] Loss: 0.3549 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [35/782] Loss: 0.4114 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [36/782] Loss: 0.3853 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [37/782] Loss: 0.2756 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [38/782] Loss: 0.3628 | Acc: 85.61%\n",
      "Train Epoch [100/100] Batch [39/782] Loss: 0.3580 | Acc: 85.70%\n",
      "Train Epoch [100/100] Batch [40/782] Loss: 0.5593 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [41/782] Loss: 0.5475 | Acc: 85.37%\n",
      "Train Epoch [100/100] Batch [42/782] Loss: 0.4022 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [43/782] Loss: 0.6534 | Acc: 85.14%\n",
      "Train Epoch [100/100] Batch [44/782] Loss: 0.4916 | Acc: 85.01%\n",
      "Train Epoch [100/100] Batch [45/782] Loss: 0.2912 | Acc: 85.07%\n",
      "Train Epoch [100/100] Batch [46/782] Loss: 0.5437 | Acc: 84.99%\n",
      "Train Epoch [100/100] Batch [47/782] Loss: 0.5397 | Acc: 84.84%\n",
      "Train Epoch [100/100] Batch [48/782] Loss: 0.3737 | Acc: 84.90%\n",
      "Train Epoch [100/100] Batch [49/782] Loss: 0.3196 | Acc: 84.98%\n",
      "Train Epoch [100/100] Batch [50/782] Loss: 0.5014 | Acc: 85.00%\n",
      "Train Epoch [100/100] Batch [51/782] Loss: 0.6821 | Acc: 84.87%\n",
      "Train Epoch [100/100] Batch [52/782] Loss: 0.5407 | Acc: 84.71%\n",
      "Train Epoch [100/100] Batch [53/782] Loss: 0.3735 | Acc: 84.76%\n",
      "Train Epoch [100/100] Batch [54/782] Loss: 0.4737 | Acc: 84.75%\n",
      "Train Epoch [100/100] Batch [55/782] Loss: 0.3497 | Acc: 84.80%\n",
      "Train Epoch [100/100] Batch [56/782] Loss: 0.5198 | Acc: 84.74%\n",
      "Train Epoch [100/100] Batch [57/782] Loss: 0.3557 | Acc: 84.81%\n",
      "Train Epoch [100/100] Batch [58/782] Loss: 0.4078 | Acc: 84.83%\n",
      "Train Epoch [100/100] Batch [59/782] Loss: 0.2935 | Acc: 84.98%\n",
      "Train Epoch [100/100] Batch [60/782] Loss: 0.2507 | Acc: 85.08%\n",
      "Train Epoch [100/100] Batch [61/782] Loss: 0.5793 | Acc: 84.99%\n",
      "Train Epoch [100/100] Batch [62/782] Loss: 0.3934 | Acc: 84.95%\n",
      "Train Epoch [100/100] Batch [63/782] Loss: 0.3611 | Acc: 84.95%\n",
      "Train Epoch [100/100] Batch [64/782] Loss: 0.3126 | Acc: 85.03%\n",
      "Train Epoch [100/100] Batch [65/782] Loss: 0.4023 | Acc: 85.07%\n",
      "Train Epoch [100/100] Batch [66/782] Loss: 0.4428 | Acc: 85.06%\n",
      "Train Epoch [100/100] Batch [67/782] Loss: 0.2472 | Acc: 85.14%\n",
      "Train Epoch [100/100] Batch [68/782] Loss: 0.3899 | Acc: 85.16%\n",
      "Train Epoch [100/100] Batch [69/782] Loss: 0.3603 | Acc: 85.19%\n",
      "Train Epoch [100/100] Batch [70/782] Loss: 0.4320 | Acc: 85.16%\n",
      "Train Epoch [100/100] Batch [71/782] Loss: 0.6106 | Acc: 85.01%\n",
      "Train Epoch [100/100] Batch [72/782] Loss: 0.2026 | Acc: 85.07%\n",
      "Train Epoch [100/100] Batch [73/782] Loss: 0.3484 | Acc: 85.10%\n",
      "Train Epoch [100/100] Batch [74/782] Loss: 0.4414 | Acc: 85.11%\n",
      "Train Epoch [100/100] Batch [75/782] Loss: 0.4775 | Acc: 85.10%\n",
      "Train Epoch [100/100] Batch [76/782] Loss: 0.4280 | Acc: 85.05%\n",
      "Train Epoch [100/100] Batch [77/782] Loss: 0.4297 | Acc: 85.13%\n",
      "Train Epoch [100/100] Batch [78/782] Loss: 0.3929 | Acc: 85.14%\n",
      "Train Epoch [100/100] Batch [79/782] Loss: 0.3421 | Acc: 85.15%\n",
      "Train Epoch [100/100] Batch [80/782] Loss: 0.4819 | Acc: 85.08%\n",
      "Train Epoch [100/100] Batch [81/782] Loss: 0.5624 | Acc: 84.99%\n",
      "Train Epoch [100/100] Batch [82/782] Loss: 0.4798 | Acc: 85.00%\n",
      "Train Epoch [100/100] Batch [83/782] Loss: 0.4028 | Acc: 85.03%\n",
      "Train Epoch [100/100] Batch [84/782] Loss: 0.2443 | Acc: 85.14%\n",
      "Train Epoch [100/100] Batch [85/782] Loss: 0.3537 | Acc: 85.18%\n",
      "Train Epoch [100/100] Batch [86/782] Loss: 0.3087 | Acc: 85.27%\n",
      "Train Epoch [100/100] Batch [87/782] Loss: 0.3920 | Acc: 85.27%\n",
      "Train Epoch [100/100] Batch [88/782] Loss: 0.3490 | Acc: 85.26%\n",
      "Train Epoch [100/100] Batch [89/782] Loss: 0.2218 | Acc: 85.34%\n",
      "Train Epoch [100/100] Batch [90/782] Loss: 0.2783 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [91/782] Loss: 0.6101 | Acc: 85.27%\n",
      "Train Epoch [100/100] Batch [92/782] Loss: 0.2411 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [93/782] Loss: 0.4375 | Acc: 85.33%\n",
      "Train Epoch [100/100] Batch [94/782] Loss: 0.3004 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [95/782] Loss: 0.4932 | Acc: 85.28%\n",
      "Train Epoch [100/100] Batch [96/782] Loss: 0.2999 | Acc: 85.32%\n",
      "Train Epoch [100/100] Batch [97/782] Loss: 0.4350 | Acc: 85.29%\n",
      "Train Epoch [100/100] Batch [98/782] Loss: 0.3823 | Acc: 85.33%\n",
      "Train Epoch [100/100] Batch [99/782] Loss: 0.5255 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [100/782] Loss: 0.5063 | Acc: 85.25%\n",
      "Train Epoch [100/100] Batch [101/782] Loss: 0.4545 | Acc: 85.18%\n",
      "Train Epoch [100/100] Batch [102/782] Loss: 0.5569 | Acc: 85.09%\n",
      "Train Epoch [100/100] Batch [103/782] Loss: 0.3193 | Acc: 85.13%\n",
      "Train Epoch [100/100] Batch [104/782] Loss: 0.4456 | Acc: 85.11%\n",
      "Train Epoch [100/100] Batch [105/782] Loss: 0.2580 | Acc: 85.16%\n",
      "Train Epoch [100/100] Batch [106/782] Loss: 0.2508 | Acc: 85.24%\n",
      "Train Epoch [100/100] Batch [107/782] Loss: 0.3063 | Acc: 85.28%\n",
      "Train Epoch [100/100] Batch [108/782] Loss: 0.3349 | Acc: 85.29%\n",
      "Train Epoch [100/100] Batch [109/782] Loss: 0.3893 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [110/782] Loss: 0.3938 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [111/782] Loss: 0.3481 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [112/782] Loss: 0.5762 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [113/782] Loss: 0.4669 | Acc: 85.34%\n",
      "Train Epoch [100/100] Batch [114/782] Loss: 0.3477 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [115/782] Loss: 0.3186 | Acc: 85.37%\n",
      "Train Epoch [100/100] Batch [116/782] Loss: 0.4976 | Acc: 85.32%\n",
      "Train Epoch [100/100] Batch [117/782] Loss: 0.2975 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [118/782] Loss: 0.3981 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [119/782] Loss: 0.4009 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [120/782] Loss: 0.3586 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [121/782] Loss: 0.6159 | Acc: 85.30%\n",
      "Train Epoch [100/100] Batch [122/782] Loss: 0.5600 | Acc: 85.30%\n",
      "Train Epoch [100/100] Batch [123/782] Loss: 0.4548 | Acc: 85.25%\n",
      "Train Epoch [100/100] Batch [124/782] Loss: 0.3854 | Acc: 85.29%\n",
      "Train Epoch [100/100] Batch [125/782] Loss: 0.3040 | Acc: 85.34%\n",
      "Train Epoch [100/100] Batch [126/782] Loss: 0.4346 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [127/782] Loss: 0.4152 | Acc: 85.31%\n",
      "Train Epoch [100/100] Batch [128/782] Loss: 0.3693 | Acc: 85.34%\n",
      "Train Epoch [100/100] Batch [129/782] Loss: 0.3995 | Acc: 85.36%\n",
      "Train Epoch [100/100] Batch [130/782] Loss: 0.3744 | Acc: 85.38%\n",
      "Train Epoch [100/100] Batch [131/782] Loss: 0.3875 | Acc: 85.39%\n",
      "Train Epoch [100/100] Batch [132/782] Loss: 0.4523 | Acc: 85.39%\n",
      "Train Epoch [100/100] Batch [133/782] Loss: 0.4226 | Acc: 85.35%\n",
      "Train Epoch [100/100] Batch [134/782] Loss: 0.3211 | Acc: 85.38%\n",
      "Train Epoch [100/100] Batch [135/782] Loss: 0.3147 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [136/782] Loss: 0.2343 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [137/782] Loss: 0.3667 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [138/782] Loss: 0.2599 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [139/782] Loss: 0.3931 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [140/782] Loss: 0.4436 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [141/782] Loss: 0.3396 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [142/782] Loss: 0.4583 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [143/782] Loss: 0.3935 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [144/782] Loss: 0.5517 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [145/782] Loss: 0.3135 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [146/782] Loss: 0.5816 | Acc: 85.39%\n",
      "Train Epoch [100/100] Batch [147/782] Loss: 0.3010 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [148/782] Loss: 0.3825 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [149/782] Loss: 0.2665 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [150/782] Loss: 0.3393 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [151/782] Loss: 0.3322 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [152/782] Loss: 0.3261 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [153/782] Loss: 0.3536 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [154/782] Loss: 0.3909 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [155/782] Loss: 0.4549 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [156/782] Loss: 0.3345 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [157/782] Loss: 0.4279 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [158/782] Loss: 0.3992 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [159/782] Loss: 0.4265 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [160/782] Loss: 0.2977 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [161/782] Loss: 0.5034 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [162/782] Loss: 0.5110 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [163/782] Loss: 0.6898 | Acc: 85.41%\n",
      "Train Epoch [100/100] Batch [164/782] Loss: 0.2738 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [165/782] Loss: 0.4829 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [166/782] Loss: 0.4573 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [167/782] Loss: 0.2961 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [168/782] Loss: 0.3735 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [169/782] Loss: 0.2670 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [170/782] Loss: 0.2523 | Acc: 85.61%\n",
      "Train Epoch [100/100] Batch [171/782] Loss: 0.5353 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [172/782] Loss: 0.3572 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [173/782] Loss: 0.4757 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [174/782] Loss: 0.6206 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [175/782] Loss: 0.2613 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [176/782] Loss: 0.4139 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [177/782] Loss: 0.6329 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [178/782] Loss: 0.2974 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [179/782] Loss: 0.3016 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [180/782] Loss: 0.3363 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [181/782] Loss: 0.5162 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [182/782] Loss: 0.4339 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [183/782] Loss: 0.4303 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [184/782] Loss: 0.4725 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [185/782] Loss: 0.4677 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [186/782] Loss: 0.3997 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [187/782] Loss: 0.3063 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [188/782] Loss: 0.2788 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [189/782] Loss: 0.5415 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [190/782] Loss: 0.3158 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [191/782] Loss: 0.4464 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [192/782] Loss: 0.3534 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [193/782] Loss: 0.4722 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [194/782] Loss: 0.3829 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [195/782] Loss: 0.5878 | Acc: 85.40%\n",
      "Train Epoch [100/100] Batch [196/782] Loss: 0.4008 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [197/782] Loss: 0.3612 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [198/782] Loss: 0.2755 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [199/782] Loss: 0.3669 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [200/782] Loss: 0.3281 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [201/782] Loss: 0.4023 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [202/782] Loss: 0.4347 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [203/782] Loss: 0.3353 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [204/782] Loss: 0.4977 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [205/782] Loss: 0.3162 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [206/782] Loss: 0.4606 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [207/782] Loss: 0.6512 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [208/782] Loss: 0.4602 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [209/782] Loss: 0.3468 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [210/782] Loss: 0.3879 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [211/782] Loss: 0.2651 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [212/782] Loss: 0.3470 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [213/782] Loss: 0.5184 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [214/782] Loss: 0.3451 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [215/782] Loss: 0.3007 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [216/782] Loss: 0.4163 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [217/782] Loss: 0.4697 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [218/782] Loss: 0.3243 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [219/782] Loss: 0.4300 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [220/782] Loss: 0.4070 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [221/782] Loss: 0.3306 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [222/782] Loss: 0.5984 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [223/782] Loss: 0.5493 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [224/782] Loss: 0.2606 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [225/782] Loss: 0.5328 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [226/782] Loss: 0.4448 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [227/782] Loss: 0.2811 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [228/782] Loss: 0.1921 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [229/782] Loss: 0.1915 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [230/782] Loss: 0.4190 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [231/782] Loss: 0.3921 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [232/782] Loss: 0.4395 | Acc: 85.61%\n",
      "Train Epoch [100/100] Batch [233/782] Loss: 0.3413 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [234/782] Loss: 0.4044 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [235/782] Loss: 0.4248 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [236/782] Loss: 0.4233 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [237/782] Loss: 0.3579 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [238/782] Loss: 0.3814 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [239/782] Loss: 0.5531 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [240/782] Loss: 0.2322 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [241/782] Loss: 0.2268 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [242/782] Loss: 0.3379 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [243/782] Loss: 0.4928 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [244/782] Loss: 0.4418 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [245/782] Loss: 0.2851 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [246/782] Loss: 0.3286 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [247/782] Loss: 0.3281 | Acc: 85.70%\n",
      "Train Epoch [100/100] Batch [248/782] Loss: 0.3477 | Acc: 85.70%\n",
      "Train Epoch [100/100] Batch [249/782] Loss: 0.4402 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [250/782] Loss: 0.3898 | Acc: 85.69%\n",
      "Train Epoch [100/100] Batch [251/782] Loss: 0.4119 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [252/782] Loss: 0.2868 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [253/782] Loss: 0.4008 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [254/782] Loss: 0.4628 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [255/782] Loss: 0.5624 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [256/782] Loss: 0.2998 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [257/782] Loss: 0.5727 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [258/782] Loss: 0.3159 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [259/782] Loss: 0.4157 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [260/782] Loss: 0.3687 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [261/782] Loss: 0.3149 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [262/782] Loss: 0.4694 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [263/782] Loss: 0.4141 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [264/782] Loss: 0.5056 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [265/782] Loss: 0.2850 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [266/782] Loss: 0.3727 | Acc: 85.70%\n",
      "Train Epoch [100/100] Batch [267/782] Loss: 0.2290 | Acc: 85.71%\n",
      "Train Epoch [100/100] Batch [268/782] Loss: 0.4393 | Acc: 85.71%\n",
      "Train Epoch [100/100] Batch [269/782] Loss: 0.4924 | Acc: 85.72%\n",
      "Train Epoch [100/100] Batch [270/782] Loss: 0.4252 | Acc: 85.70%\n",
      "Train Epoch [100/100] Batch [271/782] Loss: 0.5038 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [272/782] Loss: 0.3802 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [273/782] Loss: 0.4379 | Acc: 85.67%\n",
      "Train Epoch [100/100] Batch [274/782] Loss: 0.4081 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [275/782] Loss: 0.5833 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [276/782] Loss: 0.2757 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [277/782] Loss: 0.3817 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [278/782] Loss: 0.3032 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [279/782] Loss: 0.4172 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [280/782] Loss: 0.4575 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [281/782] Loss: 0.3734 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [282/782] Loss: 0.2641 | Acc: 85.65%\n",
      "Train Epoch [100/100] Batch [283/782] Loss: 0.3166 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [284/782] Loss: 0.2483 | Acc: 85.68%\n",
      "Train Epoch [100/100] Batch [285/782] Loss: 0.2993 | Acc: 85.69%\n",
      "Train Epoch [100/100] Batch [286/782] Loss: 0.5598 | Acc: 85.66%\n",
      "Train Epoch [100/100] Batch [287/782] Loss: 0.4344 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [288/782] Loss: 0.4931 | Acc: 85.61%\n",
      "Train Epoch [100/100] Batch [289/782] Loss: 0.3961 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [290/782] Loss: 0.4338 | Acc: 85.61%\n",
      "Train Epoch [100/100] Batch [291/782] Loss: 0.2599 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [292/782] Loss: 0.3798 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [293/782] Loss: 0.3490 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [294/782] Loss: 0.3205 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [295/782] Loss: 0.3917 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [296/782] Loss: 0.3247 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [297/782] Loss: 0.4176 | Acc: 85.63%\n",
      "Train Epoch [100/100] Batch [298/782] Loss: 0.3344 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [299/782] Loss: 0.4837 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [300/782] Loss: 0.4192 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [301/782] Loss: 0.3242 | Acc: 85.64%\n",
      "Train Epoch [100/100] Batch [302/782] Loss: 0.4853 | Acc: 85.62%\n",
      "Train Epoch [100/100] Batch [303/782] Loss: 0.5294 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [304/782] Loss: 0.4221 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [305/782] Loss: 0.4757 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [306/782] Loss: 0.3513 | Acc: 85.60%\n",
      "Train Epoch [100/100] Batch [307/782] Loss: 0.6703 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [308/782] Loss: 0.5734 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [309/782] Loss: 0.7145 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [310/782] Loss: 0.3080 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [311/782] Loss: 0.3273 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [312/782] Loss: 0.3977 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [313/782] Loss: 0.3509 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [314/782] Loss: 0.3482 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [315/782] Loss: 0.2984 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [316/782] Loss: 0.5146 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [317/782] Loss: 0.2607 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [318/782] Loss: 0.5882 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [319/782] Loss: 0.5840 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [320/782] Loss: 0.2182 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [321/782] Loss: 0.6127 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [322/782] Loss: 0.3494 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [323/782] Loss: 0.5290 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [324/782] Loss: 0.3814 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [325/782] Loss: 0.2774 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [326/782] Loss: 0.3717 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [327/782] Loss: 0.4256 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [328/782] Loss: 0.4645 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [329/782] Loss: 0.4682 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [330/782] Loss: 0.3434 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [331/782] Loss: 0.3143 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [332/782] Loss: 0.2799 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [333/782] Loss: 0.4076 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [334/782] Loss: 0.3525 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [335/782] Loss: 0.4643 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [336/782] Loss: 0.5557 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [337/782] Loss: 0.3746 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [338/782] Loss: 0.4373 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [339/782] Loss: 0.4481 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [340/782] Loss: 0.6684 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [341/782] Loss: 0.2741 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [342/782] Loss: 0.3885 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [343/782] Loss: 0.2507 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [344/782] Loss: 0.3208 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [345/782] Loss: 0.2867 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [346/782] Loss: 0.3138 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [347/782] Loss: 0.3781 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [348/782] Loss: 0.4476 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [349/782] Loss: 0.3565 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [350/782] Loss: 0.3518 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [351/782] Loss: 0.4446 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [352/782] Loss: 0.4185 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [353/782] Loss: 0.4957 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [354/782] Loss: 0.4372 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [355/782] Loss: 0.3538 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [356/782] Loss: 0.3764 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [357/782] Loss: 0.2853 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [358/782] Loss: 0.4405 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [359/782] Loss: 0.3162 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [360/782] Loss: 0.3436 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [361/782] Loss: 0.3651 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [362/782] Loss: 0.4401 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [363/782] Loss: 0.5194 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [364/782] Loss: 0.3314 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [365/782] Loss: 0.4240 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [366/782] Loss: 0.4483 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [367/782] Loss: 0.4581 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [368/782] Loss: 0.3050 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [369/782] Loss: 0.3432 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [370/782] Loss: 0.3349 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [371/782] Loss: 0.3349 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [372/782] Loss: 0.4046 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [373/782] Loss: 0.4424 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [374/782] Loss: 0.2558 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [375/782] Loss: 0.4326 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [376/782] Loss: 0.4621 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [377/782] Loss: 0.2879 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [378/782] Loss: 0.2474 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [379/782] Loss: 0.3312 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [380/782] Loss: 0.3086 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [381/782] Loss: 0.4800 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [382/782] Loss: 0.3606 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [383/782] Loss: 0.4969 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [384/782] Loss: 0.5021 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [385/782] Loss: 0.3264 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [386/782] Loss: 0.2884 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [387/782] Loss: 0.4633 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [388/782] Loss: 0.5762 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [389/782] Loss: 0.4511 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [390/782] Loss: 0.3568 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [391/782] Loss: 0.2664 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [392/782] Loss: 0.3908 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [393/782] Loss: 0.3491 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [394/782] Loss: 0.4818 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [395/782] Loss: 0.4740 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [396/782] Loss: 0.4354 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [397/782] Loss: 0.4320 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [398/782] Loss: 0.3533 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [399/782] Loss: 0.2476 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [400/782] Loss: 0.6067 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [401/782] Loss: 0.4067 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [402/782] Loss: 0.3225 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [403/782] Loss: 0.3916 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [404/782] Loss: 0.3614 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [405/782] Loss: 0.5592 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [406/782] Loss: 0.4985 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [407/782] Loss: 0.2722 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [408/782] Loss: 0.4145 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [409/782] Loss: 0.4480 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [410/782] Loss: 0.3807 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [411/782] Loss: 0.5770 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [412/782] Loss: 0.2708 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [413/782] Loss: 0.5051 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [414/782] Loss: 0.3606 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [415/782] Loss: 0.3312 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [416/782] Loss: 0.4234 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [417/782] Loss: 0.5250 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [418/782] Loss: 0.3973 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [419/782] Loss: 0.4173 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [420/782] Loss: 0.5305 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [421/782] Loss: 0.3898 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [422/782] Loss: 0.3541 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [423/782] Loss: 0.4687 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [424/782] Loss: 0.5038 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [425/782] Loss: 0.3736 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [426/782] Loss: 0.4755 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [427/782] Loss: 0.4179 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [428/782] Loss: 0.3497 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [429/782] Loss: 0.5347 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [430/782] Loss: 0.6201 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [431/782] Loss: 0.1990 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [432/782] Loss: 0.3063 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [433/782] Loss: 0.3562 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [434/782] Loss: 0.4578 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [435/782] Loss: 0.2742 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [436/782] Loss: 0.5196 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [437/782] Loss: 0.4999 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [438/782] Loss: 0.3443 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [439/782] Loss: 0.5211 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [440/782] Loss: 0.4551 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [441/782] Loss: 0.3572 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [442/782] Loss: 0.4487 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [443/782] Loss: 0.2270 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [444/782] Loss: 0.4429 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [445/782] Loss: 0.4247 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [446/782] Loss: 0.4698 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [447/782] Loss: 0.3788 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [448/782] Loss: 0.2455 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [449/782] Loss: 0.3915 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [450/782] Loss: 0.4203 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [451/782] Loss: 0.3880 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [452/782] Loss: 0.3766 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [453/782] Loss: 0.3986 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [454/782] Loss: 0.5765 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [455/782] Loss: 0.4007 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [456/782] Loss: 0.2561 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [457/782] Loss: 0.3135 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [458/782] Loss: 0.3938 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [459/782] Loss: 0.3920 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [460/782] Loss: 0.2739 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [461/782] Loss: 0.3260 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [462/782] Loss: 0.5307 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [463/782] Loss: 0.5176 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [464/782] Loss: 0.3041 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [465/782] Loss: 0.2894 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [466/782] Loss: 0.3701 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [467/782] Loss: 0.2818 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [468/782] Loss: 0.4568 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [469/782] Loss: 0.3396 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [470/782] Loss: 0.5305 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [471/782] Loss: 0.3555 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [472/782] Loss: 0.4887 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [473/782] Loss: 0.4159 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [474/782] Loss: 0.4614 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [475/782] Loss: 0.5776 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [476/782] Loss: 0.3280 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [477/782] Loss: 0.2697 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [478/782] Loss: 0.3377 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [479/782] Loss: 0.3745 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [480/782] Loss: 0.3346 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [481/782] Loss: 0.4150 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [482/782] Loss: 0.4359 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [483/782] Loss: 0.7041 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [484/782] Loss: 0.5245 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [485/782] Loss: 0.2528 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [486/782] Loss: 0.3132 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [487/782] Loss: 0.5678 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [488/782] Loss: 0.3249 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [489/782] Loss: 0.3328 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [490/782] Loss: 0.4199 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [491/782] Loss: 0.3314 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [492/782] Loss: 0.2388 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [493/782] Loss: 0.3013 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [494/782] Loss: 0.2208 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [495/782] Loss: 0.2573 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [496/782] Loss: 0.4852 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [497/782] Loss: 0.3808 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [498/782] Loss: 0.3804 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [499/782] Loss: 0.3784 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [500/782] Loss: 0.4053 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [501/782] Loss: 0.3412 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [502/782] Loss: 0.3674 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [503/782] Loss: 0.3604 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [504/782] Loss: 0.3240 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [505/782] Loss: 0.4595 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [506/782] Loss: 0.3642 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [507/782] Loss: 0.2696 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [508/782] Loss: 0.3565 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [509/782] Loss: 0.6340 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [510/782] Loss: 0.3466 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [511/782] Loss: 0.3024 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [512/782] Loss: 0.3598 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [513/782] Loss: 0.5935 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [514/782] Loss: 0.2774 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [515/782] Loss: 0.3478 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [516/782] Loss: 0.3749 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [517/782] Loss: 0.3976 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [518/782] Loss: 0.3011 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [519/782] Loss: 0.4925 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [520/782] Loss: 0.3861 | Acc: 85.59%\n",
      "Train Epoch [100/100] Batch [521/782] Loss: 0.5362 | Acc: 85.58%\n",
      "Train Epoch [100/100] Batch [522/782] Loss: 0.4693 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [523/782] Loss: 0.5380 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [524/782] Loss: 0.2943 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [525/782] Loss: 0.4604 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [526/782] Loss: 0.6168 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [527/782] Loss: 0.3440 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [528/782] Loss: 0.3328 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [529/782] Loss: 0.3821 | Acc: 85.57%\n",
      "Train Epoch [100/100] Batch [530/782] Loss: 0.5240 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [531/782] Loss: 0.3745 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [532/782] Loss: 0.5820 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [533/782] Loss: 0.5665 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [534/782] Loss: 0.4372 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [535/782] Loss: 0.2679 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [536/782] Loss: 0.5619 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [537/782] Loss: 0.3527 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [538/782] Loss: 0.5849 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [539/782] Loss: 0.4331 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [540/782] Loss: 0.4175 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [541/782] Loss: 0.4000 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [542/782] Loss: 0.2870 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [543/782] Loss: 0.3209 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [544/782] Loss: 0.3706 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [545/782] Loss: 0.3923 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [546/782] Loss: 0.4356 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [547/782] Loss: 0.3894 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [548/782] Loss: 0.3862 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [549/782] Loss: 0.5023 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [550/782] Loss: 0.3625 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [551/782] Loss: 0.4122 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [552/782] Loss: 0.4272 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [553/782] Loss: 0.3106 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [554/782] Loss: 0.4070 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [555/782] Loss: 0.3426 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [556/782] Loss: 0.5037 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [557/782] Loss: 0.5295 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [558/782] Loss: 0.3189 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [559/782] Loss: 0.2893 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [560/782] Loss: 0.4308 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [561/782] Loss: 0.2868 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [562/782] Loss: 0.4127 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [563/782] Loss: 0.3798 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [564/782] Loss: 0.4038 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [565/782] Loss: 0.3114 | Acc: 85.56%\n",
      "Train Epoch [100/100] Batch [566/782] Loss: 0.4694 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [567/782] Loss: 0.4891 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [568/782] Loss: 0.4631 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [569/782] Loss: 0.3936 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [570/782] Loss: 0.3783 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [571/782] Loss: 0.3469 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [572/782] Loss: 0.4029 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [573/782] Loss: 0.3923 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [574/782] Loss: 0.4758 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [575/782] Loss: 0.4295 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [576/782] Loss: 0.4417 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [577/782] Loss: 0.3401 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [578/782] Loss: 0.5323 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [579/782] Loss: 0.5884 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [580/782] Loss: 0.3688 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [581/782] Loss: 0.2687 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [582/782] Loss: 0.3891 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [583/782] Loss: 0.2731 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [584/782] Loss: 0.2340 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [585/782] Loss: 0.4739 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [586/782] Loss: 0.2700 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [587/782] Loss: 0.3932 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [588/782] Loss: 0.3855 | Acc: 85.55%\n",
      "Train Epoch [100/100] Batch [589/782] Loss: 0.3894 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [590/782] Loss: 0.5369 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [591/782] Loss: 0.4435 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [592/782] Loss: 0.3883 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [593/782] Loss: 0.3919 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [594/782] Loss: 0.4666 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [595/782] Loss: 0.4693 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [596/782] Loss: 0.4688 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [597/782] Loss: 0.3172 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [598/782] Loss: 0.3190 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [599/782] Loss: 0.6644 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [600/782] Loss: 0.3793 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [601/782] Loss: 0.4288 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [602/782] Loss: 0.5073 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [603/782] Loss: 0.5580 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [604/782] Loss: 0.3217 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [605/782] Loss: 0.3011 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [606/782] Loss: 0.4343 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [607/782] Loss: 0.2618 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [608/782] Loss: 0.4297 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [609/782] Loss: 0.3490 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [610/782] Loss: 0.2552 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [611/782] Loss: 0.6508 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [612/782] Loss: 0.4329 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [613/782] Loss: 0.4586 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [614/782] Loss: 0.3901 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [615/782] Loss: 0.4205 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [616/782] Loss: 0.4286 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [617/782] Loss: 0.3171 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [618/782] Loss: 0.5330 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [619/782] Loss: 0.4900 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [620/782] Loss: 0.4124 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [621/782] Loss: 0.3419 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [622/782] Loss: 0.5564 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [623/782] Loss: 0.4191 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [624/782] Loss: 0.4685 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [625/782] Loss: 0.4800 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [626/782] Loss: 0.3367 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [627/782] Loss: 0.4452 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [628/782] Loss: 0.4046 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [629/782] Loss: 0.4481 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [630/782] Loss: 0.5155 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [631/782] Loss: 0.5597 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [632/782] Loss: 0.2590 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [633/782] Loss: 0.4738 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [634/782] Loss: 0.3150 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [635/782] Loss: 0.2948 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [636/782] Loss: 0.4178 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [637/782] Loss: 0.4228 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [638/782] Loss: 0.4887 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [639/782] Loss: 0.4014 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [640/782] Loss: 0.4693 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [641/782] Loss: 0.3078 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [642/782] Loss: 0.4472 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [643/782] Loss: 0.2970 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [644/782] Loss: 0.3066 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [645/782] Loss: 0.4537 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [646/782] Loss: 0.2228 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [647/782] Loss: 0.3071 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [648/782] Loss: 0.5006 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [649/782] Loss: 0.4829 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [650/782] Loss: 0.4557 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [651/782] Loss: 0.4329 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [652/782] Loss: 0.2515 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [653/782] Loss: 0.4356 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [654/782] Loss: 0.4277 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [655/782] Loss: 0.2438 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [656/782] Loss: 0.3427 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [657/782] Loss: 0.2613 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [658/782] Loss: 0.2979 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [659/782] Loss: 0.4313 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [660/782] Loss: 0.5666 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [661/782] Loss: 0.3792 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [662/782] Loss: 0.3476 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [663/782] Loss: 0.3344 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [664/782] Loss: 0.3243 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [665/782] Loss: 0.3264 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [666/782] Loss: 0.2422 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [667/782] Loss: 0.3069 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [668/782] Loss: 0.4739 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [669/782] Loss: 0.2913 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [670/782] Loss: 0.2978 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [671/782] Loss: 0.4465 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [672/782] Loss: 0.3514 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [673/782] Loss: 0.6767 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [674/782] Loss: 0.5357 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [675/782] Loss: 0.3938 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [676/782] Loss: 0.2701 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [677/782] Loss: 0.2364 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [678/782] Loss: 0.3660 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [679/782] Loss: 0.3576 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [680/782] Loss: 0.6243 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [681/782] Loss: 0.4443 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [682/782] Loss: 0.4319 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [683/782] Loss: 0.4491 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [684/782] Loss: 0.4537 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [685/782] Loss: 0.4641 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [686/782] Loss: 0.3382 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [687/782] Loss: 0.4767 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [688/782] Loss: 0.5550 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [689/782] Loss: 0.4634 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [690/782] Loss: 0.1986 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [691/782] Loss: 0.4711 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [692/782] Loss: 0.5475 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [693/782] Loss: 0.4641 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [694/782] Loss: 0.6059 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [695/782] Loss: 0.3313 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [696/782] Loss: 0.4934 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [697/782] Loss: 0.3695 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [698/782] Loss: 0.2611 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [699/782] Loss: 0.3427 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [700/782] Loss: 0.4073 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [701/782] Loss: 0.3191 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [702/782] Loss: 0.3722 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [703/782] Loss: 0.4410 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [704/782] Loss: 0.3804 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [705/782] Loss: 0.5343 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [706/782] Loss: 0.5036 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [707/782] Loss: 0.3043 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [708/782] Loss: 0.3117 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [709/782] Loss: 0.2966 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [710/782] Loss: 0.5647 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [711/782] Loss: 0.3784 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [712/782] Loss: 0.4697 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [713/782] Loss: 0.3573 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [714/782] Loss: 0.3728 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [715/782] Loss: 0.3830 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [716/782] Loss: 0.3727 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [717/782] Loss: 0.4942 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [718/782] Loss: 0.4892 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [719/782] Loss: 0.4533 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [720/782] Loss: 0.3743 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [721/782] Loss: 0.4570 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [722/782] Loss: 0.6203 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [723/782] Loss: 0.4575 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [724/782] Loss: 0.3323 | Acc: 85.42%\n",
      "Train Epoch [100/100] Batch [725/782] Loss: 0.2020 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [726/782] Loss: 0.3533 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [727/782] Loss: 0.3026 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [728/782] Loss: 0.4639 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [729/782] Loss: 0.4210 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [730/782] Loss: 0.3519 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [731/782] Loss: 0.4182 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [732/782] Loss: 0.3255 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [733/782] Loss: 0.4793 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [734/782] Loss: 0.3688 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [735/782] Loss: 0.4267 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [736/782] Loss: 0.4133 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [737/782] Loss: 0.3260 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [738/782] Loss: 0.5642 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [739/782] Loss: 0.6106 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [740/782] Loss: 0.5029 | Acc: 85.43%\n",
      "Train Epoch [100/100] Batch [741/782] Loss: 0.2254 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [742/782] Loss: 0.3131 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [743/782] Loss: 0.4883 | Acc: 85.44%\n",
      "Train Epoch [100/100] Batch [744/782] Loss: 0.3638 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [745/782] Loss: 0.3029 | Acc: 85.45%\n",
      "Train Epoch [100/100] Batch [746/782] Loss: 0.1782 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [747/782] Loss: 0.4592 | Acc: 85.46%\n",
      "Train Epoch [100/100] Batch [748/782] Loss: 0.2245 | Acc: 85.47%\n",
      "Train Epoch [100/100] Batch [749/782] Loss: 0.3139 | Acc: 85.48%\n",
      "Train Epoch [100/100] Batch [750/782] Loss: 0.2534 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [751/782] Loss: 0.4924 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [752/782] Loss: 0.3475 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [753/782] Loss: 0.4946 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [754/782] Loss: 0.5255 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [755/782] Loss: 0.2963 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [756/782] Loss: 0.4371 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [757/782] Loss: 0.3760 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [758/782] Loss: 0.4290 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [759/782] Loss: 0.4223 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [760/782] Loss: 0.4351 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [761/782] Loss: 0.3418 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [762/782] Loss: 0.3408 | Acc: 85.49%\n",
      "Train Epoch [100/100] Batch [763/782] Loss: 0.3331 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [764/782] Loss: 0.2845 | Acc: 85.50%\n",
      "Train Epoch [100/100] Batch [765/782] Loss: 0.2927 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [766/782] Loss: 0.2943 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [767/782] Loss: 0.2204 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [768/782] Loss: 0.5646 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [769/782] Loss: 0.4289 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [770/782] Loss: 0.3270 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [771/782] Loss: 0.3087 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [772/782] Loss: 0.5897 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [773/782] Loss: 0.4435 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [774/782] Loss: 0.3850 | Acc: 85.51%\n",
      "Train Epoch [100/100] Batch [775/782] Loss: 0.3896 | Acc: 85.52%\n",
      "Train Epoch [100/100] Batch [776/782] Loss: 0.2793 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [777/782] Loss: 0.2277 | Acc: 85.53%\n",
      "Train Epoch [100/100] Batch [778/782] Loss: 0.3185 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [779/782] Loss: 0.3251 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [780/782] Loss: 0.3304 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [781/782] Loss: 0.3681 | Acc: 85.54%\n",
      "Train Epoch [100/100] Batch [782/782] Loss: 0.3596 | Acc: 85.54%\n",
      "Epoch 100 completed in 30.73s.\n",
      "Test Epoch [100/100] Loss: 1.0234 | Acc: 72.11% | Inference Time: 8.56s\n",
      "Epoch 100 results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "# 保存模型的最佳状态\n",
    "checkpoint_path = \"./Performer ReLu_lr_1e-3_dropout_0.3_checkpoint.pth\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "    start_epoch = 0\n",
    "    best_acc = 0\n",
    "# 创建或打开 CSV 文件\n",
    "csv_file = \"Performer ReLu_lr_1e-3_dropout_0.3.csv\"\n",
    "write_header = not os.path.exists(csv_file)\n",
    "\n",
    "with open(csv_file, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    if write_header:\n",
    "        writer.writerow([\"Epoch\", \"Train Time (s)\", \"Inference Time (s)\", \"Accuracy (%)\"])\n",
    "\n",
    "    # 开始训练\n",
    "    train_times = []\n",
    "    inference_times = []\n",
    "    accuracies = []\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_time, train_acc = train(epoch)\n",
    "        train_times.append(train_time)\n",
    "\n",
    "        acc, inference_time = test(epoch)\n",
    "        accuracies.append(acc)\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if acc > best_acc:\n",
    "            print(\"Saving best model...\")\n",
    "            state = {\n",
    "                'model': net.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            torch.save(state, checkpoint_path)\n",
    "            best_acc = acc\n",
    "\n",
    "        writer.writerow([epoch+1, train_time, inference_time, acc])\n",
    "        f.flush()\n",
    "        print(f\"Epoch {epoch+1} results saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb5aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Performer ReLu_lr_1e-3_dropout_0.3_bonus_CIFAR.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Performer ReLu_lr_1e-3_dropout_0.3_bonus_CIFAR.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract data for plotting\n",
    "epochs = data['Epoch']\n",
    "train_times = data['Train Time (s)']\n",
    "inference_times = data['Inference Time (s)']\n",
    "accuracies = data['Accuracy (%)']\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training time per epoch\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, train_times, marker='o', label='Train Time')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.title(\"Training Time per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Inference time per epoch\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, inference_times, marker='o', color='orange', label='Inference Time')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.title(\"Inference Time per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Test accuracy per epoch\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Test Accuracy per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Finalize and save the figure\n",
    "plt.tight_layout()\n",
    "output_path = \"Performer ReLu_lr_1e-3_dropout_0.3_bonus_CIFAR.png\"\n",
    "plt.savefig(output_path)\n",
    "plt.show()\n",
    "\n",
    "output_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
